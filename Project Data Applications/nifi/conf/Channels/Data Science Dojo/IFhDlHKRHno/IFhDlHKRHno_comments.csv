author,updated_at,like_count,text,public
@superfreiheit1,2023-09-22T15:12:01Z,0,This fuction is no longer available? createMultiFolds,True
@annamalandrino6938,2023-07-17T12:44:08Z,0,"Hi! When executing the following function  rpart.cv.1 <- train(Label~., data = train.tokens.df, method = ""rpart"",                      trControl = cv.cntrl, tuneLength = 7)  I get the following error message:  Something is wrong; all the Accuracy metric values are missing:     Accuracy       Kappa      Min.   : NA   Min.   : NA    1st Qu.: NA   1st Qu.: NA    Median : NA   Median : NA    Mean   :NaN   Mean   :NaN    3rd Qu.: NA   3rd Qu.: NA    Max.   : NA   Max.   : NA    NA's   :7     NA's   :7     Error: Stopping In addition: Warning message: In nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,  :   There were missing values in resampled performance measures.  Can you please help me? Anna",True
@jameswars14,2021-08-03T18:08:03Z,1,"> train.token.df <- cbind(labels = train$PatientNotes, data.frame(train.tokens.dfm)) Warning message: 'as.data.frame.dfm' is deprecated. Use 'convert(x, to = ""data.frame"")' instead. See help(""Deprecated"")   Any advice on how to resolve this?",True
@sakhawat3003,2021-07-13T01:07:56Z,1,"Your videos and explanations have ""lots of goodness"" in them. I have got an accuracy level of 94.5%. My 2-core pc ran for over 9 mins. I have one question though: my pc has 2 cores and 2 threads, so what value should I put into the ""spec"" argument of makeCluster function? I have put a value of 2. Thanks again for such wonderful explanatory videos.",True
@dominica1708,2021-03-16T07:33:13Z,1,"Great Series! I follow along using a different data set which is twitter data containing hate speech. The issue for me is the referencing of users in the tweets. So I get a lot of ""@user_xyz"" and my feature data with labels contains more than 25,000 variables. So the question for me is now: Do I leave every ""@user_xyz"" reference out (and if so, how?) of my data or do I just leave them be?",True
@baruchschwartz819,2021-01-18T20:08:09Z,1,"Just tried watching a presentation by the great Max Kuhn, creator of the carat package... Dave, you made it much easier!",True
@janlauzy1404,2020-11-28T10:51:09Z,2,"For dynamic core count: library(doSNOW) library(parallel) cores=detectCores() cl <- makeCluster(cores[1]-1, type = ""SOCK"") #total cores - 1 to avoid overloading registerDoSNOW(cl)",True
@aksbehera1,2020-08-05T06:44:22Z,0,"Facing issues since my dfm is quite large...it is throwing the follwing error  Error in asMethod(object) :    Cholmod error 'problem too large' at file ../Core/cholmod_dense.c, line 105  Can anyone help me out with a way around this error?",True
@alishaw9999,2020-06-16T11:09:44Z,2,"Hello David, indeed a great tutorial but can u help fix the data frame command as i stuck at that stage",True
@sk93359,2020-06-09T18:15:43Z,0,Please make a video for NER Model for entity recognization  using and how to train own training data  I am waiting for your video  Thanka,True
@MJ-sx9uq,2019-12-26T10:57:21Z,0,Hi..i am having an error in rstudio..Error:Cannot allocate vector size 287.5 mb..my system config is..windows 7..Intel celeron 1.5 GHz..2gb RAM..how to avoid this error..else i found videos are really very useful and explain very well in easy language.,True
@andyspeak3917,2019-08-30T12:37:39Z,0,"Made it through all the tutorials to this point but cant go further because my dfm is far too big to convert to matrix or dataframe, and I run out of RAM, which means i can only use the analysis in the quanteda package which isnt what i want to do .  Ah well",True
@BuonMercatoTest,2019-08-18T13:30:58Z,0,"Excellent series. A problem, however. I am using RStudio on a Mac with R version 3.5.3 and I get this error:Â  > install.packages(doSNOW) Error in install.packages : object ""doSNOW"" not found is this because 3.5.3 does not yet have an updated doSNOW package available?",True
@mohammedasadi,2019-07-24T12:58:03Z,0,"I faced this issue running the last part of the code: Error in eval(predvars, data, env) : object 'Label' not found In addition: Warning messages: 1: closing unused connection 5 (computername) any idea?",True
@airychoi,2019-07-24T02:12:56Z,7,"Hi David!  when I ran this code  rpart.cv.1 <- train(Label ~ ., data = train.tokens.df, method = ""rpart"",                      trControl = cv.cntrl, tuneLength = 7) why It's error Error in terms.formula(formula, data = data) :    duplicated name 'document' in data frame using '.' What should I do to fix them?",True
@markparee99,2019-04-08T20:55:02Z,0,"A great course but, unfortunately, my middle-age Wintel computer (2 physical/4 logical cores) does not even have enough horsepower to run the first simple model ( even with the minimal number of sockets). If I establish 2 sockets,  I can't do anything else on the PC. Using 1 socket - well, what's the point? It still spins for over 9 hours!  Was wondering if anyone else has a similar problem?",True
@kristyburns2363,2019-04-03T02:04:56Z,0,It was working great to a point then some of the packages were not available and  the as.data.frame was deprecated. I never got to finish a model. Iâ€™m very disappointed ðŸ˜ž,True
@aristoskoutras7261,2019-03-22T11:59:04Z,0,"Any clues why i get 5739 variables instead of 5744 as you? kinda followed your code on this and I cant find what could cause that, maybe I am missing something silly because i started as well with 5572 records and the same proportions in splits",True
@sunil7162,2019-03-19T12:03:01Z,3,Super!!! awesome.. great learning,True
@Brown-bk4ju,2019-02-26T13:30:06Z,0,"Hi Dave awesome video, I ran this code and I get a warning message which says -""Warning messages: 1: In train.default(x, y, weights = w, ...) :   You are trying to do regression and your outcome only has two possible values Are you trying to do classification? If so, use a 2 level factor as your outcome column. 2: In nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,  :   There were missing values in resampled performance measures.""  and when I run ""rpart.cv.1"" in R, I don't see accuracy column It shows RMSE and R-squared and Mae values for the 7 results.  I understand it showing the model likely to produce the least measure of difference(error)  by using RMSE so can I use that as an alternative for accuracy?",True
@shoebmohammad926,2018-10-27T09:48:29Z,1,"Can anyone help with the below warning message that I am getting while running the code?  train.tokens.df<-cbind(Label = train$Label, as.data.frame(train.tokens.dfm)) Warning message: 'as.data.frame.dfm' is deprecated. Use 'convert(x, to ""data.frame"")' instead. See help(""Deprecated"")",True
@shoebmohammad926,2018-10-02T01:50:06Z,0,"Hi David, I am getting a following error: train.tokens.df<-cbind(Label = train$Lable, as.data.frame(train.tokens.dfm)) Warning message: 'as.data.frame.dfm' is deprecated. Use 'convert(x, to ""data.frame"")' instead. See help(""Deprecated"")",True
@srujank9241,2018-09-27T20:53:09Z,0,Enjoying your lecture series. It's a pleasure learning from you.,True
@nawang7649,2018-09-23T12:25:16Z,0,Great video! Helps a lot for my research:),True
@schinu1,2018-09-02T09:13:53Z,1,Hi Anyone got error :  Error: protect(): protection stack overflow. while running rpart 1 model. Its due to memory issue.,True
@Adi300594,2018-07-25T05:54:18Z,0,"How can we say that the model we build in this video was 94% accurate when we have not even used validation data that we created during  createDataPartition, and taking validation.df[-index]. All we did was build a model using our training data using the train function of caret package. Also, If we donot use cross-validation techniques and directly apply train function on train.df, how much will it affect our accuracy and I wanted to know if this approch of model building without using cross validation is acceptable or not. Thanks in advance.",True
@perputual_conflict,2018-07-24T20:38:14Z,1,"I am applying rpart to another dataset. I am getting this error Error in terms.formula(formula, data = data) :    duplicated name 'document' in data frame using '.' Does anyone have any idea how to resolve it?",True
@elakariayoub5333,2018-05-27T22:06:10Z,1,"is (modifiÃ©) Hello David, I learned a lot and love what you are doing and your style of teaching. this line of code doesn't work for me : ""rpart.cv.1 <- train(Label ~ ., data = train.tokens.df, method = ""rpart"",  trControl = cv.cntrl, tuneLength = 7)""  it gives me this error : "" Error in terms.formula(formula, data = data) :    nom dupliquÃ© 'Ãƒ.' dans le data frame utilisant '.' "" what can i do to fixe that ?  thanks.",True
@youyiliu7556,2018-03-25T06:48:00Z,0,Great!,True
@kimunimel,2018-03-09T02:05:38Z,0,"Thank you very much Dave for these very interesting and helpful lessons. I have a question that I would like to ask as follow.  As we all know, our data is unbalanced (86.5% ham and only 13.5% spam). So, if we train our model with this unbalanced data, I think we may have inaccurate issues. For example, if we just simply predict all messages are ham, so we may come up with 86.5% accuracy, but we are totally fail in classifying spam message. So, should we make the data balance before training our model?",True
@aakashchugh9,2018-02-10T16:41:17Z,0,Hi Dave.. I really like the way you teach and explain every function.. I just want to ask can we not use methods like SMOTE or ADASYN to deal with imbalanced data?,True
@TomerBenDavid,2018-01-19T14:23:04Z,0,This was an amazing episode! :),True
@ashokpershad,2018-01-10T17:20:37Z,0,"cl <- makeCluster(3, type = ""SOCK"") Error in makeCluster(3, type = ""SOCK"") :    could not find function ""makeCluster"". Any Suggestion David ?",True
@deepdutta8494,2017-12-29T00:31:41Z,1,"Hi David, Videos are really amazing. However, I am stuck on something. Can you please check and tell me how to get rid of this error  ---------------------------------------------------------------------------------------------------------------------------------- rpart.cv.1 <- train(Label ~ ., data=train.tokens.df, method=""rpart"",trControl=cv.cntrl, tunelength=7) Something is wrong; all the Accuracy metric values are missing:     Accuracy       Kappa      Min.   : NA   Min.   : NA    1st Qu.: NA   1st Qu.: NA    Median : NA   Median : NA    Mean   :NaN   Mean   :NaN    3rd Qu.: NA   3rd Qu.: NA    Max.   : NA   Max.   : NA    NA's   :3     NA's   :3     Error: Stopping In addition: Warning message: In nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,  : There were missing values in resampled performance measures.  I am using the caret 6.0.78 version. Thanks and I will look forward to your reply.  ---------------------------------------------------------------------------------------------------------------------------------",True
@sanketchaure,2017-12-03T19:42:59Z,0,"part.cv.1 <- train(Label ~., data = train.tokens.df,method=""rpart"", trControl=cv.cntrl, tuneLength=7) Error in e$fun(obj, substitute(ex), parent.frame(), e$data) :    unable to find variable ""optimismBoot""  Do you have any idea how to fix it? I tried to install caret from GitHub but that somehow also didn't work. Thank you! Read more REPLY 3    mustafa latif mustafa latif 1 month ago the same my problem did you solved it ??? REPLY    marcuus ma marcuus ma 1 month ago I have same issue REPLY    Parham South Parham South 4 weeks ago I tried to install the download from github & an archived version I found at: https://cran.r-project.org/src/contrib/Archive/caret/. For what ever reason these new older caret would not install. The flawed version of caret is 6.0.77 , I found the earlier version of caret 6.0.76 in an earlier version of R that I had recently upgraded from. Try Program Files/R/R-3.4.1/library/caret. I just instructed RStudio at the Tools/Global Options to use that former version of caret.  code then ran beautifully & I outputted the exact same data as David Langer. If that does not work, I have another idea. When I did the direct install from that archive site I got notice from RStudio that the exit code of that install was not zero. But that install still may have worked. I just never tried it. Also, you could simply unzip that archived file yourself and copy it into the R library you are using. As it turned out that is what I did with my old copy of caret in the older R directory. I copied it into my newer version of R, told RStuido to go back using it, & code ran perfectly. Good Luck. Read more REPLY 1    Sanket Chaure Add a public reply...  CANCEL REPLY  Farhan Ullah Farhan Ullah 2 weeks ago Hi dear, I have the same problem but i did not resolve it yet. Please help me how to resolve it. REPLY    Arfaa Jamal Arfaa Jamal 1 week ago Has anyone found a solution to this yet? I can't get past this REPLY    Hide replies",True
@mahmudiftekharzamil725,2017-11-16T08:39:44Z,0,"Hi. I am doing text analysis on App's user reviews. After running the code, I have got best accuracy: 0.5187258, which I think is very low. Do I need more pre-processing? any suggestions?",True
@hanivlog774,2017-11-14T02:37:08Z,0,"Hi David, great work. I learnt a lot from it. Thanks for sharing such a great videos with us. I am facing an error in line r rpart.cv.1 <- train(Language ~ ., data = train.tokens.df, method = ""rpart"",                      trControl = cv.cntrl, tuneLength = 7) Error in train(Language ~ ., data = train.tokens.df, method = ""rpart"",  :    could not find function ""train....  i am using Windows windows 8.1 pro and platform       x86_64-w64-mingw32           arch           x86_64                       os             mingw32                      system         x86_64, mingw32              status                                      major          3                            minor          4.2                          year           2017                         month          09                           day            28                           svn rev        73368                        language       R                            version.string R version 3.4.2 (2017-09-28).....Please help me in this regard.",True
@ajaymahara483,2017-11-08T23:40:23Z,0,"I cant find the solution to the problem while train function in caret . i tried installing it from github but some how its not working and throwing the following error -  Error in e$fun(obj, substitute(ex), parent.frame(), e$data) :    unable to find variable ""optimismBoot"" any help ?",True
@vishamberlal6897,2017-11-05T09:55:48Z,0,"When I am runing this command  rpart.cv.1 <- train(Label ~ ., data = train.tokens.df, method = ""rpart"",               trControl = cv.cntrl, tuneLength = 7). I am facing this error ""Error in train.default(x, y, weights = w, ...) :  object 'cv.cntrl' not found""  please any one can help me.",True
@parhamsouth4201,2017-11-04T21:14:53Z,0,"rpart.cv.1 <- train(Label ~ ., data = train.tokens.df, method = ""rpart"", trControl = cv.cntrl, tuneLength = 7) would not run. It quit with an error message: 'Error in e$fun(obj, substitute(ex), parent.frame(), e$data) : unable to find variable ""optimismBoot"" The resolution involved the discovery that the current caret package distributed by CRAN v. 6.0.77  is flawed and will not run 'parallelized' code like doSNOW. The solution(s) can be found at https://stackoverflow.com/questions/46244763/caret-train-function-unable-to-find-variable-optimismboot. My solution was to revert to a previous R-package that had an earlier version of caret already installed. Caret 6.0.76 ran the code perfectly & my output was identical with David Langer's.",True
@mohammedbamajboor6496,2017-10-30T16:37:55Z,0,"Hi, I had this Error : ""Error: cannot allocate vector of size 125.8 Mb "", when running this code: > rpart.cv.1 <- train(Label ~ ., data = train.tokens.df, method = ""rpart"",  +                     trControl = cv.cntrl, tuneLength = 7)  Any advice, Thank you. I'm running Windows 7 (32-bit) v.1.1.3  > version                _                            platform       i386-w64-mingw32             arch           i386                         os             mingw32                      system         i386, mingw32                status                                      major          3                            minor          4.1                          year           2017                         month          06                           day            30                           svn rev        72865                        language       R                            version.string R version 3.4.1 (2017-06-30)",True
@mustafalatif6960,2017-10-28T08:57:47Z,0,what is the version of R and R studio you must write the version bcz you know r library is very sensitive,True
@karthik777777,2017-10-16T09:51:23Z,0,"Hello Sir, great teaching so far. I am loving it. Thanks.   but have a question:- why would we need parameter ""Tunelength""? rpart algorithm by itself brings in a optimal tree by calculating gini index. is it not?",True
@raghavp1,2017-09-29T13:12:24Z,0,Great Video Dave....Can you please let us know the rationale of choosing 10 and 3 in multiple folds during cross validation and fineTuneLength as 7 in CART modeling? Is there any optimal way of choosing these numbers?,True
@Gergoo1991,2017-09-21T19:53:33Z,3,"Awesome videos, however at the following code line I get an error message: > rpart.cv.1 <- train(Label ~., data = train.tokens.df,method=""rpart"", trControl=cv.cntrl, tuneLength=7) Error in e$fun(obj, substitute(ex), parent.frame(), e$data) :    unable to find variable ""optimismBoot""  Do you have any idea how to fix it? I tried to install caret from GitHub but that somehow also didn't work. Thank you!",True
@Amitkumar-tk9qw,2017-09-19T13:29:15Z,2,"Hi Dave, The text analytics video series is very interesting. I'm facing an issue in running a particular line of code of this video series, the code is mentioned  below:   rpart.cv.1 <- train(Lable ~ ., data = train.tokens.df, method = ""rpart"", trcontrol = cv.cntrl, tuneLength = 7) the error showing Error: cannot allocate vector of size 170.9 Mb",True
@AK-qb6cy,2017-09-15T17:07:32Z,2,"Please help : I am getting an error while execution of this line : rpart.cv.1 <- train(Label ~ ., data= train.tokens.df, method = ""rpart"",                      trControl=cv.cntrl, tuneLength = 7)  Error in terms.formula(formula, data = data) :    duplicated name 'b.day' in data frame using '.'",True
@TheScienceQuest,2017-09-13T19:06:59Z,1,"I ran the code block that you show for creating rpart.cv.1, but I am getting an error as shown below:   # As our data is non-trivial in size at this point, use a single decision > # tree alogrithm as our first model. We will graduate to using more  > # powerful algorithms later when we perform feature extraction to shrink > # the size of our data. > rpart.cv.1 <- train(Label ~ ., data = train.tokens.df, method = ""rpart"",  +                     trControl = cv.cntrl, tuneLength = 7) Error in e$fun(obj, substitute(ex), parent.frame(), e$data) :    unable to find variable ""optimismBoot""",True
@shobhamourya8396,2017-09-07T10:10:34Z,0,"Hi David! I tested with 1999 and 999 predictors - the accuracy was the same as testing with all the predictors and the time taken was far far less - 56.83036 secs with 999 predictors,  2.411296 mins with 1999 predictors and 33.58188 mins with all predictors ...  ""---------------------- Test Result with 5742 predictors ---------------------  Time difference of 33.58188 mins >  >  > # Check our cv results > rpart.cv.1 CART   3901 samples 5742 predictors 2 classes: 'ham', 'spam'   No pre-processing Resampling: Cross-Validated (10 fold, repeated 3 times)  Summary of sample sizes: 3511, 3510, 3511, 3511, 3511, 3511, ...  Resampling results across tuning parameters:  cp          Accuracy   Kappa     0.02103250  0.9429179  0.7134030 0.02294455  0.9402689  0.6957674 0.02868069  0.9356553  0.6665729 0.03059273  0.9333472  0.6508580 0.03824092  0.9302709  0.6281573 0.05098789  0.9154072  0.5141434 0.32504780  0.8796808  0.1483505  Accuracy was used to select the optimal model using  the largest value. The final value used for the model was cp = 0.0210325.  ##""  ""---------------------------------------- Test Result with 1999 predictors ------------------- Time difference of 2.411296 mins >  >  > # Check our cv results > rpart.cv.1 CART   3901 samples 1999 predictors 2 classes: 'ham', 'spam'   No pre-processing Resampling: Cross-Validated (10 fold, repeated 3 times)  Summary of sample sizes: 3511, 3510, 3511, 3511, 3511, 3511, ...  Resampling results across tuning parameters:  cp          Accuracy   Kappa     0.02103250  0.9429179  0.7134030 0.02294455  0.9402689  0.6957674 0.02868069  0.9356553  0.6665729 0.03059273  0.9333472  0.6508580 0.03824092  0.9302709  0.6281573 0.05098789  0.9154072  0.5141434 0.32504780  0.8796808  0.1483505  Accuracy was used to select the optimal model using  the largest value. The final value used for the model was cp = 0.0210325. ##""  ""---------------------------------------- Test Result with 999 predictors ----------------------------- Time difference of 56.83036 secs >  >  > # Check our cv results > rpart.cv.1 CART   3901 samples 999 predictor 2 classes: 'ham', 'spam'   No pre-processing Resampling: Cross-Validated (10 fold, repeated 3 times)  Summary of sample sizes: 3511, 3510, 3511, 3511, 3511, 3511, ...  Resampling results across tuning parameters:  cp          Accuracy   Kappa     0.02103250  0.9429179  0.7134030 0.02294455  0.9402689  0.6957674 0.02868069  0.9356553  0.6665729 0.03059273  0.9333472  0.6508580 0.03824092  0.9302709  0.6281573 0.05098789  0.9154072  0.5141434 0.32504780  0.8796808  0.1483505  Accuracy was used to select the optimal model using  the largest value. The final value used for the model was cp = 0.0210325. >  """,True
@androvich20,2017-09-04T21:15:03Z,0,"2.9 minutes on a Ryzen 7 1700 at 3,7 GHZ :)",True
@nehanandwani07,2017-08-25T11:02:03Z,1,"Hi Dave, The text analytics video series is very interesting. I'm facing an issue in running a particular line of code of this video series, the code is mentioned  below:   rpart.cv.1 <- train(Lable ~ ., data = train.tokens.df, method = ""rpart"", trcontrol = cv.cntrl, tuneLength = 7) Error in eval(predvars, data, env) : object 'Lable' not found  Kindly help resolve the issue.",True
@anandsubramaniam37,2017-08-11T18:40:45Z,1,Love your Videos!,True
@jonimatix,2017-08-09T17:37:51Z,1,"Hello, I didn't understand why you used CreateMultifolds (k = 10, 3 times) and then you used trainControl with the same parameters specified once again? Can you please explain this?Thank you!",True
@madpie109,2017-08-05T14:46:18Z,2,"This is a great and fascinating series.  This particular video was awfully dense for a noob, and I can tell I'm going to have to watch it about five times, but I still appreciate the work you have put into it.",True
@dimulja83,2017-07-27T09:10:34Z,1,"For the line: rpart.cv.1 <- train(Label ~ ., data = train.tokens.df, method = ""rpart"",                      trControl = cv.cntrl, tuneLength = 7) I always get an ""Error: protect(): protection stack Overflow""  Do you know how this could be solved ?",True
@laurafosci,2017-07-21T23:28:49Z,1,"Hello David, May I ask whether you are familiar with the below error when running the train function on a MAC?  Error in terms.formula(formula, data = data) : duplicated name 's.i.m' in data frame using '.'   I updated R and RStudio to the latest versions and all packages using the update.packages() and I still have the error  Thanks",True
@mihinduperera8688,2017-07-19T10:40:00Z,1,"@David Langer- Out of curiosity what is a workstation class system? I just want to know as I do data analytics for my job and I'm into ML and all, thanks to you.  What would be a good desktop or laptop in this case? Whats your machines specs?",True
@anughosh,2017-07-12T02:19:07Z,1,"I ran the code on my laptop, which has a 8 GB Ram, it took about 16 minutes to run the code. I got the same answer. How to reduce the runtime.",True
@gauravgawande7580,2017-07-11T20:19:26Z,2,"Hey David, when I am running the train function I am getting the following error :-  rpart.cv.1<-train(Label~.,data=train.tokens.df,method = ""rpart"",trControl = cv.cntrl,tuneLength = 7) Error in terms.formula(formula, data = data) :    duplicated name 'X.' in data frame using '.'",True
@Jayl__,2017-07-11T03:45:58Z,1,Does the number of labels affect the processing speed? like 6 or 7 using the same parameters you have set? Would it slow down my laptop and not process?,True
@mayurvira7346,2017-07-04T17:58:46Z,1,"Hi Dave... Excellent video... learn a lot from your examples and precise explanations. I did encounter a problem while doing the last part in RStudio. When I try to run the code using the same code, R hangs for a while. I even tried using 2 units but still it freezes. Do you know of any other possible way to do it. I would really love to go deep into this video tutorial and by getting hands on experience myself..",True
@amitgupta-dy4vg,2017-07-02T15:22:30Z,2,"Hello David, appreciate your work!  I have learned a lot from your videos.",True
@avishekkumar9341,2017-07-02T01:15:48Z,2,Thanks Dave.The video is highly refreshing and enriching. Thanks for it.Looking forward for the Part 5 series.I have one questions: I 'm doing text analytics as how the business users running queries against the database. The data frame looks like below:(Just imagine it has 10 k entries with 10  factors) User Name        QuertText Pete                  SELECT * From EMP INNER JOIN DEPT.....  Can i create model and corresponding visualization? Thanks in advance.,True
@ArteSuaveEconomist,2017-06-30T18:30:05Z,2,"Hi David, when I copied your code: spam.raw <- read.csv(""spam.csv"", stringsAsFactors = FALSE, fileEncoding = ""UTF-16"") , rSTudio threw an error. When I removed;  fileEncoding = ""UTF-16"". It worked fine. I don't know if this matters for anything.",True
@tylermacneill3820,2017-06-29T18:23:20Z,1,"Video series was extremely good, but the end results could have been explained much clearer. The implications/interpretation of cp and Kappa were lacking, and there was no comparison to the test data. Will there be another video explaining how to take the results in rpart.cv.1 and apply them to other data?",True
@MasoudPaydar,2017-06-27T19:35:58Z,2,"Hello David, as usual I learned a lot and love your style of teaching. A quick question: how can we build a model without the initial ""spam"" and ""ham"" label. .? Means we only have the SMS data and we want to build a smart model to predict the labels. Is this possible?",True
@bexleymike,2017-06-27T00:11:45Z,4,I just fell in love with Caret!  Great video!,True
@Tracks777,2017-06-26T17:54:50Z,0,I look forward to more videos,True
