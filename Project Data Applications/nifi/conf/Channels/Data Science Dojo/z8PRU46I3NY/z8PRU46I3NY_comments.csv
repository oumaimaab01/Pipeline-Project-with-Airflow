author,updated_at,like_count,text,public
@Datasciencedojo,2023-08-30T23:23:29Z,0,"For more captivating community talks featuring renowned speakers, check out this playlist: https://youtube.com/playlist?list=PL8eNk_zTBST-EBv2LDSW9Wx_V4Gy5OPFT",True
@seanpitcher8957,2023-02-26T19:08:56Z,0,Oh. My. God. THIS... THIS!!!!! This literally changes everything.,True
@QuickFlicksx,2022-12-29T09:59:22Z,1,Great!,True
@hannukoistinen5329,2022-11-30T00:51:15Z,1,"What is your actual test? What do you want to explain? Model fit: where is it? Coding is 'impressive', but you must get some real results too.",True
@shaunoconnell9506,2022-10-30T08:51:41Z,0,"very nice, i just used this package for an assignment. this got me enthusiastic to learn more",True
@tamafun4745,2022-07-29T07:58:26Z,0,Thank you very much Dave & team. Really enjoy the whole presentation and learn a lot!,True
@djangoworldwide7925,2022-07-04T16:33:00Z,1,You are a nice American chap,True
@pipertripp,2022-07-03T17:38:25Z,1,this was excellent I've leant quite a lot and have a few new books for the reading list. Many thanks!,True
@acada,2022-04-14T02:15:41Z,0,"Excellent presentation, you are a great teacher. Thank you",True
@a.useronly2266,2022-03-10T15:10:50Z,1,Great üëçüèª,True
@LuthieriadeBanheiro,2021-09-25T22:49:21Z,1,Excellent class!,True
@henrique6748,2021-03-31T17:01:50Z,0,Thank you so much for sharing this!,True
@wereskiryan,2021-03-04T16:01:42Z,0,Amazing video!,True
@farhanadham7237,2021-01-06T10:40:04Z,0,"Waw its amazing for turning parameter on xgboost, because we know xgboost always taking too much time for training",True
@arindambpcsrkm,2021-01-02T07:10:56Z,0,"@dave, i understood how you imputed the age. however if we have like 200 missing data for embark data, will the same method for imputing age work, ? i mean is not it possible that for some cases both Q and S might have values close to 1 for same row? what to do in that case",True
@alisterdcruz1667,2020-12-06T09:26:46Z,0,I noticed that the  other columns with large number of na's were removed and  while imputing Age variable all the other factors were having no na's . What  should I do if the variables that are critical for imputation of age variable also has na's ?  I'm a noob. So please correct me if there is lack of logic in my doubt.,True
@6toolbaseball,2020-09-12T21:27:52Z,0,"Great video! Only one question. When you say that set.seed(54321) is not random, what do you mean? I thought whatever we put in set.seed could be anything, e.g., set.seed (321). What is the meaning behind your 54321? You sorta glanced over that part and I'd love to dive a little deeper into that.",True
@joseramon4301,2020-08-16T05:49:45Z,0,Thank you so much!,True
@coolhead8686,2020-07-25T21:50:59Z,0,"Are you hiring? I am the same as you. I spend over 20 years doing system development, programmer analyst, data analyst and data scientist.",True
@fredasefamilia,2020-07-20T19:42:31Z,0,"Thank you for this. However I tried Implementing the code as written in IntroToMachineLearning.R and I get an error at line 159. I have tried it several times and the error message i get is  Loading required package: plyr Error in train.default(x, y, weights = w, ...) :    The tuning parameter grid should have columns nrounds, max_depth, eta, gamma, colsample_bytree, min_child_weight  this is all confusing being that all the columns specified are included in the code. Could this be a result of a bug? Please I'll appreciate an prompt answer to this. Thanks",True
@collinsouru3629,2020-05-15T14:28:05Z,0,"am reproducing your example but am stack at  training the model, it returning an error like Error: The tuning parameter grid should have columns nrounds, max_depth, eta, gamma, colsample_bytree, min_child_weight, subsample what could i be doing wrong?                                                                                                                                here is the part which is returning error caret.cv <- train(train.train$survived~.,                  data=train.train,                   method=""xgbTree"",                 trControl=trainControl,                 tuneGrid=tune.grid)",True
@24brophy,2020-05-01T00:17:32Z,1,This is the single best ML video on the internet. Dave for President 2020.,True
@bljangir7450,2020-03-27T14:19:21Z,0,"Simply excellent ,   I could not hold my self to comment  even if  few miniues are still left   . You are genious  to make things so interesting .",True
@atlantaguitar9689,2020-02-25T04:14:47Z,0,"Great video...Do you feel it is necessary to use dummyvars before doing the imputation ? Isn't it sufficient to do the imputation within the call to the train function as part of the preProcess argument ? That is, is the conversion to one hot encoding outside of the call to train, strictly necessary ?",True
@JerryWho49,2020-02-23T11:45:05Z,0,Isn‚Äòt there some sort of data leakage? You‚Äòre imputing the missing ages using the entire data set. So the  training set ‚Äûknows‚Äú something about the test set. That‚Äòs not good. I think you should split first and then use two pipelines for training and testing. Is there support for pipelines in caret?,True
@drnabinpaudel6984,2020-01-05T21:57:23Z,0,"So, how do we implement this model to a new dataset ?",True
@sbdavid123,2019-12-26T16:27:55Z,0,"Great video, I have watched several times at this point to get a better understanding of the caret package. It helped me out a lot. However, I have one question. Why do you split in train and validation sets and then use cross validation on train. I always thought that cross validation was repeated train test split. This way you will avoid evaluating your model on only one split, which by chance might be easy (or super hard) to predict i.e. because the test subset contains more extreme values or the train contains more of the imputed instances, etc.. . By repeating the process of splitting the data in train and test several time and averaging the performance metrics over all these splits, you get a better view of the real performance of the model. So why do you split in train test subset and then use cross validation on train? As I understand it now, it looks like you are reintroducing the problem cross validation is trying to solve. Would it not be better to not in train and test and use k-folds cross validation (which is basically a repeated split in train and test). Thanks!",True
@KarriemPerry,2019-10-12T18:35:38Z,0,"I do appreciate Dave's approach. I think it's important to stress that there is a lot more to being a data scientist than simply understanding concepts of M, AI, etc, or taking a few online courses a certificate. I believe it takes graduate coursework and years of being a practitioner underatnding and implementing a list of techniques. Engineers typically vector into data analytics completely differently than I do, having a MS in data analytics.  It is a good illustration into just how complex and broad the science of data is in these infant stages.",True
@yanivtubul,2019-07-11T07:19:13Z,2,Thanks a lot! Doing my first steps into R and Machine Learning. This talk is exactly what I needed,True
@sebastianvarela2190,2019-04-23T17:53:40Z,1,"Hi Dave, very instructive video, congratulations. Please let me ask you a question:  I know caret does not impute with factors. But how do you do in practice when you need to impute data to categorical/factor variables? (discarding the mode) In the example of your video, in the dataset ""imputed.data"" you have two columns/dummies for Sex. If you -hypothetically-impute missing values for them, how do to take them back to the original dataset, in which there is only one column for Sex?",True
@shorthand1121,2019-01-17T15:40:34Z,0,"If you get ""subscript out of bounds"" in the train() function, change the parallelization engine over to the future engine as it is better at exporting environments: library(parallel) library(future) library(doFuture) plan(""multisession"") #if you're seeing this error, you're likely on a Windows machine anyway registerDoFuture()  And also comment out the makeCluster, registerDoSNOW, and stopCluster lines.",True
@antzlck,2019-01-06T14:34:18Z,0,Brilliant and great advert for your bootcamps!,True
@mahdip.4674,2018-12-28T15:34:40Z,0,"Thanks for the tutorial. Talking about model based imputation, let us say we have 3 numeric variables to impute.   How the imputation will work if we want to impute the first variable? Does caret will consider complete case approach for the rest of data? If so, how then it will impute the original first variable if it happens that for a record one of second or third variable has missing value?  What is the procedure here? Thanks.",True
@ghexer,2018-11-25T19:19:37Z,5,This was really great Dave.  I've done a bunch of your tutorials online including the intro to data science videos you did using the Titanic Kaggle competition about 4 years ago.  What I enjoyed the most about this video was seeing how much more confident and impassioned you have become as a data scientist since those prior videos.  You can tell that it really excites you and that is infectious in a teaching environment.  I too have become somewhat hooked on data science and I was one of those students that avoided statistics at all costs at every level of education. I'm looking into coming to one of the data science bootcamps at the data science dojo and really looking forward to learning from people that are equally passionate about data science and hopefully making up some lost ground.  Keep up the great work.,True
@reubenschneider3921,2018-11-10T07:16:17Z,0,"Great guide, I was really struggling with a ML assignment and didn't realise what an absolute unit 'caret' is!",True
@yishengkim9081,2018-09-22T20:41:18Z,0,"Great video, but waiting ~ 5 mins to be recognized as having a question is troubling (between ~55:00 - 59:00). #WomeninDataScience",True
@aman_mashetty5185,2018-08-21T11:05:12Z,0,"thanks for the amazing video dev, it's going to help in future also, but I don't know the grid search concept what it does? Can you explain to me in simple terms how it works and how it helps in tuning the model???",True
@CK-vy2qv,2018-06-17T00:20:13Z,0,By far the best video out there for ML in R,True
@yannelfersi3510,2018-06-14T02:36:42Z,0,Great video @Dave. Super helpful; I love the step-by-step Q&A.  Just curious: is it 'good' practice to include the test set when imputing data? shouldn't it be done on the train set only?,True
@aakashchugh9,2018-05-07T00:58:01Z,0,Great video.. caret is amazing.. one question though... If we are doing stratified sampling then we don't have to balance the data? Because if we don't balance the data then the outcome will be biased and if we balance the data then it will be manipulation,True
@erinklark,2018-03-26T23:33:09Z,1,Thanks for the video! Quick question - why do you have to split the data into a training/test set of 70/30 when you are going to do 10-fold cross-validation (90/10 split?) anyway later on? Are these two different things?,True
@TIKITAKANEWS,2018-03-13T21:58:21Z,0,Thanks very much. I got somewhere to start and do it to the end.. Great!!,True
@flamboyantperson5936,2018-03-10T09:14:20Z,0,Extremely helpful video. I don't know the concept of grid search what it does? Can you explain me in simple terms how it work and how it helps in tuning the model? Thank you.,True
@apoorvspydy,2018-01-17T16:10:48Z,0,Thanks! This was very helpful.  Where can I get the rest of the videos on Machine Learning.,True
@hasthigiSrivaradhan1,2018-01-04T18:17:28Z,0,thank you.,True
@NikosKatsikanis,2017-10-19T13:48:50Z,0,"Hi, I am a js expert wanting to get into DS. What tools do you advise me to learn?",True
@Datasciencedojo,2017-08-25T00:44:09Z,0,Meetup Starts at: 2:57,True
@neuro1152,2017-08-10T03:26:10Z,2,"Hi Dave first of all thanks for the video.  AWESOME stuff!  One question, are the hyperparameters for the xgboost algorithm universal or are they tuned specifically to this training set? Could I get the reference for the hyperparameters it was cut off in the code editor screen.  Thanks again.",True
@paulvictor3316,2017-08-08T21:18:13Z,1,"Great video! In regards to preProcess(..., method = ""bagImpute"") what's your definition of SMALL DATA? Would 5000 rows with 10 columns be small?",True
@rajkamalsrivastav7696,2017-07-15T05:16:46Z,1,"Hi David, thanks for this session!! one question, is it always good to go with imputing using caret(e.g.  bagged decision trees for imputing age) or we should do some EDA such as finding a pattern in age using Pclass, sex aggregation and then imputing the age with that value?",True
@bobbird4957,2017-06-22T15:47:28Z,1,"Dear David, great talk, thank you very much. I have a short question: how do I know which factors are included in the ""best"" model? Thus, which factors are most predictive in separating survivors from non-survivors? Thank you in advance! Best, Bob",True
@julianonas,2017-06-17T01:57:45Z,2,Thank you for sharing ! Amazing Video and Instructions.,True
@venustat,2017-06-13T08:13:45Z,2,Great video,True
@nikhitharajashekar1637,2017-06-12T08:49:58Z,2,"Great Video to understand !  But i have doubt, how the resampling result across tunin Parameters are selected?",True
@junaideffendi4860,2017-06-11T12:37:07Z,3,"Great video but didnt see use of train.dummy? you worked on train dataset which has the imputed age but not the dummy columns, clear me please.",True
