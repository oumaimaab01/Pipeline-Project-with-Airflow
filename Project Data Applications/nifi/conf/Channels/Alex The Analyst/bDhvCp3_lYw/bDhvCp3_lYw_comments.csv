author,updated_at,like_count,text,public
@somayagarwal5290,2024-05-31T05:48:02Z,0,"initially there was a phone number for customer id 1003 i.e the third row but after we executed  "" df['Phone_Number'] = df['Phone_Number'].str.replace('[^a-zA-Z0-9]','',regex = True) "" it got replaced by NaN value plz explain",True
@user-re4ip5ms9w,2024-05-23T04:44:15Z,0,i set my index at the begining as customerID so I didn't reset my index,True
@user-re4ip5ms9w,2024-05-23T04:12:48Z,0,"Question is it bad that i dont specify the .str in this df[""Do_Not_Contact""].replace(""Y"", ""Yes"")",True
@user-re4ip5ms9w,2024-05-23T04:01:18Z,0,"help when i run this df[""Address""].str.split("","", 2) it says (StringMethods.split() takes from 1 to 2 positional arguments but 3 were given)  I can only resolved it by removing the 2 why is that?  edit: ok found it you need to specify and comma becomes n you need the param n = like this  df[""Address""].str.split("" , "", n = 2, expand = True)",True
@yanpaucon1043,2024-05-12T17:54:33Z,0,"Thank you so much, Alex. You are the Best",True
@mayanktiwari6997,2024-05-12T09:52:59Z,0,How to add this project in Resume with bullet points? Kindly help,True
@pip9601,2024-05-11T18:48:41Z,0,"at 15:19 i would like to say something. in the new version from jupyter, if u write the code from alex the data will be same. To fix this, u can input regex = True after the ''. CODE: df['Phone_Number'].str.replace('[^a-zA-Z0-9]', '', regex = True). But overall i can't say anything except thank u alex for this awesome tutorial !!!!",True
@markobe08,2024-05-10T12:48:51Z,0,"for those struggling on 33:55  df['Do_Not_Contact'].replace('', pd.NA, inplace=True)  df['Do_Not_Contact'].fillna('N', inplace=True)",True
@hishamafzal1999,2024-05-08T16:28:03Z,0,Amazing Video,True
@juandiegosuarez5159,2024-05-08T01:51:17Z,0,I love the fact that Creed Bratton doesn't have any data beside his name XD,True
@nirmalpandey600,2024-05-07T10:30:58Z,0,Amazing explanations!,True
@yvonnemukhono3566,2024-05-04T09:44:02Z,0,"Very helpful, and well explained.",True
@tinashebeans9081,2024-04-30T12:26:50Z,0,use:.... df.drop_duplicates(inplace= True) to drop duplicate rows,True
@hueytemplar,2024-04-26T17:09:07Z,0,"For those struggling getting an error @23:24 use the below code. df[""Address""].str.split(',', n=1, expand=True)",True
@jesustorralba2360,2024-04-22T15:19:51Z,0,The pd.read_excel(r[filenamem])  <<<< what does the r do? I cannot seem to find anything about it in: https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html,True
@chiraggaba8671,2024-04-13T12:11:31Z,0,really helpful,True
@OlasunkanmiOluwaseunBaba-jd7qm,2024-04-09T01:49:55Z,0,"THank you for the video When trying to filter using the DNC column, Couldn't we have done df = df[df['Do_Not_COntact'] !== 'Y']",True
@rahulrajeev9763,2024-04-05T18:42:05Z,0,How can i get this dataset?,True
@mastermatt6090,2024-04-05T14:55:32Z,0,"Thank you very much. You make it look super easy. I got an error splitting the address into State_Adress, State, Zip_Code So I just had to run with this code df[[""Street_Address"",""State"",""Zip_Code""]] = df[""Address""].str.split(',', expand=True)",True
@shotihoch,2024-04-01T17:21:48Z,0,"Not an analyst (never wanted to be), but it was very interesting. Thanks!",True
@Mwalimu-wa-Math,2024-03-27T18:49:40Z,0,"38:36 df[['Street_address','State','Zip_code']]=df['Address'].str.split("" "",n=2, expand=True)",True
@chahineatallah2636,2024-03-25T18:51:22Z,0,"hello everyone, great video alex, was trying to use some other method on phone numbers, basically was trying this df[""Phone_Number""]=df[""Phone_Number""].replace(""-"",""""), but it didnt work, didnt figure out why , but if i use str.replace it works, strange, anyone encountered that?",True
@Legomancer,2024-03-25T00:05:01Z,0,"at about 33:54, whoa! unless you were specifically told to do this, you are altering the data! Changing no value to 'N' is a no-no unless you have been told to do so. Otherwise you're adding information that was not there. We don't know if Harry Potter wants to be contacted or not and that's probably for someone above our pay grade to decide! :D",True
@kalltreaionc,2024-03-16T01:42:19Z,0,"df[""Phone_Number""].str.replace('[^0-9]',' ', regex=True) would be better and takes away the Nan..s",True
@abrilgonzalez7892,2024-03-14T18:41:59Z,0,"I couldn't replace the ""None "" values whith nothing,  Could someone help me :(?",True
@mastermatt6090,2024-03-14T12:34:14Z,0,I was intimidated by the Machine learning module but now I am not. Thanks a lot dude,True
@josha3212,2024-03-13T00:56:19Z,1,"hey guys I just wanted to leave a comment because I haven't seen an issue mentioned. There is a subtle problem I saw; whenever we run  df['Phone_Number'] = df['Phone_Number'].str.replace('[^a-zA-Z0-9]', '', regex=True)  it will remove phone numbers that have no characters to remove. This can be seen at 14:55 if you pay attention to Walter White's number on Index 2, you can see it is removed. This happens because the column is at that moment of data type object and we are performing a string manipulation on it. For better consistency and expected results, the fix seems to be to turn the column to type string and then perform the replace method. Therefore running   df['Phone_Number'] = df['Phone_Number'].astype('string')  before the string manipulation should make it so everything behaves as expected and walter whites number remains in the column. After this, you might want to run the .fillna(' ') method to get rid of the null values so that you can add dashes with the lambda function.   df['Phone_Number'] = df['Phone_Number'].fillna('')  df['Phone_Number'].apply(lambda x : x[0:3] + '-' + x[3:6] + '-' + x[6:10])  I appreciate the video!",True
@sauravsubedi7089,2024-03-12T09:22:25Z,1,"Instead of striping each symbols one by one in  9:11 i think its better to use  characters_to_remove = ['/','...','_'] for x in characters_to_remove:     df[""Last_Name""] = df[""Last_Name""].str.strip(x)",True
@md.taslim2101,2024-03-07T16:05:11Z,0,"sorry to interrupt df[""Phone_Number""] = df[""Phone_Number""].str.replace('[^a-zA-Z0-9]','') that code is not working in my computer",True
@anoldnyato8662,2024-03-04T07:34:43Z,0,"I'm getting this message when cleanin the address ""TypeError: StringMethods.split() takes from 1 to 2 positional arguments but 3 were given"" can you help me bypass it. I tried chatgpt it didn't help much tried googling it but couldn't get any solution yet.",True
@HunzaFolk,2024-02-27T15:16:59Z,1,"I am studying Data Collection and Data Visualization at Kings College, your channel is reccomned by our lecturers to understand data cleaning.",True
@HarshKumar-ws3wv,2024-02-27T14:04:15Z,0,"Sir, in your opinion : Jupyter vs Pycharm? Which is better for data cleaning ?",True
@RaySpyder007,2024-02-26T16:03:04Z,0,Thanks brother!❤,True
@alainsoppoprisogodor3629,2024-02-24T20:15:51Z,0,Looking at this tutorial having an SQL background is kinda frustrating 😅😅🤭,True
@jtmoleleki3604,2024-02-21T15:30:26Z,0,Thank you Alex.  Your videos are very helpful. Now I can resume cleaning my data.,True
@vasavipasumarthi9601,2024-02-21T14:02:24Z,0,Really u fone a good job i became a big fan of u thank u so much for doing this,True
@salaimani,2024-02-20T15:05:58Z,0,How you are at 23:27  apply the changes and go back to the previous steps in Jupiter notebook,True
@FarizDarari,2024-02-20T06:19:03Z,0,Many thanks for the dataset+code+video!!! 🔥🔥,True
@eatersdaily,2024-02-19T08:28:38Z,0,"hi professor, i heard that .apply makes the program slow, it's good to use it in necessary situation, why do you teach this and if you could, please make a video about optimizing  pandas performance to decrease memory and resources usage. tnx a lot for your tutorial videos, it helps me so much, god bless you!",True
@fadirra,2024-02-18T04:06:43Z,0,❤❤❤❤❤,True
@internetgirl3099,2024-02-18T00:56:57Z,0,"For phone number why don't you convert each record into str first, and then when you apply the reg expression, you can get rid of Nan and Na all together with other stuff?",True
@margotonik,2024-02-17T20:22:20Z,0,I enjoyed working on this project. Thank you Alex and a huge thank you to those guys who helped in the struggling minutes!,True
@frenamakenson9844,2024-02-11T05:07:47Z,0,"for the last part to filter the df, here' s a short code to do it also :  df.query('Do_Not_Contact== ""N"" and Phone_Number != """" ') just query the df",True
@frenchkiss609,2024-02-07T08:36:47Z,0,when splitting address it gives this error: tringMethods.split() takes from 1 to 2 positional arguments but 3 positional arguments were given anybody know what to do?,True
@michaelg9359,2024-02-04T00:17:47Z,0,"Anybody else get this around 19:26?       df[""Phone_Number""].apply(lambda x: x[o:3] + '-' + x[3:6] + '-' x[6:10])                                                                        ^ SyntaxError: invalid syntax. Perhaps you forgot a comma?",True
@tomaronson4419,2024-02-01T20:42:27Z,55,"For splitting the address at 21:29, you may want to add a named parameter to the value of 2, as in n=2:  df[[""Street_Address"", ""State"", ""Zip_Code""]] = df[""Address""].str.split(',', n=2,  expand=True)",True
@qlintdwayne9044,2024-02-01T06:42:43Z,1,Favorite thing to do is to come to the comments section for any errors that don't make sense to me.,True
@sdivi6881,2024-02-01T03:17:39Z,1,"If any one is getting an error on df['Address'].str.split("","",2, expand=True), you can omit 2 and use df[""Address""].str.split("","", expand=True)",True
@user-cn4zp9qw8o,2024-01-30T16:27:17Z,0,plz help me csv file ni read  ho rhy,True
@Mwalimu-wa-Math,2024-01-30T12:21:54Z,0,Plz help me 3:22 3:22 3:22 with source(link) of the data,True
@SurendraSingh-bd5wc,2024-01-25T18:29:25Z,0,Really enjoyed the video,True
@user-jq9vf3uk5d,2024-01-25T06:59:24Z,0,Hi sir i have watched your whole paylist but in this video last zip code vanishes its values,True
@adeolaa.366,2024-01-23T22:44:13Z,0,"great video thank you. when we did the first lambda, the reason was because lambda is faster. so why did we go against using a lambda when it was time to check if the customer can be called or not?",True
@georgekalathoor,2024-01-18T15:33:00Z,3,"instead of applying lambda function to convert Phone_Number column elements to string , we can also use df['Phone_Number'] = df['Phone_Number'].astype(str)  and use dictionary as an argument to be passed inside replace method to avoid Yes becoming YYes   df['Paying Customer']= df['Paying Customer'].replace({'Y':'Yes','N':'No'})",True
@artmedia5202,2024-01-18T08:09:06Z,0,"hi Alex, I'm kflyS from Indonesia, I like the way you teach and try to do it. I say this to express permission and thank you by including your GitHub and YouTube accounts on my worksheet on Kaggle, so thank you and good luck always :)🙏",True
@Charlay_Charlay,2024-01-17T23:25:34Z,0,"Great video but I got stuck on the Splitting Columns section( i figured it out. I needed to specify the the number of separations with n.)  Hey All,  I used the below  df[""Address""].str.split(',', n=2, expand=True)  Then to save.   df[[""Street_Address"", ""State"", ""Zip_Code""]] =df[""Address""].str.split(',', n=2, expand=True)",True
@chernobarry6035,2024-01-14T06:47:46Z,1,Your explanation was super cool,True
@rnjesus9950,2024-01-11T20:22:30Z,0,"After making it this far through the course over the last 2 months, looking at these last 4 videos I'm getting strong final exam vibes. Python has not felt intuitive to me at all, but I recognize its value. I guess it feels like taking Spanish 1 and having Spanish 2 tests. I'm definitely looking forward to applying what I've learned here to solidify the lessons more. I'm contracting for a company already and writing a proposal for them to transition to My SQL Server. I guess the fact that I feel overwhelmed with all the info means I'm actually learning how little I actually know, which is a good thing for growth in the long run. Rambling here, but I am incredibly thankful for the course, Alex.",True
@morris9973,2024-01-10T17:06:00Z,0,"I've been struggling with Pandas a bit and this video cleared some things for me!  what frustrates me from the way my teachers would teach Pandas, their solutions are sometimes too efficient, in the sense that a student that started from zero who's taking an exam, will never be able to come up with these hyper efficient and elegant one-liners in their code. what I appreciate in your video is how you achieve the same results, but in a way that a beginner can easily remember and apply on an exam. thank you! I'll be checking out more of your videos.",True
@rubymateo1010,2024-01-10T05:24:31Z,0,What app are you using?,True
@playwithruhaanzohan8830,2024-01-09T00:29:39Z,1,"Hi! Dear Alex the code df['Phone_Number'].str.replace('[^a-zA-Z0-9] ', ' ') is not working",True
@sj1795,2024-01-02T00:12:01Z,2,"Found this REALLY helpful! I love how you walk us through mistakes as well as explain WHY you do what you do throughout your videos. It adds so much value to each video. As always, THANK YOU ALEX!!",True
@malakilikemokaaa1385,2023-12-28T07:49:55Z,1,Python is so fun,True
@esthertemi416,2023-12-27T08:39:54Z,0,I dont get the reason for adding 123 in the strip there was no 123 in any of the last  names,True
@menyajasper4940,2023-12-23T10:27:01Z,1,This is really very important to both the beginners and pro. Kudos!!,True
@pewolo_nyenh,2023-12-23T05:53:09Z,0,"For explanation purposes, it is great. For getting the final result, I would have done differently though",True
@iinph,2023-12-18T19:59:20Z,1,"thank you for your work Alex! I went through the entire video 1 by 1 twice and I can tell I learned a lot from this video , finally understanding why we need to learn Loops etc. and how simple cleaning methods work on Jupyter.",True
@wenkanglee9596,2023-12-15T19:42:31Z,0,"29:42 Just sharing my approach to  remove the ""don't call"" rows df = df[df['Do_Not_Contact'] != 'Y'] You can apply this to the missing phone number and the rest as well.",True
@bharatsaraswat,2023-12-15T06:35:38Z,0,"Very well done! Great video. I am working on analyzing and cleaning scraped data from web and this guide is helpful, especially where you mentioned the mistakes.",True
@fede77,2023-12-14T19:36:50Z,187,"For those struggling with the regular expression at 14:57 , you might need to explicitly assign regex = True (based on  the FutureWarning displayed in the video).  That is:  df['Phone_Number'] = df['Phone_Number'].str.replace('[^a-zA-Z0-9]', '', regex=True)",True
@user-sj9wp9zg1d,2023-12-14T10:27:21Z,0,super,True
@TopGear-GT,2023-12-14T06:37:58Z,0,Perfect 👍,True
@carsinformation9735,2023-12-11T11:44:13Z,0,can i get the excel file,True
@mohitjoshi8984,2023-12-08T04:41:19Z,1,Hello Alex on time of cleaning the  Phone_Numder column(14:00 to 21:39 )   the code is executed. But at the table there are no changes . Please help me on this,True
@yakupakiniyazov4861,2023-12-07T16:55:42Z,1,"df[""Phone_Number""]=df[""Phone_Number""].str.replace(r'[^a-zA-Z0-9]','',regex = True)  If you have problem with Phone Number section you have to make regex= True to clean the Phone_Number column",True
@17art3an,2023-12-06T20:38:19Z,0,"Thank you, great video!",True
@jamilsonedu917,2023-12-03T21:24:25Z,0,"Using regular expressions for manipulating data is beneficial because it allows you to change strings as needed, especially when dealing with different types of strings.",True
@MustafaSalaheldin,2023-11-25T06:33:06Z,1,"26:06 hello @Alex many thanks for this wonderful series. I wanted to share some of my findings, if you want to replace Y with Yes you can do it using Regex as follows  df[""Paying Customer""] = df[""Paying Customer""].str.replace(r""^Y$"",'Yes', regex=True)  Once more, thanks so much.",True
@rajkumarrajan8059,2023-11-22T13:45:29Z,1,"df[""Phone_Number""] = df[""Phone_Number""].str.replace('[^a-zA-Z0-9]',' ')  I am using visual studio code and the above line not working for me.",True
@Elly-we9uc,2023-11-20T15:18:33Z,2,"Also, to clean the Do_Not_Contact field, one can use: df['Do_Not_Contact'] = df['Do_Not_Contact'].replace({'N': 'No', 'Y': 'Yes'})",True
@Elly-we9uc,2023-11-20T15:16:28Z,2,"Timestamp 32:42. I simply use #Filter out ""Do_Not_Contact"" == ""Yes"" df[df['Do_Not_Contact']!='Yes']",True
@keylanoslokj1806,2023-11-19T19:21:17Z,0,Lets say you have an Excel file with 10 columns and 500 rows. And the last 4 columns have yearly sales. How do you pick the lines of the products with zero sales and delete them?,True
@eglestankeviciute5335,2023-11-18T19:56:16Z,0,"str.replace('[^a-zA-Z0-9]', '') is not replacing stuff for me.. wondering. why :( my numbers still has +,()...",True
@thetasworld,2023-11-18T17:34:31Z,0,"Judging how grumpy Heisenberg was ,maybe it was for the best that his number got lost...",True
@meryemOuyouss2002,2023-11-13T15:37:41Z,0,Thank you soo much sir you're really a great professor 👏❤,True
@bennet5467,2023-11-12T20:06:28Z,20,"Thanks for this content, this was so helpful!!  I think i have some optimizations, correct me if im wrong :D 27:04 instead of calling the replace function multiple times, you can create a mapping just like: replace_mapping = {'Yes': 'Y',  'No': 'N'} and call it like: df = df.replace(replace_mapping), so you dont have to specify mapping for each column and need to call .replace() just once. 34:16 instead of the for loop + manually dropping row per row, you can make use of the .loc function like: df = df.loc[df[""Do_Not_Contact""] == ""N""] in order to filter the rows based on filter criterium.",True
@AndrejSpilevoj,2023-11-12T18:36:31Z,0,"This one did never work: df['Street_Address'], df['State'], df['Zip'] = df['Address'].str.split(',', 1, expand=True), it provides the error: TypeError: StringMethods.split() takes from 1 to 2 positional arguments but 3 positional arguments (and 1 keyword-only argument) were given",True
@AndrejSpilevoj,2023-11-12T18:05:11Z,0,"replace of characters in Phone Number did not work in the way you gave it, but worked this way: df[""Phone_Number""] = df[""Phone_Number""].str.replace('[^\d]', '', regex=True)",True
@user-ib8jh9jx3s,2023-11-09T11:52:06Z,0,"df['Phone_Number'].str.replace('[^a-zA-Z0-9]',   ' ') this line of code is not working it shows me the same result please help",True
@anjomanyana,2023-11-08T09:32:31Z,0,data,True
@anikkantisikder2179,2023-11-04T11:33:34Z,22,"For the address column: df[[""Street_Address"", ""State"", ""Zip_Code""]] = df[""Address""].str.split("","", n=2, expand = True). Defining only 2 was giving me an error. so i had to change it to n=2",True
@user-ln5jl8en4m,2023-11-04T10:02:10Z,0,To be honest I have used all formats I have seen online to remove the special characters in the phone number column but they are not working.. pls if anyone has the right format let me know .. thanks,True
@anikkantisikder2179,2023-11-03T18:00:20Z,0,"df[""Last_Name""] = df[""Last_Name""].str.lstrip(""/"") . This will work but is going to show a warning. So if you face the same problem like me. You can use this: df.loc[: , ""Last_Name""] = df[""Last_Name""].str.lstrip(""/"")",True
@md.shahriarabidswapnil604,2023-11-03T15:46:12Z,0,thank you very much. your video helped me a lot. good luck,True
@laryanzl,2023-11-02T17:23:37Z,0,"df[""Phone_Number""] = df[""Phone_Number""].str.replace('[^a-zA-Z0-9]','') not working for me",True
@user-jb9zd5lt2p,2023-10-30T17:29:16Z,0,i can't find the dataset you used to teach,True
@molecularptsdneuroscience4123,2023-10-30T17:08:06Z,1,"Hi! if you are having an issue where the phone numbers dashes aren't being removed,  there was an update in python changing the regex from true to false as the default issue.   try this  df[""Phone_Number""] = df[""Phone_Number""].str.replace('[^a-zA-Z0-9]', '', regex=True)",True
@DreaSimply21,2023-10-29T19:33:12Z,6,"I like how in some of your videos you show us the long way and then the short cut, instead of just showing the short cut. I think that way gives the person who is learning a better breakdown of what they are doing.",True
@avinashparchake7935,2023-10-25T14:06:52Z,0,"in Phone_number , to convert data into numeric , we can also used [^\d]  code:  df['Phone_Number'] = df['Phone_Number'].str.replace('[^\d]', '', regex=True)",True
@avinashparchake7935,2023-10-25T13:53:56Z,5,"in Last_Name columns we can used replace function in order remove regular expression like ( ./-) code:  df[""Last_Name""]= df[""Last_Name""].str.replace(""[./_]"","""" ,regex= True)",True
@higiniofuentes2551,2023-10-21T03:05:55Z,1,"In the case of column Phone_Number with all the variant of NaN, first ""stringuify"" the column, and after do the format thing and then replace with nothing all the content of the column when the content contains 2 -  Thank you!",True
@higiniofuentes2551,2023-10-21T02:55:47Z,0,"After all this cleaning, maybe we can eliminate the column Do_Not_Contact too.!",True
@higiniofuentes2551,2023-10-21T02:53:28Z,0,Thank you for this very useful video!,True
@user-to9vz6gh4b,2023-10-20T07:31:55Z,1,"Alex, I loved the Video. It have Correct Explanation. Thank you so much for your Video. There is a Small Mistake while you are typing #Another Way to drop null value df.dropna(subset='Column_name',inplace = True). I hope you will notify the Error. Thank you.  Have a Great day!",True
@jacobsanointed9981,2023-10-18T13:28:54Z,0,I have a lot of questions. How do we ask questions privately?,True
@ABDO-pd6cu,2023-10-15T07:38:03Z,0,too many mistakes,True
@khaibaromari8178,2023-10-14T12:49:57Z,2,Simply amazing! Well-explained and comprehensive. Loved it!,True
@nma7203,2023-10-09T13:13:18Z,1,"For those who want to replace Y => Yes , N => No, just need to remove .str and use only replace, like this df[""Paying Customer""] = df[""Paying Customer""].replace({'Y': 'Yes', 'N':'No'})  df[""Do_Not_Contact""] = df[""Do_Not_Contact""].replace({'Y': 'Yes', 'N':'No'})  df",True
@maryemmdini9408,2023-10-08T17:30:28Z,0,very well explained video thank youuuu,True
@josephfinch1937,2023-10-07T03:32:28Z,0,"I noticed when you went to remove the Do Not Call and missing phone number data you used a for loop.  I was under the impression that using for loops was inefficient for large data sets and we should use vectorized code whenever possible.  I redid this section using Boolean masks and got the same results.  Would this give me an efficiency advantage?  Code: dnc_mask = df['Do_Not_Contact'] == ""Y""  # make a boolean mask where anything with a Y is true df = df[~dnc_mask]  # apply the boolean mask so it returns anything that is not true  (or anything that is not Y)  phonenumber_mask = df['Phone_Number'] == ''   # make a boolean mask wehre anything blank is true df = df[~phonenumber_mask]          #apply the boolean mask so it returns anything that is not true (or not blank)",True
@dawewatwese6301,2023-10-04T22:50:50Z,5,"Hi Alex, idk if you will see this comment. So I was doing the same codes, and I noticed when you eliminated the characters for the phone numbers at 14:57 you also deleted the phone numbers that did not have any characters in them. You can see that at index 3 for Walter White, before he had a phone number but after he had NaN. If you can tell me how to correct it, it would be very great. I also never commented on your videos, but i like them very much, they are very good, and helpful. Thanks for everything",True
@pichpanha6993,2023-10-04T04:08:17Z,0,Thank you so much this awesome video,True
@gudiatoka,2023-10-01T14:39:03Z,0,"Great video mam, need more this type of tutorials",True
@manishaarya247,2023-09-25T17:23:56Z,0,"Df['phone_number'].str.replace('a-zA-Z0-9'), ' ')  Not working 🥲",True
@MrValleMilton,2023-09-25T00:11:55Z,2,Great Pandas data cleaning video. Thank you very much for sharing your knowledge.,True
@jedits7835,2023-09-23T16:37:10Z,0,21:52,True
@jedits7835,2023-09-23T14:56:28Z,0,10:21,True
@neildelacruz6059,2023-09-23T13:24:21Z,1,Thanks for this absolutely great video.,True
@browngamerOP,2023-09-21T05:40:25Z,0,why didnt you drop do not contact column  its literally of no use,True
@yashjohngaming2928,2023-09-20T22:26:21Z,0,Best video available on internet so far for data cleaning in Pandas. Best explanation. 😇😇,True
@lakkisettysaiakash3712,2023-09-19T06:40:55Z,0,please can any one explain how to download the data file using the github link,True
@50cent10891,2023-09-16T03:10:09Z,0,Great video! I enjoyed learning from you! Thanks for making things easier to understand,True
@040shubham7,2023-09-15T07:10:04Z,1,"For the phone numbers you have to write df['Phone_Number'].str.replace('[^a-zA-Z0-9]', '', regex=True) like to make it work as in the video.",True
@JK-tk2do,2023-09-12T15:51:30Z,0,Oh my.. I am going to watch every single video you created..,True
@bolajiogunfowote8603,2023-09-12T07:46:06Z,0,The video I needed to have a realistic practice in data cleaning.thanks,True
@hamzaabdullahmoh,2023-09-10T09:59:53Z,0,A Glorious Thank You!! Please Keep This UP!!!!,True
@abhinavrastogi1699,2023-09-09T18:17:38Z,0,"Hi Nice explanation. But in this data cleaning you have simply remove NA values. But as per my understanding we need to fill NA values, I am not clear about the logic to fill in. If you can provide video on how to fill NA values it will help us a lot. Thanks Abhinav",True
@emmanuelnwachukwu6071,2023-09-08T09:41:20Z,0,This is the best video I have ever watched on data cleaning using pandas.. even the mistakes were good to learn from.,True
@GuillermoPalchik,2023-09-07T21:21:38Z,0,"Great video! One thing though - When cleaning the ""Phone_Number"" column, I noticed that the numbers at index numbers 2,11,17 (basically, every continuous string of numbers without punctuation) disappear.   Here's how I did it: $ df = df.astype({'Phone_Number': 'string'}) # convert column to string before performing regex $ df.Phone_Number = df.Phone_Number.str.replace(r'[^0-9]','',regex=True) # remove everything except numbers",True
@ZeuSonRed,2023-09-06T09:09:29Z,0,Still Helpful Thanks,True
@ZeuSonRed,2023-09-06T08:52:34Z,0,"also you can use    df.query('Column_name == ""No"" ') just a line for the same result",True
@ZeuSonRed,2023-09-06T08:26:36Z,0,"Okay maybe I was not right for the previous comment but instead using replace, you can just use if else function",True
@ZeuSonRed,2023-09-05T16:11:30Z,0,"I not only survived! on 20:46 you can place AND  in .replace('nan--'  AND  'Na--' , '   '). Thank you 1:1",True
@ajayayaan6660,2023-08-31T14:13:29Z,0,"hello sir . how to work on this data i am unable process this data from github , could you please help me out . actually i would like to take raw data from the github and i am trying to paste it in my coolab  but it was  not happening",True
@devgupta8657,2023-08-30T19:24:17Z,0,It shows error while dropping not useful column,True
@naumantoor2812,2023-08-28T12:57:18Z,1,"while removing the special chars from the `Phone_Number` column you can just use use  df[""Phone_Number""].str.replace('\W', '', regex=True) but if you are doing like this  df[""Phone_Number""].str.replace('[^a-zA-Z0-9]','')  Be sure to pass that regex parameter to the replace function,",True
@ecubere,2023-08-28T11:21:55Z,0,"I ran this code for the ""Yes"" and ""No"" troubles. for x in df['Do_Not_Contact']: 	if x == ""Y"": 		df[""Do_Not_Contact""] = df[""Do_Not_Contact""].str.replace(""Y"", ""Yes"") 	if x == ""Yeses"": 		df[""Do_Not_Contact""] = df[""Do_Not_Contact""].str.strip(""es"") for x in df['Do_Not_Contact']: 	if x == ""N"": 		df[""Do_Not_Contact""] = df[""Do_Not_Contact""].str.replace(""N"", ""No"") 	if x == ""Noo"": 		df[""Do_Not_Contact""] = df[""Do_Not_Contact""].str.strip(""o"")  for x in df['Paying Customer']: 	if x == ""Y"": 		df['Paying Customer'] = df['Paying Customer'].str.replace(""Y"", ""Yes"") 	if x == ""Yeses"": 		df['Paying Customer'] = df['Paying Customer'].str.strip(""es"") for x in df['Paying Customer']: 	if x == ""N"": 		df['Paying Customer'] = df['Paying Customer'].str.replace(""N"", ""No"") 	if x == ""Noo"": 		df['Paying Customer'] = df['Paying Customer'].str.strip(""o"")  i know it is long",True
@muhammadrafehatique6790,2023-08-27T13:39:54Z,0,what think about zip_code in last minute of video when it contain nothing??,True
@atomicafk8704,2023-08-26T17:09:32Z,1,"4)Cleaning Phone_Numbers: The correct code should be=> df[""Phone_Number""] = df[""Phone_Number""].astype(str) df[""Phone_Number""] = df[""Phone_Number""].str.replace('[^a-zA-Z0-9]','')  df[""Phone_Number""] = df[""Phone_Number""].apply(lambda x : x[0:3]+ ""-"" +x[3:6]+ ""-"" + x[6:10])  df[""Phone_Number""] = df[""Phone_Number""].str.replace('nan--','') df[""Phone_Number""] = df[""Phone_Number""].str.replace('Na--','') df  ---------------------------------  7)Filtering Rows : (Using Masking) df[ (df[""Do_Not_Contact""]==""N"") & (df[""Phone_Number""]!="""")]",True
@G2Chanakya,2023-08-24T19:18:03Z,1,"My only doubt is, you saw the first 20 rows and decide only \ or .. or _ could be preceding, or  only ""Nan"" or ""N/A"" is only there in that row, while replacing it. What if the 50th row has ""%Mike"" as a name or what if ""Null"" is there one of the columns??  How do we deal with it. Great recap for me other than this. Thank you.",True
@satrapech6107,2023-08-24T13:30:05Z,0,"if u can't use str.replace to replace the number as output u can use this code  df[""Phone_Number""].str.replace( ' [^a-zA-Z0-9] ',   ' ',  regex = True)",True
@user-dj9mx1yt2g,2023-08-24T05:13:38Z,0,I cant access the dataset in the git hub,True
@Ashis_Kumar.,2023-08-21T06:08:39Z,0,"You teach well... You got yourself a subscriber. But, I still don't get it, I could have done the above task in under 2 min in Excel. Why Python?",True
@jeanaimegakwerere8591,2023-08-19T13:33:46Z,2,"Thank you sir, you can't imagine how i fill confident in cleaning data after completing this video with real data practices. Thank you once again.",True
@aaspirant5392,2023-08-14T19:19:54Z,1,"You are great, Alex. Your teaching skills excellent.",True
@atila44,2023-08-14T14:44:39Z,0,"df['Phone_Number'].replace(['NaN', 'Na'], np.nan, inplace=True)   df['Phone_Number'].fillna('0000000000', inplace=True)",True
@ramakrishnaraolakkaraju3750,2023-08-14T01:59:33Z,0,Thanks for the video. Helped a lot in understanding Pandas.,True
@reidoproject3115,2023-08-12T15:53:48Z,0,is this using Jupyter Notebook? mine looks different,True
@Honking_Goose,2023-08-11T23:50:12Z,0,"I was having issues with replacing the NaN with N here's a way i found of doing this if Alex's way isn't working for you: import numpy as np df[""Do_Not_Contact""].replace(np.nan, ""N"", inplace=True)",True
@selvas5043,2023-08-11T13:51:09Z,1,Super Explanation Thanks,True
@KevinDKao,2023-08-07T17:57:48Z,1,"I think you did a good job explaining a lot of these but I'm noticing some fatal errors in both the video and the example notebooks you've provided that the comments confirm with me. For example, the Phone Number string replace around the 15 minute mark in the video doesn't work at all and another viewer commended a correct revision.   In addition, the string split for the Addresses around the 23 minute mark also do not work because the StringMethods split function takes from 1-2 positional arguments.",True
@trendytwenty6730,2023-08-02T14:56:47Z,1,"I have a dataset has 10,000 rows...  The first 1000 rows in the dataset doesn't have any errors.  After the data had errors.  It's very tough to me to find errors in that huge dataset.  Could you please tell how can I find errors.",True
@millenniumkitten4107,2023-07-31T14:54:53Z,50,"Some of the phone numbers are removed while doing the formatting. If you look in the excel file, you'll see that some of the numbers are strings and some are integers. When you run the string method during the formatting, it replaces the numeric values with NaN and they are later removed completely. If you want to avoid losing that data you'll need to use df[""Phone_Number""] = df[""Phone_Number""].astype(str) before formatting. You also won't need to convert to string in the lambda after doing this.",True
@fagbolaayobola,2023-07-29T16:49:58Z,0,"Hi, I think I might be fundamentally misunderstanding something here but instead of using the lambda function in 18:57 why does something like df[""Phone_Number""].str.apply(lambda x: x[0:3[ ...) not work. I know it does not work, I just do not understand why it does not work. Am i misunderstanding something here?",True
@nuraiymsardarbekova6509,2023-07-29T05:14:16Z,0,"Hi everyone, can you please help me find a mistake the below function is not working for me. I tried so many times, even used Alex code and got same result.  df[""Phone_Number""] = df[""Phone_Number""].apply(lambda x: x[0:3] + '-' + x[3:6] + '-' + x[6:10])   the results are like this  0     123---5-4-5- 1     123---6-4-3- 2        nan------ 3     123---5-4-3- 4     876---6-7-8- 5     304---7-6-2- 6        nan------ 7     876---6-7-8- 8         Na------ 9     123---5-4-5-",True
@Skibadee99,2023-07-24T14:37:48Z,0,"enjoying the video and appreciate this is a beginner video, but for 11:56, i have written a function to handle non alphabetical chars from start and end of column  def remove_special_characters(text):     if isinstance(text, str):         return re.sub(r'^[^a-zA-Z0-9]+|[^a-zA-Z0-9]+$', '', text)     else:         return text   df['Last_Name'] = df['Last_Name'].apply(lambda x: remove_special_characters(x))",True
@drumkick1397,2023-07-22T05:49:33Z,1,"There is no need to iterate in Python. We can use df[(df[""Do_Not_Contact""]  == 'No') & (df[""Phone_Number""] != '')] to meet te conditions we need.",True
@drumkick1397,2023-07-22T05:20:44Z,17,"I discovered that replace() has an argument regex (regular expression). It is set  as regex = True but when we change it to regex = False, it only looks for exact matches, meaning it won't change 'Yes' to 'Yeses', only 'Y' to 'Yes'. We can write df[""Paying Customer""].replace('Y', 'Yes', regex = False) and it will work as expected.",True
@nimrod4463,2023-07-18T08:00:35Z,0,"Hey alex, could you please expand in detail about the lambda function? thank you.",True
@frybait0626,2023-07-17T04:41:55Z,0,Hi Alex! Want to ask whats the point of data cleaning and visualization on pandas if there is PowerBI? PBI is more of a click and drag interface and much more user friendly compared to pandas if its just Cleaning and Visualizing stuff. Is pandas much speedier in terms of raw performance compared to PBI?,True
@alexandermackintosh1755,2023-07-13T19:10:40Z,0,"Great video thanks! Can’t help thinking that tools like chatGPT, github copilot al, GPT engineer can pretty much tell you how to/do this all for you so maybe I am wasting my time learning this 😅",True
@L3GAT0Dantes,2023-07-05T20:39:19Z,15,"If you're getting an error when trying to split the address, this is what worked for me; I had to remove the number of values to look for.  df[[""Street_Address"", ""State"", ""Zip_Code""]] = df[""Address""].str.split(',', expand=True)",True
@ayomidealatake5244,2023-07-03T14:26:31Z,0,"Pls ...... I don't know how to remove ""\n"" (paragraph) from my value... I've tried strip,split, replace and all it not working",True
@goatsofcanton,2023-07-02T11:37:09Z,1,I saw Clark Kent's phone number went away in the RegEx step.,True
@cindystokes8347,2023-06-20T20:23:23Z,0,"Okay, everyone. Someone changed something somewhere, but in case you're having trouble dropping the rows, Bard helped me tweak it to work now:  for x in df.index:     if bool(df.loc[x, ""Do_Not_Contact""] == ""Y""):         df.drop(x, inplace=True)",True
@cindystokes8347,2023-06-20T20:15:30Z,0,I have been starting at your code and mine trying to drop the do not contact rows. It doesn't like when there's no colon. It doesn't like it with either. I'm stuck. And ChatGPT broke when I asked about it lol,True
@modern_jacob,2023-06-15T01:45:19Z,14,"If the df[""Phone_Number""].replace('[^a-zA-Z0-9]', ''"") is not working for you. Try, df[""Phone_Number""].replace('[^a-zA-Z0-9]', ''"", regex=True)",True
@Carnivore27,2023-06-06T13:26:17Z,0,"I was following the instructions to drop the column Not_Useful_Column. I was getting the KeyError ""...not in axis"".  They were lot of suggestions, one referring to missing axis=1, because it takes by default axis=0 (the rows). Nothing changed, kept getting the same error. So,  I decided to check the dataframe info with df.info(). And this is what it gives me:  <class 'pandas.core.frame.DataFrame'> RangeIndex: 21 entries, 0 to 20 Data columns (total 7 columns):  #   Column           Non-Null Count  Dtype  ---  ------           --------------  -----   0   CustomerID       21 non-null     int64   1   First_Name       21 non-null     object  2   Last_Name        20 non-null     object  3   Phone_Number     19 non-null     object  4   Address          21 non-null     object  5   Paying Customer  21 non-null     object  6   Do_Not_Contact   17 non-null     object dtypes: int64(1), object(6) memory usage: 1.3+ KB  It appears that the Not_Useful_Column does not exist!!!  strange or am I missing something?",True
@farahandini3799,2023-06-01T15:32:59Z,18,"I really like when you make mistakes, because it tells that no one perfect. I sometimes anxious when I watch tutorials and they seem to be so good. You also implicate the struggles that you experiencing throughout the process is real. Thanks for the tutorial Alex. ",True
@danielblum5691,2023-05-30T23:25:06Z,1,Thank you for this video. I just finished this part of the data analytics course and I definitely learned something new and helpful.,True
@omkar8101,2023-05-28T07:05:37Z,3,"Thanks a lot Alex for the video ! This was exactly what I was looking for. May I request you to try and upload video on how to write Python ETL code which uses table in a cloud database like snowflake, saves it in a csv format, transforms it and then again uploads it on snowflake. And all these steps are being captured in a log file which is in txt format !",True
@babelled7763,2023-05-27T20:41:30Z,0,"Thank you. One remark, dropna doesn't seem to work for Phone Number, because it's empty and not NA. Instead, we can do:  df = df[df[""Phone_Number""] != '']",True
@PoonamSingh-po1mp,2023-05-27T19:02:59Z,0,"In Python what is difference between NaN,Na and blank string(' ').Please explain",True
@ashwanikumarkaushik2531,2023-05-27T11:06:01Z,46,"This is one of the best videos regarding data cleaning I have ever watched. Really crisp and covers almost all the important steps. It also dives deep into concepts that are really important, but you rarely see anybody applying them. Must watch for everybody, who is looking to get into data field or are already in the field.",True
@Mohamed-Hassanin,2023-05-26T17:42:23Z,0,"Please , Please , Please Alex we need to know everything in depth everything about the new product Microsoft Fabric, and how this will impact on the industry and it's time to convert from Mac to Windows in sake of MS Fabric",True
@SearchingforScraps,2023-05-26T10:17:24Z,0,Great stuff ! Do a collab with Rob Mulla !,True
@Niranga.555,2023-05-25T14:52:58Z,0,"Alex, In another YouTube channel, mentioned your channel and suggesting learn Excel concepts from you. Nice to hear that you are a great teacher. https://youtu.be/Gw6hVMzna7g Thanks again for your great contents..",True
@W.xtar777,2023-05-24T21:13:21Z,1,"which one is better for data cleaning, Pandas or Excel ?",True
@enyinnayajaja,2023-05-24T20:54:18Z,0,Thank you Alex for this video on data cleaning with pandas. It is very detailed and explanatory,True
@ateebbinmuzaffar3136,2023-05-24T11:11:15Z,0,"Thanks for the detailed tutorial Alex. I was wondering, if i wanted to become a data scientist instead of a data analyst, would you recommend any people in the industry who I should follow? F.e is there an Alex the Data Scientist out there?😄",True
@Niranga.555,2023-05-24T09:20:34Z,1,"Hey Alex, Thanks for the super content ...!",True
@sachinmaroky4600,2023-05-23T22:02:30Z,1,thank you,True
@selimc3347,2023-05-23T20:39:59Z,1,Your work are amazing. Thank you so Much,True
@TJ-hu1oj,2023-05-23T19:21:49Z,1,"df[""Phone Number""].str.replace('[^a-zA-Z0-9]') can you please explain this line of code again in details. Thanks in advance",True
@alwaysbehappy1337,2023-05-23T18:31:16Z,2,"Thanks Alex, Please post more videos.",True
@TheWhiteboard2017,2023-05-23T17:39:39Z,0,"Alex i have a question regarding the part in 18:50 where you change the phone number column into string using the str() inside the lambda , can i get the same result using first df[""Phone_Number""].astype() and then do the lambda ?  or is there a nuance and it works only using str() ? Thanks for the great work !",True
@YR-up8vk,2023-05-23T16:19:11Z,2,"Thank you Alex for this detailed breakdown. Just a side note for those who don't like to use loops e.g. for, while  For 31:00, you could do the following code 'df.drop(df[df['Do_Not_Contact'] == 'Y'].index, inplace=True'",True
@dullfire8140,2023-05-23T15:05:29Z,2,"man lets go,you are our hero who can not afford paid courses",True
@rahulraj3855,2023-05-23T14:56:57Z,173,Fan from India I just got 2 offers from very good companies thanks to your videos and it helped me transition from a customer success support to Data Analyst,True
@villjack,2023-05-23T14:31:13Z,1,"My fav thing to do in pandas, thanks for making  tutorial.",True
@user-up3fr8ke7g,2023-05-23T14:11:57Z,0,Nice one Alex. Don't forget to add comments to the code! 🙂,True
@Vikram_8621,2023-05-23T14:09:50Z,1,Thank you Alex! 🙏,True
@ryuhayabusa3540,2023-05-23T13:50:00Z,1,Thanks for this,True
@RupeshBhandari-977,2023-05-23T13:32:33Z,2,Great we all make the mistake of creating a loop and not realizing that there is method just for that 😂,True
@lukekulak7165,2023-05-23T13:20:27Z,1,Yesss love these vids,True
@fitnessfreak984,2023-05-23T13:18:18Z,1,"Hey, Alex, I just Started your Pandas Tutorial, and I was waiting for Data Cleaning video, when i open my YouTube, First your Video is seen.. This is boon for me 😇🥺 Thanks, I hope you will Upload Matploib, Numpy and Many More Libraries video ❤🤗",True
@traetrae11,2023-05-23T12:58:16Z,2,Thank you Alex. That Lambda example is going to be very useful.,True
@mahfoud837,2023-05-23T12:58:08Z,0,"Thanks for the video , but im wondering how could i doing it if i treat thousandsof lines !!  How iterate all the lines to see what spécial character to strip ! How can i clean my data like this way for a big dataset ? 😮",True
@MegaDave8520,2023-05-23T12:41:34Z,8,"And I was already looking for some Pandas tutorial. Thank you, Alex, this was much needed. :)",True
@sumeetkajale3679,2023-05-23T12:40:54Z,2,"Hey alex, we don't need to take any course because you are there 😉  I am doing your bootcamp of becoming a data analyst",True
@A4O_TSL,2023-05-23T12:37:21Z,3,Alex your are the GOAT! for real thank you for all the tutorials and your help for everyone who want's to become a data analyst1,True
