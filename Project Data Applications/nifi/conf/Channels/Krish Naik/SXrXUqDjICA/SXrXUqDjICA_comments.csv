author,updated_at,like_count,text,public
@mansijadhav2997,2024-04-18T18:10:34Z,0,Thank you so much for the video! Is there a Part 2?,True
@DeepakKumar-mb2lw,2024-01-11T07:01:31Z,0,"Straightforward explanation! Thanks, sir.",True
@GoogleUser-nx3wp,2023-11-14T08:57:12Z,0,Mic quality very bad brother,True
@girikgarg8,2023-08-30T11:24:34Z,0,Done,True
@samraharif7510,2023-06-26T00:24:54Z,0,It is hard to connect your previous video to the next video. Please guide.,True
@w.a.imadhusanka1578,2023-04-20T06:37:10Z,0,The things taught are well understood.thank you sarü•∞ü•∞üòáüòá,True
@user-mu7fe8mh4b,2023-03-26T05:34:00Z,0,Can I apply Sigmoid on a set of neurons in hidden layer and Relu on another set of neurons ?,True
@user-yg6cm4lb3x,2023-03-06T14:59:16Z,0,hi MR krish  where part 2 about Type activation function ?,True
@mohammedkareem549,2022-12-19T08:07:50Z,0,we depend on what? to select suitable Act function?,True
@mahfuzraihan8690,2022-09-30T15:21:45Z,0,"a nice explanation, but I got confuse on ReLu activation function, max(-ve, 0), (+Ve, 0) and related graph. Please could anyone help me to understand this term.",True
@sohamajgaonkar3119,2022-09-22T18:47:02Z,0,sir plz upload part 2 of this video,True
@kin_1997,2022-08-02T17:36:00Z,0,amazing,True
@kanchanapallynikhilsai4347,2022-07-04T17:16:33Z,0,Thanks bro,True
@satya8411,2022-04-20T13:33:17Z,0,Sir what's the intuition behind relu,True
@user-lx5yp8rg4z,2022-04-07T20:48:13Z,0,The graph of sigmoid is incorrect... at 0 it should be 0.5,True
@jaisvarghese7304,2022-03-29T12:21:18Z,0,"the curve of sigmoid is wrong, half comes in the negative x axis...",True
@abdulqadar9580,2022-03-09T19:43:07Z,0,Amazing Sir,True
@priyankagupta5538,2022-03-09T14:45:40Z,0,plz provide me part-2,True
@PushpendraSingh-ub7if,2022-03-09T05:57:05Z,0,Sigmoid and ReluoidüòÅ that was human neural network at worküòÇ,True
@elahmedi24,2021-12-29T07:39:50Z,0,Dear Krish who is activating your activation function in your body?                                                                                               Simply God is activating. SO do you worship Allah?,True
@ashwinshetgaonkar6329,2021-12-02T09:52:24Z,0,what is activation is explained but why we need one is not,True
@SalmanIbne,2021-11-19T12:24:29Z,0,All of your videos are really helpful...great explanation :),True
@prashanths4455,2021-10-28T14:28:37Z,0,"though sigmoid graph is wrong, krish explanation is super.",True
@maithiltandel4762,2021-07-19T14:51:38Z,0,"Hey Krish! in one of my regression problems I have used relu, but sigmoid is giving much better results, what could be the explaination for that because i have been in that confused state for months now and so started to brush up on my basics!!",True
@kingdomman1078,2021-05-04T08:35:14Z,1,I sincerely like your enthusiasm as you teach. Thanks!,True
@louerleseigneur4532,2021-04-17T12:35:32Z,0,thanks sir,True
@mukund198526,2021-04-07T02:28:14Z,0,Hi Krish...why Activation Function Part 2 is not part of this playlist?,True
@harikrishna-harrypth,2021-03-29T10:02:47Z,1,the G.O.A.T(Teacher) of AI tutorials = KRISH NAIK!!!!! Thanks much for taking your valuable time to make these tutorial videos!!! GOD BLESS YOU MUCH!!! üôèüôèüëçüëçüëåüëå,True
@priyagrandhi7918,2021-03-03T11:24:03Z,0,"ur just awesome,u r deep learning videos are very clear and easily understandble by everyone,Thanks a ton krish",True
@satishkundanagar3237,2021-01-28T16:34:58Z,10,"Sigmoid function converts -inf to +inf values to range between 0 and 1. 0 and 1 would be asymptotic values. Also, in the graph the sigmoid function passes through y-axis=0.5 when ""y=0"".",True
@hiteshnettam3188,2021-01-15T07:39:43Z,0,"if I am not wrong, the sigmoid activation function is depicted incorrectly. Please look into it and would suggest an edit if possible to make one.",True
@AkashRaj-if6di,2021-01-11T07:50:38Z,0,bias will add separately with each Wi*Xi or with whole???? i am asking (W1*X1 + B1) + (W2*X2 +B2) + (W3*X3 + B3) OR (W1*X1 + W2*X2 + W3*X3) + B..............WHICH ONE IS CORRECT???,True
@bibhupadhy4155,2020-12-26T10:27:56Z,0,"For Sigmoid Activation Function, The value of y at x = 0.5 should be 0.5 , What you are showing is a x axis translated sigmoid activation function, You may have missed it, Krish. Kindly recheck !!",True
@vaibhavgupta4413,2020-11-27T16:21:22Z,1,Thank u sir Respect üôèüôèüôèüôèüôè,True
@codesandroads,2020-11-18T09:19:09Z,1,"Krish many people want part 2 of this, if this is uploaded on your channel please pin this comment and provide the suitable links, we all are face same problems while learning.",True
@rakshitraushan1650,2020-11-11T10:24:22Z,2,I think u r the only one who is gonna make my DL awesome,True
@sakshijaiswal1135,2020-10-28T15:51:13Z,0,I think formula will be y= 1/1+e power(-x),True
@santoshkumarsabat4086,2020-10-16T09:47:25Z,1,‚ù§Ô∏è‚ù£Ô∏è Thanks ‚ù§Ô∏è‚ù£Ô∏è,True
@shubhangiagrawal336,2020-10-15T12:20:41Z,1,part -2 video plzzzzz,True
@hariprasad1744,2020-09-04T07:16:37Z,0,Can you please add part 2,True
@deokumarjnu,2020-08-30T02:53:20Z,0,"Hello Krish sir, in which case the value of y will be negative for Relu AF ? I just started learning Deeplearning along with ML.",True
@naveenvinayak1088,2020-08-28T02:20:39Z,0,krish can we expect Activation Function Part 2 ?,True
@SuryaPrakash-xf5jv,2020-08-27T15:55:35Z,0,"currently i am a data science intern, and suddenly i got to know about your videos. All the concepts are explained really nice. Though i know all the basics, but i again i will watch each and every video of yours. Thanks a lot for this amazing course.",True
@kumarpiyush2169,2020-08-03T15:43:08Z,0,"Hi Krish.. Sigmoid function delivers the output in the range (0,1), then how we get the value as 1 or 0 in the case of classification problem. I know - in the logistic regression, if the output is 0.5 or greater , then the result is 1. Here sklearn takes the output from sigmoid in the range (0,1), then converts the output further.",True
@abhishekmanral9476,2020-08-02T19:39:04Z,0,Why did you not make its part 2 I'm in middle of the understanding..,True
@laxya6779,2020-08-01T22:24:25Z,0,Best videos on YouTube thank you so much sir üòá,True
@anilkshirsagar5624,2020-07-26T17:40:29Z,0,Best way to teach...,True
@vinayak186f3,2020-07-20T19:41:38Z,0,Could you plz upload the 2nd part of this .,True
@himabinduh7623,2020-07-06T13:51:36Z,0,Sir could u plz upload the 2nd part...,True
@blackkingrg3867,2020-07-05T16:02:58Z,0,i was wondering why this youtube algo doesn't show the second part of Activation Function. got answer in the comments . please upload the second part of the activation function.,True
@akrsrivastava,2020-06-23T19:44:10Z,1,Activating functions are required because they introduce non linearity.,True
@Thelaunius,2020-06-18T11:07:59Z,0,How can RELU return a binary output?  Sigmoid was already between 0 and 1 and we used a threshold.  But RELU just returns a positive number or zero. How can we make it return 0 or 1?,True
@souravbiswas6892,2020-06-08T20:55:46Z,1,What about softmax? Can you explain that as well?,True
@ashishchandra8391,2020-06-04T19:21:39Z,1,Sir waiting for part 2.........,True
@siddharthdedhia11,2020-05-25T20:29:14Z,0,"Hello Sir , can you upload part 2?",True
@chayankathuria7801,2020-05-03T15:05:46Z,1,"Incorrect graph of the Sigmoid function is shown. At y=0, it should be at 0.5 and not 0.  Please correct it",True
@soumyaranjansethi1790,2020-04-27T12:37:25Z,0,"Hi krish nice video ,I don't find the part 2 of activation function could you please help me if possible",True
@deepanshupant8282,2020-04-21T09:33:00Z,1,Is it the complete playlist of deep learning Sir or will u upload more..,True
@mathai1003,2020-04-16T15:50:37Z,0,Nice explanation http://mathai.co/2020/04/activation-function,True
@sandipansarkar9211,2020-04-14T21:30:40Z,0,Hello Krish. Just finished this video.With your style of teaching I don't believe in making notes.I hope I am correct from the interview standpoint.Please guide and do reply.Thanks,True
@praneethaluru2601,2020-04-01T20:23:02Z,0,What is the difference between Sigmoid  Activation and Batch Normalization?,True
@shashiyadav4528,2020-03-29T14:08:11Z,0,Really good,True
@Adinasa2,2020-03-29T06:11:38Z,0,Please give us an example of use case of relu function in case of regression,True
@nandalala7915,2020-03-16T18:40:02Z,0,What if Val is 0.5 Will it accepted to 1 or 0?,True
@aghileslounis,2020-03-07T10:15:20Z,2,great video ! PART 2 please !,True
@mizgaanmasani8456,2020-03-06T20:13:48Z,0,In sigmoid function why always 0.5 is the value in y-axis used for classifying data?,True
@Thelee4music,2020-02-24T18:21:49Z,1,"Wonderful explanation of the topic, but please remove this extra wind noise from the video ...its irritating, I am so sorry had to say this.",True
@madhugarg7499,2020-02-09T18:22:23Z,18,"Hi Krish...Can we expect Activation Function Part 2 ? Most of the subscriber has requested the same, hope you will post it !!!",True
@ravineeshgoud8145,2020-02-09T00:14:01Z,1,Why the sigmoid function is starting from the origin ?,True
@madhugarg7499,2020-02-03T13:22:36Z,14,It's just Awesome as usual...Could you please upload the Activation Function Part 2 Many of your followers are requesting the same. So please upload it.,True
@simanchalpatnaik2566,2020-02-02T06:22:23Z,6,Please upload Activation Functions part 2 video,True
@akshat9722,2020-01-26T07:49:44Z,0,I think what you mean is receptors pickup signal from hand and then pass to the neuron with increased weight.,True
@dipayanroy8357,2019-12-22T18:33:04Z,2,Great video. Appreciate the effort,True
@saravananshanmugam4116,2019-12-14T14:30:53Z,0,softmax pls,True
@veerabhimanyusingh779,2019-11-30T17:00:57Z,0,sir ....!!! a general sigmoid function reaches to value 0.99 by (w*x+b == 6 or 7) and reaches to value nearly zero if (w*x+b == -6 or -7) i want to widen the range let us suppose i want 0.99 value if (w*x +b == 30),True
@ananthakumar7048,2019-11-28T09:15:05Z,0,how to take the weight value bro,True
@rakeshacharjya8512,2019-11-20T13:46:22Z,32,Why the Activation Functions part 2 was not uploaded,True
@uncommon_common_man,2019-11-14T05:11:04Z,0,very useful best quality videos,True
@kamal6762,2019-11-13T19:08:27Z,0,"in case of the ReLu function is the value of ""Y"" or ""X""? means if the value of ""X"" is positive than the value of ""Y"" is positive or what?",True
@muhammadjaffarrazadar967,2019-11-04T19:52:21Z,0,Very Helpful. please make videos in hindi also,True
@svishaliyer2254,2019-09-30T05:37:24Z,3,"Hi  Krish I have 1 question. what if in sigmoid activation function, we get value equal to 0.5. Because in other cases we have either value greater than 0.5 or less than 0.5",True
@mdenamulhaque7589,2019-09-27T13:51:05Z,0,in one word... awesome.........go ahead,True
@sudipsen04,2019-09-23T17:48:56Z,2,Please mention the link of part 2 didn't found in Playlist.,True
@ramleo1461,2019-08-25T08:54:48Z,9,"Hi,  Your videos are helpful.  Is there activation function part 2??",True
@parakhsrivastava7743,2019-07-21T05:30:38Z,3,"Nice explanation... Sigmoid works for multi class classification too? But how, because it gives values between 0 and 1?",True
@kothapallysharathkumar9743,2019-07-18T15:39:57Z,1,hai sir please explain about bias and weights,True
@sekharpink,2019-07-18T10:39:07Z,1,"Hi Krish,   One question. If the output value of record after applying sigmoid activation function is  < 0.5 then output is 0, if it's more than 0.5 output is 1. What if the value is exactly 0.5 i.e. what is the output in this case?",True
@ga43ga54,2019-07-18T05:36:08Z,1,Can we have Live Q&A session with you?,True
@sriramswar,2019-07-17T20:47:14Z,8,"Very good and To-the-point explanation. A small suggestion. If the videos are prefixed by Serial numbers, then it would be easy for reference. Eg:  ""03. Activation Functions Part-1"" as this is the third tutorial in this playlist. Same suggestion applies to your earlier playlists too. Thanks for understanding!",True
@nullf6950,2019-07-17T17:41:45Z,2,I like this whiteboard set up. As always great video,True
@shaz-z506,2019-07-17T12:59:05Z,6,"Good explanation Krish, please tell more about vanishing gradient problem arises and how RELU can help in such a scenario.",True
@meanuj1,2019-07-17T12:58:31Z,1,Thanks for classroom type lecture,True
@chinnam8053,2019-07-17T12:40:41Z,0,Bro...I like to learn from u..please share ur details for contact u,True
@soumyasrm,2019-07-17T12:06:44Z,1,Nice explanation sirq,True
