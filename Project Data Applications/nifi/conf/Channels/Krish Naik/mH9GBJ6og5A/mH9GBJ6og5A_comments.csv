author,updated_at,like_count,text,public
@liass6354,2024-05-25T19:29:38Z,0,thank you for making this video! hope I can get a good grade in next week exam on AI,True
@aneeshkrishna4375,2024-03-24T04:20:34Z,1,I have paid fortunes to do masters in data science and ended up watching your videos. You deserve a nobel prize for all these videos.,True
@yashub9580,2024-02-17T09:02:51Z,0,what is the meaning of derivative here??,True
@deepknowledge2505,2024-01-10T19:08:53Z,0,"Backprobagation with example, very simple  https://youtu.be/EQPjZwyBa1g",True
@thundertech4025,2024-01-02T07:47:08Z,0,Thank you so much sir,True
@sajidalam1989,2023-11-29T16:57:49Z,0,well explained!!,True
@yashdeshpande9202,2023-11-21T07:13:44Z,0,"I think that , during the probleme discussed about pass or fail i.e. binary classification the loss function should not MSE . It should be cross entropy loss i.e. -ylog(y)+(1-y)log(1-y)",True
@user-ti8su2jx9z,2023-09-25T02:38:28Z,0,üôè,True
@adityashewale7983,2023-07-24T03:42:51Z,0,"hats off to you sir,Your explanation is top level, THnak you so much for guiding us...",True
@isiomalisaclement6254,2023-07-18T12:26:49Z,0,This channel is a discovery...you have been able to cut through all the jargon and make these theories less abstract. Thank you very much,True
@nuamanjaleel5430,2023-06-26T16:21:31Z,0,"Sir could you please explain back propagation with an example, It would be of great help as that's the part where most of us make mistake",True
@sapnilpatel1645,2023-06-08T16:32:09Z,0,so far you are the best teacher.,True
@naresh8198,2023-05-24T09:52:44Z,0,"you have explained  it in the simplest way ,Thank you !",True
@anahi_kr8235,2023-05-21T09:39:26Z,0,Thankyou sir,True
@w.a.imadhusanka1578,2023-04-20T06:48:46Z,0,The things taught are well understood.thank you sarü•∞ü•∞,True
@kathanparekh6135,2023-04-19T16:07:57Z,0,can you please provide notes???,True
@priyasanthakumara6520,2023-04-16T16:30:57Z,0,Amazing....great job with lot of thanks....,True
@kaustubh27961,2023-04-16T12:39:57Z,0,What is epochs sir?,True
@jaideepraulji1395,2023-04-16T06:29:27Z,0,Depth plus Simplicity means Krish Naik,True
@_al00sk,2023-04-12T13:17:18Z,0,Your style of explanation is helping me a lot - thanks for these videos!,True
@user-xd4cl3qd8x,2023-04-03T11:47:51Z,0,"Well done bro, simple and precise",True
@shikhajangra2760,2023-03-09T18:10:50Z,0,"thank you so much sir, your way to simplify this problem is very nice.üëçüëçüëçüëçüëçüëçthanks again sir.",True
@harshaddeshmukh2935,2023-02-19T18:41:40Z,2,"Krish sir you are really amazing! You have made difficult concepts simpler! Our teachers are not able to do this, but you have done it very well! Thanks for being with us in this learning journey!",True
@harshalibhoyar6768,2023-01-05T08:05:59Z,0,khatrnak sikhata he ye banda...... ek bar dekh lo pure dhyan se fir nind mai bhi koi puch le no issue ....chhap jata h dimag mai ......,True
@travel_for_life9727,2023-01-05T03:30:04Z,0,Sir do we need to update bais when we do backward propagation,True
@pravachanpatra4012,2023-01-02T02:27:22Z,0,2:00,True
@yezewotirbirhanu3944,2022-11-13T15:14:12Z,0,great,True
@manjotsingh7602,2022-11-03T11:08:22Z,0,but why you take regression error as loss function as example was of binary classification & likelihood error will be used,True
@codderrrr606,2022-10-15T16:03:54Z,0,bro all these videos simply tells how deeply you have the knowledge of deep learning,True
@akashsinghdahiya5862,2022-10-03T11:52:19Z,0,üëçüëç,True
@vdharek,2022-07-17T16:10:23Z,0,Thanks Bhai.,True
@indranisen5877,2022-07-13T10:43:28Z,0,"Excellent, you are our confidence!",True
@shruthikeerthi6231,2022-07-06T15:23:21Z,0,excellent sir.sir what is learning rate,True
@islamuddin6021,2022-06-04T12:56:38Z,0,"Amazing work, sir gi, love it, And Thank you for such a concise and understandable explanation.",True
@indirasakthivel716,2022-04-13T21:57:18Z,1,You are genius!!! No other instructor can teach in 10 minutes this complicated conceptüëèüëèüëè Thank youüôè,True
@mimansatripathi6888,2022-04-12T02:46:14Z,0,"sir, what is epoch?",True
@abdulqadar9580,2022-03-09T20:14:42Z,0,Thank you Sir for your great efforts,True
@ochanabondhu,2022-03-05T22:22:34Z,0,"Wonderful video. Just one question, why we are not taking the mod value of the Loss function and going for squared values?",True
@bivasbisht1244,2022-02-21T10:33:13Z,0,what an Explanation !!!! amazing,True
@mallu_boy123,2022-02-19T16:55:25Z,0,learning in 2022,True
@almassaba9377,2022-02-10T06:26:51Z,0,This was amazing. Thankyou Kris. Thankyou for existing.,True
@danilzubarev2952,2022-02-09T11:43:32Z,0,"How is everything makes sense? Wow, so inspiring! Amazing.",True
@nagrajwellness9720,2022-01-21T21:13:37Z,0,Mind blowing video sir this is the main difference between you and others other institutions run behind the money,True
@RanjithKumar-jo7xf,2022-01-13T05:42:06Z,0,"Nice Explanation, I like the way you teach.",True
@venkateshc5286,2022-01-10T16:29:28Z,0,itll be a good thing if you add subtitles...,True
@iamdare,2021-12-09T18:39:02Z,0,"Wow man, you‚Äôre a blessing. Thank you for this great teaching, you simplified everything.",True
@maralazizi,2021-11-14T17:20:07Z,0,Best tutorial about deep learning ever!! Thank you so much for making it easy to understand! You are very much appreciated!,True
@sanchitsawant4450,2021-10-06T21:26:53Z,1,Sir I don't know why but whenever I watch your videos I get motivated to go in the more depth of  that particular topic.Thank u sir sharing such valuable content for free .,True
@vishaljhaveri6176,2021-10-02T12:40:04Z,0,Nice video. Thank you sir.,True
@anshi6205,2021-09-07T07:00:32Z,0,Your lectures is amazing and very helpful but you looks so serious in every video,True
@satirthapaulshyam7769,2021-08-18T10:43:57Z,0,Btw how the loss function has defined.like lets suppose u have given a random weight first  and depending on that u have get a average lost value for all the train sample.so for a specific set  of weight u r getting a specific lost value than how u r getting a function.cz u have just got a specific output  for a specific input.it Doesn't make anysense about the costfunction,True
@karthickd537,2021-08-02T16:27:11Z,0,What is a learning rate? how to define that?,True
@premranjan4440,2021-07-22T15:14:59Z,0,So neural network works in Supervised Machine learning!,True
@citoyennumero4434,2021-07-16T06:59:15Z,0,"Simple et concis, je vous remercie pour l'explication :) :)",True
@daddyofalltrades,2021-07-04T05:23:01Z,0,You are highly underrated üî•,True
@poojaav7972,2021-06-03T07:41:08Z,0,what is weights here (i know its a parameter) but why it is necessary here.i am new to this field.Thanks in advance,True
@movie4dilip,2021-05-31T06:28:45Z,0,How to compute learning rate?,True
@affiliatastic1269,2021-05-25T11:32:41Z,0,"@krish you make way more sense than Andrewng , seriously",True
@HungNguyen-pr5ci,2021-05-23T15:47:02Z,0,Man thank you so much,True
@suryakirannvs,2021-05-20T19:32:45Z,0,Thank you Sir. Amazing.!!! Derivative: Ratio of change of dependent variable w.r.t independent variable,True
@harshshah2916,2021-05-04T07:51:19Z,0,"Sir, where is Activation Function Part 2",True
@sagardesai1253,2021-05-01T06:06:27Z,0,Awesome explanation üëå,True
@souravdey1227,2021-04-23T03:20:14Z,1,Finally the stuff I had been looking for. Simple and to the point.,True
@sudhanshukumawat3872,2021-04-19T06:15:03Z,0,nice Explanation  :),True
@ftt5721,2021-04-18T07:52:36Z,0,maza aa gaya...awesome,True
@louerleseigneur4532,2021-04-17T12:39:43Z,0,thanks sir,True
@subhadipghosh8194,2021-04-16T11:43:37Z,0,"@Krish Naik As this is a classification problem, how can it use squared error as a loss function?",True
@classictremonti7997,2021-04-12T13:24:08Z,0,Hi Krish...I love this video series!  I am curious if you have a PhD in data science or similar?    Not that it matters at all because your explanations are much clearer than any papers I have seen even from top researchers in this field!    Keep up the great work!,True
@pranjalsingh1287,2021-04-08T09:21:37Z,0,I  have watched many videos on coursera as well as my college profs way of teaching but no one matches the simplicity you have.,True
@girish2555,2021-03-31T05:47:57Z,0,Simply great üôè,True
@bilalghauri6516,2021-03-21T14:57:19Z,0,(1):why we use loss function   (2): how should we know that the loss value is minimal or increased (3): where should we find the learning rate?,True
@saikiran-sq8zz,2021-03-20T09:48:28Z,0,How do we define weights is it user defined or else predefined.. ?,True
@miteshmohite7829,2021-03-20T07:09:00Z,1,I want to know how does each observation gets trained over here you have used just one one observation,True
@ashwanikumar-zh1mq,2021-03-13T12:31:32Z,0,In classification the loss function should be different like log loss here sir you use regression loss function please correct if I am wrong,True
@hashimhafeez21,2021-03-12T12:57:45Z,0,pretty great explanation,True
@rohitjagdale4648,2021-03-09T07:41:44Z,0,Excellent explanation !!! One question : what happens to biases in backward propagation ?,True
@vasachisenjubean5944,2021-02-25T17:48:32Z,0,"the man, the myth, the legend",True
@akashgarg5770,2021-02-04T06:16:41Z,0,"Great Video. Sound is too low, please increase sound",True
@srishtikumari6664,2021-02-01T11:09:09Z,0,How to visualise neural network training for multiple records? Does this happen parallely?,True
@cybergame.,2021-01-31T03:53:11Z,0,Sir your videos are much more better than coursera courses...........Thank You.,True
@foxfinance9362,2021-01-28T22:18:01Z,0,simply the best,True
@satishkundanagar3237,2021-01-28T18:08:45Z,1,"Could you please clarify my following doubts? Thanks in advance.  1. Are you using any affine function and/or activation function in the output layer node in order to calculate y_hat? Reason being, weight W4 is passed as input to the output layer node and no details are mentioned about the usual two step process that take place in every node of the neural network i.e. an affine function (where weights are actually used) and an activation function. 2. Is it or is it not the cost function is average of the loss function for individual training samples? Cost function is defined as summation of loss function in this video and not average? 3. I'm not clear on why propagation helps in tuning the model parameters. Back propagation and Gradient descent work together in tuning the weights. Mathematically and geometrically I'm not convinced with the statement ""back propagation is used to train the weights of a neural network"".",True
@2die4mario,2021-01-16T12:37:24Z,49,This is really simplified. Greatly appreciated. Much better than those university professors who get obsessed in the math without  showing the audience the big picture !!,True
@sukumarroychowdhury4122,2021-01-07T03:15:24Z,0,Great,True
@venkateshmorishetty5489,2021-01-05T07:37:42Z,0,"Hi sir, what is the reason behind derivating loss with respect to weights. with that what we will get?",True
@pareshb6810,2020-12-27T16:13:12Z,2,Underrated content!  Keep up the good work! üíØ,True
@bibhupadhy4155,2020-12-26T10:37:20Z,0,"Krish, I think it would have been better if you would have taken , Regression example and explained it , Coz the loss function you are showing over here is squared error, which is not the correct loss function for a classification problem, rather binary cross entropy is . May be you can rectify it. :).  Even the cost function , You forgot to divide it by number of samples .",True
@hemajalmoru3837,2020-12-08T18:20:52Z,0,"baaki 2 activation function bola tha next, it's missing.",True
@mohammedmunavarbsa573,2020-12-07T09:02:10Z,0,super bro,True
@_JoyshreeMozumder,2020-11-27T13:15:44Z,0,excellent,True
@rakshitraushan1650,2020-11-10T19:28:36Z,0,Clearly the best DL and ML teacher!,True
@_bohemian2778,2020-11-06T06:15:57Z,0,I don‚Äôt understand why we decrease loss function? Can Anyone explain to me?,True
@_bohemian2778,2020-11-06T06:12:53Z,0,‚ù§Ô∏è‚ù§Ô∏è,True
@AgaGrusz,2020-10-21T09:31:53Z,2,You are what I needed. Thank You soooo much :),True
@varunss9057,2020-10-08T20:11:02Z,8,I am  new to deep learning. The content you provide helps me understand the concept from the very basic and this clarity i could not find in any videos. Keep up the good work!!!!!You are doing a great job.,True
@niazmorshedulhaque4519,2020-09-22T15:32:59Z,0,sir please upload activation function II lecture,True
@sriramanramalingam9892,2020-09-05T15:27:56Z,0,"Sir, thanks for providing wonderful videos. Sir if possible could you provide a basic explanation for  construction of neural networks in equation format (in first order differential equations) including state vector, activation functions. Thank you sir",True
@madanmohanpachouly6135,2020-09-05T05:55:48Z,0,Good explanantion,True
@chandrimad5776,2020-09-01T05:59:49Z,0,I did not get activation functions part 2 video. Can you kindly upload that if you missed it?,True
@vamsinadh100,2020-08-24T08:25:37Z,0,watch this only if you know about gradient descent,True
@vivekkumarsingh3966,2020-08-23T04:15:06Z,0,üôèüôèüôèüôèüôèüôè,True
@skipjack02,2020-08-21T19:46:34Z,2,Thanks for turning off the fan! :D,True
@TheJyotirocks,2020-08-18T10:55:33Z,0,Keep it up.,True
@laxya6779,2020-08-01T22:37:36Z,17,I came here after watching Coursera course and I think it's more clear and magnificent ü§§,True
@commonboy1116,2020-08-01T03:15:06Z,0,Way you have explain complex topic in such simple way ......,True
@jpdubey1765,2020-07-29T13:21:26Z,0,Inspirational story about importance of Being a balanced controller https://youtu.be/4BiKhka7APc,True
@jessiedavis2628,2020-07-24T17:33:02Z,0,Good explanation,True
@diecastboiis5825,2020-07-24T11:17:13Z,0,Please upload activation part 2,True
@anilchauhan-kl9of,2020-07-13T03:03:18Z,0,Do u have videos on YOLO and SSD?,True
@anikethdeshpande8336,2020-07-11T18:35:51Z,4,The best explanation on NN I've ever seen so far. Thanks for going ahead step by step and explaining in simple words,True
@praveenkumar-nh5qs,2020-06-26T07:21:56Z,0,"If ≈∑ and y is same at first attempt only, then backward propagation happens in that case ?",True
@hari.prasad_,2020-06-24T02:08:51Z,0,This course is simple and clear than most of the courses out there.,True
@priyanath2754,2020-06-23T07:54:29Z,20,"I have taken courses in other platforms, but I must say, the simplicity I found in your explanation helps me grab the topic much easilyüôèüôèüôè",True
@burhangarari8164,2020-06-22T11:30:56Z,0,Does the bias associated with the neuron in the hidden layer also need to be  updated during backpropagation?,True
@manukhurana8042,2020-06-20T11:09:53Z,1,"hi krish , At 3:30 you said we can do square to make it +vs , we can also use |mod| to make it +ve.",True
@chahinezhigoun1078,2020-06-17T22:00:20Z,0,This is the best explanation i'v ever seen thank you so much,True
@dushyantsingh4278,2020-06-14T06:43:09Z,0,Thank you sir for clearing all the doubts by this video,True
@amartyabasu9552,2020-06-12T09:43:03Z,0,When backpropagation will stop reducing lost function?,True
@sarkandawale,2020-06-05T15:03:41Z,0,"Sir there is one thing for sure  to tell u,  your way of teaching is so relatable and hence easy to understand,  Also very effective, I've  went through so many tutorials and lectures but it is all making sense now in your video, I m very thankful to u sir keep teaching,. u r a  great teacher.",True
@siddheshbhure1009,2020-06-04T13:15:49Z,0,is it dW3 at 7:04 ?,True
@akiya2112,2020-06-03T21:24:53Z,1,"thanks sir but I have one question how can I get w1,w2,w3.... from the beginning?",True
@computeropedia,2020-06-02T10:13:59Z,0,You saved me.. Thank you,True
@manikantamamidipaka6876,2020-05-24T14:37:18Z,0,"Thank you Mr.Krish, you just nailed it.  I have a question here, how to find loss at any hidden neuron for backpropagation purpose since we will not be knowing the actual value at any hidden neuron except at the output node, right? then how? Thanks in advance.",True
@BiprojitNath,2020-05-22T07:09:30Z,0,excellent!,True
@Jane-ce2dq,2020-05-14T09:36:03Z,0,Very clear,True
@Jane-ce2dq,2020-05-14T06:48:46Z,3,Krish thanks for work. Tutorial 4 supposed to be Activation function part 2.,True
@RAVINDRABACHATE,2020-05-13T15:16:20Z,1,"Your are great. The way you explains, anyone can understand. Thank you.",True
@mdsaif831,2020-05-13T11:17:18Z,0,best trainer i have ever seen....,True
@aajaykapoor,2020-05-10T19:38:57Z,0,"Hi Krish.... I am a regular learner from your videos, this is great. I have a question, in the forward propagation for the very first iteration where and how do we get the values of weights?",True
@arpittiwari6590,2020-05-10T15:11:30Z,1,Sir I had watch more than 10 videos but didn't understand now in 9 mint I had understood very well. Simply awesome!!!!!!!!!!!,True
@kosk1997,2020-05-05T20:59:03Z,0,The best video so far. So clear and crisp. Hatsoff sir!!,True
@seedcardsstore882,2020-05-04T07:56:49Z,0,you make this topic seem so easy!!!!! Thank you!,True
@taoufiksouidi6060,2020-05-02T22:30:26Z,0,thank you very much sir!! u gained a subscriber.,True
@rahulagnihotri344,2020-05-02T05:35:12Z,0,üëåüëç,True
@mashroorsakib4006,2020-04-26T19:31:50Z,0,Awesome explanation sir. Thank you for sharing your knowledge,True
@sandipansarkar9211,2020-04-15T19:18:46Z,0,That was a superb video.But now things are getting tougher and tougher.Need to cope up with.,True
@mohitrock100,2020-04-12T15:37:11Z,4,Great Video Sir. I haven't seen such a simple explanation of such a brainstorming concept. Many people just take days to understand Backpropagation and here you have cleared my concepts withing 10 minutes.,True
@RAZZKIRAN,2020-04-05T05:32:40Z,1,GD vs SGD vs PSO vs GA ? please give the efficiencies of these optimizers?,True
@adityasharma2667,2020-04-02T18:08:37Z,0,Sir in Your cost function what is the significance of (n)??,True
@praneethaluru4801,2020-04-02T14:44:35Z,0,Literally great explanation brother.,True
@fthialbkosh1632,2020-04-02T06:58:15Z,0,"Thank you, Sir, for your sharing, with perfect explanations.",True
@ruchit9697,2020-04-01T10:21:28Z,0,How can you calculate Mean squared error for a classification problem.... maybe you should have gone for cross entropy loss,True
@Adinasa2,2020-03-29T06:53:20Z,0,Till how many epochs will the back propagation happen,True
@mehakrajput1649,2020-03-20T12:25:50Z,1,Thanks sir. I found your tutorials interesting. I have a question ... what is global minimum and Gradient descent the words that you have used in your lecture. Can you please elobrate. If any video related to thz is available kindly share the link. Thank you,True
@devgak7367,2020-03-08T14:07:03Z,10,you just nailed it. Simplicity of his explination is unmatched anywhere. Thanks you sir.,True
@satyajitrajbanshi3620,2020-03-07T05:52:30Z,0,What is global minima sir and why is it required to be reached..? is it the point where the losses will be minimum?,True
@yuvi12,2020-03-03T13:54:01Z,0,use back propagation to  work reduce the error to go update weights and also bias?????,True
@shawnsingh9605,2020-02-23T23:31:52Z,1,How do I get access to Tutorial 2 of Tutorial 1- Introduction to Neural Network and Deep Learning,True
@vishwaskabbur4367,2020-02-20T16:14:12Z,0,perfectly explained !!! Simple and to the point !... Kudos ....,True
@sumanthpichika5295,2020-01-30T11:21:57Z,0,"Hi Krish, if we suppose have 20 data points and initially will do the forward prop for all the 20 data points and calculate the loss. if the loss is high then will back propagate by updating the weights using(Wnew=Wold-learning_rate*(derL/derWold)) for all the weights  and  again will do it for multiple epoch's untill we convergent. Is it correct?",True
@97-bibhutiswain59,2020-01-20T18:23:38Z,2,Sir what is the learning rate (n),True
@shahrzadamini140,2020-01-15T09:43:48Z,0,It was perfect. Thanks a lot,True
@RS-el7iu,2020-01-06T17:39:34Z,0,the best explanation...simple n straight to the point. thanks alot,True
@mohdazam1404,2019-12-30T11:48:19Z,3,"Damn good explanation .... One question, how we choose learning rate??",True
@ananthakumar7048,2019-11-28T09:13:57Z,0,please provide the code and code explanation,True
@Qutybar,2019-11-20T08:42:25Z,1,You deserve 1M like,True
@premurmaliya1753,2019-11-17T18:47:32Z,0,Please  provide  some coding video,True
@satyamuralidharpeddireddi6192,2019-11-11T06:56:17Z,0,loss function reduced upto to zero right,True
@chandnisoni5108,2019-11-10T11:28:02Z,5,Awesome playlist. Thank you for sharing your knowledge üòäü§ü,True
@mhdomarbahra1678,2019-11-09T11:51:59Z,7,magnificent explanation the simplicity is perfect hard is made easy with you thanks!,True
@muhammadjaffarrazadar967,2019-11-06T17:35:49Z,0,"Thank you, Sir",True
@manishsharma2211,2019-10-29T17:50:34Z,1,Mahn. You are too good,True
@fet1612,2019-10-23T14:39:22Z,0,@Krish Naik How methodical your work is! Brilliant! Keep it up. Your videos clarify things lucidly.,True
@AmitYadav-ig8yt,2019-10-14T13:04:45Z,1,"Thank you, Sir, May you please  make videos on Unsupervised ML algorithms ?",True
@satarupapanda7774,2019-09-25T13:44:16Z,2,sir please upload activation function part II,True
@sudipsen04,2019-09-23T18:07:01Z,0,Give me some light in learning rate,True
@Abhishekpandey-dl7me,2019-09-18T14:59:29Z,0,thanx a lot,True
@DANstudiosable,2019-09-12T18:20:29Z,0,Well explained... So back prop and fwd prop both happens in 1 epoch at the same time?,True
@NaveenDama,2019-08-29T04:32:25Z,0,How the Initial weights are decided for the features?,True
@akshaykumarsingh9770,2019-08-28T06:26:42Z,0,"Sir, to decrease loss we adjust weights but what are the ways of adjusting weights? Any example in which we can see the weight are getting adjusted.",True
@MrVivekc,2019-08-25T10:50:51Z,0,How weights are defined. I am still not clear with this.pls explain. Thanks in advance.,True
@laxminarasimhaduggaraju2671,2019-07-24T05:49:39Z,2,Krish I have one query  How can we decrease the loss function when the preduxtion is already zero We need to get that prediction value to 1 right So we need to increase it know Can u pls explain it,True
@isaackumba2688,2019-07-23T06:20:26Z,1,thank's so much Sir,True
@hokapokas,2019-07-19T06:20:50Z,1,"Kish can you explain bias  as well because I believe, we can adjust bias as well as a measure of back propagation. Pls guide around it",True
@sriramswar,2019-07-18T12:17:24Z,2,"Hi Krish, What are the ideal Learning rates that need to be used? How do we decide which Learning rate value is ideal for a Neural network?",True
