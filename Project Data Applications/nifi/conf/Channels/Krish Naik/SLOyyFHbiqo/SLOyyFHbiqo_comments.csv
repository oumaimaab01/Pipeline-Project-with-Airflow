author,updated_at,like_count,text,public
@mansikumari4954,2024-01-27T09:47:09Z,0,Can we create decision trees for xgboost or lightGBM models?,True
@YuvrajSingh-dw1fy,2023-07-09T08:10:09Z,0,How are we going to do this with pipelines?,True
@vaibhav9727,2022-07-12T07:08:23Z,0,how to prune for regression tree ? can we do pruning for decision tree regression model ?,True
@muamarmohamed5476,2022-05-11T20:22:19Z,0,Hi how to change it to database saved on own pc,True
@ajaykushwaha-je6mw,2022-04-19T11:30:24Z,0,I have a small question. If we get over fitted model then getting ccp value is sufficient or we have to do hyperparameter with all values ?,True
@CloudyML,2022-02-18T17:14:53Z,0,The topic is described Amazingly. we have a great blog on this topic.  Take few time to check out our blog: https://www.cloudyml.com/blog/decision-tree-pruning-techniques-in-python/,True
@learnnorwegian207,2022-02-05T13:19:12Z,0,amazing tutorial!,True
@ashwinshetgaonkar6329,2021-12-11T10:26:36Z,0,accuracy_score for classification?? roc_auc is better option,True
@fundatamdogan,2021-12-04T08:41:38Z,0,Thank you so much .This is exactly what I need to learn.Great explanations,True
@mmarva3597,2021-11-29T07:18:01Z,0,"before even watching, I hit Like. thank you for all this effort ( respect from France)",True
@aakashyadav7928,2021-10-08T15:59:36Z,0,What is the criteria for selecting the ccp_alpha value??,True
@sachinmotwani2905,2021-09-22T04:57:40Z,0,really helpful!,True
@Anupam_0104,2021-09-21T11:12:57Z,0,Thank You Sir!!,True
@karthebans248,2021-08-19T16:15:50Z,0,Whether CCP is enough for Hyperparameter tuning or we have to also use the gridsearchCV  for better accuracy. Please clarify,True
@shwetadalal1549,2021-08-02T18:05:12Z,0,Why would one use so much time to improve Decision Tree model when we have models like RandomForest and XGBoost!!!,True
@mdmynuddin1888,2021-07-20T03:53:45Z,0,Please Explain Parametric and non parametric tree,True
@aninsignificantman001,2021-06-13T15:42:47Z,0,Thanks for the video . Very informative .,True
@parveenparveen9384,2021-06-08T12:06:56Z,1,"sir, by pruning the decision tree, it will not fit the entire train data, but still it is prefered as better than a un pruned one, why?",True
@haneulkim4902,2021-05-09T11:35:56Z,0,"Goooooood stuff, thanks Krish!",True
@adityachakaraborty3119,2021-04-07T07:12:16Z,0,In this case you have chosen random_state as 0 .. but in some cases if I change random_state value Accuracy also changes ... so my question is that in that particular case if I change random _state can we also see changes in alpha or max_depth ?,True
@adiflorense1477,2021-03-04T09:29:22Z,0,4:05  Where can I use the information gain ratio (C4.5) feature selection?,True
@adiflorense1477,2021-03-04T09:25:45Z,1,"please discuss Reduced Error Pruning, Pessimistic Pruning",True
@omkarbabar4420,2021-01-25T02:52:54Z,0,Hello sir.. Does pruning also work for decision tree regressor?,True
@finnzhang1323,2020-11-29T02:10:53Z,0,I mean here your testing dataset had been used twice to get the best model. Maybe split a validation set is better?,True
@_curiosity...8731,2020-11-14T15:02:49Z,5,What is the math behind selecting perfect Alpha value in cost complexity pruning? Can you please make a video on that?,True
@arunmohan1211,2020-10-28T14:22:23Z,1,Is it good to do a hyperparametertuning first and then do cost complexity pruning.,True
@ramendrachaudhary9784,2020-10-17T07:24:35Z,0,"The graph is slightly different when i run the same code. And the ccp_alphas has one extra value. Why would that be?     I am getting the result you have at @6:36  in cell no. 11. But it  changes the value when you rerun it for me it remains same.   When i run the code, i  am getting  Number of nodes in the last tree is: 1 with ccp_alpha: 0.3272984419327777  Any explaination?",True
@adiflorense1477,2020-10-08T04:12:59Z,0,"Sir, can misclassification be handled by pruning?",True
@ashishbhatnagar9590,2020-09-29T10:34:02Z,0,Extremely useful video. Thanks a lot,True
@mohammadarif8057,2020-08-11T12:21:52Z,0,Thank You ðŸ˜Š,True
@ayushsrivastav8220,2020-06-17T14:18:55Z,10,Hello krish! I have just one simple question. Is it necessary to perform ccp if we are performing hyperparameter tuning and if we have to perform only one of both which will give us the best result?,True
@sharmaramdhan,2020-06-14T23:53:54Z,1,"Hello Krish - is it always necessary to use this technique , does is always proves to be accuracy enhancer?",True
@shivamkala4105,2020-06-14T19:31:59Z,0,sir can you made a video in which we need to convert the values of input feature using standardization and then deploy it using flask.,True
@debasishchaulia8035,2020-06-14T16:17:04Z,0,"Hello sir, thanks for the post, really helpful !  Just one thought, in jupyter notebook (Cell 13), while iterating thru different values of ccp_alpha and computing train_scores and test_scores , can you pls explain why we are using score method and not accuracy_score (of sklearn metric) ?   I tried as below and eventually it is gving the same results as yours : train_scores = [accuracy_score(y_train,clf.predict(X_train)) for clf in clfs]  test_scores = [accuracy_score(y_test,clf.predict(X_test)) for clf in clfs]",True
@allenalex4861,2020-06-14T14:00:39Z,0,Am I the only one who can't join the telegram link?,True
@ranjit1able,2020-06-14T12:53:19Z,0,sir! please explain the parametric and non-parametric tree?,True
