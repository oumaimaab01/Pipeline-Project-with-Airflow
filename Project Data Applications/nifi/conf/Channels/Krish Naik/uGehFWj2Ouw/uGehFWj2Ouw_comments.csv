author,updated_at,like_count,text,public
@louerleseigneur4532,2021-07-31T09:17:25Z,0,Thanks Krish,True
@swathisheshabattar5844,2020-12-13T02:29:52Z,1,"Hello sir, I am working as faculty from computer scince background with experience of above 10 years in teaching field. Is there any chance to shift from faculty to Data Science jobs after 35+ age.",True
@AstraByteEducation,2020-11-30T06:51:19Z,0,"Sir can you suggest to me, How i forecast Blood Pressure (High and Low) using MultiClass Classification using SVM",True
@swapnilbhabal5289,2020-11-29T11:37:29Z,0,sir would love to watch audio classification tutorial in deep learning section by you,True
@woonie3134,2020-11-26T20:05:30Z,0,Nice one,True
@sahanamd707,2020-11-26T19:09:44Z,0,"How do you know the degrees of the equation.  Suppose y = ax^2 + bx +c so here the degree is 2 so how do we know that ? I know how to calculate a,b,c but I am thinking how do we know the degrees of the data",True
@DuyTran-ss4lu,2020-11-26T18:18:08Z,1,Thanks so much,True
@prashantsingh-bo8vu,2020-11-26T17:43:01Z,0,You are cute and chubby,True
@zenithkottayil1623,2020-11-26T17:23:53Z,1,Very good presentation. Liked it. Thank you krish.,True
@subhashunasikatti1984,2020-11-26T17:21:13Z,1,Not necessary,True
@subhashunasikatti1984,2020-11-26T17:10:26Z,1,Yes sir from your s,True
@subhashunasikatti1984,2020-11-26T17:09:13Z,1,Regularisation,True
@subhashunasikatti1984,2020-11-26T17:08:35Z,1,Cross validation,True
@subhashunasikatti1984,2020-11-26T17:07:16Z,1,High bias and low variance,True
@subhashunasikatti1984,2020-11-26T17:06:34Z,1,Low bias and high variance,True
@MaheshWaranpr,2020-11-26T17:06:08Z,8,Waiting for your salary history vedio,True
@subhashunasikatti1984,2020-11-26T17:05:41Z,1,Gloroid,True
@subhashunasikatti1984,2020-11-26T17:05:16Z,1,Relu,True
@subhashunasikatti1984,2020-11-26T17:05:00Z,1,He normal,True
@subhashunasikatti1984,2020-11-26T17:04:52Z,1,He uniform,True
@subhashunasikatti1984,2020-11-26T17:03:54Z,0,Relu,True
@subhashunasikatti1984,2020-11-26T17:03:24Z,1,"Sigmoid, threshold, relu, elu, prele",True
@subhashunasikatti1984,2020-11-26T17:02:34Z,0,8,True
@subhashunasikatti1984,2020-11-26T17:01:41Z,1,Yes,True
@subhashunasikatti1984,2020-11-26T16:49:12Z,0,To handle skewness,True
@subhashunasikatti1984,2020-11-26T16:44:20Z,1,Web page,True
@lokeshkaturi4040,2020-11-26T16:35:15Z,1,"accuracy , roc , sensitivity, confusion , f1 score",True
@subhashunasikatti1984,2020-11-26T16:32:06Z,1,Is there any seperate deep learning course?,True
@hemantmishra6879,2020-11-26T16:21:53Z,1,When we have very large value in data,True
@rishabhjain7572,2020-11-26T16:20:19Z,7,What are the companies that hire data scientist in large number frequently,True
@KnowledgeAmplifier1,2020-11-26T16:18:37Z,6,"Hello sir , please just check my this comment , please sir , please --  I gave these answers in this video but some answers which were like--""depends on data"" got preference  .   Here are my logics for the question , you asked --when should we use which transformations and when not to use which?  At 18:44 , I gave that answer , here is my logic  1)We can not use log transformation directly, when my data has 0 value as log(0)=-infinite. So one way is to add 1 with all values and then take transformation. log transform is applicable for positive values only as log10(-ve)=imaginary number   2)We can not use square root transformation directly if my data has negative value as square root of negative value is imaginary  3)Cube root is applicable for all cases --positive , negative and 0 value  Now one more question , I have given answer:  At 20:50 , I gave the answer that we use log transform if my data is right skewed (positive skewness). Because if we see log graph , it is almost like y=x for lower values of x(i.e. for lower values(near to x=1) are not affected that much by this transformation) and as the value increases , the log value does not go proportionally high. So it basically compresses high values (positive outliers ) & convert the right skewed data to normal distribution which is requirement for many algorithms.  And log transformation can not be used to reduce negative skewness (according to the graph) , for negative skewness we have to use square or cube or some higher order polynomial transformations.  I have no other intension , just I am bored with the answer ""depends on data"" as I believe ,  everything has a logic , a mathematical intuition in DS ,ML .",True
