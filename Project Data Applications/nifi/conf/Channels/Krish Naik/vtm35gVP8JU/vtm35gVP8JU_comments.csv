author,updated_at,like_count,text,public
@d0rzA,2024-03-05T13:50:16Z,0,I did the same as you but I get MasVnrType       872 as current NULLS Why is that?,True
@aboutbusiness.,2023-10-31T14:04:24Z,0,Sir Xgboost not installing in my system please suggest solution,True
@edilmonica386,2023-10-30T07:27:51Z,0,"Hello sir,   Can you explain the dummy coding.",True
@subparman6553,2023-10-29T16:25:35Z,1,kitna powerful hein tera caamputar,True
@greenshadowooo,2023-10-27T11:56:44Z,0,A very useful sharing !😍😍😍,True
@aakashgohil859,2023-09-14T02:31:13Z,0,"Hi Krish, would you mind sharing your email? I have some questions and need help to understand. I really appreciated the way you explained the problem statement and the feature engineering process. Your explanation was clear and insightful.",True
@shwetasaini6892,2023-07-04T15:55:08Z,0,"Has anyone tried to fit the model using Sklearn library ? I am getting error - float() argument must be a string or a real number, not 'method'  I have changed the floating points too.",True
@natures_soul763,2023-07-04T06:23:16Z,0,why their is no feature scaling in this code,True
@Arceus948,2023-06-17T14:01:05Z,0,why didn't u scaled the features data??,True
@Artista1010,2023-05-19T10:26:17Z,0,"Rather going feature by feature go like this         df.isnull().sum().sort_values(ascending=False).head(20)                                                PoolQC          1453 MiscFeature     1406 Fence           1179 FireplaceQu      690 GarageType        81 GarageFinish      81 GarageQual        81 GarageCond        81 GarageYrBlt       81 BsmtFinType2      38 BsmtExposure      38 BsmtCond          37 BsmtFinType1      37 BsmtQual          37 MasVnrArea         8 MasVnrType         8 Electrical         1 BsmtFullBath       0 Functional         0 HalfBath           0 dtype: int64  it will save time  :)",True
@bivekyadav08,2023-05-10T18:56:20Z,0,This man is always there to help🙌 Thanks 🥺❤🙏,True
@kevinmartinezperez4111,2023-03-11T17:05:22Z,0,"Men que buen video, muchas gracias, Saludos desde Perú",True
@christiansetzkorn6241,2023-02-19T12:59:03Z,0,I might be missing something but what is advanced about this?,True
@Marcel-f1,2023-02-06T17:46:14Z,0,"In summary: the machine learning engineer is making a “guess” about the dataset he is working on, and making multiple repetitive tasks like fill null values, feature extraction, and all these work that can be automatized",True
@abhishek6854,2023-01-10T17:28:16Z,0,23:22 is not working,True
@Peter-ns6jg,2022-12-24T01:32:37Z,0,this helped me a lot. thanks,True
@rajinirox,2022-11-21T15:02:25Z,0,"around 22:07 - if you want to check it yourself if actually number of categories are different in training and test data set, use this ""for column, col in zip(df,test_df):     print(len(df[column].value_counts()), len(test_df[col].value_counts()))"" this will print the number of categories column wise for training and test dataset",True
@vivianjoseph822,2022-10-25T14:05:30Z,0,tqsm brother!!,True
@nguyennhi8524,2022-10-15T18:23:24Z,0,Thank you a lot,True
@datasciencetoday7127,2022-09-26T06:38:09Z,0,at 27:58 if you drop the sales price XGBoost will give error features mismatch,True
@trashantrathore4995,2022-08-28T18:12:44Z,0,"Just need to know 1 major thing here , For ex for most of the Problems - We are given a Train data of 8000 rows and Test data of 4000 rows and also a submission file which contains a sample result containing all 4000 rows of test dataset , So my question is while performing Data Cleaning on Train Data if I found out few NAN values/Outliers are present in few rows and I remove these rows and suppose Train data now becomes 6500 rows and 1500 rows are removed and I apply same process for Test Data and suppose we are left with 3300 rows out of 4000 rows in test data after performing data cleaning but as we know, we are given sample solution which contains ALL 4000 rows of Test Data but after Data Cleaning I am left with 3300 rows which will create a mismatch error and whole ML model will be a waste, So in the end I want to know can we not remove any NAN values/ Outliers containing rows and only impute without removing the row? How to do it I am getting confused, please anyone know about it can comment in reply, I would be glad to hear.",True
@me_debankan4178,2022-08-15T11:25:45Z,0,you haven't done normalization?,True
@sauravsrivastava2353,2022-08-09T12:04:56Z,0,"This video was really helpful for me because I am just fresher in the Data Science world and I even don't know how to deal with such real-world data science problems, So thanks Krish sir for this kind of video, pls make another video regarding another Kaggle competitions.",True
@upgini,2022-06-20T17:13:54Z,0,Has anybody used a public data from upgini python library in Kaggle? I  Looking for any feedbacks about this data enrichment library.,True
@mohammadhegazy1285,2022-06-12T14:28:53Z,0,thanks a lot,True
@dikshagupta3276,2022-06-02T10:07:00Z,0,I don't understand I thing why we combine train data with test data for pd.get dummy pls reply,True
@nicholasjordan5661,2022-05-27T03:31:14Z,0,"I really need helo on this i keep getting this issue: ValueError: DataFrame.dtypes for data must be int, float, bool or category.  When categorical type is supplied, DMatrix parameter `enable_categorical` must be set to `True`. Invalid columns:",True
@oleholeynikov8659,2022-05-26T12:13:45Z,0,it is my exam project. Thanks a lot for the video!!!!,True
@jeremyheng8573,2022-03-10T17:18:34Z,0,Thank you! Good tutorial!,True
@shivadigitalsolutionsandam56,2022-03-08T12:59:52Z,0,bhai tum bolte bahot achcha ho. maine kuch nhi to 10 video dekhi same problem per. but your video is good one,True
@gtaunlimited007,2022-02-03T13:54:36Z,0,what was your r2 score of final model? Mine never cross above .78 for this dataset,True
@mohammadj.shamim9342,2022-01-12T10:21:45Z,0,"It was a great explanatory video, however, there was some jumping over the map. I am fine with it, but for a beginner, it will be problematic.",True
@zeuspolancosalgado3385,2021-12-03T23:10:48Z,1,Kaggle Competition Link: https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview Original Dataset Link: http://jse.amstat.org/v19n3/decock.pdf,True
@dennisbesseling9267,2021-11-17T12:57:21Z,1,in the description file it says that N/A values should be considered as a value for the absence of the feature. So if there is a null value in any of the basement columns this means that the house doesn't have a basement and so on..,True
@ibrahimnada4702,2021-11-09T05:51:39Z,0,"this is not machine learning, you're just calling functions and sorting rows .....",True
@thejswaroop5230,2021-10-27T16:15:46Z,0,Thank you it was helpful,True
@izike09,2021-09-25T10:55:30Z,0,Why isn't xgboost working on my notebook. It keeps telling me there is no new module for xgboost?,True
@zac231,2021-09-06T14:02:30Z,0,👍👍👍,True
@ravikanth6534,2021-08-30T13:38:27Z,0,"Hi Krish sir,  what is the purpose of concatenating the train and test datasets, when the test dataset has no dependent feature ""SalePrice"", how can the extra categories help in predicting sale price? Kindly clear my doubt, Thankyou",True
@ravikanth7179,2021-08-30T13:28:42Z,0,"Hi Krish sir,  Thank you so much for your valuable time to share your knowledge with us. Please answer my doubt, sir, what is the purpose of concatenating the train and test datasets, when the test dataset has no dependent feature ""SalePrice"", how can the extra categories help in predicting sale price? I hope you will clear my doubt sir, Thanks in advance",True
@arrafihriday1333,2021-08-14T17:46:42Z,0,"I have learnt  plethora of things from this project. Lastly ,can you please tell me ---what is the use of 0 here> mode()[0] ??",True
@somashaker5753,2021-08-04T06:43:33Z,0,Hi Krish I need to talk to you on this. How can I contact you on this. Plz let me know,True
@athikurrahumans4740,2021-08-03T08:01:37Z,0,guys iam getting an error in 37 th line im train dataset that name 'columns' is not defined what to do...,True
@edzhem,2021-07-20T18:34:46Z,0,"Hey Krish, Thanks for your effort! just one quick question is data heteregenous data isnt it?",True
@x_x3557,2021-07-15T12:22:34Z,0,Can we do the preprocessing for the whole data and then split it instead of concatenating it?,True
@anoopk4659,2021-07-08T14:16:44Z,0,"Garagecars is a categorical variable ,but  mean is used for fill na",True
@sripuramneeraja,2021-07-07T20:30:13Z,0,"Hi Krish, Thank you for your videos. I have a question, if train and test are in same file. Do we need to encode data after train_test_split or before. Your answer would be helpful for me.",True
@katocharles1501,2021-07-05T19:33:03Z,0,Thank you very much Mr Krish you have given me a clear start,True
@ApurvaMishra9,2021-06-29T08:49:44Z,1,"Hi Krish! Thank you so much for this ml intro to kaggle via house price prediction. I am a novice in the field and had a doubt. I shall be grateful if you could help me out. In theory, isn't testing data the data that is not touched at all meaning how can we perform preprocessing on the new untouched data and not violate that concept?",True
@learnforfuture2611,2021-06-26T16:55:49Z,0,"Sir , in this you combined train and test dataset and then split it using sklearn library . Then how the id in sample_submission.csv file (taken from competition) will match to your predicted values.",True
@Mayur586,2021-06-03T05:16:08Z,0,Thanks for your videos it helped a lot to clear doubts & learn new things but I have few queries as below: 1. how to convert/inverse predicted values to original format after using any transformation because np.exp/np.expm1 is not giving actual value 2. why we have to save it new column while transformation 3. if skewness not reduced in 1 or 2 iteration what to do,True
@pembasherpa3240,2021-05-26T17:10:04Z,0,Very helpful! Thank You,True
@faisalkhan-oo5jd,2021-05-11T07:26:28Z,2,Great videos! Thanks a lot   But in the property description text file it is written for some features that NA means the feature is not available rather than meaning that data for that column is not available. Does anyone else agree that we don't have to treat all the columns with mean and mode?,True
@shailrkardani7242,2021-03-16T09:39:49Z,0,df.isnull().sum() is only returning few of the column . How can I view all of them ?,True
@sogolgolafshan7843,2021-03-10T04:34:40Z,1,"as I type final_df.shape, I get the 'NoneType' error. Can you help me on what I should do?",True
@shobhikpaul1607,2021-03-09T21:31:18Z,0,what do we do to the float data? I understand we try to convert the object(catagorical data) to Integer. But Do we leave the float values? or do we try to convert them to Int as well.,True
@SaadAhmed-js5ew,2021-02-25T13:03:01Z,0,good work (Y),True
@divya8agarwal,2021-02-14T15:31:00Z,0,can i get the github link,True
@anilchaudhry804,2021-02-14T03:35:18Z,0,"Hey Krish, nice video. Do you offer some personal mentorship??I would be very interested",True
@tonyt6379,2021-02-08T13:02:05Z,2,Thanks. Great work!  Could you explain where the duplicate columns come from at 26:23 ? I don't understand why you get these from one hot encoding the train and test set together.,True
@rakeshkumarrout2629,2021-01-22T14:57:34Z,0,Krish this is really useful for upcoming decads...,True
@randallblake1213,2021-01-21T23:29:04Z,2,"Krish, there is a big problem with your analysis UNLESS the dataset has been changed by Kaggle in the last year. Around min 9:00 you speak about the large numbers of missing values in certain columns. I have not checked them all, but I did check ""Alley"" and ""PoolQC"". The numbers which you say represent ""missing values"" are NOT missing values. They are coded values (NA = no alley access; NA = No pool, respectively) - see the data_description.txt file. Either Kaggle changed the dataset after this video, or, more likely, you misinterpreted those numbers. It looks like your good score was just based on the lucky happenstance that those features are, apparently, not important.",True
@cusematt23,2021-01-20T18:10:07Z,12,"I'm pretty sure you're deleting perfectly good columns when you're removing ""duplicates"". For example the categorical features can come in conditions of ""good"" ""bad"" ""excellent"". This can apply to garage, basement, or attic. Since you didnt use a prefix for get_dummie, you now have 3 columns with the name ""good"", ""bad"", and ""excellent"" and you delete 2 when you ""remove duplicates"". They were never duplicated, they simply weren't intelligently named. If you use a prefix which is equal to fields, there are now no duplicates. Logically, why would there be duplicates in the first place? It doesn't make logical sense to me that there would be duplicate columns after applying get_dummies, when there weren't duplicate columns before applying get_dummies!",True
@shaileshrana7165,2021-01-10T23:42:06Z,0,Thanks bruh,True
@sulaimankhan8033,2021-01-04T01:25:14Z,0,06:27 Paaaandaaaaaaz,True
@MrAnant1993,2021-01-02T12:24:00Z,4,"@Krish Naik : Sir, after reading the data_description.txt I got to know that the NaN value has some meaning because in the description of ""MiscFeature"" the None is interpreted as NA.  For better understanding please read data_description.txt (eg. GarageType, GarageFinish, etc)",True
@hiw92,2020-12-20T20:00:36Z,0,Great video,True
@arindamghosh3787,2020-12-18T17:48:42Z,0,"I just know basics of machine learning i,e linear regression ,logistic regression and clustering . Can anyone suggest me some good projects to work on .Also can i use linear regression here to predict the house price ?",True
@hassan3665,2020-12-13T14:14:56Z,0,where to download csv file?,True
@user-tf3ec1fl8e,2020-12-03T23:36:12Z,0,"Open youtube, search for a thing, like kaggle To many India people broadcasting it. Then I know this thing has no future.",True
@welldone3806,2020-11-13T16:10:28Z,0,Why not do combination of test and train at very beginning,True
@preetdahiya3012,2020-11-11T07:24:03Z,0,I am getting an error  i converted float into int32 but while saving a csv file of same it convert 'Id ' column data type in int64 which shown error on kaggle.... so in last do have knowledge to overcome from it? please help me if you know,True
@ashwinraj8918,2020-10-19T10:33:00Z,0,"Krish, please provide the dataset.",True
@techboosters9048,2020-10-14T13:14:31Z,0,You are combining training and test datasets. so what do you think it is somewhere going to overfit your model,True
@heetshah5175,2020-10-11T07:52:58Z,0,"Hey, Thanks for making the video. Why have done drop_first = True in the get dummies part ?",True
@himanshumehndiratta7124,2020-10-07T10:08:50Z,0,First of all thank you for the tutorial. I just wanted to ask whether It wouldn't have been better to combine training and test dataset in the initial phase and after data preprocessing we could separate them. JUST A RANDOM THOUGHT.,True
@sandrafield9813,2020-09-28T06:45:28Z,6,"Hey thanks for this!! You're a great teacher.  You really helped me parse through some things in my machine learning class.  Sadly, I almost pushed ctrl-enter to enter this comment. lol",True
@chetanmazumder310,2020-09-15T05:00:57Z,0,You are GREAT sir .,True
@rakesh2you,2020-09-11T17:53:36Z,0,Thanks for this videos . It helped me in submission to Kaggle and understand what else goes in data science project,True
@MrAnandml,2020-08-31T15:31:08Z,0,"I know it's been 11 months   But just noting down an easy way to convert categorical features into dummy vars. .if anybody has noticed  it before plz ignore this  For selecting categorical features mixed with numerical set ..   cat_cols = df.select_dtypes (include=['object']).copy ()  and initiate a for loop to carry out encoding   for column in cat_cols.columns:      cat.cols[column] = pd.get_dummies (cat_cols[column],drop_first=True)",True
@darshikaverma9170,2020-08-26T13:17:13Z,0,"what if we scale the features, then how to predict the accuracy on the test/submission file???..should we unscale it back. If yes, then how?",True
@vivekkumargoel2676,2020-08-21T16:59:29Z,0,do coursera course on Machine learning are good to take??,True
@rohitbharti9360,2020-08-14T08:27:27Z,0,Thank you so much..... It is very helpful 🙂,True
@sahil-7473,2020-08-12T09:17:36Z,3,"Hello Sir. Thanks for showing walkthrough of this problem. I have a suggestion.  In test data, why are you replacing nan with those values that are there in test data. This is wrong! In test data, you have to replace nan with with those values that are there in train data. Test data is just like hidden. For example, let say I trained model with train.csv and i feed a query. For a query, these values can be anything either it is null or some values in some features. Now, for this query, to be replace null value, u don't have a bunch of test data, right? But u have done it with train data. So, it should be replaced with those values that has performed in train data. Thanks",True
@ankitnamdev643,2020-08-05T07:27:23Z,0,26:27    how you got to know that final_df  have  duplicate columns.....,True
@liiinx_com,2020-08-03T13:50:17Z,0,"Hey Man,  Thanks for the Video!",True
@videonomicsencyclopedia3711,2020-08-03T01:19:00Z,0,Can you make a video on Pune price prediction and competition?,True
@santoshkumargullala3471,2020-07-29T20:12:17Z,0,super explanation,True
@ShubhamGuptaGgps,2020-07-28T10:39:39Z,1,"what to do for this, my jupyter notebook on writing df.isnull().sum() not shows complete instead shows using dots in mid for continuation instead of scroll bar  df.isnull().sum() Out[13]:  Id                        0 MSSubClass    0 MSZoning         0 LotFrontage      259 LotArea             0                      ......... MoSold             0 YrSold               0  SaleType          0 SaleCondition  0 SalePrice          0 Length: 81, dtype: int64",True
@rajraj-rv6ii,2020-07-25T05:31:12Z,1,"Hi Sir,   Thank you for the Video. Your explanation is simply amazing and even a starter in machine learning can understand clearly  I have one small question. Why we dropped GarageYrBlt when null values are less than 50 % in the train dataset?. Please help",True
@RahulVarshney_,2020-07-19T04:42:56Z,42,How to extract all the categorical features: features=df.select_dtypes(include=['object']).copy() This will give dataframe of all categorical feature. To extract columns we will write Categorical_features= features.columns 😊,True
@upagna1,2020-07-14T14:27:02Z,0,where i find the code?,True
@o_rod8954,2020-07-11T17:13:20Z,0,Thanks for the video. You make it easy to understand and follow!,True
@codingfun915,2020-07-11T07:24:08Z,0,"Instead of writing the whole big column with categorical values......we can do this c = data.columns categorical=[] for a in c:     if data[a].dtypes==object:         categorical.append(a) and our categorical will be the list similar to columns list in the video Btw amazing video just loved it",True
@nandalal-dev6095,2020-07-09T12:26:59Z,3,"sir, not every feature requires one hot encoding For example: for feature LotShape : we have values like this   	Regular	       	Slightly irregular       	Moderately Irregular       	Irregular we can do LabelEnconding for these values ( [1,2,3,4]).",True
@hasninemirja5836,2020-07-03T06:05:20Z,0,"i was going to purchase your book it cost me 1,02,716 Rs please provide the book in reasonable price Hands-On Python for Finance: A practical guide to implementing financial analysis strategies using Python Paperback – Import, 30 March 2019 by Krish Naik (Author) 4.5 out of 5 stars 15 ratings See all formats and editions     Paperback     from ₹ 1,02,716.00     1 New from ₹ 1,02,716.00",True
@rationalbeliever5542,2020-07-03T03:34:19Z,0,Sir... I am let get starting with 'House Price: Advanced regression techniques' competition using kaggle notebook itself. But I don't know how to access or load dataset given in the competition description into the kaggle notebook for data analysis. Can anyone please help?,True
@AmeerulIslam,2020-06-25T14:15:56Z,0,where is part 2?,True
@SnkRobertoHz,2020-06-25T01:56:49Z,0,Amazing work. Sorry for my question but did you impute the variables of the test dataset?,True
@abhishekbajiya3332,2020-06-24T09:14:37Z,1,"Hey Krish,  Why didn't you use OneHotEncoder and ColumnTransformer to change categorical variables?",True
@arunmohan1881,2020-06-23T02:21:58Z,0,"Hi Krish, is it a good approach to concatenate train with test data and one hot encode it because in real-time test data is always unseen.right? So this approach will cause data leakage right? Please correct me if I am wrong",True
@prerakchoksi2379,2020-06-22T19:47:15Z,1,what does .mod() does?,True
@yeshwanths7198,2020-06-19T17:02:57Z,0,Sir can you please share your email-id,True
@devleenabanerjee4036,2020-06-19T10:44:15Z,0,"Hi Krish, while appending the test data row wise, what will we impute for the column 'SalePrice' as it is not their in test data. Or we will append after splitting test and train ?",True
@ak12_7,2020-06-19T05:26:00Z,0,"we can also use KNN to fill null values , correct?",True
@asdubey007,2020-06-15T19:47:27Z,0,thanks a lot sir to Crystal  clear my concept ....... .........thank you soo much for your this much of efforts ........ keep doing really awesome work,True
@jeevanthikaratan5181,2020-06-13T13:16:26Z,0,Where is the part-2?,True
@advocatesanthoshreddy9524,2020-06-11T13:21:01Z,0,"Till line no 256 it was all okay but, Krish got Df as ""1stFlrSF	2ndFlrSF	3SsnPorch.....but, I got Df as ""MSSubClass	LotFrontage	LotArea........Am I missing something.   Can anyone help??",True
@manu93ize,2020-06-11T05:14:10Z,0,this is Gold.,True
@vatsalanarkat4474,2020-06-07T16:07:43Z,0,"Hi Krish,  I am studying MSc. Construction Management at City University London and I wanted to use ANNs for my research. Is there any way we can touch base?",True
@humptyneupane9226,2020-06-06T07:30:57Z,0,why is duplicated columns being produced ? please reply !,True
@nizarhaidar5225,2020-06-02T01:17:18Z,0,Why not combine both the test and train dataset in the beginning?,True
@wtfJonKnowNothing,2020-05-31T06:15:02Z,0,"Hi bro , I used this function for missing values. Please tell me if it works good for Larger datasets. Here is the code.. def filling_missing_values(df):     for column in df.columns:         if df[column].isnull().sum() < len(df[column])//2 :             if df[column].dtype != 'object' :                 df[column].fillna(df[column].mean(),inplace=True)             else:                 df[column].fillna(df[column].mode()[0],inplace=True)         else:             df.drop(column,axis=1,inplace=True)     return df",True
@hafizmfadli,2020-05-30T13:45:08Z,0,"nice video,thank your for sharing this video",True
@harshitahluwalia8443,2020-05-28T03:08:49Z,44,"In 18:08 , if you want to see those values then  do this, pd.set_option('display.max_rows', None)  then after writing the above code, again write df.isnull().sum() Now you will be able to see all the values",True
@Prajwal_KV,2020-05-25T14:10:04Z,2,"sir,how are you dividing the training data set and testing data set df_train=final_df_iloc[:1422,:] df_test=final_df_iloc[1422:,:] how did you know it was 1422?how to calcluate?",True
@isingcauseimliving,2020-05-24T02:39:06Z,0,"Hi Krish. It could have helped if you would have read the description of the pricing. Why some features were chosen or why some features like say area = f(length * breadth), but both are given separately. So we could have done something by creating features ourselves. So I would have liked to see why you removed any of the features. I am just a noob, learning ML, so allow me to question. Can you also take it that the reason that ""Fence"" has so many null values is that there are actually very few houses that have fences. However, the houses which have fences, by intuition are costly houses. In this case shouldn't we take into consideration the value of the indices rather than the value of the null points. For example a big mansion would have fences, however, there are not many mansions in the training set. This does not mean that we do not include the housing price of the mansion for our solution. We would need to go over all of the 81 features to determine, with intuition, what could be the real life scenario rather than just thinking about data as ""null points"". Please let me know if I am right or wrong. Thank you.",True
@ninamayer8396,2020-05-05T16:19:34Z,0,HHH,True
@vijayanarayanan3425,2020-04-29T12:09:46Z,0,"Hi Krish, it was so nice listening to your video....thoroughly enjoyed.......",True
@mohitnagarkoti4086,2020-04-25T11:18:22Z,0,"Here is the confession, I didn't liked your videos earlier. But this is series and the way you explained things with why and how is awsome. Thanks alot for this. helped me clear multiple doubts.   and a note to the viewer(audience) i have never commented on a youtube video. But this guy deserves it",True
@whatitgoingtoB,2020-04-23T21:49:22Z,0,"Thanks Krish, appreciable, not slow and time consuming, it is what every beginner need everything without wasting time...Loved it.",True
@prayassingh8292,2020-04-23T09:12:18Z,0,can anyone please tell me how to download the train/test dataset from kaggle. I am clicking the 'download all' button but it is opening some new tab which is blank and nothing starts downloading there.  PLEASE HELP ASAP.,True
@harikaepuri9337,2020-04-21T14:11:47Z,1,Very neat and detailed explanation sir. Thank you very much for making me understand the whole project and how to participate in Kaggle competition. Looking forward to more such Kaggle competition videos sir.,True
@akshayjadhav2213,2020-04-19T11:15:00Z,0,very nice dear sir..u try to explain from basics and which is the necessary and important thing one should do. I had heard about kaggle competitions but today understood how it works.Thanks a lot and keep encouraging us.,True
@tavishgandhi363,2020-04-09T20:03:11Z,0,"After one hot encoding, why did you delete some columns saying these are duplicated columns, can you give insight to how some columns were duplicated?",True
@jayanigunasekara9157,2020-04-08T07:56:13Z,0,"Hi, I have a general question about RMSE value. How do you determine the accuracy of the model in terms of RMSE when there is a limited range of actual values? (Example the actual y values vary from 600 to 615, and RMSE is close to 1.00)",True
@shubhirajsingh3055,2020-04-01T21:06:30Z,0,"sir why you dropped    ""GarageYrBlt"" column and not taken mode value of column to NaN values",True
@dineshreddy3776,2020-03-25T16:45:49Z,0,"why can't we club the train and test datasets beforehand and then do data pre-processing, and thereafter before modeling, we can split the dataset and do modeling using train dataset, and check the accuracy or any performance metric with the test dataset. So, that no need to put any extra effort in data preprocessing for test dataset.",True
@mandalaquotes_arts9919,2020-03-24T12:54:56Z,0,The submission.csv file hs to be checked manually or any testing is applied,True
@kalyanprasad4069,2020-03-19T15:20:47Z,3,Hello Krish -  It would be really helpful if you do a video on how to step into kaggle competitions? what are the  basics thing that one should aware  before entering into competitions.  Thanks for understanding Sincerely,True
@abhinavshrivastava4637,2020-03-15T08:01:35Z,1,"I want to evaluate my model with confussion matrix but in test data we don't have that column 'SalePrice' then if i run this commond : confusion_matrix(y_test, y_pred). Here I dont have 'y_test' . What to do ???? please suggest",True
@saurabhtripathi62,2020-03-13T09:20:47Z,0,krish when we concatenate train n test to have encoding dummy will it create data leakage?,True
@trackbackresearch,2020-03-12T07:54:27Z,0,In the code if i drop the df_test= 'SalePrice' how will i predict for test .,True
@ashutoshkumar2834,2020-02-29T11:47:32Z,1,"I have one question. Let's say I have 2 dataframe train_df and test_df. Both have same type of columns(column_A,column_B,column_C).Both dataframe have some missing values. If I drop column_A in train_df , is it mandatory to drop same column train_A in test_df ?",True
@kadhirn4792,2020-02-25T18:53:44Z,0,Good techniques. I have learnt a lot from this thank you so much,True
@sachink7955,2020-02-23T10:15:31Z,0,"Sir, could you please do a video on toxic comment classification by kaggle  https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge.",True
@s.m.solimanhossain2198,2020-01-28T01:20:14Z,0,hello! Thanks for nice video...but In [311]: ## Combine Test Data    test_df=pd.read_csv('formulatedtest.csv') where you get this formulatedtest.csv?,True
@mohitkeshwani456,2020-01-25T07:27:04Z,0,Really helping this... Thanks alot for making these types of videos,True
@sourabhsharma9830,2020-01-06T06:53:49Z,0,can anyone please explain me the function which he created?,True
@santosharavind2887,2020-01-06T05:19:05Z,0,"Thank you Krish, would like to know when are you releasing continuation video, so that we all will get complete exposure on the whole project. Thank you in advance..",True
@rahulverma8814,2020-01-05T17:54:31Z,0,i am beginner in machine learning and i want to create a team for kaggle competitions and other doubt purpose,True
@user-rs4hf7ud2e,2020-01-04T22:22:20Z,5,You're the best! My RSME dropped dramatically after watching your video from 0.20 to 0.14. Thanks to XGBoost and you! Thanks a lot!,True
@HarpreetSingh-ut2px,2019-12-08T13:12:05Z,0,Is this Supervised machine learning method?,True
@maheshwarang2008,2019-12-05T07:04:19Z,0,"Thank you so much, sir.  you are doing a superb job for us who wants to enter in Machine learning",True
@vinothkumar5024,2019-11-27T05:26:58Z,0,Is there anyway to get categorical features using code instead of implicitly taking column and assigning to values then checking length .. If yes help me,True
@PradeepSingh-gh1jp,2019-11-26T10:33:02Z,0,"Made a great mistake here If two or more features have identical category names, doing             final_df =final_df.loc[:,~final_df.columns.duplicated()]    will actually create problems. You must have done             pd.get_dummies(final_df[fields],drop_first=True, prefix=fields)   to avoid such problem, but you did           pd.get_dummies(final_df[fields],drop_first=True)     here prefix is very important to distinguish each category by its associated feature.   The rank you achieved here doesn't make sense after that, but the knowledge you gave is awesome. Thank you",True
@BhartiDeepak,2019-11-18T16:32:29Z,1,"First of all thanks for the video, it is very informative.  I am new to data science so this could be a novice thing to ask; however, one part that I wanted to point out is that you are combining train and test data for modelling. From what I have learnt we should never combine the train and test data for training as it will not be good for predicting the results for the dataset that is not seen by model. Please correct me if I am wrong.",True
@anandnettem2236,2019-11-08T18:36:59Z,0,sir pls tell me how to install xgboost in jupyter notebook,True
@muzamilshah8028,2019-10-27T09:59:20Z,0,very nice work,True
@anandacharya9919,2019-10-26T18:15:09Z,0,Please make video on  Kaggle Titanic also.,True
@anandacharya9919,2019-10-26T15:09:08Z,0,"Super, but we can merge the test and train data first then can do feature Eng, to avoid double work.",True
@AmitYadav-ig8yt,2019-10-17T15:13:23Z,0,"Sir, Is it alright to combine both Training and Test data set and then perform Imputation, encoding etc on combined data?- Or Should we impute null values first in each dataset separately then combine dataset for encoding?",True
@amartyabasu9552,2019-10-15T09:06:52Z,0,What if I do not drop those columns where most of the entries are null?,True
@redsnow123456,2019-10-09T03:56:57Z,0,Why are you using i==0 in if else ?,True
@redsnow123456,2019-10-09T03:56:32Z,0,Sir. Does get_dummies() avoud dummy variable trap?,True
@redsnow123456,2019-10-08T19:16:35Z,0,Why didnt you transform categorical features into numeric then avoid dummy trap then calculate correlation and remove non correlated fields with sale prices,True
@redsnow123456,2019-10-08T19:14:54Z,0,You didn't avoid dummy trap?!,True
@amankhaira2249,2019-10-07T19:01:07Z,2,"How did you make a function for 39 columns, that part I want to learn rest all seems to be pretty clear to me   Also if anyone have any other way please post it here    Thanks in advance.",True
@himanshusahoo143,2019-10-05T17:59:12Z,0,"Hi sir, just one question, why you apply 'Get dummy' feature, Rather 'label encoding'. Get dummy, is creating huge numbers of columns. And again removing duplicate columns. Can't we simply apply label enc? Please advise.",True
@darpan810,2019-10-02T05:54:13Z,0,Hellos sir  Good video but not getting for loop code and instead of get dummies can we apply label encoder please guide  Thank you,True
@chandrakanthshalivahana8616,2019-09-30T16:19:22Z,4,"sir, why did u drop df.drop(['GarageYrBlt '],axis=1,inplace=True) as it has only 81 null values",True
@aryamahima3,2019-09-28T17:56:06Z,0,very very helpful videos.. your efforts are highly appriciable.,True
@vikrantchoudhary4411,2019-09-27T16:33:49Z,0,if i directly uses the function onehotencoder how it will affect my rank??,True
@eanamhossain1156,2019-09-23T16:58:00Z,0,Thanks brother for this video. Continue..and more video upload.,True
@sachinrathi7814,2019-09-19T17:15:45Z,0,"Hey Krish, I want to need feature scaling and variable transformation, then i should do it only for train data ? or should be done on train and test set after combining them and once they follow gaussian transformation, we should divide them in again train and test set. please help.",True
@prachiarora7823,2019-09-19T07:17:25Z,0,Can anyone explain me the onehot function in the code spcly what is the purpose of the condition if  i==0  @krish please explain the code too,True
@sachinrathi7814,2019-09-18T09:47:36Z,1,"Hey Krish, you have handled and imputed missing value for train and test data separately and to handle categorical feature, you concat them .. Instead we can combine in start of code it self so that we can avoid to write code for test and train data separately. Can we do that ?",True
@ayeshakhan2233,2019-09-18T05:29:11Z,3,"Sir please explain the codes in detail too. Especially that pd.get_dummies, the defining of the function category_onehot_multcols and how that loop works",True
@sanjaykhanssk4530,2019-09-17T09:31:58Z,0,"haha top left singham : kadhal vandhaley kallu redu thanaley , yo broo",True
@vishalmalpure6008,2019-09-16T14:59:35Z,0,"Hi Sir,Can i use linear regression in this problem ? Which is the best algorithm to be used in this case? How can we get to know that ???Someone please help",True
@chetannalinde1441,2019-09-15T15:25:06Z,17,"Thank a ton, Krish. This is what I was exactly looking to start with Kaggle, keep the awesome work coming. Looking forward to more such videos.",True
@aktharm1317,2019-09-15T02:58:13Z,0,Great !!             Good Work by you !,True
@VaibhavPatil-rx7pc,2019-09-12T04:36:51Z,1,good job!!!,True
@shailendraverma761,2019-09-11T18:34:53Z,0,HI Krish. Thanks for your such a nice explanation. I was able to easily followup  and tried few others things on data which results into score 2513 rank,True
@adityaghosh8601,2019-09-11T14:08:17Z,0,Thx man,True
@anandacharya9919,2019-09-11T12:02:32Z,2,"Sir, can we merge table then take action on missing value and feature eng etc, then split data in training and test ??",True
@anandacharya9919,2019-09-11T10:47:48Z,1,Please make it in R,True
@sonalisingh2136,2019-09-10T22:01:18Z,1,Why are we not doing scaling to it??,True
@babayaga626,2019-09-10T10:55:56Z,4,"Hello Sir, Can you please discuss about the parameters and values for XGBosst classifier. Also how do we get the best value of parameters using cross validation.",True
@Girish0512,2019-09-10T06:25:01Z,3,before getting into it what should be the basic preparations to be work on?,True
@pranavkirdat8192,2019-09-10T04:42:02Z,3,keep up the good work . u channel will grow,True
@MrJaga121,2019-09-09T19:49:28Z,2,Great work Krish . Thank you very much for explaining line by line .,True
@beginner6715,2019-09-09T19:18:47Z,1,Creta ...19:25,True
@selvaprabu3878,2019-09-09T19:03:41Z,1,"Superb sir......great ...I have one doubt, sir  1)while treating the skewness and normality ..is it required to check all the columns(IVs) or only in DV...I am a beginner for Data science (Because , Linear regression Assumption not says about IVS) Can u explain clearly sir?   2)Another thing for feature selection I have to each and every column separately or can I with auto selection method. In, Manual condition for Numerical features based on Correlation what about categorical features? I have chi2 or ANOVA test I have to take or some other... I know theoretical...but actual real-time projects how it will be?(some Dataset having 400 Columns)",True
@vishal56765,2019-09-09T18:28:02Z,2,Loved it...try to upload next videos like the one you did on hyperparameter tuning so that we understand how to iterate on the same problem to get better results. So slowly make this problem a complete series jsing same datset.,True
@pradipkaushik6583,2019-09-09T17:27:38Z,1,"Thank you so much Sir, you have explained these topics with so much ease. Keep posting such excellent videos.",True
@hemanthreddy8991,2019-09-09T16:26:33Z,1,"any one help me ,i am getting id in float and not in integer while submitting it is showing error as    Expected 'Id' column to be of type 'Int32', but was 'String'",True
@Nitsoney,2019-09-09T15:05:32Z,4,"Hi Sir, thanks for uploading the videos and training us with such good content, I didn't get the one hot column part  why it was done??",True
@vinaykumar-gg4mx,2019-09-09T14:32:44Z,2,Hi Krish What is the IDE that you have utilized for coding ?,True
@zeealwaysshan,2019-09-09T13:43:34Z,1,df.isnull().sum() this code gives the null values but it is only showing top 5 and botm 5 more like a collapsed list of null values,True
@anandacharya9919,2019-09-09T10:00:09Z,1,Also can u please add kaggle titanic competition,True
@Akshat.agr13,2019-09-09T07:35:17Z,1,Why are we dropping some records in test and train data because null values should have been removed after applying mean to numeric features and mode to categorical features? (The heat map generated for 2nd time still shows some null values for some features before you execute the above step),True
@shovonpal4539,2019-09-09T06:47:18Z,3,SK learn could make the solution easy,True
@devathimahesh8007,2019-09-09T05:08:19Z,1,Nice  video,True
@shreeyaraychoudhury3531,2019-09-09T04:14:51Z,2,"After 3 years of work ex in a different domain, is it advisable to learn DATA Scientist course PGDBA ?",True
@atulpandey1979,2019-09-09T01:44:02Z,1,Excellent..!!,True
@xpabhi,2019-09-08T19:34:40Z,5,Liked the way you explain the problem statement and the feature engineering part. I am pursuing the data scientist carrier and have great interest in the ML techniques. It's always a pleasure to watch you.,True
@samudragupta719,2019-09-08T19:27:26Z,3,All I can say this is one of the best exploration I've ever gone through! This must go on... ❤,True
@PrasadHonavar,2019-09-08T19:09:08Z,1,Excited for your next Kaggle video.,True
@soumyadrip,2019-09-08T18:30:13Z,1,when to use mean and when to use mode to fill up the null values?,True
@BiancaAguglia,2019-09-08T17:47:40Z,81,"Nice job, as usual, Krish. 😊 One note about accuracy: I recently heard a data scientist at Netflix say that some of the models that win competitions on Kaggle are too complex and too impractical to be put into production. So our job is to find a balance between accuracy and usability. I thought that was interesting. 😊",True
@niteshsoni5379,2019-09-08T17:16:47Z,1,Great job sir..,True
@samratkishore4668,2019-09-08T17:09:33Z,2,Sir I think you have to..fix the outliers in the data set....that can increase your prediction sir..,True
@sabyasachighosh9847,2019-09-08T16:29:07Z,9,Krish... U r going a great job... Good to learn from u...,True
@shashankvm,2019-09-08T15:23:14Z,3,You are my role model brother...I want to be like you :),True
@akshayjhamb1022,2019-09-08T15:22:58Z,2,Thanks Krish for the video. keep coming for more solutions of kaggle competitions,True
@abhimanyutiwari100,2019-09-08T15:03:20Z,4,"Nice. Coincidently, I too, completed this advanced regression kaggle problem yesterday.",True
@hitendrasingh9620,2019-09-08T14:58:09Z,1,how  did you get to know xoboost algorithm will fit the data perfectly where did. Please explain that,True
@borntolearn6333,2019-09-08T14:58:04Z,14,Sir pls upload a ene to end datascience project  solution..TIA,True
@codedestiny6955,2019-09-08T14:57:42Z,1,Nice,True
@abhileshm7216,2019-09-08T14:45:23Z,1,Thank you for this initiative.... Can you please explain  in detailed way of ...what are different levels in category data of train and test ......why we concatenated ...and when dummified what are duplicates in dummified created and why we removed those duplicates from this example ....please explain it sir,True
@MrPriti999,2019-09-08T14:31:11Z,1,great one,True
@Zeba_Sayyed,2019-09-08T14:29:23Z,2,Thank you soo much sir.. Ur videos are soo helpful,True
@Amrrkevin,2019-09-08T14:26:13Z,2,Please continue/complete Deep Learning series. We r waiting for those videos very eagerly.,True
@Sol-fg2go,2019-09-08T14:25:51Z,1,Why don't u replace value by mode in lot front ?,True
@gaganlohar5517,2019-09-08T14:19:25Z,2,"Thank You, Krish, you are doing a great job. Very nice video.",True
@bars-qt9yi,2019-09-08T14:19:01Z,2,Hi sir nice work but please make your videos in odered way or in sequence we don't know how to start from scratch,True
@geekydanish5990,2019-09-08T14:12:22Z,1,Great start man hope to see more videos soon,True
@nabeelpm4894,2019-09-08T13:38:20Z,6,Thanks again krish..love your passion and humbleness..you are giving such a  valueble knowledge..indeed.. sharing knowledge is the best thing in the world..Thank you so much brother..,True
@bibhasgiri527,2019-09-08T13:35:58Z,1,Thank you.. This is really helpful.,True
@gurditsinghchandok1641,2019-09-08T13:17:45Z,1,Thank you sir very helpfull,True
@sachinborgave8094,2019-09-08T13:13:58Z,3,"Hello Krish,  How to fill missing values using Linear regression? Please provide a code with demo.",True
@animeshbagchi708,2019-09-08T13:13:13Z,1,Can you please make a video on data cleaning?,True
@ashutoshvarma8384,2019-09-08T13:07:14Z,4,"sir as a begineer, how would I start with kaggle comp.",True
