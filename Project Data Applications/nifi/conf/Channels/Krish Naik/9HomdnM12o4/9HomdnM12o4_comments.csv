author,updated_at,like_count,text,public
@jayashreepaul3890,2024-03-22T07:07:59Z,0,the exited column is in binary formar we should have used classification problem right?,True
@rohankamble6424,2024-01-08T11:30:50Z,0,"Useless video, parameters defination not explained",True
@dauntless4498,2023-12-12T07:12:38Z,0,I am facing error while trying to find correlation without encoding the categorical variables.,True
@titangamer5157,2023-06-14T05:27:54Z,1,Thanks a lot sir‚ù§,True
@MoumitaHanra,2023-05-07T21:17:02Z,0,What each hyper parameter means would also have been helpful,True
@habidata,2023-03-06T15:28:24Z,0,"Hey Krish, my code pops an error "" TypeError: Cannot clone object. You should provide an instance of scikit-learn estimator instead of a class."" when I execute ""random_search.fit(X,Y)"". Do you have an idea why?",True
@abhishekpanjiyar8266,2023-02-05T05:13:47Z,0,"hi sir,how to learn xgbregressor hyperparameters",True
@jagadeeshmandala4097,2023-01-09T06:06:53Z,0,"8:45, you said Randomized search will go with Permutation and combination. But i think GridSearchCv use that concept. Randomsearchcv, won't take all the values to check whether it is optimal or not. As the name implies it will pick that parameters randomly",True
@jasonclement6305,2022-11-12T19:54:08Z,0,Great video sir,True
@umangbhaisoni4567,2022-08-31T03:20:58Z,0,Nice Explanation. Great Work !!,True
@Copepiece,2022-08-15T02:18:02Z,0,Tree based models required n-1 encoding of categorical features?,True
@neeleshnayak4375,2022-07-06T04:21:56Z,0,set argument  missing value as  1 instead of  None if you are getting list of nan values as score,True
@asifahmed1801,2022-07-05T10:01:48Z,0,"i got ""ValueError: n_splits=5 cannot be greater than the number of members in each class."" this error while i running my own file  using this hyper-parameter setting",True
@deyoz1,2022-05-13T15:00:19Z,0,"Okay 86 percent acc is good, but what about recall. If this model is misclassifying exited class more then we can say its a good model. You have missed this point",True
@DEEPAKSINGH02041992,2022-05-05T00:43:50Z,0,Liked and subscribed...!!!,True
@v1hana350,2022-03-11T22:27:19Z,0,I have a question about the Xgboost algorithm. The question is how parallelization works in the Xgboost algorithm and explain me with an example.,True
@vamsikrishnagannamaneni912,2022-01-05T17:41:47Z,0,We are we not scaling estimated salary column? When it comes to income and salary the data is always skewed üôÉ,True
@AThoughtOnAutomation,2021-11-05T20:50:25Z,0,Helped me a lot,True
@poojashah5032,2021-10-19T07:30:08Z,0,"Hi @Krish, Great explanation. Just a quick suggestion. Please rearrange the playlist to include the theoretical explanation video before the practical implementation. Thanks.",True
@vinaypratap620,2021-08-15T07:48:40Z,0,Plz ans me score.mean() is accuracy score????,True
@isalys1867,2021-07-28T08:25:56Z,0,God bless you. You are talented in teaching. Keep going.,True
@subhashg6987,2021-07-18T14:45:13Z,0,"Hi sir, Can you please re-order the videos in Complete ML playlist. Its little clumsy and makes diversion from the previous topics. Thanks in advance.",True
@balapranav5364,2021-06-29T11:25:24Z,0,Please explain on sample_weights and scale_pos_weight  in xgboost hyperparameter tuning,True
@legechgetu5450,2021-06-10T20:12:24Z,0,thanks so much this is a good explanation,True
@modhua4497,2021-06-04T13:10:15Z,0,"Krish, thank you very much for your video. Very helpful and insightful.",True
@r21061991,2021-05-30T17:11:46Z,0,Google colab taking huge time for the training...Dont know why,True
@NEHAGUPTA-fo3ny,2021-03-23T11:44:59Z,0,"hello sir , I am trying  one my project using your code but getting warning  : ""Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers. [Parallel(n_jobs=-1)]: Done  19 out of  25 | elapsed:    5.8s remaining:    1.8s [Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    6.6s finished C:\Users\Neha Gupta\Anaconda3\lib\site-packages\xgboost\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].   warnings.warn(label_encoder_deprecation_msg, UserWarning) [17:06:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.  please look into this and please provide me some solution",True
@hiteshsingh9859,2021-02-19T15:55:06Z,0,"very sad things ,in real life we don't appreciate  people who puts so much efforts like krish sir. example in this video we have 40k views but only  810 likes and 80 comments. Thank you so much Sir.",True
@qrubmeeaz,2021-02-12T13:57:58Z,2,"Stop saying ""this particular"" please. There is no need for it.",True
@sarthakdargan6447,2021-01-13T07:05:40Z,0,If we use pandas get_dummies function with drop_first as true; what if a column dropped in Train data is not the same as that of test data. Should it be added manually?,True
@keshavsharma-pq4vc,2020-12-31T11:06:49Z,0,Please sir Whenever you got time can you arrange all videos Sequentially And Thanks a Lot for This Lectures,True
@smithparekh1423,2020-12-26T06:16:49Z,0,on which basis we are selecting params ?? or we are randomly giving any number respectively?,True
@rahul.s7,2020-12-19T17:57:21Z,1,"Thank you soo much sir, this helped a lot in my assignment.",True
@ratulghosh3849,2020-11-29T06:26:57Z,1,Thanks for explaining the concepts related to Hyperparameter Optimization in layman term's.,True
@ankushjamthikar239,2020-11-24T13:03:25Z,8,You explained it very nicely. I just have one doubt. Should we perform hyperparameter optimization for (i) entire input data or (ii) should we first divide into training and testing datasets and then perform hyperparameter optimization on training data only?,True
@beautyisinmind2163,2020-11-11T14:48:20Z,0,could you please use PSO to optimize xgboost hyperparameters?,True
@samuelpolontalo6882,2020-10-27T10:35:52Z,0,THE BEST CHANNEL FOR MACHINE LEARNING!,True
@anamitrasingha6362,2020-10-09T11:43:39Z,0,"Shouldn't we use distributions like normal, uniform, ... for each of the parameters in case of RandomizedSearchCV",True
@ravindarmadishetty736,2020-10-03T05:37:00Z,0,"Hi Krish, how to write better functions using def in python. Please suggest",True
@sandipansarkar9211,2020-09-22T21:23:51Z,0,Thanks Keish.Great explanation from interview perspective,True
@HhhHhh-et5yk,2020-08-29T09:07:34Z,0,Why can't u use np.arange() instead of writing numbers in list?,True
@devarajuessampally1338,2020-08-22T11:23:02Z,0,"Hi krish sir, please upload XG boost video..",True
@anithkjoseph1631,2020-08-18T04:08:50Z,0,can i use this in XGBoost Rergressor also??,True
@samriddhlakhmani284,2020-08-08T07:50:17Z,0,"So, There are cetrain youtube search that I do, expecting not even one video. This is the third time Krish ji has come up as the solo content creator for the topic...   you are a blessing to this industry  Also, can I ask you, I am not being able to find this answer. When we do bootstrapping. the algorithm will be taking samples multiple times. When that happens it ensures that every data is taken the same number of multiple times.  like 100 values are there, and bootstrapping is making sub samples of 10 with 200 data points. does the technique ensure that the 32nd data point from the original 100 was taken 6 times and also the 74th was taken 6 times across the 10 samples?",True
@sandeepkumar-mo3mm,2020-07-26T18:03:53Z,0,Sir you did not uplaod XGBoost video in your ML playlist Please upload it,True
@AmeerulIslam,2020-07-16T12:14:24Z,0,"Mr Naik, what is the benefit of doing cross validation for the second time? How is this different?",True
@shalinianunay2713,2020-07-07T14:36:04Z,0,Just wonderful!!,True
@ByWayOfDeception,2020-06-18T22:44:52Z,0,Super interesting.  I tried to improve my XGBoost with this the day after handing in the project.  No improvement but it could just be the data doesn't work well with decision trees.,True
@carolinnerabbi965,2020-06-15T19:23:11Z,6,"Very good explanation, straight to the main points. Thanks!",True
@mizgaanmasani8456,2020-06-12T16:06:58Z,0,Is Gradient Boost Is Same as XG_Boost ?,True
@MrVaibhav488,2020-06-09T23:30:56Z,13,"Hi Krish, At 6:49, u have told u have uploaded XGBoost video. Where it is. I have searched in the playlist but didn't get it. Can you please share the link in description.",True
@akashkamerkar5257,2020-06-01T17:55:31Z,1,"sir getting this error AttributeError                            Traceback (most recent call last) <ipython-input-50-f44a8c5ec901> in <module>() ----> 1 random_search.best_estimator_  AttributeError: 'RandomizedSearchCV' object has no attribute 'best_estimator_'",True
@ashishasashu,2020-05-22T22:47:42Z,1,"Hi Krish, thanks for video , could you please put a final graph with also create a ROC curve for the testing set.",True
@inaccel1796,2020-05-19T08:39:39Z,0,"Great video.  Would you be interested to run 10x faster XGboost hyper-parameter tuning?  InAccel provides a framework based on hardware accelerators (on cloud (aws) or on-prem) that can help you run 10x faster the hyper-parameter tuning on XGboost with zero code changes:  Read how to run 10x faster the XGboost hyperparameter tuning on the following article:  https://medium.com/@inaccel/accelerate-ml-workflows-with-kubeflow-using-inaccel-fpga-orchestrator-a2b20f73e9df  More info: https://inaccel.com/",True
@sadabratakonar4219,2020-05-09T18:13:11Z,2,"sir, kindly upload some explanation of Xgboost.",True
@kumarrishabh8904,2020-05-08T16:47:20Z,0,"One of the most informative video on YouTube, great work by you. Although I have one doubt that like when we do train_test_split we simply train the model on training data and then predict the model for test data and using those predictions we find out confusion matrix which is fine....but here in RandomisedSearchCV how can we find the confusion matrix for them? Or when I wanted to know the accuracy, recall and precision at the same time?",True
@gsainathreddy2742,2020-05-07T11:08:14Z,1,ValueError: continuous format is not supported  when i have found the error when i have performed the iterations,True
@biswakalyanmishra6592,2020-05-03T18:21:44Z,0,"You have mentioned here that u have a video of XGBoost theoretical part in the playlist but i cant find it anywhere on the channel,is it still there?",True
@nareshjadhav4962,2020-04-28T13:39:49Z,0,I am not getting xgboost algorithm vidio in play list ..please suggest where is it..,True
@NOCMG-ht9bd,2020-04-21T10:59:52Z,0,kindly provide the video link for theoretical explanation of xg boost algo,True
@mohitsachdeva7763,2020-04-12T13:50:50Z,2,"Hi Krish, Your videos are clearing concept and way of your teaching really appreciated In video you mentioned about indepth intuition of Xgboost but there was no video for therotical concept of Xgboost indepth intuition. I have checked in other playlist. Could you please share link for that also?  Thanks in advance.",True
@shashikantrrathod3617,2020-04-10T10:02:52Z,0,"Hello Krish one question i want to ask you, how to select the 'best parameter' of any machine algorithm to apply RandomizedsearchCV on it. In this case you have use 'params' as object, so how you have selected that only??????????",True
@BalaMurugan-cb9ho,2020-04-05T12:20:50Z,0,Pls share xgboost tutorial link???,True
@rajdeepakvishwakarma23,2020-03-25T17:43:04Z,1,thankyou sir for this video it will help me to learn the concept of hyperparameter turning,True
@mukeshtechub,2020-03-05T15:45:17Z,0,"Hi Could you please help how to see all the arguments of classifier = xgboost.XGBClassifier(, which shortcut we need to use .",True
@yogenjoshi1668,2020-03-05T05:04:28Z,1,"Nice learning on tuning parameters! I tried to run the same and got the following error,... ""TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker. The exit codes of the workers are {SIGABRT(-6), SIGABRT(-6)}"" Checked the Available memory which is ~ 26GB so that is not an issue. Any suggestions. Many thanks!!",True
@bhumanandabarik4671,2020-02-03T20:59:27Z,0,"I am getting error while fitting random_search.fit(X,y)  --   OverflowError: Python int too large to convert to C long  .  "" I am using python 3 """,True
@ranjithks1743,2020-01-29T10:04:25Z,0,"This is a Similar video to RandomSearchCV with RandomForestClassifier right. Then why does the Video Title says ""Hyper Parameter Optimization"", it could be ""RandomSearchCV for XGBoost"". The name confuses that this is other type similar to Grid search and Random search",True
@akshay4081,2020-01-05T07:54:03Z,1,Sir please upload video on Bayesian Optimization.,True
@abhisheksv1232,2019-12-28T14:23:13Z,1,"in cross_val_score u are no where mentioning the test size, so how the algorithm will split train and test?",True
@raihankhanphotography6041,2019-12-28T05:00:40Z,0,Super tutorial.  Many thanks.  You're an awesome teacher.,True
@bhaveshchiplunkar6062,2019-12-23T16:16:44Z,1,"Hi Krish, Great explaination. Thank you for such informative video. It helped a lot. Can you also please explain the timer function that you have used in your code.",True
@sunnysavita9071,2019-12-15T03:57:02Z,0,sir is hyperparameter optimization and hyperparameter tunning  same,True
@Raja-tt4ll,2019-11-17T22:42:38Z,0,Very nice video,True
@Sam-wp7gw,2019-11-04T23:23:00Z,28,"Awesome! Spent all day trying to improve my AUC for an assignment without much strategy,  about 20 min after I found this video I got an A",True
@yingdonghao3462,2019-11-04T03:26:44Z,1,Can we input list as one of the training feature?,True
@swativipsita2269,2019-10-24T10:26:15Z,0,How are the weights updated? no equation has been mentioned in this video.,True
@rsinh3792,2019-10-19T08:21:18Z,2,"Thank You, after many days I understood this concept",True
@salseid1033,2019-10-09T03:06:38Z,1,Dear Kirish  Your tutorial is wnderful and clearl.  May u help  on Bayesian optimization. Thank you in advance.,True
@sunnysavita9071,2019-10-07T04:54:48Z,0,sir please make the video on AUC and ROC,True
@kushalminachi445,2019-09-25T11:16:35Z,1,"XGBoost takes a lot time to run, how do I make it faster?",True
@kapilsharma2124,2019-09-23T16:58:32Z,1,"Hi Krish, I have a question on this. I just wanted to know that hyperparameter tuning applies on every Machine Learning model or not? Can this be used in Linear Regression ?",True
@ujjwaljindal7093,2019-08-22T14:38:39Z,0,this is the best video on hyper parameter optimization i have come across on youtube,True
@coolsun-lifestyle,2019-08-20T11:33:35Z,0,"Hi Krish, Your videos are extremely helpful in learning. I daily watch atleast 1 video to learn. Thanks a lot. I have a question. In any interview there will be a question like how you select your model for a particular model. For do we need to apply multiple midels and select based on evaluation metrics or is there any better approach? Please explain",True
@satishakuthota6290,2019-06-27T09:27:32Z,1,Superbbb Krish and make video on Timr series analasis,True
@ijeffking,2019-06-26T14:40:33Z,2,Very good. Thank you,True
