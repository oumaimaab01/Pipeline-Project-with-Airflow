author,updated_at,like_count,text,public
@abhimanyud5968,2024-05-26T18:50:18Z,0,"Can it be used for clustering models like kmeans. Please answer. If so, please provide a resource.",True
@AbhishekJain-jl3oj,2023-08-11T03:54:44Z,0,"This is local interpreter, how to explain the overall model?",True
@mehulsakariya6245,2022-07-21T07:23:31Z,0,"Great, very informative!",True
@aditiarora2128,2022-02-03T16:44:53Z,0,krish sir plz make vedios on visualizing deep learning models through attention mechanisms and gradCAM,True
@kartikeybisht1309,2022-01-07T11:05:56Z,0,hello sir are we assuming that the features are independent of each other (no collinearity) before passing the feature for interpreting through lime,True
@ayushaneja9076,2021-11-08T19:40:26Z,0,Kindly put a video about Language Interpretable tool too,True
@madhu1987ful,2021-09-16T18:51:21Z,2,Pls make a video on SHAP,True
@Codeplay13,2021-09-14T15:01:47Z,0,Will this work if we had 3 categories in target variable???,True
@sanyasharma4395,2021-06-26T13:44:56Z,0,Please make videos on drift analysis,True
@garomabasha6066,2021-06-12T03:32:27Z,0,Thanks a lot your videos are helpful,True
@marijatosic217,2021-03-31T12:56:04Z,0,Just what I needed! Thank you!,True
@arpanghosh3801,2021-03-13T08:36:23Z,0,While using Lime to interpret XGBoost  in the interpretor.explain_instance step getting below error:  Feature name mismatch....  ValueError: feature_names mismatch  . any idea how to resolve the same. I am having xgb version 0.90,True
@amansaini868,2021-01-18T10:04:55Z,1,"Can I use this for LSTM or complex models? As far, I am aware I can use lime on linear models but LSTM and other Deep neural networks are not linear. Please update me, if I am wrong. Also can you please make video on LRP (Layer wise relevance propagation) or some similar techniques.",True
@paramita2674,2020-12-03T18:58:02Z,0,Very informative..,True
@masterrikku96,2020-12-01T03:58:51Z,5,"Very informative. Adding to this, we can use SHAP and PDP plots for global interpretation (to get an overall view). And ALE, ICE and Lime for local interpretation (to study individual instances).  I used knn to gather similar data points for the input of Lime interpretation as it trains a local interpretable model.",True
@manikantadevasish,2020-11-30T11:04:58Z,2,How is model interpretation offered by lime different from feature importance method given in randomforest?,True
@ShahnawazKhan-xl6ij,2020-11-30T10:00:12Z,1,Great sir really appreciable for your enthusiasm,True
@ranjit9427,2020-11-30T09:56:58Z,2,Should I never install package in my conda base env?,True
@darkhorse9694,2020-11-30T09:02:50Z,2,"Try SHAP , which is also very good foe explainable AI.",True
@subbaraogannavarapu7405,2020-11-30T08:24:20Z,6,"It is Explainable AI. LIME ,ELI5, SHAP these can be used . But we can't use for all models as some are model agnostic. Again nice one from Krish",True
@himanchalchandra6202,2020-11-30T08:22:01Z,2,We can use GradCAM or Saliency Maps in case of Interpreting Deep Learning models,True
@susmitvengurlekar,2020-11-30T07:45:48Z,3,"@Krish Just in time! Was going to make a notebook Model Validation , for when target is continuous, was going to plot the line plot with points of residuals for continuous features and box plot of residuals for discrete features to check whether the model is stable or not.  Will use this also in the notebook. Thanks a lot!  By the way,  Useful shortcut, ""A"" to insert row above, ""B"" to insert row below.",True
@sayitavii,2020-11-30T07:22:27Z,4,Can i get a heart‚ù§‚ù§,True
@limitlessplays007,2020-11-30T07:21:21Z,2,Can i have heart,True
@madanmaram276,2020-11-30T07:19:48Z,4,Please make a video about ZERO -SHOT LEARNING üß†üß†üß†üß†,True
