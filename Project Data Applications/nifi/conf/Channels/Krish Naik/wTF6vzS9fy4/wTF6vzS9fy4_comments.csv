author,updated_at,like_count,text,public
@social_media789,2023-08-07T05:33:22Z,0,how to find radius in knn ( in jupyter notebook with code ),True
@87040256,2022-09-29T02:53:24Z,1,Thank you so much! This is exactly what I need it.,True
@tagoreji2143,2022-07-07T08:59:20Z,0,"this is what is needed, thank you so much sir",True
@thomsondcruz,2022-07-02T14:34:36Z,1,Excellent Video! 3:41 Euclidean Distance is nothing but Pythagoras theorem's way of calculating the hypotenuse,True
@sahilvlogs5848,2022-04-08T18:53:43Z,1,grt explanation my teacher took 2 days i didnt undersatand a word by watching this 18 min main done with knn thnku,True
@hasnainalibohra8232,2022-03-28T00:10:38Z,1,Hello Sir for k=1 im getting overfitting data and as i increase the value of k the error rate is increasing. How to choose k value if the error graph is linear,True
@shlokdoshi7162,2022-02-03T17:01:30Z,0,"If a give an input list for the KNN algorithm to predict the classes of each element, How can I print out the list of inputs only belonging to a particular class?",True
@amulyatiwari3019,2021-12-30T03:59:35Z,1,"I didn't get why you took k=23 as in the accuracy plot, we can see that the accuracy is increasing after that point. We should take k value so as to maximize the accuracy, right?",True
@SpiritedTravellerr,2021-12-14T14:54:09Z,0,sir I have gone through ML playlist and some videos  are not according to step by step after 50 th video so can you check it again please. bcz some videos are interchange up down,True
@studio2038,2021-12-09T16:39:44Z,1,üôènice video easy to understand,True
@eugeneliu1212,2021-10-31T03:57:31Z,0,"If K is 4, and there are 2 2 equal distribution, what would be the classification?",True
@VC-dm7jp,2021-10-25T21:04:50Z,2,Thank you so much for explaning the concept and code in such a friendly manner.,True
@gauravkumar2602,2021-10-09T22:14:19Z,0,Amazingly explained.Thanks a lot,True
@yijunshen9287,2021-09-30T16:20:53Z,0,best comparing other resources !!!!!!!!!!!,True
@madhabipatra8973,2021-09-23T05:03:17Z,0,PLEASE HELP ME TO FIND OUT ML TUTORIAL -44,True
@mallikharjunv6805,2021-09-09T09:29:43Z,0,Thanks Krish. Good explanation..!,True
@howdontanalytics6158,2021-08-18T18:07:39Z,0,"Can you tell me how I can choose variables for KNN? I have 20+ variables, and not sure how I would keep some of the variables with what criteria.",True
@Neerajkumar-xl9kx,2021-07-19T03:00:15Z,0,great way of teaching by putting code and implementation,True
@dragolov,2021-07-16T11:36:05Z,0,These are 2 musical (jazz) solos generated using K Nearest Neighbor classifier: https://youtu.be/zt3oZ1U5ADo https://youtu.be/Shetz_3KWks,True
@louerleseigneur4532,2021-07-16T09:11:40Z,0,Thanks Krish,True
@louerleseigneur4532,2021-07-16T09:11:26Z,0,Thanks Krish,True
@sindhumathi9209,2021-06-23T03:17:23Z,0,I have started learning about Data Modelling and ML. My doubt is K-Nearest Neighbour will come under classification algorithm which is type of supervised learning. But here it is explained with regression also. Can anyone help me to understand!,True
@RaviSharma-tg6yx,2021-06-03T20:15:05Z,0,It this is also necessary to standardize the categorical variable in KNN to find the better K-value?,True
@raghuram6382,2021-05-14T07:26:41Z,1,"@Krish Naik  The dataset you explained here is a Regression problem right? then why have you used ""KNearestClassifier"" in the codes while importing from sklearn library? could you please tell me? Also why classification report is needed for a regression problem here?",True
@sairohithpasham,2021-05-11T07:09:39Z,0,Thanks for giving a lucid explanation.,True
@kushalhu7189,2021-05-04T19:30:36Z,0,Perfectly explained,True
@iftikhar3609,2021-04-26T06:10:43Z,0,Sir DO you have any discord or slack community if yes please share it here i would like to join your community.,True
@atifroome,2021-04-23T06:56:51Z,0,Hue = hoie üòÄ,True
@sharmakartikeya,2021-04-19T19:36:45Z,5,"Thank you sir, KNN is pretty clear to me now !! : )",True
@nileshkulkarni2845,2021-03-16T05:17:38Z,0,Very well explained sir. ..... Thanks a lot for making my concept clear,True
@chaitanyasrinevas8764,2021-03-07T07:03:20Z,2,"In the error rate vs value of the K plot, shouldn't the value of K be around 37? At k=37, we are getting the least error. At this point, the error is less than 0.6?",True
@istech21,2021-01-28T05:11:31Z,1,"You did not mentioned which metrics is applied when test. Eucledian, Manhattan? sklearn library seems to be use minkowski by default.",True
@unezkazi4349,2021-01-22T14:06:21Z,0,How does it train itself on the data?,True
@ashishgarg5186,2021-01-21T19:47:47Z,0,How does outlier effect knn??,True
@aashishdagar3307,2020-12-30T15:35:09Z,2,"Hi, Krish why not use k =33 it has min error and max accuracy instead of 23?",True
@naveendubey2815,2020-12-21T08:08:14Z,1,Excellent Krish...you are really giving a lot to the society..,True
@kamran_desu,2020-11-21T09:02:58Z,8,"Great explanation, just adding my thoughts here. @12:20, you've mentioned K=1 is underfitting. I think it's the other way around. Low K means highly flexible and jagged boundaries (low bias high variance) leading to overfitting.",True
@awesomeak7083,2020-11-18T11:38:57Z,0,Great,True
@helenhilamariam3149,2020-10-29T07:22:43Z,0,"Hello sir would you please explain about Nearest Neighbour Algorithms for Forecasting Call Arrivals in Call Centers article",True
@anandprasadcc0967,2020-10-12T03:19:54Z,0,Thankyou sir :),True
@srinathakarur9798,2020-10-03T05:22:38Z,0,Thank u sir 4 ur logic.,True
@sandipansarkar9211,2020-10-01T21:40:36Z,0,Finished practicing in Jupyter notebook.Thanks,True
@Charmingenby,2020-09-22T11:27:57Z,0,Hi Krish did u find error.rate (1-mean) becz u standardised the data points forehand; that part confuses me,True
@sandipansarkar9211,2020-09-21T06:48:39Z,7,Superb explanation. Now just need to make my hands dirty in the Jupyter notebook.Thanks.,True
@shubhamsahu943,2020-09-03T06:23:09Z,0,sir what is the name of this data set on kaggle,True
@sajidurrehman89,2020-08-31T07:32:27Z,1,why we need training if we just calculate distance from points in testing ? What exactly is done in training phase if we just classify points based on distance ?,True
@ablearing4927,2020-08-12T06:35:14Z,0,"Hi Krish, I am trying to learn about  algorithms which can be used for text base analysis. Could you please advise?",True
@chetanmundhe8619,2020-06-27T18:24:19Z,0,"Very nice explaination, thank u for this video",True
@AdityaRaj-kl1be,2020-05-31T03:14:36Z,13,"In this video, you told that your model will underfitting  when  k=1, but in this case model always go to  overfitting  when k is low but we increase  the k then our model goes to underfitting .",True
@shreyanshdubey8530,2020-05-21T16:22:41Z,1,Instead of standard scalar can't we use MinMaxScalar?,True
@manikaransingh3234,2020-05-20T03:17:29Z,4,"I don't understand the idea of using KNN for a regression problem. For classification, it's fine: - There you know the location of the point (x and y value) and you have to predict it's category. picking up the five nearest points is understandable. But in a regression problem, you only know the x value of a point and you have to predict the Y value, If I'm not wrong here. In the video, you first plot the point and then pick 5 or some nearest points. But if you already know the location (x,y) of the point, what is the problem here? The mean of 5 neighbors distances gives you what? I'm guessing the Y value but if that is so then how will you pick k neighbors. Please Answer!",True
@xinyuanliu1959,2020-05-17T16:05:34Z,0,I don't understand why to choose k=5 while later in the video it chooses 23?,True
@subbareddyjangalapalli4708,2020-05-15T18:54:41Z,2,"Than you Krish, can we call all multiclass logit regressions are non-linear?  please confirm or post small video. Thank you",True
@solomongift951,2020-04-18T14:43:31Z,1,Wa.kn was.pkw,True
@shreyanshsahay,2020-04-15T15:15:34Z,0,Hi Krish Why we didnt take sqrt of datapoints to calculate K?,True
@kavyasharma5540,2020-04-06T05:57:50Z,0,Where is the link to this kaggle code,True
@sarthakbhatnagar961,2020-03-29T17:28:34Z,0,go corona corona go!!,True
@pabitrakumarghorai7623,2020-01-27T17:34:54Z,2,I do not understand why you take k nearest neighbors as 23? pls reply me sir...,True
@pavankumargopidesu4730,2019-12-14T22:49:28Z,1,hi krish in what situations we can use KNN and logistic regression and what is the difference between them.,True
@surendratadakaluru8900,2019-11-27T06:38:57Z,0,"Why we take k=5, We can take any other value or not",True
@arunkumarr6660,2019-10-04T22:18:11Z,0,could see kadhal vandhale sonf from your bookmarks !!! hah hah ...nice song though,True
@azharshaik21,2019-10-01T18:41:20Z,1,Could you please briefly explain about euclidean and Manhattan distance,True
@siddheshpawar1441,2019-09-24T11:11:36Z,1,thank you sir  great explanation sir can you make one video on yolo algorithm?,True
@karalworld,2019-09-21T16:38:45Z,1,Excellent work.. Done a good job.,True
@manjunath.c2944,2019-09-06T19:11:28Z,1,superb ..good job very much appreciated,True
@roopagaur8834,2019-08-11T11:03:27Z,0,Thank you so much ....!!! It's really nice explanation.,True
@HARSHRAJ-2023,2019-06-26T07:34:16Z,0,Hi Kris. Can you please share the link of video on imbalance dataset.,True
@kvsaipratap7697,2019-06-19T16:35:20Z,4,HI Sir thank you very much for your transfer of knowledge Can Please explain about concept of Weight of Evidence(WOE)  and how it is used in classification algorthims,True
@abhiyujaiswal7579,2019-06-19T04:25:42Z,0,Impressive ! Nice Clarification..,True
