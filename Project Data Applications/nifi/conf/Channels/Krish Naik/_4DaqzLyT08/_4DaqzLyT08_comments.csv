author,updated_at,like_count,text,public
@jamalnuman,2024-03-21T03:40:57Z,0,Great,True
@redreaper8652,2023-12-05T18:47:46Z,0,Basically diminished returns?,True
@salihsartepe2614,2023-10-31T13:08:32Z,0,Thank you for this simple explanation :),True
@subratapaul061325,2023-08-19T17:01:30Z,0,I have a perfect example.....my instructor gave me a 2.5-hour lecture on this finally m confused but in 7 min video you made it clear. It's a  Curse of Dimensionality.........great.,True
@masalaaa3,2022-11-09T13:50:37Z,1,"One concern: When you are using the word exponentially, you are using it wrongly. The exponential increase required for ensuring reliable modeling is in the sampling size and not the number of features. Thank you for the good illustration though. Time: 5:55",True
@jayasimhayenumaladoddi1602,2022-07-23T09:03:11Z,0,Can you please make a very on OLPP?,True
@anithaani4672,2022-07-20T14:57:50Z,0,Thank you bro,True
@Albertrose.24,2021-10-28T02:29:57Z,0,Thanks for explaining clearly sir..,True
@louerleseigneur4532,2021-08-03T09:04:51Z,0,Thanks Krish,True
@manujkumarjoshi9342,2021-05-01T03:44:25Z,28,I have a perfect example.....my instructor gave me a 2.5-hour lecture on this finally m confused but in 7 min video you made it clear. It's a  Curse of Dimensionality.........great.,True
@kamran_desu,2020-11-24T05:40:19Z,1,"Not a sufficient explanation, should add a mathematical lens to it. Check this one: https://www.youtube.com/watch?v=R2hQIJb0Lis&list=PLBv09BD7ez_4InDh85LM_43Bsw0cFDHdN&index=3",True
@senadredzic8835,2020-11-22T22:05:19Z,0,Well explained! Thanks,True
@sandipansarkar9211,2020-09-29T18:32:35Z,1,Watched it for second time for better understanding and coding practice. Thanks,True
@sandipansarkar9211,2020-09-27T20:11:39Z,1,Great explanation Krish. No need to make notes .Just understand. Thanks,True
@chaitanyamallepudi3531,2020-08-30T20:08:36Z,3,Could we select the features using the l2 regularization coefficients; which helps us to select the right features which are not shrinked? By that can we reduce the curse of dimensionality?,True
@subho2859,2020-08-26T05:02:17Z,1,Is it necessary that the curse of dimensionality happens when the no of features increased exponentially ?,True
@discoverdevops5368,2020-06-14T18:08:51Z,2,"In a very simple term, if you are working with  large number of dimensions the pattern discover is challenging, this is what the curse of dimensionality.",True
@dholearihant6011,2020-04-30T07:15:45Z,0,sir thanx for the video i am new to the scenario of machine learning and this helped me,True
@hsin-yuku4086,2020-04-26T09:52:01Z,0,What does accuracy here mean? Does it mean the ability for the model to predict?,True
@cmbharathi2064,2020-02-19T21:14:19Z,0,simply explained.. thank you Krish,True
@somubd,2020-01-26T22:19:03Z,0,Thank You,True
@akashgayakwad9550,2020-01-15T13:30:35Z,5,How do u we know what is threshold value of features selection?,True
@eneskosar.r,2019-11-26T13:24:17Z,0,Very well explanation. Easy to understand.,True
@MarcelloNesca,2019-09-20T18:01:14Z,0,This was a great video explained very easily!,True
@manjunath.c2944,2019-09-07T11:13:39Z,0,kindly do video on Chunking and Lazy Learners method,True
@HARSHRAJ-2023,2019-06-11T08:02:06Z,0,Eagerly waiting for your next video. Please upload soon.,True
@vijaynale7893,2019-06-11T05:45:47Z,0,Thanks you much bro.. waiting for your next video,True
@skyman7290,2019-06-11T04:47:27Z,7,Thanks for the effort. But what you explained is not curse of dimensionality it is simply increasing the model parameters which leads to overfitting. Whereas curse of dimensionality talks about high-dimensional data which their distance distribution gets independent of the data.,True
@ga43ga54,2019-06-10T17:07:25Z,5,Please make a video on the math behind t-SNE.... Great video!! Thank you,True
