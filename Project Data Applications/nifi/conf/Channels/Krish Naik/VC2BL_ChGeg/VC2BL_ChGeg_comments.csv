author,updated_at,like_count,text,public
@krishnaik06,2022-08-26T07:43:29Z,3,"Check out our 30 days Data Science Interview course satrting from 19th September https://ineuron.ai/course/Data-Science-Interview Use Krish10 coupon code to get additional 10% off",True
@jannroche,2022-11-09T01:43:55Z,1,"I don't get why we would want to keep pin code column? It doesn't contribute to this data because it doesn't have a pattern that may or may affect other variables let alone our decisions?it's not like we can ask this data a question of ""what's a pincode pattern that can affect our target?"" It doesn't make sense to me, there's a lot of missing values that evidence of even a slight correlation is nil.",True
@spicytuna08,2022-09-02T13:15:16Z,0,cannot drop customer id if you need to make some recommendation per customer,True
@shaikirfanrahim7334,2022-09-01T12:59:34Z,0,"Hi sir,  Instead of Smote technique wich technique will be use for getting better results I hope you will be answering my question",True
@zaafirc369,2022-08-29T07:05:43Z,3,"Features to be dropped  CustomerID - It is just an id column  Pin Code - Too many data is missing  We can use a variance threshold to remove low variance features as well  City Tier has low variance   Missing values  For numerical features such as age, we can use univariate imputation techniques such as mean/median or we could use random imputation as well.  If distribution of age is normal, I would use mean If distribution of age is skewed, I would use median  But if there are many missing values in the age column, mean/median would change the shape of the distribution of the age column  we could then use random imputation.   These are univariate techniques But we could also use multivariate techniques such as knn imputation or mice.  For categorical features, we can use most frequent/mode or we can use random imputation  We can also use knn imputation or mice.   For pin code encoding, we can use target encoding (but as we are already missing lots of values, I don‚Äôt think it would be necessary)  Derived features - This one would require domain knowledge  I was thinking of converting the age into a categorical feature using numerical encoding techniques like discretization/binning. Creating categories like 30-40(Young),40-50(Mid),50+(Old)   But if we do not have domain knowledge, we could be using pca techniques to transform the high dimensional data into low dimensional and at the same time keeping the essence of the data.    In terms of feature scaling, it all depends what model we are using.  If we are using models that require the dependent variables to be normally distributed, then we can apply log transformation,box-cox transformation to convert into normal distribution",True
@Arjun147gtk,2022-08-28T14:03:01Z,0,"Found an article  Leveraging Value from Postal Codes, NAICS Codes, Area Codes and Other Funky-Arse Categorical Variables in Machine Learning Models",True
@bhupeshmahara,2022-08-28T13:33:38Z,0,"Sir, is this included in Tech Neuron also ?",True
@rahultekade6446,2022-08-27T06:44:08Z,0,We have city feature as  tier i ii III then why do we need pincode?,True
@shresthaditya2950,2022-08-26T18:30:16Z,2,1:12-Feature engineering and E.D.A takes around 30% of the project time,True
@pankajkumarbarman765,2022-08-26T14:05:11Z,0,‚ù§Ô∏è‚ù§Ô∏è awesome sir,True
@AgnikChowdhury,2022-08-26T12:55:05Z,0,Looking forward to learning all of these soon from you Krish..super excited to see you in class..,True
@anilbhargava6227,2022-08-26T11:07:41Z,6,"2 scenarios:   1) If there are only 2 Pin code data available and the rest are missing. Then replace the Pin code column with A Pin code dummy variable with missing as 1 and non-missing as 0.  2) If we know that multiple Pin codes are missing, if a substantial number like 90% of the Pin codes are missing, drop that column. If less, say 27% of Pin discreet categorically column and apply one hot encoding with multiple levels, wherein, look at the frequency distribution of the pin code and take a call. If the distribution is random, then push the business to provide data for these, if no data is available for this then ask the business whether this column is very important if not remove the column.",True
@prateek6306,2022-08-26T10:31:16Z,2,"Hi Krish, When will you take NLP live session ?",True
@shahbazansari7318,2022-08-26T09:30:43Z,0,for pincode encoding I think min-max scaling technique is a better option because using this range will be between 0 to 1.,True
@2galacticos,2022-08-26T08:40:03Z,1,Pincode encoding = p(class|pincode)/len(pincode column),True
@piyushjayasawal2201,2022-08-26T08:29:44Z,1,Please make this Data science Interview preparation course available to tech neuron also,True
@neeshantn9742,2022-08-26T08:23:45Z,2,Hi Krish... thank you for the video...just wanted to know if I'm still learning DS now...can i join your stated course regarding the interview... because it's a lifetime access...but registration time may be limited right?? Just let me know please,True
@amitdatta595,2022-08-26T08:14:54Z,8,"Hi sir - If someone is enrolled for One-Neuron, will he get access to this interview course videos as well? Or he still needs to take this course separately.",True
@mdodamani642,2022-08-26T07:48:16Z,2,"Hi Krish, Thanks for the video,, few months over i have completed ML Course...  I am from Commerce background, Feeling so much difficulty to crack 'Data Science' interviews. Your guidance will be very helpful",True
@Akanksha-Tiwari2702,2022-08-26T07:45:59Z,3,Sir please upload a full interview video please sir üôè,True
@RahulSharma-cn9fy,2022-08-26T07:45:48Z,1,Happy Birthday sir,True
@msgupta07,2022-08-26T07:45:02Z,1,Really helpful... Before watching videos,True
@shaistaparveen417,2022-08-26T07:44:54Z,0,Happy belated birthday Krish sir,True
@thealgorithm7633,2022-08-26T07:44:48Z,0,Big fan sir,True
