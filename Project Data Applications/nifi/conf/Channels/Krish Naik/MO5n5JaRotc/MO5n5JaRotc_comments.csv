author,updated_at,like_count,text,public
@pec8377,2023-08-14T08:32:39Z,0,"Hi @Krish, shouldn't you create the bag of words on the X_train instead of the full dataset ? Otherwise the accuracy will not be the same when providing a new sentence",True
@MuhammadAbdullah-gx2ou,2023-07-24T06:35:19Z,0,"dear sir i am facing this error here:  TypeError                                 Traceback (most recent call last) <ipython-input-30-8fb5f9428800> in <cell line: 5>()       4 corpus = []       5 for i in range (0, len(messages)): ----> 6     review = re.sub('[^a-zA-Z]', ' ', messages['title'][i])       7     review = review.lower()       8     review = review.split()  /usr/lib/python3.10/re.py in sub(pattern, repl, string, count, flags)     207     a callable, it's passed the Match object and must return     208     a replacement string to be used."""""" --> 209     return _compile(pattern, flags).sub(repl, string, count)     210      211 def subn(pattern, repl, string, count=0, flags=0):  TypeError: expected string or bytes-like object",True
@faryaltahseen7197,2023-06-08T08:55:19Z,0,"Sir ! I m very new to NLP, Thank you so much  for this playlist... i am learning so many things from you....but plx tell me how can i fix this error? 12 from unicodedata import normalize      14 if normalize: ---> 15     cm=cm.astype('float')/cm.sum(axis=1)[:,np.newaxis]      16     print(""Normalized Confusion Matrix"")      17 else:  AttributeError: module 'matplotlib.cm' has no attribute 'astype'",True
@vasanthrohith4564,2023-05-24T09:47:05Z,0,It's super usefulü§©.... thanks for teaching ‚ù§,True
@parthraghuwanshi2980,2023-01-20T19:58:47Z,2,People like u are gems who after working hard all days in office takes out time just to do post quality content that too being selfless I can truly understand how much good values a person has,True
@mohammedzia1015,2022-08-02T05:00:56Z,0,"Hi Krish,, It was a nice video, but I have one ques, the condition ""If score = previous_score"" will satisfy every time right ? As you have set the value of previous_score to ZERO. So what is the use of this ? Don't we have to assign score value to previous_score like this ""previous_score = score"", after the IF condition ?",True
@mainuddinali9561,2022-07-14T11:09:21Z,0,"i m not able to download dataset , without practice it is waste",True
@samirpaul5499,2022-06-01T16:22:19Z,0,"Hello Krish - This is an amazing video. I have been watching your videos and learned many things. Wonderful contribution towards the aspiring Machine Learning engineers. I have one question, request you to clarify. After this Bag-of-words/TF-IDF model is built, for new sentences, how do we construct the input featues (to be passed to predict function of the model). If such explanation exists in any other video, please point me to that, else would request you to make a short video on this, this will be immensely helpful. Thank you again. -  Samir Paul",True
@rajarshidgp2003,2022-02-25T11:38:21Z,0,time[15:40] - u r not able to see the because you had done reset_index - so the original index numbers have been lost,True
@karanshethia3560,2022-02-24T14:03:29Z,0,Hey Krish. Great video. Can you let me know how can we make a predictive system once we have tried out different models and selected the one that is more accurate/effecient?,True
@adarshgupta9952,2022-02-05T06:21:53Z,0,"I have exported this model as a "".sav"" file using Pickle. Now, how can I test this model? I want to write a news statement and want to predict if it is true or not. Please help anyone!",True
@thepresistence5935,2022-01-07T06:29:41Z,0,"Waited 2 hours, but it not executed in my lap, so tooked first 1000 data and changed worked",True
@RadomName3457,2021-12-08T09:05:29Z,0,"Hi guys, could anyone explain to me what the coefficients of the models are. Why do we have those numbers?",True
@jonashero5054,2021-09-16T10:00:43Z,0,where is the part 2,True
@mansikumari9533,2021-07-07T06:24:18Z,0,I am getting parser error while uploading dataset .Please solve,True
@sourav521878,2021-06-17T12:49:53Z,0,"Sir, from line 52, (from nltk.corplus import stopwords), my output is not showing in anaconda jyputer. . .any idea, how to deal with???",True
@sabafarheen4918,2021-06-02T09:55:59Z,0,Sir just with single word how we can say it's fake?? Please answer,True
@preethisetty4309,2021-05-24T16:00:41Z,0,Can u explain fake online reviews detection using passive aggressive classifier,True
@saisubramanyam3243,2021-04-27T07:30:56Z,0,Sir how to predict the label of test data instances whether it is fake or real.,True
@tirumalaparise9474,2021-04-15T23:20:38Z,0,"Sir, how can this model predict fake news or real news, when some other external news is given Preprocessed in the same way of x[title]?  Does it work for real life? Or just on testing data..",True
@jainilpatel1173,2021-04-14T08:50:30Z,1,I got error in -- please give ans In passive aggressive classifier algorithm: Unexpected keywords argument n_iter(50),True
@bahargk4626,2021-03-27T09:34:08Z,0,"Could you please upload train.csv in Github?  I got an Error: We're sorry, but this service is not available in your location",True
@avibitm,2021-03-22T21:47:32Z,0,Hi krish can u help us make API on this,True
@sivarajasekharyannam9398,2021-02-19T06:35:58Z,0,Hello sir please send the  document in this project,True
@junaidyousaf4602,2021-02-17T09:52:05Z,0,Sir after this please make one video on How To Detect Hate Speech ...,True
@ushirranjan6713,2021-01-23T06:43:37Z,0,"Sir,When I am trying to import the data and read in the colab, then it not is happening. There was some error due to that I have to do these changes, to read the data.  df=pd.read_csv('train.csv',engine='python', encoding='utf-8',error_bad_lines=False)",True
@rohitbaisane6712,2021-01-04T18:46:22Z,1,How your classifier detect fack news It detect every news or like only the news of dataset?,True
@CasualGamer669,2020-12-29T03:30:32Z,0,can tou make it to be a simulator ??,True
@tejashshah5202,2020-12-18T23:14:53Z,4,"At 10:48 , CountVectorizer() should not be performed before train_test_split(). If you do, this leads to data leakage and is not correct. Correct way is to fit_transform() on train and transform() on test data.",True
@1pmcoffee,2020-12-08T22:15:13Z,0,@Krish Naik Sir do you provide paid personal consultation on hourly basis? Its there any way i can connect with you?,True
@sahityakandru6134,2020-11-27T15:40:18Z,0,"While I was running the ipynb file you gave i can find an error that Unable to allocate 698. MiB for an array with shape (18285, 5000) and data type int64 Can you please explain this",True
@aravindnaidu1286,2020-10-29T05:49:44Z,0,"sir, I have a doubt why you havent taken other parameters other than title and we are getting an accuracy of 94 pecent  Iam just shocked!!!!! plz reply plz",True
@tusharpangare2468,2020-10-26T16:02:42Z,0,"messages.reset_index(inplace=True)  im having error like: AttributeError                            Traceback (most recent call last) <ipython-input-68-349e4a68ab3c> in <module> ----> 1 messages.reset_index(inplace=True)  AttributeError: 'function' object has no attribute 'reset_index'  can someone help me",True
@011_mohdanwar2,2020-10-23T17:02:27Z,0,"Dear sir , I want to ask u, can we Work on title or text . Process of remove the stopword??? Can u explain me ???",True
@vishaldas6346,2020-10-16T14:35:21Z,0,"Hello Krish, I think there is a mistake while explaining True Positive & True negative. Correct me if I'm wrong.",True
@johannachristy7515,2020-10-11T11:14:46Z,0,Pls also tell us how to implement this in a web application,True
@harikrishnanm5109,2020-09-25T17:12:49Z,0,"It  was really helpful. Can u make  videos on Grammer Correction using  Rule based methord, Language Models &  classifiers. its really hard to understand it otherwise",True
@lokbharatendu7063,2020-09-23T17:20:15Z,0,"Hi Krish First of all thanks for such good videos! I am very new to data science so my question might sound very basic.  In the current video and also in some of the other videos in the current playlist, you have mentioned that algorithms like Naive Bayes/ MultinomialNB work very well with text data.   In all the samples we are converting sentences to words and then to features (having values 0 and 1 in case of BOW). So post this conversion aren't we just dealing with numeric data rather than textual data? As all the text has been converted to independent features having numeric value.  Can't we just use any of classification algorithm? if yes then why we say Naive Bayes works well with text data.",True
@muskannadaf3790,2020-09-19T06:25:03Z,0,"hello, I am getting an error in this line : import nltk from nltk.corpus import stopwords from nltk.stem.porter import PorterStemmer import re ps = PorterStemmer() corpus = [] for i in range(0, len(messages)):     review = re.sub('[^a-zA-Z]', ' ', messages['text'][i])     review = review.lower()     review = review.split()          review = [ps.stem(word) for word in review if not word in stopwords.words('english')]     review = ' '.join(review)     corpus.append(review)  error as :  LookupError                               Traceback (most recent call last) C:\ProgramData\Anaconda3\lib\site-packages\nltk\corpus\util.py in __load(self)      82                 try: ---> 83                     root = nltk.data.find(""{}/{}"".format(self.subdir, zip_name))      84                 except LookupError:  C:\ProgramData\Anaconda3\lib\site-packages\nltk\data.py in find(resource_name, paths)     584     resource_not_found = ""\n%s\n%s\n%s\n"" % (sep, msg, sep) --> 585     raise LookupError(resource_not_found)     586   LookupError:  **********************************************************************   Resource stopwords not found.   Please use the NLTK Downloader to obtain the resource:    >>> import nltk   >>> nltk.download('stopwords')      For more information see: https://www.nltk.org/data.html    Attempted to load corpora/stopwords.zip/stopwords/    Searched in:     - 'C:\\Users\\MUSKAN/nltk_data'     - 'C:\\ProgramData\\Anaconda3\\nltk_data'     - 'C:\\ProgramData\\Anaconda3\\share\\nltk_data'     - 'C:\\ProgramData\\Anaconda3\\lib\\nltk_data'     - 'C:\\Users\\MUSKAN\\AppData\\Roaming\\nltk_data'     - 'C:\\nltk_data'     - 'D:\\nltk_data'     - 'E:\\nltk_data' **********************************************************************   During handling of the above exception, another exception occurred:",True
@avanishsingh8518,2020-09-08T08:59:34Z,0,"Hi sir , Sorry but I have a question ,in the video you were telling that you are going to use text column for countvectrozer ..but you are taking title column. why?",True
@varunpusarla2590,2020-08-31T18:03:49Z,0,Why do we use Naive Bayes for NLP problems ?,True
@Cho11y10,2020-08-22T21:29:19Z,0,"Easy solution:  Array MsMNews[]= get(garbageCollector); array fakeNews[]=MSMNews[],  üòâ",True
@surajthallapalli4227,2020-08-13T06:57:14Z,1,"Hi Sir, I guess there is a data leakage problem. First we need to split train and test and later we have to apply Countvectorizer rite? In the video first the CountVectorizer is applied and later train and test split is done. Please clarify this.",True
@subarnasamanta4945,2020-08-09T05:56:49Z,0,I am trying this project in kaggle with gpu enable but gpu is not working showing 0% usage there can yu tell me why,True
@abhishekpurohit3442,2020-07-28T13:13:45Z,1,Just got 97% accuracy by combining both title and text....using passive aggresive classifier..,True
@sonalgarg5628,2020-07-22T05:21:13Z,0,"review = re.sub('[^a-zA-Z]',"" "", messages['title'][i]) i get the error in this line-  expected string or bytes-like object please solve this",True
@abhishekpurohit3442,2020-07-20T11:25:19Z,1,Sir you've not uploaded the video on passive aggressive classifier....Please upload it Sir!!,True
@vishalvanpariya1466,2020-07-04T18:33:19Z,0,Greta video but I have one query why you use only title feature in modelling you should use all the features,True
@ishwarjagdishashar9096,2020-06-23T11:43:01Z,0,"I have followed all codes. Getting error in re.sub(). ""NameError:name 're' is not defined"".  Do I have to install any library to run the re.sub() function?",True
@2500204,2020-06-22T20:04:13Z,3,"I am a machine learning engineer , I like that you post such videos but the problem with real data set is that there is no training data .   You have to collect and create your own training data . People who are watching this video don't know what is about to hit them once they enter this field.   It's not plug and play.   I spend 80% of my time creating data and processing it and only 20% actually doing ML  In one anomaly detection project we had to use db scan to find noise in the data then we marked the noise dp's as anomalous and cluster dp's as non anomalous. Then used that data to train our ANN.",True
@shauryananda207,2020-06-20T19:25:37Z,0,Not able to implement Passive Aggressive Classifier. The argument  'n_iter'  is unexpected,True
@sandipansarkar9211,2020-06-17T17:02:38Z,0,Superb video .But while practice coding I am stuck at corpus and from there on wards it is all stuck.I have tried a number of times but to no avail.Thanks,True
@johnyjose3941,2020-06-09T14:00:24Z,3,"Hi Krish, @ 8:28, why did you take messages['title'] ?? I think we should take messages['text']",True
@malik_msn,2020-06-07T07:32:22Z,1,Would have enjoyed it but the poor audio made mess of ut,True
@ebrahimkutty1491,2020-06-03T04:48:49Z,0,CountVectorizer can remove stop words.,True
@themightylion5147,2020-05-30T20:31:22Z,1,"Sir @ 8:28, why did you take messages['title'] ?? I think we should take messages['text'].",True
@piyushvyas2475,2020-05-24T06:46:41Z,1,"Can you please add F1, recall and precision score in this tutorial for used algos.",True
@rubabvlogs1843,2020-05-18T20:43:20Z,0,aggle fake news icon is Trump ...:),True
@thechaoticneuron,2020-05-11T07:25:20Z,10,"Hello Krish, this is a great video. I started my learning into NLP with this. A small question;   I followed the entire procedure similarly and I implemented  Logistic Regression at the end. It gave me a higher accuracy of 94% with less false positives and negatives as well.    I'm just keen to know how PassiveAggressive Classifier is said to be better for NLP applications and why not s simple logistic regression cannot be used.    Thank you :)",True
@sgrsgr5663,2020-05-11T06:27:37Z,0,"Krish, Voice in this video is not much clear.",True
@tanishbothra5044,2020-05-10T06:52:31Z,1,"Hello, Suppose we need to add more features in our X  which are not text..i.e suppose we get a sparse matrix after count vectorizer and now we have one more feature  length and we want both features.How to combine both?",True
@omkarpatil2854,2020-05-09T15:34:06Z,1,"Hello krish, For the for loop which generates the corpus. Yours was done in few minutes but for my laptop (i5 7th gen, 1050tx 4gb graphics) it took more than half n hour. It's there anything i need to configure?",True
@vipindube5439,2020-05-09T06:02:56Z,0,Hello Krish Sir your voice getting lower please play on high pitch.,True
@subhamacharya7084,2020-05-08T04:20:54Z,2,"Sir,kindly make some basic video on Pandas",True
@alexanderbalasky6174,2020-05-08T03:57:00Z,6,Great walkthrough but look into your audio!,True
@mdenamulhaque7589,2020-05-08T01:41:46Z,2,"Dear Krish, for being a data scientist should we need to learn SQL or something like this? If it's need then why it's absent in your data science play list or do you have any idea in future for that. I'm very confused.please info.thnx",True
@urvashisingh3329,2020-05-07T16:58:12Z,1,Sir i need help its very very urgent i want the code for the speakers age and gender classification plz help sir i really need it.,True
@suresherriboyina,2020-05-07T16:29:05Z,7,"Please upload Part 2,  Because now we have so much of time , so keep upload new project videos",True
@sachinborgave8094,2020-05-07T14:51:10Z,2,"Thanks Krish, please upload GBM indepth intuition.",True
@ganeshhegde8972,2020-05-07T14:45:36Z,1,Nice sir,True
@kalppanwala6439,2020-05-07T14:06:28Z,2,krish can u make videos regarding BERT can't find any good explanations regarding the same,True
@thunder440v3,2020-05-07T13:50:01Z,1,Wow!,True
@krishnaik06,2020-05-07T13:49:25Z,54,"Hello All,This video were for the members, but many of you all had requested this video. So I have uplaoded for everyone. It is also added in NLP playlist  Happy Learning!!",True
@souravsingh9443,2020-04-09T06:36:31Z,2,"Hello sir i want to ask ques about analysis data...can you tell me in short...it will be helpful for me.....      at influrocket, we help users to perform keyword research to discover new topics with great potential. one important aspect of a good topic is its search volume. for example, let's say the keyword ""superman"" has a search volume of 250k per month. other related search terms can be ""superman logo"" (55k), ""batman vs superman"" (60k), ""superman returns"" (50k) etc. using which users search for a certain topic in google in a country (say us). however, there may be thousands of keywords with the word ""superman"" in it, and we don't always have exact data for many of these keywords with low volume (less than 1000). in order to find the volume of these topics we use predictions based on the data that we already have for high volume keywords. for example, we may say that the term ""future superman"" will not be searched by a lot of people and its volume can be medium (close to 300). similarly, terms ""superman image"" and ""superman jacket"" will have medium volume and terms that people rarely search will have low volume like ""long sleeve superman shirt"" (100) and then there are terms like ""cheap superman shirt"" or ""superman college"" which will have very low volume. can you think of an approach on how you can classify keywords into ""medium"", ""low"" and ""very low"" by using some logic when we only know the high volume keywords. your answer should be descriptive and backed by reason. (hint- your approach may be to classify certain words which if present will make the keyword ""low"" volume or ""very low"" volume. or your approach can be based on number of words in a keyword, spellings, where exactly a term appears in a phrase and other common human....  How will i do these please summarize this in short",True
@ronaksengupta6174,2020-04-05T12:16:28Z,8,Sir after this please make one video on How Pandemics impact the Financial Markets or anything regarding covid19 dataset analysis,True
