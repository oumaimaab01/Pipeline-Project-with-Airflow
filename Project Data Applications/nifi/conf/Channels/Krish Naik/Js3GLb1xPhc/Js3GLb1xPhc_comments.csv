author,updated_at,like_count,text,public
@data_science_tutorial,2024-04-22T12:05:23Z,1,krish ji you failed to explain the concepts,True
@usamaahmad7191,2024-03-26T14:46:39Z,0,"Thank you so much Sir, the way you were teaching and i was getting all of your points, my love for your method and dedication starts hiking, a lot of love , respect and salute from Pakistan... knowledge have no boundries...",True
@manishkumarmaurya190,2024-01-28T16:23:28Z,0,nicely explained,True
@tamantony2485,2023-11-22T11:26:34Z,0,"At 11:00, how does b get cancelled they have different values right as they are passing through y axis at different points Can someone explain this",True
@optimusVideo,2023-10-26T11:23:20Z,0,You tought good i understood Quickly.,True
@naveeeeeeeeennnnnnn,2023-10-01T16:51:26Z,0,Rather than explaining stories it's better to explain with an example,True
@arindammallik4974,2023-09-28T16:09:10Z,0,Why/how the slope is -1 for the hyper plane there?,True
@mmm-me4kk,2023-08-12T22:19:30Z,0,Thanks Krish!,True
@nitinudgirkar,2023-07-24T10:50:36Z,1,"At 4:43, I think the W transpose will be a row vector. W itself is a column vector and you need to take a transpose of W to make it a row vector - that it [-1  0]. x is fine as its a column vector anyways. Your calculation of -4 for y=w(transpose)x will be correct for the row vector of W - that is transpose of the column vector W",True
@janavinayak7176,2023-07-03T10:58:35Z,0,"THANK YOU !!!! I can not even explain how much you helped me, I was about to cry as i was not able to understand the math behind SVM and why we use Lagrangian function. I have exam after 10 days and your videos are really helping me in this time thanks once again and HAPPY GURUPURNIMA from bottom of my heart !!!",True
@ankitjhajhria7443,2023-06-12T18:31:15Z,0,can anybody tell me how the total distance is x2-x1 ? it should be x2+xe,True
@someotherstuffs,2023-05-23T12:42:45Z,1,Hello Sir! Thankyou for this lovely video but sir at 3:20 i dont understand how can we get 1√ó1 as output after multiplication because as per the rule of matrices if wt has a dimension of 2√ó1 and x has a dimension of 1√ó2 then resultant matrix will be 2√ó2.....Please explain anyone,True
@lisa-sf7no,2023-05-02T14:06:59Z,0,Thanks,True
@gianlucalepiscopia3123,2023-04-21T11:40:42Z,0,soon the best teacher out there,True
@tramytran1992,2023-04-04T08:14:05Z,0,thank u so muchh for ur teaching. wish the best things to you,True
@faizalmakhrus8645,2023-03-25T07:25:22Z,0,Superb! This explanation is difficult to find in youtube.,True
@jatinsharma1915,2023-02-28T11:08:06Z,0,@5:39 How are we getting a scalar value after multiplying 2x1 matrix with a 1x2 matrix?,True
@nirangannirangan7175,2023-02-13T08:57:22Z,0,Excellent sir.Crystal Clear explanation.,True
@swarnachoppella388,2023-02-06T16:18:33Z,0,thank you üôÇ,True
@sasikala_chowdary,2023-02-02T13:43:17Z,0,"No words for this great work.   Thanks you very much For making these concepts very very easy to understand.   I would suggest you to arrange all of them in a particular order or give some sequential number for these videos, so that I will be easy to go through all the topic without any deviation.   Thanks again, keep uploading more videos on different topics.",True
@shadiyapp5552,2023-02-01T10:21:16Z,0,Thank you sir ‚ô•Ô∏è,True
@omkarnigade521,2023-01-29T11:31:36Z,0,"Distance of point  (4,4) from origin/ hyperplane is not 4 units but square root of 32. Is there any mistake in distance formula or I am wrong with calculations? @Krish Naik",True
@mohamedgaal5340,2023-01-23T20:05:28Z,0,Thanks bro. You really did your best to simplify things. I truly appreciate it.,True
@madhuriyadav5574,2023-01-17T18:11:36Z,0,"I have a query at 3:40 how is the value always positive? Considering I take a point (1,-2)? Could you please elaborate more on this?",True
@zinaibrahim,2023-01-09T12:21:15Z,0,"Krish, all I can say is thank you! the best and most comprehensive SVM lecture I've seen (and I've seen many).",True
@sudheerpullagura1387,2022-12-29T16:36:28Z,0,Thank you Thank you sir,True
@datahat642,2022-12-21T17:32:52Z,1,"Very informative video and simple to understand. A slight oversight error, as the X here is 2-d [x1,x2], W (without b) must be 2-d as well [w1,w2]... If we consider bias b, then X = [x1 x2 1]  and W is [w1 w2 b]... and in such a case we shall have a plane instead of a line",True
@saisharadhashivakumar1004,2022-12-18T06:46:43Z,0,Hi sir without you i would have not understood deeplearning this much thank you so much,True
@LaeTech,2022-12-05T06:03:43Z,0,"It is a linear regression, not a logistic regression.",True
@sujatabasu282,2022-12-02T19:26:27Z,0,Why this is (x2-x1) for distance? What is x2 and x1. This not clear to me.please explain,True
@sachinbilung2584,2022-11-14T07:34:06Z,0,i have a doubt if some of them are misclassified how we gonna classified its category,True
@Don69Muk,2022-10-23T04:25:40Z,0,Tanks Ghuru,True
@digambarpuri1699,2022-10-21T05:31:30Z,0,"Thank you sir for this video on SVM. Its very informative. However, the optimization equation should have some variable as output variable. (w*,b*) should be Z(w*,b*). Please reply to this",True
@vandanabhatt1314,2022-10-01T10:25:42Z,1,KSSVA SVM üëçüëçüëçüëçüëç,True
@sivareddynagireddy56,2022-09-28T15:57:33Z,0,"I saw so many articles about svms, every one say directly distance formula simply maximize,but your simplification from strach is awesome sir !!!!",True
@victor75570,2022-09-26T02:01:39Z,3,I cannot begin to thank you enough for breaking down and simplifying the math behind the machine learning algorithms. Understanding the math under the hood is pertinent to tuning the hyperparameters. I love your videos and I'm always recommending aspiring data scientists to check out your channel.,True
@anshulagarwal6682,2022-08-30T07:17:10Z,0,You would have used signum function which is +1 for positive -1 for negative and 0 for 0.,True
@jevoncharles8680,2022-08-16T21:18:36Z,0,You are a GENIUS!,True
@YouTubelesss,2022-07-31T10:31:00Z,1,man how could you remember all this... I keep forgetting the concepts after few weeks and had to watch it back to get a grasp on it. A million thanks for you in sharing your precious knowledge with us.,True
@suganyasuchithrra6992,2022-07-04T04:18:53Z,0,Sir... please can you tell me LGBM algorithm working,True
@mitultank7872,2022-06-26T05:10:31Z,0,Thanks üëå,True
@LanteLuthuli,2022-06-11T19:22:51Z,0,Legendary ... New subscriber!,True
@rupeshnaik7626,2022-06-09T07:36:18Z,0,Sharing is caring,True
@Shakibfan,2022-06-03T06:42:48Z,0,Hats off!,True
@bhabeshmali3640,2022-05-19T20:20:57Z,0,You are a Gem Krish Naik.,True
@mbbkr1248,2022-05-07T14:52:25Z,0,"Thank you for this excellent explanation! The only point I can't get in 12:10, why we need to maximize 2/||w|| ?",True
@emmanuelibrahim6427,2022-04-15T16:32:32Z,0,Excellent delivery!,True
@msrraju1987,2022-04-15T09:00:59Z,0,There are plenty of mistakes in what you taught.,True
@ahmedelsabagh6990,2022-04-03T20:23:27Z,0,Great video,True
@akshaykhavare5898,2022-04-02T09:01:40Z,0,The way you simplify things is really commendable. After reading lot of blogs and going through other resources finally landed here and it was worth it. Thank you Sir.,True
@bruceWayne19993,2022-03-29T06:06:47Z,0,"1.  is this an important topic? 2.  is it frequently asked in interviews? 3.   can i skip this topic ?",True
@debanjangoswami1181,2022-03-28T15:54:41Z,0,just WOAW,True
@AshishRohilla.,2022-03-27T12:06:35Z,1,change your youtube name as computer walaw because ur face mathces to physics wallaü§£ü§£ü§£,True
@afsarullashareef3567,2022-03-22T18:55:39Z,0,"Krish , I'm really thankful to you .. may God bless you .",True
@bahjamustapha2516,2022-03-21T20:06:17Z,0,good job ..thanks a lot,True
@expertreviews1112,2022-03-09T18:26:51Z,0,very nice and lot of effort put in to explain... complex topic but really nicely explained...,True
@mwaurades,2022-03-08T11:51:17Z,0,"I really appreciate the tutoring Sir , keep up the good work !!!",True
@hafimaoubarry6967,2022-03-07T05:21:05Z,0,Very Informative video. GOD bless you,True
@tukaramugile573,2022-02-16T11:41:26Z,0,Very good explanation. Thanks,True
@varshafegade4688,2022-01-31T08:56:49Z,0,why you performed x2-x1 as we need to find total distance then it should be x1+x2 according to your diagram,True
@sushantpatil2566,2022-01-30T07:12:21Z,0,thanks,True
@tomthomas1431,2022-01-29T14:29:05Z,0,very good explanation....easy to understand,True
@K-mk6pc,2022-01-29T08:14:51Z,0,"Sir can you disclose how to learn these concepts, what reference materials You usually use so that we can start to learn in your way.",True
@ranabhavesh1191,2022-01-23T09:55:43Z,0,Awesome video everything got clear.. üôèüôè,True
@sumanyaliwal5883,2022-01-12T10:09:30Z,0,Thank you Krish,True
@rajeshnimma155,2021-12-31T07:05:17Z,0,C value -as you mentioned how many misclassifications are allowed. if C is a high tends to hard margin and c is low high misclassification allowed. Can you please justify it with the final optimization equation we got?,True
@danishwais2701,2021-12-29T06:11:02Z,0,Is the distance between hyperplane and +ve marginal plane & the distance between hyperplane and -ve marginal plane equal? ie is x1=x2?,True
@tarunmunjal9227,2021-12-19T15:19:06Z,0,"Hey krish. In you video, You mentioned that whenever a new data point has a value y*(W*x + b) < 1, Then, It's a misclassification. What will happen if the value is in between 0 to 1 ? I think if the value is in between 0 to 1, Then it would be a correct classification (If we consider the hyperplane) but the data point will lie in between support vector and the hyperplane.  If the value is less than 0, Then we can say that the data point has been misclassified, Since, The data point will lie on the other side of the hyperplane.",True
@shekhargaikwad5767,2021-12-05T10:43:10Z,0,"Superman, batman, Shaktiman of Machine Learning",True
@cryptogaming8026,2021-12-01T11:17:01Z,0,"Please Check that whether w1 is the slope of the hyper plane because if we consider the equation w1x1+w2x2+b=0, then the slope comes out to be -w2/w1 , so tehnically in the example you explained you took y axis to be your hyperplane",True
@rajmani4486,2021-11-26T14:53:31Z,0,Sir give playlist in which this video is part,True
@ammunandy6876,2021-11-23T04:05:27Z,0,Hi krish...at 11:24  the equation is actually -2/||w|| but u have written 2/||w||....kindly explain,True
@darshantank554,2021-11-01T19:06:42Z,0,Why it is  x2-x1 instead of x2+x1 ü§î,True
@NicJd01,2021-10-27T14:24:05Z,0,Bhari dada!!! Mast samjavlat!!üëåüëå,True
@malathiavinash984,2021-10-23T12:46:53Z,0,This video is so good. Thank you Krish!!!,True
@muhammednishad6003,2021-10-23T06:51:33Z,0,Why we are taking +1 and -1 for support vector planes equation,True
@betanapallisandeepra,2021-10-21T00:06:36Z,0,thank you for doing it..,True
@jean-bosco729,2021-10-19T03:00:41Z,0,A+,True
@vishaljhaveri7565,2021-10-12T09:09:42Z,0,"Thank you, Krish Sir.",True
@sarabjeetsingh5033,2021-10-10T22:38:28Z,0,"Hi Krish @3:32 the matrix multiplication is incorrect. Consider a matrix A of order  m X n ie it has m rows and n columns Consider a matrix B of order  n X p ie it has n rows and p columns  When you do matrix multiplication of A and B, the resultant matrix should of order m X p  While in your case you multiplied a matrix of order 2 x 1 with 1 x 2, so the resultant matrix should be of order 2 x 2 but you have 1 x 1 order. Also, what you have written looks more like a determinant of a matrix ( integer value) than a matrix. Could you check on this?",True
@himtyagi9740,2021-10-09T19:01:31Z,0,Lots of efforts are given by you in creating this clip...You are an excellent teacher...Best wishes,True
@yashasvibhatt1951,2021-10-08T05:50:19Z,0,"Can't we use distance formula like Manhattan Distance to calculate distance between the points or is there some specific reason to not do this, the reason could not be the n-dimensional space because we use the same formula on KNN Classifiers with ND space problems as well.",True
@SAURABHKUMAR-ql8wi,2021-09-26T17:11:57Z,1,It was wonderful session. I have gone first time for SVM and able to relate the mathematics very well. Thanks a lot for this session.,True
@semireddy5108,2021-09-16T09:36:12Z,0,thank you so much can i have the soft copy like pdf or other of this example,True
@PrashantThakre,2021-09-10T18:16:36Z,0,The main game starts at 18:24 when the main hero of the movie gets entry.. Nothing but our favorite regularization :),True
@prashantkumarvishwakarma8645,2021-08-28T14:56:59Z,0,"Thanks Sir, For all of yours video agr aap nhi hote to kbhi v itna sikh nahi pate humare instute wale log sirf  overview bata k chor diye but real knowledge to aapki video se mila..... Thank You So Much",True
@adipurnomo5683,2021-08-23T14:37:27Z,0,You SUCH great! How could you learn all this things,True
@adipurnomo5683,2021-08-23T14:30:39Z,0,Clear explained. Very recommended,True
@akshaybagal2208,2021-08-15T13:05:53Z,0,great stuff and nice explanation!!!,True
@jainitafulwadwa8181,2021-08-09T21:25:42Z,1,"I feel Andrew ng's lecture on SVMs give better intuition than this, some of the concepts here seemed vague and irrelevant",True
@dushananuradha1098,2021-08-08T05:08:10Z,0,Good explanation..,True
@deleolukoya4634,2021-08-07T14:24:30Z,1,"Wow! God bless you for all the efforts u put together to make this known to us, in fact, you're passionate and affectionate about us ur students. More strength and grace unto you. From Nigeria",True
@vigneshvicky6720,2021-08-02T12:05:57Z,1,Nice nice very nice‚ù§,True
@dung.nt085,2021-07-30T19:25:01Z,0,Perfect,True
@saumyamishra5203,2021-07-29T19:07:23Z,0,Sir please make a video on SVM regression problem.... ANd guys really you are not going to understand this for 1st time... At 1st glance it look like what is going on i was tricking for 1st time....along with this u have to read some blogs also.,True
@geogeo14000,2021-07-04T14:54:09Z,0,thank you so much,True
@mahikhan5716,2021-06-21T11:29:08Z,0,a sensible tutor i have seen my life who always traces students pulse . there are lot of tutorials about svm in youtube but no other covered  A to z as like as krish . appreciate u krish,True
@sravaninallabelli1251,2021-06-13T10:33:26Z,1,Sir what is Twin support vector machine (TWSVM) and how it is differ from SVM,True
@rohanshah1957,2021-06-11T04:52:38Z,1,@3:14 how he take w as [-1 0] ? W is coefficient of x and y of plane . Am I correct?,True
@AbhishekKumar-gu3ny,2021-06-07T10:39:13Z,1,"I have a doubt, at 10.43, Isn't the maximum distance between margins be X1 + X2?  Thank you for this simplified lecture on SVM.",True
@parikshitmukherjee9895,2021-06-05T15:12:25Z,0,is it primal or dual?,True
@amirfadzil,2021-06-02T15:46:49Z,0,how do you conclude C is number of error allowed? it seems not right. maybe I'm wrong. can you explain please thanks,True
@unezkazi4349,2021-06-01T11:02:52Z,1,How did you decide that equation would be wx+b=1 and wx+b=-1 for the marginal lines? It could be anything in place of -1 and 1 and hence the function that you have to maximize can change. please solve this doubt,True
@venirajan2772,2021-05-27T02:33:15Z,0,Thank you so much for awesome explanation.keep on doing sir.,True
@mayursalunke1654,2021-05-26T12:26:37Z,0,"by looing this video, I actually understand, How important math in real life! and also How logistics and support vector machines actually differ. Thank you Krish sir",True
@wenqichen4151,2021-05-19T03:35:18Z,2,"I can't wait to express my infinite appreciation for you, sir! This video is so so so intuitive and uses less advanced math!",True
@rupeshsingh4012,2021-05-17T06:15:07Z,0,Very very impressive explanation.. Thanks a lot. Bhagwan aapko hmesa khus or swasth rakhe....,True
@trivendratiwari9231,2021-05-11T09:37:41Z,0,nailed it sir,True
@vignanvennampally6852,2021-05-10T18:56:17Z,0,Watching One video of yours = reading 100 blogs. Thank you for saving our time!,True
@iramarshad700,2021-04-28T03:50:56Z,0,Why below origin values are treated as positive? Can anyone explain it?,True
@gaganarvind3036,2021-04-12T03:58:44Z,0,Thank you!,True
@kirushikeshdb1885,2021-04-09T03:19:35Z,5,"The w matrix should be [1 1] because the line equation is x1 + x2 =0, also while computing the value of y, wT should be a dimension of 1x2 and X should be 2x1, so that you will get a single value.",True
@yousrachahinezhadjazzem5969,2021-03-14T21:26:31Z,0,Best video to understand the math behind SVM. Thanks a lot Sir!,True
@navoditmehta8833,2021-03-12T14:59:30Z,1,"At 3:20 what will be the value of y if x is at (1,-2) ?",True
@geetanshkalra8980,2021-03-10T14:29:20Z,1,Thank you sir! Your video has helped me to get an internship to a very good company!  ‚ù§Ô∏èüî•üí•  Please continue the same work! It really helps us! Thank you!üî•üî•üî•,True
@kannansingaravelu,2021-03-10T04:13:31Z,0,"Very informative, you nailed it. Can you recommend the best text book or literature detailing these concepts?",True
@hessamjamalkhah9781,2021-03-08T06:20:10Z,0,"Thank you dear Krish, you nailed SVM for me, I totally understood the concept behind it, and I really appreciate that.   wish you all the best",True
@harshpathak754,2021-03-08T06:09:30Z,0,Concepts given are very easy to grasp. Thanks for uploading such an amazing content.,True
@hemangdhanani9434,2021-03-06T11:57:56Z,0,understand completely... thanks for simplifying,True
@surajpagad7759,2021-02-13T12:07:43Z,0,"i think the b variable is wrongly represented. it cannot be the distance from origin on the x1 axis. rather, it should be perpendicular distance from the hyperplane to the origin.",True
@bharadwajsatya5633,2021-02-11T19:55:17Z,0,"I can't seem to find the SVM kernel trick video, does anyone know if he has uploaded it yet?",True
@vijayalakshmi3968,2021-02-09T09:48:43Z,0,thank u much sir.... ur videos are more helpful for my course......well explained!,True
@brown_bread,2021-02-02T18:56:57Z,0,"at 2:55, b is not equal to c, which is consider here as 'slope'. b is bias term which is not added to the feature vector when dealing with SVM.",True
@rengarajanraman8608,2021-01-30T08:23:21Z,0,Thanks for putting lot of efforts in explaining such complex concepts.,True
@callmeravi81,2021-01-28T08:19:33Z,0,Awesome lecturing even for non maths background . Sir please post the link for Kernel tricks for SVM. I didn't find that video in your channel,True
@abhijitbhandari621,2021-01-28T06:31:45Z,7,"You really are too passionate about teaching sir. Sometimes you even are being breathless, that excitement of teaching..got no words. Hope you will upload videos on topics related to DNN as well. Proud to be learning from you",True
@aishni6851,2021-01-25T23:11:38Z,1,Great video! Understanding the mathematical intuition behind SVM was very helpful. Thanks for making it so simple!,True
@appliedskill,2021-01-24T16:58:09Z,0,"So instead of writing +1 or -1, we can write +k or -k for avoiding the confusion.",True
@aaryamansharma6805,2021-01-21T10:19:56Z,0,SVM part 3 ?????,True
@harshjangid4339,2021-01-09T18:54:04Z,0,@krishNaik sir i could not understand how we decide the +ve side and the -ve side of the hyperplane?,True
@aradhyamehra,2021-01-07T18:24:40Z,0,Sir can we expect a video on the SVM kernel,True
@arunmehta8234,2021-01-06T01:11:53Z,0,"sir, you write x2-x1 === but in equation you wrote x1-x2",True
@arunmehta8234,2021-01-06T00:55:03Z,0,"W^T = [-1 0] slope is -1 that I understood, but from where 0 came?",True
@lakshyaaggarwal8198,2021-01-05T02:07:03Z,0,Where is the link to kernel trick svm?,True
@billlee8670,2020-12-31T02:11:32Z,0,Wish you had posted this video earlier so that I didn't have to struggle with the SVM stuff in my ML class.,True
@sciWithSaj,2020-12-28T17:52:16Z,0,Clearly explained Nice work sir,True
@srirajvemparala2054,2020-12-28T07:38:57Z,0,"I have a question. While calculating x2-x1 and substituting in the equation wtx+b won't the value of ""b"" change and Isn't ""b""  taken on y-axis. Thanks a lot for explaining the concept.",True
@fancy4926,2020-12-20T13:32:05Z,0,"at around 5:30, take point (4,4) for example, if the b=1, the product should be [-1, 1]T  [4, 4] = A 2*2 matrix. then we cant say it is a positive or negative value? is there any error during writing the equation?",True
@shivadumnawar7741,2020-12-15T17:02:00Z,0,Great tutorial. Thank you so much sir.,True
@sridharmakkapati6586,2020-12-13T17:15:57Z,0,Thanks for knowledge sharing,True
@SumanBhartismn,2020-12-10T05:42:08Z,2,"Abhi tk kahan the sir, I was searching a teacher like you in ML. Finally mission completed. Love from my side.",True
@godse54,2020-12-07T10:28:15Z,0,Pls make Vedio for SVM kernel and SVM for regression... Your videos are just greatüî•üî•,True
@vijethrai2747,2020-12-05T06:20:30Z,2,"18:49 C value is not how many errors to consider. It is quite the opposite.   If C value increases, then tendency to make mistakes decreases because loss will increase with increase in errors. And vice versa.  Greater C will create overfit and lesser C will create underfit.",True
@ArunKumar-sg6jf,2020-11-29T04:01:08Z,0,Sir u don't explain Lagrange used in svm for minmaize the ||w|| / 3,True
@SAN-te3rp,2020-11-26T12:14:01Z,3,I ve been searching who teach maths like this finally found üôèüôè,True
@pathupathu2962,2020-11-25T15:25:31Z,0,Thanks sir . Thank you very much .,True
@deepasarojam4425,2020-11-25T03:51:09Z,0,Once again thanks for the Video!! Your teaching is just amazing.,True
@DhruvSharma14,2020-11-22T21:58:13Z,0,Salutes to you dear teach! You are one of the best for all concepts related to Data Science!,True
@ghadialhajj,2020-11-20T10:49:50Z,0,"I think w should be [-1,-1] instead of [-1,0], because b=0 is already used in the equation of y, and the derivative of y with respect to, both, x1 and x2 is -1. Thanks.",True
@royalzak4019,2020-11-14T14:59:06Z,0,I don't understand why u giving wrong theory about wtx+b=0. Matlab kuch bhi pheko aur hame pata bhi nehi chalega . I am one of ur disliker.,True
@abhishek_sengupta,2020-11-13T04:00:33Z,0,Thanks a lot!!,True
@jbhsmeta,2020-11-04T19:50:19Z,6,Just Great !!! Wow!!! - It was a great experience. Eagerly waiting for the part 3 of SVM covering the kernel trick.,True
@anandhiselvi3174,2020-11-01T16:58:21Z,0,please do video on svm kernel,True
@manojkumar-cm2ym,2020-10-31T14:27:37Z,0,"Your explanation about math behind SVR is really good!! I have one  problem is, how to find the output formula or regression function of given inputs in SVR on python. or indeirectly say develop a correlation between a input or output for a given sitution . please if posiible can you explain it on python exercise with taking defferent kernels. i am greatful to you.",True
@mk5863,2020-10-30T22:44:56Z,0,"If value of C is high then it will magnify error. so if C is high ,we will have to do less no of error. And hence  boundary width will be decrease. And reverse when Value of c is low.",True
@jyotikoli1129,2020-10-25T06:38:49Z,1,Sir...How to find values of 'w'.,True
@sheenanasim,2020-10-25T04:26:01Z,0,I don't think you can just find distance between two hyperplanes by just subtracting their equations. is there any proof for that?,True
@gaayathritradings5135,2020-10-21T06:36:09Z,0,Upload video how svm used in stock prediction.,True
@ahmedhusham7728,2020-10-18T18:22:11Z,0,Please can I know what did you mean by transpose when you talking about (T)?,True
@BharathKumar-vs8fm,2020-10-17T17:00:57Z,0,"Krish, you make the complex things too simple to understand..... Could you make a video on how to convert linearly non-separable data to linearly separable data",True
@myeschool2129,2020-10-14T00:29:09Z,57,"My Dear Teacher From my heart, I salute you, cause you to work so hard for us, your students, to teach the things with so much clarity. Praying for you. ....Noushad Rahim, Kerala",True
@prabhdeepsingh2058,2020-10-12T02:37:15Z,0,"Sir your lectures are great ,Sir make a lecture on svm kernels also üôèüèª",True
@dhruvsingh3566,2020-10-11T21:26:22Z,0,Can I get a link for part 3 if available?,True
@smeetkathiria1182,2020-10-11T16:46:01Z,0,"Hi sir, great video. when will you make the SVM kernel video?",True
@md.muntasirulhoque8563,2020-10-07T16:36:26Z,0,I can understand  thanku,True
@ektatank7652,2020-09-30T05:20:45Z,0,"sir, can you please make a video on SVM kernel trick?",True
@sandipansarkar9211,2020-09-28T16:08:07Z,0,Great explanation Krish.Thanks,True
@axa3547,2020-09-27T20:35:21Z,1,algorithims and concepts like these makes me realize you can never become a dat science in months only a pseudo one you can be,True
@waqarsarwar7012,2020-09-26T05:45:42Z,0,i appreciate your effort and your way of teaching,True
@tanvishinde805,2020-09-24T10:55:30Z,0,"can anybody tell why the values will be always +ve under hyperplane and -ve above hyperplane? i am not convinced by the explanation for this point. I have two issues with the derivation : 1. at 3:09 how and why does b=0 gets included in w' matrix ? 2.  at the time matrix multiplication should result to  2x2 matrix as 2x1 matrix mul 1x2 matrix = 2x2 matrix , so how do you get just ""+4""? @KrishNaik",True
@usamanavid2044,2020-09-21T17:24:35Z,0,particular,True
@shrikantsawarkar3929,2020-09-19T10:32:15Z,0,pls release part 3,True
@carearayam,2020-09-12T17:09:19Z,0,"Excellent explanation, my friend",True
@kerolesmonsef4179,2020-09-12T12:52:57Z,0,"i think you got fat , thanks anywhay",True
@ravigupta-xb9wc,2020-09-10T17:17:00Z,0,Can you provide link of SVM Kernel Trick video you are talking about at the end of video.,True
@himanshumaurya6347,2020-09-09T10:37:00Z,0,good work!! thanks for explaning this topic!!,True
@ravindrasonavane1469,2020-09-04T14:47:38Z,0,sir can I get more numerical problems based on classification...,True
@mathrisk,2020-09-02T08:15:54Z,0,I am a beginner in the subject and your video gave pretty good idea about the topic. Thanks,True
@prashantjha488,2020-08-29T10:23:44Z,0,"Can you provide videos on svm kernel too,thanks again for putting all these together.",True
@davidlee4293,2020-08-28T16:10:38Z,0,super good... you explain it so very well. thank you,True
@himalayasinghsheoran1255,2020-08-27T11:48:46Z,0,Thank you for the great explanation.,True
@sidduaduke6495,2020-08-26T18:09:53Z,0,"Krish, could you please post the your tutorial session SVM Kernal",True
@sakshitajaiswal1439,2020-08-24T06:49:32Z,1,"kitta ""particular""",True
@HhhHhh-et5yk,2020-08-20T17:35:54Z,0,"Sir! C doesn't tell how many errors , bcoz if  C is large SVM becomes strict and if C is small SVM becomes loose and sacrifice some points. Sir,Reply if i'm wrong.",True
@rohitprakashsahoo4004,2020-08-19T21:08:57Z,0,I not got WT*X + B = 0 how ? Line is passes through origin so as per Y = m*X +C it should be Y=X.,True
@karamveersingh8164,2020-08-19T20:01:34Z,0,When is the part 3 expected ? looking forewrd too,True
@williamblanzeisky2524,2020-08-19T14:45:27Z,0,dude u r so fun to watch and u make SVM so much easier lol,True
@ishtiakahmed3272,2020-08-17T20:42:52Z,0,please upload svm kernel trick video,True
@ratulghosh3849,2020-08-13T08:14:53Z,0,Thanks for the explanation of intuition behind SVM.,True
@ravindrasonavane9017,2020-08-10T11:48:17Z,0,Is the video for SVM kernel available? Couldn't find any.... kindly send the link...,True
@khushburajput1841,2020-08-09T07:50:16Z,1,"Thankyou very much for these explanations. Im getting to understand the maths behind the algorithm, most of the interviewers ask about svm. Could you also please upload the overview of svm-kernel types? The differences between kernel types.",True
@harshitgupta1951,2020-08-08T06:34:22Z,0,Is the video for svm kernel available? Couldn't find any,True
@neelark,2020-08-07T01:41:22Z,0,thank you,True
@AnushreeChakraborty68,2020-08-02T20:02:30Z,0,Thank you ‚ù§Ô∏è That's all I can say .. Keep up the great work Sir !,True
@sajidchoudhary1165,2020-08-01T05:54:33Z,0,please make 3rd part,True
@datakube3053,2020-07-30T15:14:53Z,0,respect to u r work n efforts,True
@rahulreddy9137,2020-07-27T19:02:24Z,0,Sir pls Upload video about Kernel Trick,True
@debahutimishra3348,2020-07-26T16:42:07Z,0,This is an awesome video on mathematics behind Linear SVM... Too Good...Keep it up,True
@bwalya773,2020-07-26T11:40:45Z,0,üëèüëèüëègratitude,True
@KKinHD10,2020-07-23T17:31:53Z,0,"If you have the red vector say at point (1,-1) i.e in the 4th quad under the straight line, then the wT.x gives a (-)ve value. Then how will all points under the line have a +ve sign as u said?? same goes for black point in the 2nd quad where point is (-1,2) the value will be +ve and not negative.. In other videos also they say this but i dont understand how will the values in 2nd and 4th quad be as they say??",True
@mayanknaithani5412,2020-07-23T05:28:22Z,0,"thanks Krish, wonderful as always, I have one doubt W^T .X is the equation of line/plane where W is normal to the line/plane, hence shouldn't W be [1,1]..?",True
@shaikhanuman8012,2020-07-22T10:18:03Z,0,hi sir can you explain these with help of examples we can easily understand,True
@dipanwitamanna9540,2020-07-21T11:42:20Z,0,Beautifully and easily explained. Helpful,True
@mrunalannadate7896,2020-07-21T11:32:36Z,0,Very well explained . Could you please tell the books that you refer so that it will be easy to relate with the contents you explained in the video.,True
@thiyagarajanr225,2020-07-20T16:39:59Z,0,"Rocked it ! As you say the data can't be always as expected , it is full of surprises ‚ú®",True
@shindepratibha31,2020-07-19T12:11:52Z,0,Nicely explained. Can you please explain more about svm kernel?,True
@turkeshpote3239,2020-07-18T14:41:57Z,0,fantastic explanation,True
@sakshamkumarsharma2309,2020-07-14T10:42:59Z,0,What is w here??,True
@user-ky7bi9cl2z,2020-07-13T19:16:04Z,0,What will happen in the case for multi - label classification?,True
@lokeshrathi5500,2020-07-12T22:25:25Z,12,"The b value that you plot on the graph should be at the y-axis, right?  Time: -@8:57 please have a check and let me know. Thanks",True
@darshanpatil1765,2020-07-06T11:58:12Z,0,Hats off sir!!,True
@RinkiKumari-us4ej,2020-07-04T13:48:11Z,0,sir please make a video on SVM regressor,True
@SaulWilliamss,2020-07-03T19:55:45Z,1,"These videos are incredibly helpful, thank your very much for sharing your knowledge with us!",True
@nayazithousifkhan1696,2020-07-01T15:24:23Z,0,Krish.... can  you cross check this with your final optimized function  { optimized = Min ( ||W||/2 ) + [ C*(1/n) sum(zeta(i)) ] } Bcaz i found this in some other video,True
@faycalnabaoui9550,2020-06-30T02:04:02Z,0,"hi, ty for the video, i just wanna ask about the link of the video that talks about non linear problems",True
@bishwarup1429,2020-06-28T04:34:55Z,0,@Krish Naik sir please introduce Lagrange multipliers for SVM in the next part. Thank you. :),True
@lamikbj,2020-06-27T13:36:06Z,0,Ty sir,True
@dhruvgrover7416,2020-06-24T10:57:44Z,0,where is svm kernel trick video?,True
@chetnachandwani9487,2020-06-24T09:47:45Z,0,Thanks for the great video,True
@amitavadhar4826,2020-06-21T15:56:28Z,0,"Direction of + 1 and - 1 is flipped.  In an eqn ax + by = c, if you increase c, then the line moves up, and if you decrease c, then the line moves down.  This video shows just the opposite.",True
@a.a3265,2020-06-20T13:36:38Z,0,Great vedio . if I have the data x and t how I start first.   I will draw the data ? or I find the W and b after that I use the svm model,True
@a.a3265,2020-06-19T18:07:38Z,0,can you help me   I have some questions in this subject.  if you allow I send them for you,True
@nandalal-dev6095,2020-06-15T22:17:56Z,0,We want a video on Kernal tricks.,True
@nandalal-dev6095,2020-06-15T21:58:47Z,0,Part3 please,True
@sanyuktabaluni4608,2020-06-14T20:39:14Z,0,"In the actual dataset, we label encode the dependent variable y to 0 or 1. So how is y here 1 or -1?",True
@AmitSharma-rj2rp,2020-06-14T10:29:30Z,1,At 3:07 - Can anyone explain why the vector wT = [-1 0]? I thought w was the orthogonal vector i.e. [1 1]?,True
@biplabkantidas3378,2020-06-14T05:27:15Z,0,Very nice lecture. Thanks Like to know about SVM Kernel,True
@sshiv908,2020-06-09T13:38:10Z,0,What is w* and b*,True
@arghyadeepbarat5624,2020-06-08T09:30:38Z,2,Very good tutorial! I had a doubt. please refer to the portion after 3:15 .WTX ..Is C a component of W? as we know W1X1+W2X + ..WnXn + Wo = 0 . so the equation of the line is X+Y = 0 .so here WT should be [1 1]. Could you please clear my doubts?,True
@piyushdhasmana2575,2020-06-06T04:36:40Z,0,M not getting it after logistic regression SVM concept of plane is totally different as   Uh told in log regression  Plane side i.e +/-ve * yi (+/-) if it turns outt to be -ve then that means there is a missclassifier but here it is totally opposite,True
@andrewwilliam2209,2020-06-03T05:52:35Z,1,"Hey Krish,  I just want to say that your explanations are superb. I am new to Machine Learning and I took an online course about it but it barely gets into the mathematics. I understand that to get good and serious at ML we need a solid mathematical understanding of the various models, so i appreciate these videos that go in depth.   To be honest I watched it the first time and didn't completely get it, but I'm going to watch it again now!",True
@dr.muhammedj.a.patwary4464,2020-06-02T17:59:36Z,2,"Thanks for your nice initiative. However, I have a confusion, at around 4:48, for example, if we consider two points (-1,5) and  (1,-5) according to your description (-1,5) should be considered as a positive class similarly (1,-5) should be considered as a negative class but in reality if plot these two points (-1,5) seems as negative class and (1,-5) seems as positive class. Please clarify this. Thanks in advance.",True
@souravsaha6757,2020-06-02T05:52:55Z,0,Krish it was a very good explanation and waiting for the next part of SVM Tutorial..When is it coming?,True
@Prajwal_KV,2020-06-01T11:01:17Z,0,11:10 it should be -2 right?,True
@devasheeshvaid9057,2020-05-27T10:37:15Z,3,"At 3:00 how is 'WT'=[-1, 0] . W extends from origin and is perpendicular to 'X'(i.e. the hyperplane)  So, shouldn't 'WT' be [-1,-1] (or any other point perpendicular to 'X' i.e. the hyperplane) ?",True
@tabindabhat9078,2020-05-27T10:08:10Z,0,Wow. Great video. Thanks.,True
@sheetalweiz3128,2020-05-27T02:11:43Z,3,this was very intuitive :) so glad to have had this explanation from u .:)  just a question @11:03 .. isnt it -2.,True
@hemantdas9546,2020-05-25T07:50:57Z,6,Sir we need SVM regression,True
@peaceall6585,2020-05-25T05:11:13Z,0,"why   Wt*X + b=-1/+1 and not -5/+5,-2/+2 etc?",True
@eeshdeepsingh7030,2020-05-20T17:41:46Z,5,Thanks alot for this video sir‚ù§Ô∏è waiting for svm part 3 sir!!!,True
@mukulsharma384,2020-05-19T12:14:31Z,1,how id you write w transpose as [-1 0]? please reply,True
@AnilKumar-sv4qn,2020-05-19T06:49:11Z,0,waiting for SVM Kernal Trick krish sir,True
@jitenderthakur697,2020-05-18T13:27:06Z,0,how the support vector works on regression problem,True
@mayankkhanna9644,2020-05-14T12:19:24Z,6,Won't the value of w be [-1 -1]?,True
@followabhi,2020-05-09T11:05:15Z,3,"Hi Krish, I just have one question, how do we use the intuition of maths of an algo while coding? Usually I understand the maths behind the algorithm but not sure how to use it while coding.",True
@masterstats8064,2020-05-09T08:46:42Z,0,"Hi krish, What is the parameter update equation in SVM and logistic regression?",True
@shashankbandi5591,2020-05-08T15:07:32Z,0,"Hey Krish, Can you please suggest few Machine Learning and Data science books for an indepth understanding after watching your tutorials. Thanks in advance.",True
@AnilKumar-sv4qn,2020-05-05T06:54:47Z,1,Please continue this playlist in SVM classifier .....can u explain all concepts,True
@AnkitYadav-tz3ph,2020-05-05T02:49:35Z,1,In soft margin svm points inside the margin are also called support vectors or not,True
@ranchetpierre221,2020-05-04T20:01:14Z,0,Amazing video Krish. Your intuiton about this concept is quite impressive. Do you plan to show an implementation through a project for example of SVM ? Will you talk about the difference between SVM classification and SVM regression ?  Thank you for all your content.,True
@kshitijyelpale1713,2020-05-04T18:52:44Z,0,"Hello Krish,   Very well explained. Liked it. In the video you mentioned about hyperparameter tuning many times.   If possible please make a video on that parameters and hyper parameters tuning for every model, ML and DL all  Thanks üòä üëç",True
@Neuraldata,2020-05-03T17:52:44Z,0,You are really an inspiration to many üëå,True
@anuragshandilya3556,2020-05-03T14:04:16Z,0,Best explanation!,True
@somnathbanerjee2057,2020-05-03T10:14:33Z,1,"Hello my brother, where can I get your mail id? Please try to respond as per your convenience. Would I expect interview materials if I do join with 59Rs./month plan?",True
@arjundev4908,2020-05-03T07:32:40Z,1,@Krish Naik.. My respect towards you and your work has increased by multiple folds.. You are godsend..my saviour :) Thanks for your contribution!! ‚ù§,True
@JaydeepSinghTindori,2020-05-03T05:28:28Z,3,"Thanks for your good explanation on SVM. But I have a confusion that when you changed the representation at 20:29 from max(2/||w||) from algebraic representation to to calculus representation min(||w||/2), I think it should be min(||w||^2)/2 as the derivative will give you min(||w||) as we want to maximize the (1/||w||) or minimize (||w||).",True
@ProgrammingCradle,2020-05-02T22:26:24Z,3,Beautifully explained... Thank you Krish :),True
@ManishKumar-qs1fm,2020-05-02T20:05:50Z,1,In one words awesome,True
@somnathbanerjee2057,2020-05-02T19:45:31Z,0,"https://datahack.analyticsvidhya.com/contest/janata-hack/ Hi, I really appreciate your teaching and sharing knowledge with us. A few days back I tried to complete a hackathon at Analytics Vidhya. I didn't crack the dataset to process it further for model building. I shared the relevant link. I didn't find your mail-id. That's why I posted my concern over here. Could you give any suggestions on breaking down the data for further process. I would be grateful for your response.",True
@rvg296,2020-05-02T18:52:19Z,2,"Krish, I guess you missed the squaring of |W|. Basically, maximizing (2/|W|) or (1/|W|) is essentially the same. This means we have to minimize |W|. Just for math convenience, we will write it as (1/2) (|W|)^2  because differentiating this w.rt to W will lead us to obtain |W|.",True
@darshitsolanki7352,2020-05-02T18:43:24Z,5,Kernel have sigmoid s shape graph n linear and polynomial form  I m from statistics degree u have grt knowledge dude keep it up,True
@rvg296,2020-05-02T17:53:11Z,22,"The Regularization Parameter C is basically how much we want to avoid misclassification of points. If C is very large (infinite) we get the perfect classification of training samples smaller margin is considered, but if C is very small(0) it will cause the optimizer to find the maximum margin classifier even though it misclassified some points. Hence we have a find a good value of C in between. The Gamma parameter defines how much influence a training example has. For example, if gamma is high only the nearest points from the margin are considered for calculating distances, but if gamma is low even farther points from the margin are also considered.",True
@sushilchauhan2586,2020-05-02T17:46:05Z,3,I LOVE YOU MAN SERIOUSLY... i dont have to watch it again now krish ..i m sure .. but I have one question can you pls explain that how max became min,True
@rajraji417,2020-05-02T17:28:48Z,6,Thank you so much Bro and I like you so much bro and Your individuality is seen through everyday and every videos I will become a data scientist one day ...,True
@midhunskani,2020-05-02T17:16:31Z,3,I was for this video. Thanks again. Liked and subbed,True
@Agrima_Art_World,2020-05-02T16:55:19Z,1,"Great Vedio Krish.I hope Zeta which u mention is Gamma.If not ,please explain what is parameter Gamma.",True
@missionai6736,2020-05-02T16:53:04Z,1,sir can u have whatsapp group ??,True
@drc.ezhilarasan2359,2020-05-02T16:37:02Z,1,Hai sir. It was useful video. Can you give some explanation related to machining characteristics prediction during turning etc. May I contact you.   Can you share your mail id. ezhilshriram.c@gmail.com.,True
@tanzeelahmed2055,2020-05-02T16:37:00Z,8,I was waiting for this video to come since your first video about SVM (really sad we waited three days),True
@mangaenfrancais934,2020-05-02T16:25:25Z,2,Your are the best,True
@572varuag,2020-05-02T16:17:02Z,120,I'm glad someone like you decided to make a video on this. I have found that many find SVM hard to grasp because they dive directly into the code without understanding the intuition behind it. This goes a long way in helping people out.,True
@chekrasena,2020-05-02T15:58:07Z,8,Krishna Anna Thoppuüôè,True
