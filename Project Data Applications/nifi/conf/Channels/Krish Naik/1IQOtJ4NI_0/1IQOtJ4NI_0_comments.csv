author,updated_at,like_count,text,public
@user-cy9zf4oz2i,2024-05-31T06:10:31Z,0,why a lot of talks tho... just show the example case,True
@mdbelalhossainsanto6523,2024-03-10T06:19:59Z,0,How did you get 0.78 ?,True
@funwithzaeem8417,2024-01-24T14:33:45Z,0,bro you look like a great teacher,True
@user-uy5ls9eq7l,2023-12-08T16:48:55Z,0,This is one of the best explanation thankyou somuch sir,True
@beastjaguar7196,2023-05-18T16:23:34Z,0,thanku a lotüôèüòä,True
@vinayakrao4754,2023-05-04T12:53:32Z,0,What do you mean by feature?,True
@ambresh009,2023-04-13T09:44:15Z,0,"@krishNaik, I like your videos very much as they are quick reference guides for me to quickly understand something required for interview prep or for any project.   Just noticed here that, you mentioned Entropy is a measure of purity. But, it is a measure of impurity which makes more sense. The more the value of entropy, more is heterogeneity in the variable.",True
@mehdicharife2335,2023-03-15T18:39:19Z,0,You don't explain the intuition though.,True
@yogendrashinde473,2023-02-17T06:02:00Z,2,Dear Krish Naik Sir. Could you please recheck the calculation. As per my calculation entropy for  f2 node where the split is  3|2   is 0.97  and not 0.78 ? Kindly correct me if I am wrong.,True
@ABINASHPANDA-be7ug,2023-01-20T08:34:04Z,4,"Hi, there might be calculation mistake in the entropy part. its not 0.78. Can you please mention that in a caption in the video or a description. So that people dont mistaken it in the future. Great video!!",True
@memeddk,2022-09-25T14:14:03Z,1,tidak membantu,True
@MrBank1717,2022-08-11T03:44:26Z,0,Awesome video.,True
@MuhammadAwais-hf7cg,2022-06-30T02:48:33Z,0,"why this entropy in bits? as for normal its about 0.97, and how can i convert my entropy iinto bits",True
@skvali3810,2022-06-22T11:34:12Z,0,i have one question .at root node is the gini are Entropy is high are low..,True
@lekhnathojha8537,2022-06-14T06:12:06Z,0,very well understandable your teaching curriculum.,True
@ashishkumari762,2022-04-26T15:53:02Z,0,thank you,True
@ernestanonde3218,2022-04-02T21:39:52Z,0,I SAID I LOVE YOU,True
@deepalisharma1327,2022-03-15T06:31:46Z,0,Can we use same feature for multi level split in the decision tree?,True
@yamika.,2022-03-03T11:01:16Z,2,thank you. we all need teachers like you. god bless you. you're a blessing for us college students who are struggling with offline colleges after the reopening.,True
@sohammukherjee837,2022-01-17T11:00:42Z,0,"Hi Krish, can you please explain the process of calculating probability of a class in a decision tree and whether we can arrive at the probability from feature importance",True
@sakshiaggarwal3259,2021-12-30T08:18:09Z,0,I think your log calculation is wrong. Calculation as shown at 5:54 in video is giving me result of 0.97 bits,True
@ankitac4994,2021-12-21T10:33:28Z,0,good explanation,True
@RahulKumar-ec1dp,2021-11-22T20:43:22Z,0,"@2:16 Entropy is ""measure of impurity"" thats why we tried to decease the entropy",True
@loganwalker454,2021-10-28T06:47:46Z,0,"Krish, I love you so much, more than my girlfriend, zillions like from my side. You always make knotty problems so simple",True
@vishaljhaveri7565,2021-10-12T13:00:24Z,0,"Thank you, Krish sir.",True
@arunkumars3966,2021-07-18T10:28:17Z,0,how is 0.79 bits when you compute it?  someone pls explain,True
@louerleseigneur4532,2021-07-15T22:52:03Z,0,Thanks Krish,True
@abdulkayumshaikh5411,2021-07-11T08:32:20Z,0,Explained in a great way ...Thank you krish,True
@murumathi4307,2021-07-05T16:43:30Z,0,"Entropy is thermodynamics concept measure tha energy, why using mechine learning.",True
@shwetadalal1549,2021-05-27T12:18:31Z,0,Nice explanation. But actuallly we dont use this formula while modelling. We just set the parameter of decision tree to either entropy or gini. So when does this formula of entropy really help??,True
@shubhamnehete8020,2021-05-16T07:13:47Z,0,"Sir, here u didn't mentioned that how f3 is in right side and how f2 is in left side node. As u said the attribute having less entropy is selected for split. This is understood but why f2 is on left and f3 os on right?",True
@yashmehta8886,2021-05-14T08:22:19Z,2,"Can you mathematically explain how you obtained entropy=1 for a completely impure split(yes=3, no=3)?",True
@bhavikdudhrejiya4478,2021-04-29T08:37:38Z,0,Best channel for Data Science Beginners,True
@AK-ws2yw,2021-04-18T11:13:43Z,0,"In the formula of Entropy what is the significance of log base 2, why not simple log having base 10?",True
@AromonChannel,2021-04-02T06:42:37Z,0,"Definitely subscribe and tell my fellow other programmer to see and subscribe your channel, you are the best explainer i've ever seen!",True
@sandupaegodage8163,2021-03-29T12:49:11Z,0,GOOD ONE,True
@ayberkctis,2021-03-26T10:47:21Z,1,You clearly explain the mathematics of machine learning algorithms! Thank you for your effort.,True
@b.f.skinner4383,2021-03-25T00:36:05Z,0,"Great introduction to the topic, thank you",True
@ahmarhussain8720,2021-03-09T17:29:02Z,0,"excellent explanation man, thanks",True
@spurthishetty6834,2021-03-08T15:37:32Z,0,"Hi Krish, Have you explained how decision tree works? because im not finding it",True
@alastairbowie,2021-03-07T10:36:47Z,0,Nice explanation. Cheers =],True
@sameerkhnl1,2021-03-07T06:10:01Z,3,Thank you for a great tutorial. The entropy value is actually 0.97 and not 0.78.,True
@lemonoji288,2021-03-04T11:56:34Z,0,"Thank you, this was very helpful!",True
@amitmodi7882,2021-02-27T00:10:22Z,0,Super Awsome!,True
@AbhishekRana-ye9uw,2021-02-22T07:56:09Z,1,very much helpful sir thank you you are best :),True
@maximumthefirst,2021-01-23T14:25:11Z,3,"Thanks for the video.  At 05:48 , how does -3/5log2(3/5)-(2/5log2(2/5)) equal 0.78 ??? I think the correct answer ist 0.971  Could you explain?",True
@abhiramikc6883,2021-01-02T14:43:48Z,0,"if we have very high dimensional data , how do we apply decision tree ?",True
@shivadumnawar7741,2020-12-27T14:52:11Z,21,One of the great teacher in the Machine Learning field. You are my best teacher in ML.Thank you so much sir for spreading your knowledge.,True
@anandachatterjee2976,2020-12-13T14:04:10Z,0,"I tried to purchase the going through the above pasted link but its showing unavailable now, could you please tell me how to get your book?I really need that,I follow your channel frequently whenever I face trouble in understanding any concepts of data science and after watching your videos it gets cleared so please let me know how to purchase your book.",True
@vaddadisairahul2956,2020-12-02T08:31:29Z,0,"in my opinion, calculating entropy is sufficient and we don't require information gain, as in information gain we simply subtract from the entropy of attribute from the entropy of dataset; the entropy of dataset is always constant for a particular dataset.",True
@subrahmanyamkv8168,2020-11-07T06:39:26Z,1,As Entropy of pure node is zero..I think Entropy is measure of impurity..lesser the Entropy..more pure the node is,True
@nirajchaudhari5974,2020-10-24T04:36:15Z,1,please upload the video for regression tree also and discuss it in detail manner,True
@lucianoval903,2020-10-23T19:25:16Z,0,"Yours videos are very nice, but you really need to improve the quality of your microphone",True
@harivgl,2020-10-16T19:34:33Z,0,Did not say how to select the root node?,True
@marijatosic217,2020-10-15T17:56:23Z,1,Great explanation! Thank you :),True
@rchilumuri,2020-10-03T11:59:30Z,2,"You are doing an awesome job  with our expecting returns. good job Krish, You just nail down the concepts in a line or two thats the way i like it.",True
@cequest9456,2020-09-28T18:00:41Z,4,"You should start explaining from the root node.. Like take entropy of all f1, f2 ,f3 first.. then select the best one as the root node, then calculate entropy for remaining data for f2 and f3, and select next best entropy as the node... and continue the same process",True
@vijayachokkapu724,2020-09-20T17:31:50Z,1,"Sir, To select an attribute at a node in a decision tree we calculate information Gain which ever is having highest that we select as the best attribute at that node but for an example I am getting all the 4 attribute information gain same. When I browsed in net it is saying that if we have all the attribute information gain as same then we have to select the best attribute according to their alphabetical order for example if we have A,B,C,D We have to select A first then B,C and D Is the procedure is correct or any other explanation can u give please",True
@sandipansarkar9211,2020-09-17T17:55:06Z,1,Good explanation Krish.Now my misconceptions about decision trees is dwindling away.Thanks,True
@swetapatra,2020-09-10T04:58:07Z,0,so based on entropy we select the parent node?,True
@artificialintelligence1680,2020-09-09T11:37:13Z,0,Nice https://youtu.be/jm4G0qlOJLg,True
@patanjalikumar212,2020-09-05T11:53:51Z,0,Could you please create a video on decision tree random forest and other classification algorithm from very scratch which could be helpful for new learner or newbies  in data science,True
@digantaroy1310,2020-09-03T08:12:46Z,0,"Hi Krish, Can you please share -Decision tree for Regression? Having problem in understanding DT incase of regression",True
@ankursaxena4942,2020-08-21T05:14:01Z,0,Nice Video   How to use#Linear_Regression in #Machine_Learning,True
@shivamd.908,2020-07-22T16:49:01Z,0,"lower entropy, higher information gain",True
@deepakkota6672,2020-07-12T10:53:30Z,3,"No doubt you have wonderfully explained,  What if we have multiple classes in our target variables with not only binary Yes or No?  Like a boy, girl and others?",True
@GhizlaneBOUSKRI,2020-06-14T06:32:24Z,2,I always think it's hard until you convice me how ridiculousely easy it is ..,True
@deepaksurya776,2020-06-08T18:54:21Z,3,Entropy value is 0.97 not 0.78,True
@sonamkori8169,2020-05-24T04:32:33Z,0,Thank you Sir üëç,True
@hemantsharma7986,2020-04-08T13:14:14Z,5,"Hi Sir, this video is 37th in ML playlist but we don't have any decision tree video before it.",True
@sahilaseeja7686,2020-03-21T11:10:18Z,0,"Hello sir, i have a question like how does decision tree works in mixed type dataset i.e it includes bot categorical and numerical data type. Suppose its a regression problem and data set include both data type so how will algorithm deal with categorical data type in this?",True
@karthikvinnakota1943,2020-03-16T15:44:04Z,0,What if the class attribute has 3 types of tuples...like Low medium and high...??,True
@shrikantkulkarni5550,2020-03-15T04:19:58Z,2,"Good explaination however always I observed that you will not explain the meaning of the term on which you made the video and always you will explain things in diplomatic way, please use the simple terms to explain the concepts.",True
@143balug,2020-03-04T05:29:49Z,0,Thank you so much for providing the videos with detail explanations.,True
@PrinuTriesHerBest,2020-02-23T15:51:43Z,0,I couldn't find any videos for information gain. Could you please upload,True
@keamogetsethaoge6688,2020-02-13T21:24:59Z,1,Thank you Thank you Thank youuuuu!! After this I am ready for my test tomorrow.... You are boss with these concepts!!.. Please keep making more. I''ll definitely subscribe and share with friends.,True
@paragjp,2020-02-05T15:39:56Z,0,hi can you pl add link for Gini Index video ? Also pl let me know in which  playlist these videos are ? Thanks,True
@muhammadihsan8689,2019-12-18T13:41:38Z,0,Great yaar!!!,True
@swaruppanda2842,2019-12-16T18:47:11Z,0,Waiting for Information Gain video,True
@ankush_in_sync5998,2019-11-25T15:56:13Z,0,Best,True
@omerahmaad,2019-10-30T20:43:01Z,0,"Good Video, I think you should add gini impurity in the video to explain the decision tree splits, also what is the difference between entropy and gini impurity. Good Video",True
@mdrashidansari7476,2019-10-23T06:25:10Z,2,You cleared my all doubts about Entropy..... Excellent Explanation üòçüòçüòçüòç,True
@muhammadjunaidmajeed1211,2019-10-15T00:34:39Z,0,how to make fuzzy c4.5 on same data-set?,True
@AbhishekVerma-oe8pk,2019-10-11T18:57:06Z,0,Brilliant,True
@AmitYadav-ig8yt,2019-10-11T08:34:15Z,0,"Sir, May you please make a video clip on the Decision tree?",True
@saurav0777,2019-09-07T06:58:49Z,0,Great bro ..thanks for uploading it.,True
@vishal56765,2019-09-03T04:20:04Z,0,Very nicely explain sir. Thanks a lot. Waiting eagerly for next video on information gain.,True
@vigneshnagaraj7137,2019-08-27T16:45:13Z,0,Can you please give the overview of Decision Trees as you have given for Random Forest,True
@vigneshnagaraj7137,2019-08-27T16:44:32Z,0,Waiting for information gain bro,True
@pritomdas6215,2019-08-24T00:36:42Z,1,"Sir Can you also upload about ""Information Gain""?",True
@reshaknarayan3944,2019-08-22T04:34:01Z,0,Best explanation,True
@aaroncode2634,2019-08-12T18:53:12Z,10,This is what I was looking for.  Thank you so much for making this video. Eagerly wait for video on information gain. Please keep going üôè,True
@srujanjayraj9490,2019-08-12T09:24:10Z,1,waiting for the next video,True
@SALESENGLISH2020,2019-08-11T20:53:31Z,85,I checked all the codes in your book. Everything works like charm. I can guess that you have mastered Machine Learning by struggling through it. Those who are spoon-fed cannot be half as good as you.  Great job!  We wish you all the success.,True
@VivekKumar-nf8fh,2019-08-11T18:50:01Z,2,Nice explanation.... But looking for deep learning video..Please don't stop DL in-between,True
@aditisrivastava7079,2019-08-11T15:39:48Z,2,Nice explanation...... I am learning a lot,True
