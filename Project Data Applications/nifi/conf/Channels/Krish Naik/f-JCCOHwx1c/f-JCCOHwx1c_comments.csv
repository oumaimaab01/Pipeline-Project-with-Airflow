author,updated_at,like_count,text,public
@iffatmehrindisha5517,2024-05-02T03:35:21Z,1,Can you please share the code?,True
@lol-ki5pd,2024-04-27T09:44:39Z,0,why suddenly we are talking about characters when in previous vedios you mentioned of doing one-hot encoding of words?,True
@asim-turivlogs,2024-03-13T12:12:12Z,0,I will suggest you watch the output context of LSTM. The output context of LSTM would be not a single vector it would be multiple vector generated at each time step. This is were attention  would be implemented and differentiate from the RNN. I appriciate your tutorials,True
@DEWAAN-ud7ss,2024-02-08T13:35:25Z,0,krish kindly upload the image captions projects ..,True
@no_num_no_gum,2023-11-23T11:30:31Z,0,great video but u are mistaking the term character by word which creates confusion,True
@mohsala5498,2023-09-24T17:12:43Z,0,"honestly, I watched many great videos for you, but this one is very poor and lacks explanation and clarity... I suggest in future you remake this session again. Any way thanks a lot for your efforts.",True
@sairajdas6692,2023-09-18T14:49:44Z,1,Where is the code ?,True
@ravinderbadishagandu2647,2023-08-27T11:59:34Z,0,can you please provide notebook link,True
@abhijittdhavlle,2023-07-28T04:22:56Z,0,@krishnaik06 This is super helpful video. I have been following the NLP playlist. Do you mind sharing this code in the Git repo? The folder for seq2seq in your repo seems empty.  thanks:),True
@deepaklonare9497,2023-07-17T06:44:54Z,1,can you please share the github link for above code,True
@tanish1018,2023-07-16T07:36:03Z,0,Sir can you plz add the Jupyter notebook respective to the model,True
@N-fx9uz,2023-07-07T20:04:20Z,0,Seemed like you yourself were not understanding the code you have written. Zero logic building and only reading out the code. Very upsetting ðŸ˜‘.,True
@kaustubh52q45,2023-06-08T06:36:48Z,0,"please provide your github repo where you're code is present, please provide the code",True
@fatimaezzahrakharmouch7700,2023-06-06T15:57:41Z,2,"Hello Sir, thank you for this video. I did all the steps but in the end I don't receive the correct output, can you help me please. thanks",True
@DeependraSingh-jh8xf,2023-05-30T06:24:05Z,1,"i have followed every step. still my encoder_input_data is all same, for each sentence, please help",True
@DeependraSingh-jh8xf,2023-05-30T06:22:45Z,0,i dont understand why my final testing loop is decoding every input to ' i want to go to room'  i have made hindi to english translation and used the dataset of the blog which was just shown below english french database,True
@thelife5628,2023-05-24T05:53:39Z,0,ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥,True
@MurariMahaseth,2023-04-08T12:51:34Z,0,17:36,True
@anirbanmukherjee3028,2023-03-25T01:54:22Z,0,"Sir, unable to locate github code...can you please share?",True
@joguns8257,2023-03-23T15:05:03Z,0,Where is the dataset? How can I get it?,True
@MASadat-lz9yz,2023-02-15T10:15:16Z,0,"Greetings from Austria, thanks for your knowledge sharing!",True
@piyalikarmakar5873,2022-08-29T18:28:44Z,1,"Sir, thanks for this nice explanations. But I have one query, Instead of text I have  numeric indexes of the text, but these are not vectors. How can I translate those indexes into its corresponding text?",True
@nawazalilone701,2022-01-24T08:10:08Z,0,"What is the encoding scheme used in this tutorial e.g one hot, word2vec, glove etc",True
@bluemonkify,2021-10-08T10:15:37Z,0,Az yavaÅŸ anlat yiÄŸido anlayamÄ±yok!,True
@madhu1987ful,2021-09-11T05:32:29Z,0,"Hi Krish, 2 questions: 1. why are we not using word2vec here and instead using OH encoding? 2. when u say A,B,C as inputs to encoders -- are these characters or words? I am confused",True
@willywijaya9302,2021-09-04T17:38:04Z,2,"excuse me sir, i wonder why use one hot encoder method instead word embedding layers ?",True
@soumyagupta9301,2021-08-17T12:00:38Z,0,Are encoder_outputs and h_t not the same thing?,True
@soumyagupta9301,2021-08-17T10:33:05Z,0,Thanks for the video but you are not going deep into the code or the architecture. Please try to go a bit deeper.,True
@pratikshaunale4885,2021-08-15T13:03:57Z,0,in latent dimensionality how you define 256 plz explain,True
@8889705048,2021-07-30T18:52:45Z,4,"Can you please take a small sample text and perform encoding and decoding functioning briefly, so that we can understand it briefly as there are few doubts regarding t=timestamp.",True
@apicasharma2499,2021-07-10T21:44:53Z,0,does this apply to time series as well?,True
@rahulrajpandey8232,2021-06-23T05:22:59Z,0,Github link??,True
@davidhenry3553,2021-06-18T17:13:04Z,0,"Hey Krish, I think you forgot to upload or provide a link to your notebook.Can you please upload it.",True
@rabiaaiqbalmalik5208,2021-06-18T05:53:01Z,0,Can you help for english-urdu machine translation model?,True
@omrajgure8441,2021-06-15T02:35:07Z,2,sorry to say but you didn't explain as properly as you are capable of  ::(( Does anyone feels the same like here.,True
@manjeetmanu4547,2021-06-03T17:12:02Z,2,In this video only predefine values are converting to their respective meaning. I don't understand how this helps us to covert user input into other language.,True
@narendraparmar1631,2021-05-31T21:25:49Z,0,Thanks Krish,True
@pvbsuresh4156,2021-05-15T11:22:46Z,0,Loss is very high,True
@_jiwi2674,2021-05-12T03:57:44Z,0,"Hi Krish, thanks for these video :) Do we have to join your channel in order to access your codes? I found your github but couldnt find codes for this video. Otherwise, how can we access them?",True
@MuhammadAli-ie7ps,2021-05-07T07:46:46Z,1,"hey man, kindly give the link of code. if you did not upload there. please upload code there. it's a request.",True
@Manojrohtela,2021-04-28T19:18:50Z,0,Where i can get this code ?,True
@shashankpal376,2021-03-29T19:26:04Z,7,What is the function of dense layer after decoder? Aren't we actually interested in decoder output? Why adding dense layer would not hamper the actual output by decoder? I would be very thankful if someone answers all my questions.,True
@athiragopalakrishnan4316,2021-03-18T09:12:20Z,0,"Dear sir, I would like to join your channel. I tried to contact you (FB/LinkedIn). But the site can't be reached. How can I contact you, sir? Please help me",True
@Rajkumar-vc2pg,2021-02-20T16:29:04Z,3,okay now ill  try to train english-telugu and add it on my resume,True
@ankurlimbashia3697,2021-01-25T05:58:50Z,1,"Hey krish, I am getting some cardinality in inference model input with this code Model fits perfectly but while predicting the inference model I am getting this error.",True
@cinebuffhometheatres,2021-01-02T12:28:30Z,1,i have a simple doubt is this character encoding or word encoding,True
@sauravjha5666,2020-12-25T08:47:15Z,14,"bro this video doesn't make any sense, sorry to say but it's not at all intuitive.",True
@akshayabusa007,2020-12-16T09:21:03Z,0,"for line in lines[: min(num_samples,len(lines)-1] why are we doing -1 can anybody explain and why are we taking min ?",True
@rajak7410,2020-12-11T13:23:52Z,4,"Sir take a sample text and perform encoding and decoding functioning briefly, so that it makes sense",True
@piyushmajgawali1611,2020-11-08T11:50:16Z,1,You are using *word* for characters,True
@sagarnarula660,2020-10-07T17:03:37Z,2,Please provide the github link for the code.,True
@user-or7ji5hv8y,2020-10-04T16:29:02Z,0,may be better audio would be really helpful.,True
@arkadeepdas7397,2020-10-04T16:25:10Z,0,"can any one explain ""encoder_input_data[i, t+1:, input_token_index[' ']] = 1."" this line? why we should use?",True
@alphonseinbaraj7602,2020-09-23T01:46:48Z,0,decoder_input-data and decoder_target_data will be same ?,True
@naivedhshah2980,2020-09-05T15:16:34Z,5,Can you share the notebook?,True
@drashyabansal7749,2020-09-04T11:03:20Z,0,Hello Sir! I tried computing the code but its crashing when working on google colab and in case of initialising the zero matrices system is crashing,True
@Kumar08,2020-08-24T09:43:35Z,10,Please provide Github link for this code.,True
@Mohankumardash,2020-08-12T12:35:27Z,0,jerry,True
@Mohankumardash,2020-08-12T12:35:15Z,0,jeery,True
@gurdeepsinghbhatia2875,2020-08-10T23:51:42Z,0,"Sir why we not given the inputs like this : encoder_inputs=Input(shape=(max_encoder_sequence_length,num_encoder_tokens))",True
@hasiburrahman96,2020-08-05T20:21:56Z,1,"Can i use this, for question answering instead of language translation??",True
@gurdeepsinghbhatia2875,2020-08-04T22:39:49Z,0,"Sir i dont understand the input dimension , that how input dimension is like that",True
@gurdeepsinghbhatia2875,2020-08-04T01:30:18Z,0,"sir its compulsary to give input as one hot encoder ,, may we use the word embedding",True
@anjanas6048,2020-08-01T04:59:47Z,2,"Hi Krish..Thanks for the video...waiting for more topics like attention mechanism, transformers etc",True
@sunnybhojwani3199,2020-07-31T06:40:32Z,0,Kindly upload more videos,True
@tyylermike2830,2020-07-25T11:46:07Z,9,"Greetings!! Can you please upload more stuff on Deep learning like attention models, Transformers, BERT and do cover unsupervised learning too if possible. It would be highly appreciated.",True
@SelinTosun,2020-07-12T09:06:21Z,0,Is the Attention model posted? I have been waiting since this video was posted. Looking forward to it...,True
@TheShaan22,2020-06-29T16:41:18Z,0,"Can you explain the inference code please, thanks.",True
@koustavdutta5317,2020-06-29T16:35:09Z,0,"sir please provide your notebook ... it will be really helpful, the notebook which you have prepared",True
@mmgtechm,2020-06-29T06:18:01Z,0,"Hi @krish, Can you tell how you create this new format. I mean which application you use. This looks so cool. I also want to record videos, but not sure which software can give me these features. Any insight ?",True
@mohan5867,2020-06-27T18:21:08Z,0,Sirni have written the code exactly the same... but my accuracy is just  0.0020.... what could be the reason.?,True
@thetensordude,2020-06-27T16:03:01Z,13,"YOLO, BERT, TRANSFORMERS!! Please bring explanations on these",True
@siddharthaborpuzari9000,2020-06-27T14:39:07Z,0,Thank you,True
@babritbehera4087,2020-06-27T13:55:47Z,8,U skipped the main part ... Decoder input n decoder output . That how we r dividing the target as input n output with 1 timestep ..,True
@ponrajs5396,2020-06-27T13:13:48Z,1,"I've been waiting long time for this video,  I have one doubt, in case if need to update the neural network with some extra stacked LSTM layer how could I do that, because this is not like other sequential model.",True
@mukulsharma9673,2020-06-27T12:57:46Z,1,Thanks krish for this video... I was waiting for this .!!,True
@yashmadhogaria7418,2020-06-27T11:50:10Z,1,Please make videos on semantic segmentation,True
@nishantsharma2022,2020-06-27T11:46:31Z,2,First Like,True
