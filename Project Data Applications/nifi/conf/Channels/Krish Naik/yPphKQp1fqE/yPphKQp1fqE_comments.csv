author,updated_at,like_count,text,public
@computerauditor,2024-05-12T09:02:56Z,0,Really insightful krish!!,True
@usingsk,2024-05-11T15:45:52Z,0,Thanks for Sharing knowledge. Can we fine tune with company domain content in downloaded model and the data is not shared. I mean it comply with IPR if we use locally,True
@rajarshidey424,2024-05-08T08:22:49Z,0,How can we get the code?,True
@ashishdayal172,2024-05-04T12:00:03Z,0,"hii krish, i am facing error creating modelfile .Please help",True
@VishalKumar-gv6gy,2024-04-28T06:22:31Z,0,Does it require GPU ?,True
@hassanahmad1483,2024-04-25T20:01:55Z,0,How to deploy these custom gpts...?,True
@roshanchandel7929,2024-04-23T18:11:36Z,0,The heroes we need!!,True
@BelhsanMohamed,2024-04-19T15:06:09Z,0,as always thanks for the information,True
@SomethingSpiritual,2024-04-17T07:25:15Z,0,"why ollama not taking full gpu? its taking full cpu only, pls guide",True
@jatinchawla1680,2024-04-02T12:27:27Z,0,"llm=ollama(base_url='http://localhost:11434',model=""llama 2"") TypeError: 'module' object is not callable Can someone pls help w this?",True
@lionelshaghlil1754,2024-03-28T15:16:54Z,1,"Thanks Krish, the briliant, innovative and master of the AI üòä, I have a question please related to the hosting, so assume I'd like to implement my solution on a server, will I need to have both, OLAMA and my app in two seperate dockers? they would communicate together? or they could be implemented in one single docker?",True
@deekshad4774,2024-03-25T08:24:59Z,0,You are the best!ü§ì,True
@pssab8,2024-03-14T06:42:42Z,0,Excellent videos. I set up mistral model locally on ubuntu20.04 and found that it is taking more than a minute for every response .Running in cpu mode only.Can you suggest me to improve the performance.,True
@starkgaming1425,2024-03-12T06:27:57Z,0,Please release a step by step guide on how to fine tune Gemini API in Python.....I tried by refering to documents but encountered a lot of errors with OAuth Setup please...........!!!,True
@sanjaynt7434,2024-03-10T11:01:25Z,0,Can this read a document and answer  my questions on that document can it.,True
@manjeshtiwari7434,2024-03-10T06:02:45Z,2,"Thank You so much for a such a great video , I have a query , I am getting very slow response does the speed of response depends on system config , I have chekced out system use and while running it isn't using much resource , can you tell how can we increase response speed",True
@mohammedalfarsi4361,2024-03-09T02:22:53Z,0,are these model support arabic language ?,True
@ankitshaw2011,2024-03-06T17:04:10Z,0,Thankyou so much for these videos,True
@AjaySharma-jv6qn,2024-03-06T02:21:31Z,1,"Content is helpful, thanks for your effort.üéâ",True
@YashDeveloper-rq2yc,2024-03-05T14:57:56Z,0,Bro using these techniques can I convert it as superb ai assistant? And what capabilities can use?,True
@nagasudha6928,2024-03-05T10:38:35Z,0,"Hi Krish This is Sudha from ISRO Hyderabad, I would like to know the documents to be provided for ollama and get the answers from it",True
@manasjohri2495,2024-03-05T10:19:47Z,0,Can you please tell me how we can run this ollama on GPU right now it is working on CPU?,True
@vishalnagda7,2024-03-05T08:53:18Z,5,I'm feeling lucky that I got this video in my suggestions.,True
@jacobashwinmathew3763,2024-03-05T03:37:19Z,0,Can you make a complete video of  production ready open source LLM basically LLMOps,True
@kashishvarshney2225,2024-03-04T07:06:31Z,0,"hello sir, what is the minimum system configuration for ollama",True
@YashDeveloper-rq2yc,2024-03-04T03:34:19Z,0,After installing it will work in offline?,True
@AjayYadav-xi9sj,2024-03-04T03:33:09Z,0,Make a video on Python framework of ollama. Make a end to end project and also host it somewhere where real people can use it,True
@nasiksami2351,2024-03-04T00:32:33Z,0,"Great tutorial! Can you please make a video on finetuning model on custom csv dataset and integration with Ollama. For instance, consider I have class imbalance problem in my dataset. Can I finetune a model, then ask it in Ollama, to generate more samples of minority class using the finetuned model?",True
@krishnaprasadsheshadri6206,2024-03-03T20:24:47Z,0,Can we get a video about reading tables using unstructured and such frameworks,True
@tharunps8048,2024-03-03T17:53:29Z,0,"Since it is running locally, using this model with organization's data doesn't expose it right ?",True
@DeadJDona,2024-03-03T17:40:14Z,0,please finish that Chrome update üò¢,True
@omarnahdi3380,2024-03-03T15:45:11Z,0,"Hey sirüòÑ, please make a video on BioMistral( a LLM trained on Medical and Scientific Data). It would perfectly fit your AI Nutriationist. Thanks for your daily dose of GenAI",True
@kenchang3456,2024-03-03T15:40:54Z,0,"Hey Krish, thanks for doing this video in Windows.",True
@susnatakanjilal703,2024-03-03T15:34:56Z,0,Sir I need to create a custom text data set from common crawl.for Bengali language....and train llama2 using that...can you plz demonstrate similar project!?,True
@user-lq7sx8qw5t,2024-03-03T15:17:55Z,0,Great content Krish...Need these coding files kindly share those,True
@rajendarkatravath2207,2024-03-03T15:06:09Z,0,Thanks krish! for sharing this knowledge . what an amazing model it is .....!,True
@naveenkumarmaurya3182,2024-03-03T14:22:12Z,0,"hi krsih i m getting this error Ollama run codella! üê∞üí®  (Note: I'm just an AI, I don't have personal preferences or the ability to run code, but I can certainly help you with any questions or tasks you may have!)",True
@KumR,2024-03-03T12:59:26Z,0,Do we need to download the entire 7gb llama2 locally to use with ollama,True
@copilotcoder,2024-03-03T12:39:59Z,0,Sir please create a codebase understanding model using ollama and test it on a opensource codebase,True
@user-fs9mz3rn6q,2024-03-03T12:28:03Z,1,Every time we see a kid we ask him to say a poem and when you have so many llm models but you only want a poem on machine learning,True
@NISHANTKumar-ct3pb,2024-03-03T12:27:40Z,1,"Thanks , it's great video. Wanted to ask when we say local what is the configuration of local is it a cpu or GPU based system? Are models compressed / quantized or same as original ? Is there a model size limitation vs local system config?",True
@mehdi9771,2024-03-03T11:38:21Z,0,We need a long versions videos like previously and thanks for your efforts ‚ù§,True
@divyaramesh0101,2024-03-03T11:31:47Z,0,"Thank you Krish sir. In Building RAG from scratch ,sunny sir showed about Ollama. Both of you were giving foundational knowledge and updates in GenAI. It was very useful sir.",True
@rishiraj2548,2024-03-03T11:28:03Z,0,üôèüíØüëç,True
@velugucharan8096,2024-03-03T11:27:44Z,0,Sir please complete the fine tuning llms playlist as much as possible sir,True
@haritdey430,2024-03-03T11:26:42Z,0,Nice video sir,True
