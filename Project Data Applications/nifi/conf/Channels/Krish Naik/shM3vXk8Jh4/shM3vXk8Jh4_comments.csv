author,updated_at,like_count,text,public
@sandyofficial9962,2023-08-19T05:15:35Z,0,When you require the magnitude not the direction and if the outliers present in the data use mean absolute error and when there is  no outlier present in the data and the magnitude is more preferable then direction of the error we will go with mean squared error as the mse will squares the values by that if there is any outliers present in the data it will be heighly impact and the squared error will be very high result will be fail to give good model.,True
@user-xz1se8xq2j,2023-07-31T15:12:08Z,8,"Mean Squared Error (MSE) and Mean Absolute Error (MAE) are both commonly used metrics for evaluating the performance of regression models. They are used to quantify the differences between predicted values and actual (observed) values in a dataset. The choice between MSE and MAE depends on the specific characteristics of the problem and the preferences of the analyst. Here's when to use each metric:  Mean Squared Error (MSE):  MSE is the average of the squared differences between predicted and actual values. It penalizes larger errors more heavily due to the squared term. Use MSE when you want to give higher weight to large errors. This is useful when outliers have a significant impact on your analysis or when you want your model to focus on reducing larger errors. Mathematical Formula: MSE = Œ£ (predicted - actual)^2 / n  Mean Absolute Error (MAE):  MAE is the average of the absolute differences between predicted and actual values. It treats all errors equally since it doesn't use squared terms. Use MAE when you want to give equal weight to all errors. This is useful when you have a more balanced dataset and outliers are not as important. Mathematical Formula: MAE = Œ£ |predicted - actual| / n  Considerations:  MSE is more sensitive to outliers than MAE, as the squared term amplifies the impact of large errors. If your dataset has a few extreme outliers that you want to be particularly attentive to, MSE might be more appropriate. MAE is more robust to outliers since it only considers the absolute differences, making it a better choice when your data is noisy or contains significant outliers. Both MSE and MAE can be used together or in combination with other metrics depending on the context and goals of your analysis.",True
@mehulgoyal5-yeariddcivilen832,2023-06-18T08:30:35Z,0,For a feature having outliers the mae is better than the mse .since the mse value is greater for outliers than mae.for gradient descent optimisation we will use mse because it is quadratic equation and have a parabolic curve where the minimum point is our optimal loss and the parameters corresponding to that is our optimal parameters for our ml model which gives us best accuracy among all the set of parameters. Mae has a curve of straight line and gradient descent technique is not suitable for that because there is no convergence point in that.,True
@user-tj7dy3hu1v,2023-05-09T16:49:32Z,0,in case of outliers we use MAE and if there is no outlier or less effects on model then we use MSE,True
@iam-sp,2021-08-06T14:11:27Z,0,"I will use mean squared error, because mean absolute error cannot be differentiable at 0. Briefly, I think, regression problem will have an optimization problem to solve, to solve an optimization problem, we take the derivative of the loss and the regularisation (if used), so the mean squared error can be differentiable but the mean absolute error cannot be differentiable at 0.  Please reply me with the correct answer.",True
@RupeshKumar-bu2xy,2021-05-22T00:38:21Z,0,use mse because it is differentiable because while backpropagating to adjust weights we need derivative with respect to loss function,True
@Americakijai,2021-05-18T06:04:10Z,0,Here the Loss Function was y-y^ and to stabalize the loss function we can use two types performance metrics and they are MSE & MAE MSE : where MSE is always positive and which is close to zero or lower value is better it consider that(yi-y^)^2 = due to the square of the error it takes always positive MAE : if the defference between actual value and predicted value is negative or a positive we used to take a positive value. which is similar to the MAE(here it doesnt consider any direction). where the two loss functions range 0 to infinity * in MSE the values near to the zero which is good fit for the regression * Based on the data set if the data is large i used to prefer MSE and if the data is small i used to go for MAE(if we use small data for MSE penalize the large error due to noisy. which is not good for Outliers in this case i go for MAE.,True
@mihirnatani4479,2021-05-04T17:43:51Z,5,HUBER LOSS function can be used -- It is  1 ) MAE for outliers. 2 ) MSE for small values . Hence giving us the benefit of using both functions .,True
@rachitban,2021-04-27T17:52:00Z,0,Squaring a number which is in range 0 to 1 will result further in a small number. Hence use MAE in case Yactual is small like in range [0-1] so that |Ypred-Yactual| is not small and hence ultimately loss is appropriate. Use MSE otw.,True
@richaasenthil,2021-04-26T15:08:49Z,0,"Based on the application in hand: When we want to penalize a lot for deviation, go for mse (more accurate; less generalized). When you don't want to penalize a lot (more generalization), go for mae",True
@08bic019,2021-04-23T19:12:16Z,0,MSE when we create modle from scratch but when we update that modle with some new parameter then we must consider MAE because when we add new parameter then MSR has very high value at that time we must consider MAE,True
@prashantsharma2593,2021-04-23T14:36:42Z,0,"If there is no outliers or effect of outlier are very less we can use MAE bcz the change in gradient is abrupt and no outliers but we can use MSE If there are ouliers then we must use MSE ,because the gradient is not abrupt it will be smooth so the learning can be done easily .  There are two cases of MSE  |MSE| - used when ouliers are too large because the value obtained can be limited to a range and leaening can happen (MSE ) - can be Used when ouliers are not that large from data. Because it give both type of values",True
@survivor9367,2021-04-21T03:58:07Z,0,Bases on outlier.. I will take mse Or mae,True
@shubhamchoudhary5461,2021-04-20T19:44:31Z,1,"@Krish Naik  As we know that outliers is big issue in Linear regression.. If our data has some outliers or extreme values then we use |MSE| error , coz in case of outliers the error difference will be high (even the model is predicting close to actual values) hence error terms will be very high , gradient descent will try to penalize those error in such way that the error will reduce and tend to zero(ideally) & if we used (MSE) at this situation ,our best fit line is more towards the outliers side rather than original normal data points so it'll affect the final predictions significantly. When the consideration of outliers are necessary then we can use MSE as a cost function. MAE loss useful if training data corrupted with outliers , but MAE also have some disadvantages like gradient will be large even for small loss values ,this is not good for learning .  MSE will perform better in this situation , the gradient of MSE is high for larger loss & vice versa .. Meanwhile , if the outliers represent anomalies that are important  in business then we can use MSE ,else if outliers are useless then we can use MAE.    Make me correct & suggest some additional topics !! Thanks for reading and helping out !!üôè",True
@prithwishchakraborty2286,2021-04-20T16:44:33Z,0,When we have a huge difference between actual data and predicted data we use mse else we use absolute mse which gives us the actual difference between actual result and predicted result,True
@durgeshmajeti,2021-04-20T14:25:27Z,3,"We usually use MSE because the MSE penalizes the outliers. That way we are ensuring that the model learns from all the points. With MAE, the model doesn't penalize the outliers as much as MSE does. So, the model will not be learning much from outliers.",True
@anuragdhadse1426,2021-04-20T13:46:39Z,0,MSE can be used when our dataset has doesn't have lots of outliers. MAE will penalize large outliers less in comparison to MSE which might cause an imprecise model in the MSE case.,True
@myfeelings9938,2021-04-20T13:10:13Z,0,"MSE:Mean Squared Error is used if the numbers associated with the data points are  not  large enough to compute.Therefore normally it is used if computational complexity does not arise at a significant label. Mean Absolute error is used if the data points are sufficiently large numerically.To reduce computational complexity, it is useful there.",True
@mlvali1350,2021-04-20T12:23:06Z,0,one of the interview question is what is the use of alpha value in xgboost?,True
@NG-sb9pd,2021-04-20T12:20:58Z,0,If outliers in dataset we usually go with MAE else we can use MSE,True
@varunsingh2103,2021-04-20T11:55:10Z,2,"Mae will be used if there is outliers in data else we will use MSE, as in MSE error due to outliers will increase, this type of loss function is called huber loss function.",True
@arunmeghani1667,2021-04-20T11:33:24Z,3,"the answer will be mean squared error probably. the reason is that whenever the differences between y true and y predicted is increasing, then the value of mean squared error will increase more rapidly than mean absolute error, thus mean squared error will punish our model more than mean absolute error, and thus the optimization will be faster. I hope this is the reason",True
@MohitSharma-vt8li,2021-04-20T11:26:09Z,0,"Sir uses the word ""Particular"" Alot",True
@AInamedMia,2021-04-20T11:00:22Z,0,"We prefer MAE over RMSE in case there are outliers. The higher the norm index, the more it focuses on large values and neglects small ones. This is why the RMSE is more sensitive to outliers than the MAE.",True
@rajkir2852,2021-04-20T10:36:12Z,1,LOSS FUNCTION CACULATES LOSS BETWEEN ACTUAL AND PREDICTED VALUES... THAT IS.. HOW MUCH YOU ARE FAR AWAY FROM THE ACTUAL VALUES.  SQUARING IS GOOD AS LOSS BECOMES PARABOLA AND IT BECOMES EASIER TO DEAL WITH SQUARES IN MATHMATICS,True
@AkshayKaushik,2021-04-20T10:26:35Z,1,Explanation is Andrew Ng machine learning 1st week.,True
@chiragverma6773,2021-04-20T10:26:12Z,24,MAE:  when we have outliers we use MAE as MSE will give a very large amount of error for outliers. MSE:  But when we don't have outliers then we use MSE as MAE is not differentiated at 0 and also MSE gives an optimum amount of error and due to which loss is get reduced much faster in MSE as compared to MAE in this case.,True
@luvdhamija7982,2021-04-20T09:41:35Z,1,I will go for Mean Absolute Error when I would see Any outlier as it is robust to outlier if not then I would go for Mean square error as it penalizes the model for error by squaring it .,True
@edwinsamuel3875,2021-04-20T09:00:29Z,0,"Mean absolute error is generally the best and simplest value of error , but it fails to punish extreme values. So when we are in need of punishing extreme values in our dataset , then MSE is used.",True
@subhadipghosh8194,2021-04-20T09:00:07Z,62,"Mse is used because mse is continuous and differentiable at all points, and for the gradient descent algorithm to work, the loss function must be differentiable at all points. Whereas in MAE, the mathematical expression is mod of y_act - y_pred, and mod is not differentiable at all points which is why we choose Mse as our loss function.",True
@RishSandMagic,2021-04-20T08:58:20Z,2,"When we have outliers we should go for MAE. MSE actually penalize large errors much more than they actually are. Lets suppose, we have a financial related problem statement, we should go for MAE as a diff of 30Inr is better left at 30inr rather escalating it to 900inr in case of MSE",True
@vishnumuthyaboina7546,2021-04-20T08:57:44Z,0,If we don't want a very generic model wanted to penalize the model we will go for MSE,True
@harikrishnakokkula3207,2021-04-20T08:54:35Z,2,when outliers are more we go to MAE when outliers are less we go to MSE,True
@amarpratapsingh4806,2021-04-20T08:54:07Z,1,"MSE is more sensitive to outliers in our predictions so it diminishes the effect of smaller errors and one large error could mislead us into thinking that the whole of our model is not working as it is supposed to be. Also the error value it gives is not on the same scale as the data points(ie why rmse exists). MAE has ""equal"" weightage to each error and is less prone to outliers. The value provided is on the same scale as our datapoints.  If our overall error is linear ie an error of 10 is twice as bad as an error of 5, we should use MAE otherwise MSE or RMSE.",True
@winyourself553,2021-04-20T08:52:28Z,0,"MSE: is not robust to outliers, so if we have a dataset that does not contain outliers, in that case, I could go with MSE, otherwise, I will go with MAE, as we know we perform the absolute operation in MAE to overcome from the problem.",True
@jjayeshpawar,2021-04-20T08:48:24Z,0,"When we want to get values, we can differentiate and get it by mean square error function. But if we don't find values, we can use MAE and which is more relevant because If error is large, it's square will be very large and will lead to false judgement",True
@niyazahmad9133,2021-04-20T08:47:09Z,2,Outliers makes the difference...,True
@kripalsinghbamel9819,2021-04-20T08:45:56Z,2,MSE is generally preferred as it's differentiation is easy. Also  it penalize more for large errors.,True
@mohammadmaaz731,2021-04-20T08:43:27Z,19,"MSE : This measures the squared average distance between the real data and the predicted data. Here, larger errors are well noted (better than MAE).but disadvantage is that it also squares up the units.  MAE :This measures the absolute average distance between the real data and the predicted data, but it fails to punish large errors",True
@theinnoverse,2021-04-20T08:41:02Z,0,Mean absolute error when there are very less outliers or zero outliers  Mean squared error when there are large number of outliers and want to use them too to fit to model,True
@PritishMishra,2021-04-20T08:37:44Z,15,"Means absolute error will ignore the large error in the data as it just substracts.. but Mean squared error is more efficient when we does not have to ignore large errors...  That's why MSE is more generally used over MAE  Secondly, MAE also ignores outliers and more usally used when we have to ignore the outliers in our data..  While MSE also accomodate outliers in our data!",True
@Sayakvids,2021-04-20T08:37:08Z,13,here i am waiting for others to answer xD,True
@faika3094,2021-04-20T08:34:36Z,0,1st viewer,True
