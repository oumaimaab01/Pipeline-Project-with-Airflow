author,updated_at,like_count,text,public
@mahalakshmirajabattula276,2024-02-23T11:04:50Z,0,Im getting this error Im struck ..Please help me with this error SeleniumManagerException: Message: Selenium Manager failed for: /Users/mahalakshmirajabattula/Library/Python/3.9/lib/python/site-packages/selenium/webdriver/common/macos/selenium-manager --browser chrome --output json. The chromedriver version cannot be discovered,True
@aniketlahiri8296,2024-02-10T13:36:34Z,0,"It is showing ->  Scraping terminated before reaching target number of jobs. Needed 15, got 0.  Please help",True
@shedrachkambai5787,2023-09-26T14:58:40Z,0,"Hi Ken, Great work @12:35 I got this error ""IndentationError: unindent does not match any outer indentation level""",True
@hibakhan9764,2023-09-09T18:05:36Z,0,"bro you got all modules installed but some people aint got , plz show how to install modules also",True
@priyadiwnale1340,2023-09-09T10:08:12Z,0,Can anyone here help me with this project,True
@sarthakkelkar4917,2023-08-25T14:46:43Z,1,"Thank you so much,finally after a week I completed this video with solving all errors i got ,i learnt so much and learning.",True
@aaronwong5882,2023-07-01T16:49:12Z,0,Could you share the link of your background music plz?,True
@faraday6521,2023-06-25T07:24:24Z,0,"i can't find the glassdoor_scraper module to install, how do i go about it please?",True
@abinpm1736,2023-06-23T11:02:52Z,0,"i'm having trouble in using the jobs button, can some one help",True
@lyantubillara6547,2023-06-12T06:46:28Z,0,"I did everything u did at the start but I just couldn't get it to work, I already put the right path for my chromedriver but its not working, it says this error : ""TypeError: WebDriver.__init__() got an unexpected keyword argument 'executable_path' """,True
@RealCoDeR,2023-05-28T13:58:01Z,0,"Hello sir, I have a question, If we give a list of locations so it will change location by itself after completing scraping of jobs in one location?  I am waiting for your response. Thank you sir for making such a good videos for us.. these are very helpful.",True
@sonamshrishmagar6035,2023-05-18T11:05:35Z,0,8:53 you can select the first word of the with a double click and then go to the end of the code and then Shift +  click on the last code you want to select. And there you go. I find this easier.,True
@Night47807,2023-05-09T00:51:08Z,0,I'm stucked in the finding the x part. The structure of glassdoor changed so I updated the class but I still get 'x out failed',True
@Digital-Light,2023-04-04T07:47:06Z,1,"your position in front of a computer is wrong, care for your health, and thanks for tuts",True
@ankitsharma41,2023-03-03T23:16:38Z,0,Hi Ken I am not able to see screen clearly now it's bluring,True
@yemam4156,2023-02-27T15:48:07Z,1,"In order to copy many lines of code,  you can highlight the first couple words in the code, then scroll to the end of the code you want to copy. Then hold shift button and click with the mouse the end of the code.",True
@anirudhs792,2023-02-06T14:24:59Z,1,Should the aspiring data scientists be aware of Web Scapping? Should we learn about selenium and beautiful soup? Or is this the work of a data engineer?,True
@mayuringole9679,2023-01-01T20:43:56Z,0,: 'WebDriver' object has no attribute 'find_elements_by_class_name' help >>>,True
@karishmasewraj6437,2022-12-13T14:13:18Z,1,"When I get to the scraping part I am unable to move on...I get a message saying ""Error Loading , please try again""...I am doing it on Jupyter notebook....could you plz tell me where I am going wrong   On jupyter notebook the error points at   --> get_jobs(""data science "",15, False, 15)   --> driver.find_element_by_class_name(""selected"").click()   AttributeError : 'WebDriver' object has no attribute 'find_element_by_class_name'",True
@adityasood5303,2022-11-22T04:06:54Z,0,18:46,True
@shresthaditya2950,2022-11-12T14:45:55Z,0,1) Import files 11:30 Selenium 14:30-,True
@U1TR4TR4P,2022-10-25T20:09:26Z,0,is the chromedriver at the end important ? 12:35,True
@pathak_atharva,2022-10-01T14:24:44Z,1,"can you please help how to deal with this? Scraping terminated before reaching target number of jobs. Needed 15, got 0.",True
@aadiltai2468,2022-09-24T10:32:24Z,2,"hello sir your explanation is very good but i am getting an error like this ..      df = gs.get_jobs('Data Scientist',1000, False, path,15)    File ~\salary_project\glassdoor_scraper.py:39 in get_jobs     driver.find_element_by_class_name(""selected"").click()  AttributeError: 'WebDriver' object has no attribute 'find_element_by_class_name'",True
@geji2428,2022-09-13T06:55:17Z,0,Thanks for the video. I use Jupyter nootbook. How to solve such error 'ModuleNotFoundError: No module named 'glassdoor_scraper'?,True
@ishikachaudhary641,2022-08-28T03:44:57Z,0,'Scraping terminated before reaching target number of jobs' - any leads to solve this error?,True
@kneelakanta8137,2022-08-26T15:39:35Z,0,"though I'm a fresher & could not understand a single code in the whole video, I simply sit back and  watched how simple he is doing his work ??",True
@vashitvaraj3520,2022-07-22T05:29:20Z,1,can I use scraping tools like Instant Data Scraper or some other tool for the purpose of data collection?,True
@ashvrob810,2022-07-17T10:28:17Z,1,"Lovely playlist Ken!! thanks a lot , as a beginner going through this made me understand the working process!",True
@Fatima-gw7sm,2022-07-14T22:20:55Z,0,"Can anyone please share selenium python code, iam not able to fetch the data..",True
@rizbasamalah5326,2022-07-12T06:35:45Z,0,"Hi Ken! I'm a little late here but I'm getting stuck trying to run the initial web scraper and getting the following error after printing 'Progress: 0/15'    ERROR:ssl_client_socket_impl.cc(996)] handshake failed; returned -1, SSL error code 1, net_error -200  x out failed Scraping terminated before reaching target number of jobs. Needed 15, got 0.   What seems to be happening (based on the message and looking at the screen as it attempts to scrape) is that the code is either not properly able to exit from the 'Sign Up' pop-up or maybe it's not able to click on a posting.   I've been scratching my head at this for a while now and I'm really stuck. I'm using your code now directly from your GitHub. Anything you recommend trying? I love this series and am finding it very helpful but would love to follow along.",True
@freemovieshub9607,2022-07-06T13:45:41Z,0,Can you please maje another same Blog on web scraping,True
@Anggytri09,2022-07-01T12:08:47Z,1,Thanks you Sensei Ken jee,True
@unpatel1,2022-06-22T01:31:26Z,2,Little complicated but worth watching because I learned a few new things. I couldn't make it run though so moving to the next video and will use your data file. I will come back to this video in the future after I learn some Selenium. Thank you for this unedited video!,True
@ShivamRajput-rg8zc,2022-06-17T06:21:49Z,1,"Hello Ken Jee,  i was trying this code, but in my case the below line is returning a empty list.  job_buttons = driver.find_elements_by_class_name(""jl"")",True
@nishadingale5408,2022-06-15T19:53:50Z,1,"@Ken this content is gold and qualitative in terms of pushing individual horizons to do trial and error and build stuff~  Anybody who was able to solve the issue of scraping the job_buttons off the current Glass door website please lend your help, the website has changed and it no longer accepts 'jl' as the class name for those elements thanks. :)",True
@kevinpaul9191,2022-06-02T17:17:19Z,0,"Hi Ken, I followed your scrapping process. After following the process you did to get rid of sign up prompt and when I run the scrapping, it gives me the following error   ""x out failed Scraping terminated before reaching target number of jobs. Needed 5, got 0.""",True
@DevilTidusX,2022-05-30T12:41:10Z,1,"I really enjoy this natural approach, picking up real examples without preparation, it feels more genuine, great video, thanks",True
@mohammedrwelly2432,2022-05-19T01:12:07Z,0,"I'm from Syria and I am working on Data Science Project from Scratch - Part 2 (Data Collection) and I replace the code from driver.find_element_by_class_name(""ModalStyle__xBtn___29PT9"").click() to  driver.find_element_by_css_selector('[alt=""Close""]').click() but the photo will not show ''   Sign In to get instant access to millions of salaries and reviews By continuing, you agree to our Terms of Use and Privacy Policy."" 'and output is  x out failed Scraping terminated before reaching target number of jobs. Needed 15, got 0.  Note : in Syria we need to VBN with glassdoor",True
@lisitashamatutu1140,2022-04-21T14:32:54Z,0,Team or anyone who can guide me how to create a creating a web scraping file,True
@mathiasdeleur6596,2022-04-06T22:55:49Z,2,"Great video ! However, is it possible that : ""job_buttons = driver.find_elements_by_class_name(""jl"")"" does not work anymore ? where did you find it in the HTML code ? if I print the job_button in job_buttons, I get an empty list. thanks a lot !",True
@rubalsharma4869,2022-03-21T12:14:04Z,0,"Hey, it's not working for Microsoft Edge Browser. Error: AttributeError: module 'selenium.webdriver' has no attribute 'EdgeOptions'",True
@sareek007,2022-03-15T17:24:04Z,0,are anybody getting errors with import glassdoor_scraper as gs?,True
@jingyung5537,2022-03-15T00:10:52Z,0,"Hi Ken, Thank you for the video it was very informative. However, I ran into a problem where I ran the code it says ""Scraping terminated before reaching target number of jobs. Needed 15, got 0"". Any advice on this?",True
@sofiavaldez500,2022-03-10T00:32:11Z,1,Awesome series! Can you do another series like this- maybe with a more complicated project?,True
@brianx2405,2022-03-04T18:21:42Z,0,"i dislike the programming practices but i love to see people getting passionate about their trade, so for that, i respect ken jee. video's pretty old, i hope u got better with  some of the stuff u do with python, github, etc. lol but that's ok, nbd, i suppose, but it obviously wouldn't hurt and i imagine it's pretty common among people who use programming but are not programmers..  sorry just commenting out-loud.",True
@abhaybanugariya4926,2022-03-04T09:37:08Z,0,"for 18:27 which got succeeded in scrapping, mine is getting terminated? what can be the solution?",True
@lisitashamatutu1140,2022-02-28T07:33:47Z,0,"Hi Ken, what the steps for creating a web scraping file",True
@shrishtiagarwal6125,2022-02-21T05:36:53Z,0,"I have tried this too many times but the only result I got is ""Scraping terminated before reaching a target number of jobs"".Please if someone can help how to fix it.",True
@albink.robert387,2022-02-17T01:45:29Z,0,"Hi , getting the following error on trying web scrapping, pls help with this  <ipython-input-3-9f35248b0e1a>:12: DeprecationWarning: executable_path has been deprecated, please pass in a Service object   driver = webdriver.Chrome(executable_path=path, options=options) <ipython-input-3-9f35248b0e1a>:27: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead   driver.find_element_by_class_name(""selected"").click() <ipython-input-3-9f35248b0e1a>:33: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead   driver.find_element_by_css_selector('[alt=""Close""]').click() #clicking to the X.. <ipython-input-3-9f35248b0e1a>:40: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead   job_buttons = driver.find_elements_by_class_name(""jobLink"")  #jl for Job Listing. These are the buttons we're going to click.  x out failed Progress: 0/15 <ipython-input-3-9f35248b0e1a>:53: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead   company_name = driver.find_element_by_xpath('.//div[@class=""employerName""]').text",True
@ankursahu7704,2022-02-14T18:53:53Z,1,Thanks Ken for such a informative tutorial,True
@didimoescobar2247,2022-02-09T21:48:06Z,1,"Could someone help me with this issue? Scraping terminated before reaching target number of jobs. Needed 15, got 0.",True
@lucasalvarezlacasa2098,2022-02-07T22:21:25Z,1,Great video Ken! Thank you so much for sharing.,True
@ritikajaiswal3824,2022-02-06T11:33:02Z,3,I feel so satisfied seeing you copy the codes. I thought only freshers does that,True
@Esmeralda-ut1br,2022-02-06T08:12:41Z,1,"In my case it was not so easy like copy-paste, I found a scrapper from 3 years ago ðŸ˜…ðŸ¤­ i'll should do by myseld, and i think write a blog of something, ðŸ¤”",True
@rishigandhi57,2022-02-04T20:53:59Z,0,"Since im in Europe scrapping for me is not working as i think the allow cookies part is stopping it from scrapping, any suggestions on how to bypass that?",True
@vickyzhang820,2022-01-28T23:46:14Z,1,"Hi Ken, how did you achieve 12:46 by doing the 11:25 part? Did you create a new file?",True
@jineshvan2256,2022-01-19T08:27:38Z,0,"Is it just me or glassdoor has made its html scrape-proof? I tried reproducing the code but I couldn't comprehend how I could access the elements with company name, salary est., location, etc. The elements are just divs with job ids in class name and no extra attributes to access them. Anyone have a workaround, please help? If possible, can anyone share the link with the dataset you scraped because I really want to follow along with the tutorial. Thanks in advance",True
@sakshilunawat2242,2021-11-26T07:34:09Z,0,"Hey, do we need to install anaconda or is just spyder okay?",True
@sumanthns1538,2021-11-20T17:42:39Z,0,"Can someone please help understand the below error I am getting, "" Unable to locate element: {""method"":""css selector"",""selector"":"".selected""} """,True
@LukeBarousse,2021-11-17T19:43:51Z,12,"Ken, I envy your ability to build something of value so quickly. ðŸ¤–",True
@zafarpat,2021-11-09T23:20:11Z,0,"Hello, I am trying to use the code to extract information from glassdoor but code is no more working may be due to changes in glassdoor . can you suggest",True
@BeerHuntor,2021-11-02T23:57:48Z,0,"As much as I admire this series, blindly making a tutorial where your copy and pasting code as part of a tutorial -- which is aimed at beginner's is not the best way to teach, as more often than not, they won't understand what's going on, selenium is easy enough to read the docs for, this could of been achieved by showing your process how you would do this on your own.",True
@gauravaga8486,2021-10-30T03:57:28Z,0,"Hi Ken  After making suggested changes in Glassdoor_scrapper code when I try to import as module in new window but It shows following error ""ModuleNotFoundError: No module named 'glassdoor_scrapper'"". Please help me to address it.",True
@x7331x,2021-10-21T00:10:21Z,0,"Hello Ken Jee, thanks a lot for the playing. It is awesome for newbies like me!  I am trying to follow along with the video, but I get the following error: ""<input>:1: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead""  I am trying to replace all ""find_element_by_xpath"" with find_element(by=XPATH, value = xpath) but I cannot figure out how to make it work!   I would highly appreciate any advice!",True
@bhargav1811,2021-10-12T09:48:28Z,1,I LIKE YOUR TEACHING WAY BHAI!!,True
@GagandeepSingh1984,2021-09-18T10:01:01Z,1,How to copy multipage code:    ( BTW yours videos are awesome .. like real crispy and to the point )  1. Mouse click on the starting position say .. def  2. scroll down ( No mouse selection .. just scroll ) the position to the point  and the click while you hold the shift button..   * Please ignore if someone already suggested the same..,True
@statstutorials,2021-09-07T09:38:16Z,2,Would be good ot mention that some websites (like glassdoor) are updated all the time and that this script won't work after a while,True
@mashaka6557,2021-09-06T10:30:04Z,0,Hello Ken  I am running into this error.... please assist   ModuleNotFoundError: No module named 'glassdoor_scraper',True
@prithikaa7281,2021-09-02T10:15:04Z,0,AttributeError: module 'glassdoor_scrapper' has no attribute 'get_jobs' ----- this is the error im getting. send help,True
@prithikaa7281,2021-09-02T07:43:52Z,0,Can someone help me with installing the chrome driver?,True
@arthurnazariodacosta8035,2021-08-18T17:37:53Z,1,"Could someone help me with this issue? Scraping terminated before reaching target number of jobs. Needed 15, got 0.",True
@thelastcipher9135,2021-08-18T15:23:42Z,1,Thank you so much for this series! I am planning on transitioning to data science and I'm new to its programming aspects. How did you know what to do at 15:29? I figured that was HTML code. Do I need to learn HTML to be able to spot and fix those errors? Thanks again Ken!,True
@vikshukla44,2021-08-16T02:16:29Z,0,"NoSuchElementException: no such element: Unable to locate element: {""method"":""css selector"",""selector"":"".selected""}   (Session info: chrome=92.0.4515.131)  I'm getting this error during scraping data",True
@MuhammadAsim-ce4gn,2021-08-08T11:01:45Z,0,"@Ken Jee I am facing this error, I googled it but didn't find any solution. I am very new to this so if anyone know how to get done with this.  no such element: Unable to locate element: {""method"":""css selector"",""selector"":""[alt='Close']""}   (Session info: chrome=92.0.4515.131)",True
@soorian6493,2021-08-06T20:05:41Z,1,8:52 Ctrl+a selects all the text on a page. That might be a bit anything to clean up though.,True
@nicolebell8994,2021-07-22T01:05:55Z,0,"Hello, I am on Mac using Python 7.22, since this video was made, I am sure there are some changes to the code. I am getting 'str' object has no attribute 'click' as an error on most of the lines ending in .click(). Does anyone have a solution for this? I am fairly new to this and really want to get through the project but have been stuck here for days.",True
@kylow3004,2021-07-19T20:04:34Z,1,Thank you for this inside look.,True
@kaungwintshein6529,2021-06-29T08:33:17Z,1,"Hello Ken.Can u fix the error of no such element: Unable to locate element: {""method"":""css selector"",""selector"":"".selected"" please. Thank You.",True
@AmmarAli1214,2021-06-16T19:13:12Z,0,"print('x out worked')         ^ SyntaxError: invalid syntax why am I having this error? Can someone help me, please",True
@jackkar3525,2021-06-13T14:05:14Z,1,Sir is it possible to do this complete project  raspberry pi 4??,True
@srikar1626,2021-06-12T07:06:51Z,0,"Hi I tried to re create this am getting an exception  no such element: Unable to locate element: {""method"":""css selector"",""selector"":"".selected""  how do i fix this? any one",True
@ahmedshahrukhali9733,2021-06-08T01:36:39Z,2,"Hi Ken. Great video. Following along, but it seems Glassdoor changed their class names especially infoEntity from the parser. Any suggestions on how to workaround this?",True
@sherifarafa90,2021-06-02T14:40:40Z,1,whenever i launched selenium it says that it cant locate  element method css selector selector selected,True
@iamtoqeerzafar,2021-05-23T12:25:03Z,0,"i spent  two days preparing and learing this project and i am stuck at 17:00. i am getting this error Message: no such element: Unable to locate element: {""method"":""css selector"",""selector"":"".selected""}  if someone has got the solution, let me know. I already searched a lot on internet but didn""t find solution. i replaced the glassdoor website with indeed.com too but the same error on  indeed. Also i changed the sleep time from 1 up to 500 but still no luck.",True
@ayushjain8685,2021-05-17T08:37:00Z,2,"Hi I am getting the error : NoSuchElementException: no such element: Unable to locate element: {""method"":""css selector"",""selector"":"".selected""}   (Session info: chrome=90.0.4430.212)  Have downloaded the correct version of chrome still getting the issue.  Please Help!!",True
@user-dk7cd7rp6h,2021-05-14T22:26:25Z,1,"Thank you for this great video!!! I am trying to scrap data more than 30 rows, it failed when it scraped into page 2. The error shows ElementNotInteractableException: Message: element not interactable   (Session info: chrome=90.0.4430.212) Does it means this code did not write the case when scrapping more than one page.",True
@skipa9906,2021-05-11T09:53:46Z,0,"Hi, when I try to run the scraper  I just get stuck on chrome opening with the message ""Chrome is being controlled by automated test software"". I don't know what could be causing this.",True
@alexi_space,2021-05-09T00:17:50Z,0,"i got this error while running: OSError: [WinError 193] %1 is not a valid Win32 application EDIT: I solved this problem by adding anaconda3 to path variables, but now I can't click the Close button. I tried many ways to do this but since 3 hours I still CAN'T Do this... I surrender.",True
@divyamdubey9333,2021-04-25T15:23:01Z,0,Hey ken! I am getting the same error as you got when you changed the 'find_element_BY...'  please help me out,True
@vipundenuwan9293,2021-04-25T03:43:41Z,0,"Hi KenJee!  Firstly I code manually then I got below error and after that I copy & paste your code from GitHub then also I got same error....Can you give solution for me...Thank you so much... Error - NoSuchElementException: no such element: Unable to locate element: {""method"":""css selector"",""selector"":"".selected""}   (Session info: chrome=90.0.4430.85)",True
@rubyherring,2021-04-16T18:38:53Z,44,"The fact that you make this video with no cuts, showing us the whole process, trial and error and everything, makes this so unbelievably valuable. There's thousands of data science videos and how tos online, but I've never seen someone who lets me look right over their shoulder during the process. Kudos.",True
@ANKStardust,2021-04-16T14:31:22Z,3,How did I not know of this before! Brilliant work man. Thank you so much for doing this!,True
@raghavarora1612,2021-04-08T08:14:50Z,0,why keyword is written,True
@mohitchatterjee5517,2021-04-07T07:02:17Z,0,"sir i am getting this type of error....plz help me out    import glassdoor_scraper  as gs  ModuleNotFoundError: No module named 'glassdoor_scraper'",True
@TheRedPrometheus,2021-04-03T12:50:37Z,2,Im guessing since this a bit old now the code doesnt work cuz all class names are different!,True
@handydesvarieux6565,2021-04-02T17:57:43Z,1,"Hello Ken, i'm new to data science, i watched your videos which i find very interesting. i got an error when i try to reproduce your tutorial. the error is << selenium.common.exceptions.NoSuchElementException: Message: no such element: Unable to locate element: {""method"":""css selector"",""selector"":"".selected""}>> can you help me solve this problem so that i can continue the tutorial. thank you",True
@aanchaldogra9802,2021-04-02T11:17:44Z,6,"Having this error -- NoSuchElementException: Message: no such element: Unable to locate element: {""method"":""css selector"",""selector"":"".selected""}   (Session info: chrome=89.0.4389.114) PLEASE HELP",True
@hoanghanguyen1410,2021-03-25T05:37:56Z,1,Thank you. Dying to see a real process that worked,True
@MasaruHayashi,2021-03-19T23:41:28Z,1,"9:00, why not just use ctrl + A / cmd + A to copy the whole cell?",True
@mateocomba3821,2021-03-15T18:23:07Z,0,"Hi!, I'm having problem to get the data, apparently the problem is arround this line of code when trying to bypass the sing up thing:  try:         driver.find_element_by_class_name(""selected"").click()  I get the error: NoSuchElementException: no such element: Unable to locate element: {""method"":""css selector"",""selector"":"".selected""}   (Session info: chrome=89.0.4389.90)  why does it not find the element?  Thanks in advance!",True
@chaitanyasharma6270,2021-03-15T11:22:15Z,0,can any one tell me what do i have to put in the path variable at 12:12 i dont use chrome,True
@shi12924,2021-03-11T01:31:44Z,0,"I am always getting this error . Can you help me with that NoSuchElementException: Message: no such element: Unable to locate element: {""method"":""css selector"",""selector"":"".selected""}   (Session info: chrome=89.0.4389.82)",True
@prashansagupta1596,2021-03-06T15:44:03Z,4,"Hello Ken, Thanks for uploading this helpful series. It is really helping me understand the basics very well! :)     I had a question about data collection. Is data collection supposed to be a one-time process or does it have to be repeated over when the data in the source has changed? Taking the example of glassdoor, the data around salary will change over time, so how do we decide how often we should re-collect the data? And what if the website structure changes so often and hinders the scraping process? For example, this data scrapper code we referenced doesn't work very well if I run it now as many locators have changed, so I would also have to keep up with the changes in the glassdoor web structure. How to mitigate this problem?",True
@mattmovesmountains1443,2021-02-26T13:44:23Z,2,"This is huge; exactly what I was hoping to find because I couldn't visualize what a data science project really even means, where to start, etc - I'm learning on my own. I greatly appreciate the unedited process for tweaking the scraper. That stuff could be passed off as a bullet point ""collect data"", but we all know that even folks that do this daily spend some time going through what you went though in this video.   If anyone else is working on a raspberry pi or Linux system, and has issues with selenium.. let me know. I went down a rabbit hole figuring out how to set it up.",True
@BM-uf4pp,2021-02-25T17:37:36Z,3,"Unfortunately this code is broken now. I think Glassdoor has made some changes. For example, class ""jl"" is now ""react-job-listing"". I've made a little progress in making some changes.",True
@BM-uf4pp,2021-02-24T18:01:19Z,3,"Is this script still working for you? I grabbed the code from your repo. I keep getting a NoSuchElementException ""Unable to locate element: {""method"":""css selector"",""selector"":"".selected""}""",True
@siamakfarjami2116,2021-02-24T11:01:27Z,1,"Hey Ken, really good content, thank you so much. There's nothing like these series, looking forward to more of these type of series.",True
@devanshsrivastava5589,2021-02-16T14:18:32Z,2,"Tried almost everything but getting this error:  Message: no such element: Unable to locate element: {""method"":""css selector"",""selector"":"".selected""}.",True
@terrancegreen5383,2021-02-10T18:52:01Z,2,"ugh. im not sure what im doing wrong. I keep gettingÂ  selenium.common.exceptions.NoSuchElementException: Message: no such element: Unable to locate element: {""method"":""css selector"",""selector"":"".selected""}.Â  Does anyone have any idea how to fix?",True
@omarpasha2968,2021-02-08T10:09:06Z,1,"At 11:25, How did you go from a fully coded screen to just 5 lines of code when the driver path and other things were typed in? After you said, ""Let's run this"", I have no idea what you did to remove all that code, and just wind up with only 5 lines of code.",True
@omarpasha2968,2021-02-07T10:02:21Z,1,"you can select all the code all at once by holding down 'command/shift'. Just keep holding down command/shift, and the previous code will not deselect.",True
@chiragpatel5267,2021-02-01T17:36:54Z,2,Loved the video!!!!,True
@eyesongeopolitics,2021-01-29T12:21:01Z,0,please can someone help me  i can't install glassdoor package  i'm using pip3 and i have python3 install but when i run the pip3 install glassdoor command on my command prompt  i get a verry long error message which at the end says invalid syntax,True
@nicksanfilippo312,2021-01-29T04:31:05Z,1,How can I install glassdoor scraper?,True
@vickiepriyan,2021-01-24T00:48:39Z,1,"Hello Ken, Thank you for this tutorial..  Need a help.. ""alt=close"" not working.. cant find close button in the Inspect as well.. please help as to what key to fetch in.. Much Thanks:)",True
@kurtispykes836,2021-01-19T09:05:54Z,2,To copy a full code cell you click in the code cell and use CTRL +  A which would highlight everything the CTRL + C to copy everything. Great vid!,True
@eyesongeopolitics,2021-01-17T10:00:16Z,1,"yeah there's a better and easy way to copy the entire script  first, off you highlight the entire script by clicking at the beginning of the first line of the script and then scroll down to the end (make sure you don't click anywhere else) now hold the shift key and click at the end of the last line of code (while still holding the shift key)it will then highlight the entire script and now u can press ctrl+c to copy it.",True
@eyesongeopolitics,2021-01-17T08:40:43Z,1,"this is greater stuff that I have come across I'm new to data science and I spend over a month on youtube trying to get me started with the journey but didn't really find a step by step tutorial as simple and straight forward for a beginner like this channel right here. thanks, bro  its really so helpful   please can you make a video on git bash and how to connect it to GitHub?",True
@lamaadministrator2595,2021-01-15T16:19:32Z,1,"the process stops at: ""Progress: 0/15"". No error message whatsoever. :/ Anybody has an idea why?",True
@jimmylim1857,2021-01-15T00:14:46Z,3,"Hi Ken, I am trying to use your scraper, but it is not scraping, it just shows ""x out worked Progress: 0/15"" and that is it. Do I have to download something else? Im a beginner!",True
@hossam8454,2021-01-04T00:16:29Z,0,"i got that error  from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException",True
@hadihassan372,2021-01-02T10:08:51Z,1,"Ken, i'm going through this entire project with you:) As selenium goes through the glass door website i get the error after a few cases saying ElementNotInteractableException ... i have added this error to the webscraper.py and like the other errors added pass but the error is reoccurring....can i get some advice?",True
@adityagaikwad3172,2020-12-26T22:12:51Z,1,"I was facing an issue while scrapping.  Search as per keywords was not happening.  To tackle that I had to add the following code just below the ""#clicking to the X."" try block.  Code :-          try:             driver.find_element_by_id('HeroSearchButton').click()         except NoSuchElementException:             pass  ##I'm just clicking on search before scrapping. ## Make sure it executes only once Thanks for the content @Ken",True
@marku7z,2020-12-23T15:54:48Z,1,"When scraping the 600th job there is no progress in scraping anymore and when I look into chrome I see a reload button and when I click it by myself then a ""StaleElementReferenceException: stale element reference: element is not attached to the page document"" Error is thrown. But before clicking myself at the reload button, there is no error thrown nor progress anymore. Does anybody knows a solution to that problem?",True
@ojeifooziegbe360,2020-12-23T15:16:58Z,0,Having issues  with the chrome driver,True
@aroojahmed1540,2020-12-17T23:14:48Z,0,Thank you for an informative tutorial. I am having the following error while running the code: OSError: [WinError 193] %1 is not a valid Win32 application,True
@CrazyFanaticMan,2020-12-14T07:47:45Z,3,"To copy the selenium scraper in one go just go to the first line of the code block and click so that your cursor is flashing, then scroll down to the bottom, once you get there, hold shift and click again and that will highlight everything between the two points where you click with your cursor  Huge time saver :)",True
@shrutijain1628,2020-12-13T14:32:04Z,2,Had some issue understanding the scrapper part because IDE is in dark mode but other than that understood very easily  Thank youðŸ˜ŠðŸ’¯,True
@rakshitvyas4919,2020-11-30T13:56:23Z,0,"I am not getting salaries in my data frame(It's coming -1 as default) I did some digging, but I am not getting it. Please help!!!!!",True
@muhammadmalik3518,2020-11-21T18:54:21Z,0,** ERROR (HELP) When changing the Grey small salary to grey salary still no results. Went in and inspected the element it is written as (CSS-1uyte96 CSS-hca4ks e1wijj24) which should be grey salary  If anyone has any insight on this and could help I would greatly appreciate it!,True
@suheturing810,2020-11-20T09:24:03Z,1,"I'm getting some random css number as the span class name (css-1uyte9r css-hca4ks e1wijj242) of the salary estimate. When I'm entering that name in the scraper code, its returning -1. Any idea how to overcome this?",True
@vinipuonder5455,2020-11-11T14:50:03Z,1,Amazing job Ken. I will definitely give you credits for my first project.,True
@ABDULRAHMAN-od7hq,2020-11-04T20:38:05Z,0,"hey, ken wonderful video , i faced an error while copying the data soo many a times i used to get this output  (x out failed) in the middle of the extraction, and then suddenly it just paused at 622 /1000 like didnt pause but its just stuck there idk what to do @ken",True
@seytanc4,2020-11-04T13:39:01Z,2,07:38 scraping Jupyter Notebook into Spider IDE ðŸ¤£ðŸ˜‚,True
@waweruwachege2094,2020-10-30T06:55:20Z,1,"Hi ken, thank you for the video tutorial. However, my code works in reverse. The 'keyword' search works at the end of the Scrapping. Any help?",True
@mufaddalkanpurwala462,2020-10-28T20:12:19Z,1,My scrapper gets stuck when getting the data...Any suggestions to resolve??,True
@pratikgehlot9516,2020-10-26T14:54:19Z,0,"All the indian guys trying this project , use the data directly present in the github repo , dont run scrapper coz indian version of glassdoor is a bit differnt imo.",True
@ishpandey7886,2020-10-23T14:18:12Z,1,"Hi Ken, amazing content, never come across such a thorough video (especially data scrapping part). Big fan of playingnumbers.com too. Can you make a video of the same type for a data visualization project maybe using tableau.",True
@ozanguven2307,2020-10-15T21:45:34Z,0,cant import glassdoor_scraper as gs. anyone knows why?,True
@jaiminshah143,2020-10-14T13:50:25Z,0,Hello I wanted to ask that I want data related to job profile- Data Scientist and Job location as Bangalore. When I searched in glassdoor.com the salary for the jobs posted in bangalore is not specified so any help here would be appreciated.,True
@adeyemiqudus2049,2020-10-11T00:43:08Z,1,Thanks Ken!! you are the best. I manage to get my hands dirty. but I am curious about starting up my own scraping using another problem. can I still make use of the same function?,True
@mohammedazeem3303,2020-10-10T05:10:11Z,1,Great approach for working on a good project. Thanks for sharing. I'll get my hands on it when I master my basics,True
@kirtib7079,2020-10-08T17:40:19Z,7,Hi Ken ...Project from scratch series really helps me to understand how does data scientists works on real world project in their companies...Thank you so much for your efforts...very appreciating ... looking for more such kind of projects from you.,True
@BlackExcellence_243,2020-10-05T08:44:43Z,0,@12:56 how do you run the browser ?  am getting this: WebDriverException: 'chromedriver' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home,True
@fawziaalanazi2506,2020-09-20T22:18:32Z,2,"I do not know why all salary estimate values are repeated,  I followed your video and fix it the same as you then I copy the source code but the salary estimate keeps repeated ,do you have any solution ? Thanks a lot for these videos, they are really helpful.",True
@mikemaresh2417,2020-09-19T17:45:04Z,2,Awesome concept for a series!,True
@kaushilnagrale6766,2020-09-19T15:51:15Z,1,Great Video!!,True
@BonusFiddle,2020-09-07T22:34:51Z,1,This is helpful and enlightening. In my certificate program weâ€™ve been using different tools and add ons to do all this. THIS is much more work but a worthwhile endeavor. It will take some time to get up to speed with github and my coding environment. I was doing coding in a different arena 5 years ago. I hope it informs my ds coding environment,True
@mustafamegahed7873,2020-09-07T02:49:00Z,3,**An easy way to select text** @8:52 1. click where the text starts (just place the cursor and click without holding) 2. scroll down to the end of text 3. press and hold Shift then click where the text ends,True
@MilliardoPeacecraft590,2020-08-21T19:52:55Z,1,Ken I'm curious as to why you prefer spyder over jupyter? Just your preferred editor?,True
@MilliardoPeacecraft590,2020-08-21T19:49:21Z,37,This is a game changing playlist. By far one of the most valuable lessons to date. Thank you!,True
@flawedlogic342,2020-08-20T02:13:17Z,0,Ken the just scrape the code that scrapes the website so obv bruh,True
@flawedlogic342,2020-08-20T01:58:28Z,1,use css selectors to get html and use scrapy to scrape.,True
@smoggyraptor6521,2020-08-17T02:45:48Z,2,"Hey Ken! Loved the video as always.  I'm still in college and I am aspiring to be a data scientist later on. I just had a question that considering my current academic condition (year 2) is it all good if I use the code of other users (giving them proper credit of course) for my projects which I intend to present for securing an internship later on?  As always, truly appreciate your videos. Keep up the good work of helping us!",True
@mimikoko4299,2020-08-13T18:40:25Z,2,Thanks alot,True
@Ledesma184th,2020-08-13T15:44:27Z,1,Do you have another way of determining the IDE you want to use outside of it being your preference?,True
@heetshah5175,2020-08-11T09:38:23Z,1,He ken ! great series  When i run the program the data starts fetching but after a few records one more pop up appears and the entire process stops!  What should i do?,True
@skydivingverylover,2020-08-07T19:16:41Z,1,"Thank you so much for the video! I followed along. Unfortunately I got the result for Salary all the same values. I am from the USA. I checked Inspect section, made sure that it's still ""gray salary"". Any ideas how I can fix it?",True
@dounianouar2516,2020-08-05T23:54:30Z,1,hi thank you and keep doing this amazing job and i have question i was doing the same like you but i have problem is spider give this message module not found error can you help me thank yoou,True
@RSUtsha,2020-08-02T07:48:54Z,1,Downloading ipynb from github as py file -  Loading Public Notebooks Directly from GitHub in google colab: https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb#scrollTo=K-NVg7RjyeTk  From colab you can then just download the ipynb file as py file... Saves a lot of hassles.,True
@aakibshaikh3864,2020-08-01T17:04:14Z,1,"guys this error message is hard to crack. help please ElementClickInterceptedException: Message: element click intercepted: Element <li class=""jl react-job-listing gdGrid selected"" data-id=""3606797381"" data-emp-id=""1309610"" data-is-organic-job=""false"" data-ad-order-id=""1060438"" data-sgoc-id=""1019"" data-is-easy-apply=""false"" data-normalize-job-title=""Data Scientist"" data-job-loc=""San Francisco, CA"" data-job-loc-id=""1147401"" data-job-loc-type=""C"" data-njslv=""false"" style="""">...</li> is not clickable at point (216, 248). Other element would receive the click: <div class=""background-overlay"" aria-label=""Background Overlay""></div>   (Session info: chrome=84.0.4147.105)",True
@aakibshaikh3864,2020-08-01T13:37:38Z,1,"hey where can i get raw data, which you scraped",True
@pythonchallenge3551,2020-07-31T13:52:59Z,2,"Hi , There  : is it needed to know selenium ??",True
@adityanegi8388,2020-07-30T18:01:28Z,1,"Hey, great series! I am not able to fetch salary data in glassdoor of my country. It's not showing there, can you suggest a way around. Th",True
@ogawasan5581,2020-07-26T23:51:42Z,1,"I know we didn't sign any contract lol , but it is a big honor being your student , i'm learning so much from you , thank you so much !",True
@darklight3731,2020-07-26T09:53:36Z,0,"Hi ken, I got problem after execute the code. it said that 'x out failed'. can u suggest me what's wrong with my code?",True
@khairihilmisaputra6620,2020-07-25T11:36:24Z,1,i have problem with glassdoor_scrapper module. it said that there is no module in there. what should i do about that?,True
@chaitanyamundle3713,2020-07-23T22:11:58Z,0,Hey Ken!  I am facing a problem while importing glassdoor_scraper. Hope to hear a solution from you about it.,True
@mohitsahni2452,2020-07-20T11:38:53Z,1,"hey, ken I'm facing trouble regarding salary, all the salaries in the data frame are the same as the first one, can u help?",True
@kushagrayadav.fitness,2020-07-19T13:45:38Z,1,"Hey, Ken why you prefer spyder than Jupiter notebook...which one I should go for? any suggestions!",True
@NikicaJEa,2020-07-18T15:31:52Z,2,"Anyone encountered the  ElementClickInterceptedException: Message: element click intercepted: Element <div class=""tab"" data-test=""tab"" data-tab-type=""overview"">...</div> is not clickable at point (547, 475). Other element would receive the click: <p id=""onetrust-policy-text"">...</p>   (Session info: chrome=83.0.4103.116) ?",True
@teenutarcis9013,2020-07-11T00:58:44Z,8,"Great video Ken!! *Solution to the error messages* I made these two changes to the scraper file and now it runs all OK.  1. JOB button: Replaced job_button.click() with  driver.execute_script(""arguments[0].click();"", job_button)   2. NEXT button: Replaced  driver.find_element_by_xpath('.//li[@class=""next""]//a').click() with next_button=driver.find_element_by_xpath('.//li[@class=""next""]//a'); driver.execute_script(""arguments[0].click();"", next_button)",True
@Sumta555,2020-07-09T15:11:56Z,1,"When I also put the Job title keyword as ""Data Scientist"", and run the program, the glassdoor Job search bar only shows first 5 character as ""datas"". Can't seem to understand why this is happening? I have also tried with the other keywords like Analyst -  even here it  just shows first 5 character as Analy. Can you help why this is happening?",True
@RahulPatel-kc3bu,2020-07-08T20:03:16Z,0,selenium.common.exceptions.ElementNotInteractableException: Message: element not interactable: element has zero size  (Session info: chrome=83.0.4103.116)   I am getting this error every time I run this model.,True
@nan4061,2020-07-08T18:32:17Z,1,"Thank you for making these excellent series, very well structured!",True
@ruizhang9615,2020-07-04T00:24:15Z,2,"Thank you so much for this series, it's really helpful for beginners like me. I have a question though, I followed almost exactly how you revised the codes, the only difference is probably that I am using data from both Canada and USA, and the ""salary estimate"" column shows all identical values (e.g. CA$89K-CA$100K (Glassdoor Est.)) but all the other columns (e.g. rating, company name) are just fine. This is so confusing to me since the codes formats for reading ""estimate salary"" and ""rating"" are the same. Any insights you can share why this occurs? Thank you so much.",True
@nikhitaputta,2020-07-02T03:11:44Z,1,"Thank you Ken for such a wonderful tutorial, it was easy to follow and simple for a beginner to keep up with. I have been scraping Data Science jobs in Canada and they are less than 1000. My num_jobs variable is 1000. So, what is happening is when the scraper reached the last page on glassdoor it is going in a loop and collecting data from the same 5 jobs over and over, I guess it will do that till the length of jobs dictionary reached 1000. What can I do to make it stop once there are no new jobs?",True
@dwj489,2020-06-30T07:58:02Z,2,"Thanks for the great video! Just out of curiosity, is it illegal to scrape data online with selenium and BeautifulSoup for a project?",True
@mashewll,2020-06-25T15:11:30Z,2,"Ken, you are the G.O.A.T.  I recently started to learn python and its application in data analysis, but I was struggling with getting the data in the first place. This series is awesome! keep up your good work",True
@mathangpeddi2710,2020-06-24T11:49:37Z,1,Thank you veryy much for such an amazing project!! You have covered end to end of this project and it is very very helpful for beginners like me! Thank you so much ðŸ˜Š,True
@sonsangsom,2020-06-24T03:51:11Z,1,Why this is so fun to watch :D,True
@BecomingSuyogya,2020-06-22T13:56:11Z,23,"****Solution to one of the problem that I ran to **** Error :  ElementNotInteractableException: element not interactable: element has zero size (Session info: chrome=83.0.4103.97)  Just replace the line  job_button.click()  #You might  [ Line number around 63 ] with driver.execute_script(""arguments[0].click();"", job_button)  I just scraped my 1000 job posts without this nagging error.  Cheers !!!",True
@0x007A,2020-06-22T01:48:04Z,1,"You can easily select and copy code on GitHub by clicking 'Raw' when you view the file, then press CTRL+A and CTRL+C to select and copy it before pressing CTRL+V to paste it into your editor.",True
@utkar1,2020-06-21T19:09:37Z,6,"Thanks a lot for this Ken, loving the raw approach!! Also you could've just downloaded the Jupiter notebook as a .py file.  Looking forward to this. Cheers!",True
@perfectlyimperfectgirl2874,2020-06-17T16:01:07Z,1,"Ken Jee thank you for this video. Iâ€™m just. Beginner and while Iâ€™m trying to run the code I keep getting the following error even though selenium is already installed.  ModuleNotFoundError: no module named â€˜seleniumâ€™  I tried manually installing selenium by unpacking the taz file, still the error is there. What has gone wrong?",True
@bhaskargoswami6283,2020-06-17T12:05:03Z,1,How do we know when to stop.the scraper,True
@mohammedafaounoddenahmed8420,2020-06-16T21:36:04Z,1,Do we actually need to know the purpose of each line  of copied Selenium code or we can just copy and paste it as it is ?,True
@niyousha6868,2020-06-16T15:47:33Z,1,thank you Ken,True
@vjukulkarni6057,2020-06-14T07:05:06Z,0,"HI Ken I am getting X out failed ,while scrapping",True
@ryzary,2020-06-10T16:47:00Z,1,"Hi Ken! I tried to use 'Business Analyst' instead of 'Data Scientist'. When I reached 167/1000, i got this error:  ElementNotInteractableException: element not interactable: element has zero size   (Session info: chrome=83.0.4103.97)  Do you have any idea how to solve this? Thanks in advance!",True
@ritajyagupta4666,2020-06-10T15:51:53Z,0,selenium module error on python3? please help,True
@matthewgefen938,2020-06-09T20:27:26Z,1,"Hi Ken! I'm a little late here but I'm getting stuck trying to run the initial web scraper and getting the following error after printing 'Progress: 0/15'  ElementClickInterceptedException: Message: element click intercepted: Element <li class=""jl react-job-listing gdGrid selected"" data-id=""3343053790"" data-emp-id=""1309610"" data-is-organic-job=""false"" data-ad-order-id=""919804"" data-sgoc-id=""1019"" data-is-easy-apply=""false"" data-normalize-job-title=""Data Scientist"" data-job-loc=""San Francisco, CA"" data-job-loc-id=""1147401"" data-job-loc-type=""C"" data-njslv=""false"" style="""">...</li> is not clickable at point (216, 292). Other element would receive the click: <div class=""background-overlay"" aria-label=""Background Overlay""></div>   (Session info: chrome=83.0.4103.61)  What seems to be happening (based on the message and looking at the screen as it attempts to scrape) is that the code is either not properly able to exit from the 'Sign Up' pop-up or maybe it's not able to click on a posting.   I've been scratching my head at this for a while now and I'm really stuck. I'm using your code now directly from your GitHub. Anything you recommend trying? I love this series and am finding it very helpful but would love to follow along.",True
@QuanNguyen-ck9zw,2020-06-09T02:57:13Z,1,It could be better to just download the notebook and convert it to .py https://stackoverflow.com/questions/17077494/how-do-i-convert-a-ipython-notebook-into-a-python-file-via-commandline,True
@samriddhlakhmani284,2020-06-08T07:19:15Z,1,Just cause you asked :  There is a suggestion - Why did you not select raw format and copy from there ?,True
@kohxiangming,2020-06-05T15:47:19Z,1,Am new to the DS environment and the setting up of the repo and all had already overwhelm me.  And the nitty gritty details to amend the code.  Hope I am able to digest and pick up as I continue my upskilling,True
@thelifepolice,2020-06-04T13:42:27Z,0,Hi Ken! What keyboard shortcut did you click to run the program at 20:29 where it showed the Chrome browser opening?,True
@elisapashku2827,2020-06-01T12:28:57Z,1,Hi Ken! I love all your tutorials but in this one I am facing some problems. I keep getting the error 'ModuleNotFoundError: No module named 'selenium' ' on the console.,True
@djk5867,2020-05-28T07:22:24Z,1,"Hey Ken, I'm getting the following error when I run the file :  ElementNotInteractableException: element not interactable: element has zero size   (Session info: chrome=83.0.4103.61) Can you suggest a solution please?",True
@lajuklengtu,2020-05-26T12:03:30Z,2,"First of all, thank you for your great content. Beautifully explained. I came across an issue, when I run data_collection.py after progress 44/1000, it shows the following errors: selenium.common.exceptions.ElementNotInteractableException: Message: element not interactable: element has zero size   (Session info: chrome=83.0.4103.61) Can you please help. I tried slack but still stuck.  Thank you again for your content.  Really appreciated !!!",True
@khanhtruong3254,2020-05-25T20:48:01Z,4,"Thank you very much. The way you faced and solved the bugs is unique and inspirational. Some other videos out there are too well-prepared, which is easy to delude people into the perfectness of the code. Consequently, if the code somehow does not run, people don't know how to solve. Please keep this style.",True
@valerysalov8208,2020-05-25T19:11:10Z,1,I am not sure if this is legal cause the robots.txt file at LinkedIn disallows everything on jobs. Mostly every useful data to scrap is disallowed.,True
@hoeeeng,2020-05-25T09:41:52Z,2,"For other people - if you have the remote URL permission problem(?) with SSH (26:35), this website could help you. https://help.github.com/en/github/using-git/changing-a-remotes-url",True
@hoeeeng,2020-05-24T12:33:00Z,1,I got the same Salary Estimate values from start to end... I don't know why and it's really a pain in the ass,True
@chibao4522,2020-05-20T21:17:41Z,2,"Thank you so much for posting! I am learning so much, especially what I don't know. and need to learn for my current data project. I'm changing my career to be a data scientist (well aiming for data analyst for now and I'll build up more skills to transfer to data science). It's quite exciting!",True
@namanshah9216,2020-05-20T10:48:45Z,1,"Hey Ken, really appreciate your effort.   I am facing a problem though. Since, i am an Indian user, the website is being redirected to Indian version of the web page and Indian version lacks salary on top where company name, position and location is mentioned.  What can i do to solve this?   p.s: Also, while redirecting it gives an option to undo it, but as soon as undo it, the scrapping process gets terminated with an error KeyboardInterrupt.",True
@construct.2249,2020-05-20T00:44:43Z,1,"I don't usually comment on youtube videos, but this series is simply amazing! It's often difficult to find content on data cleaning and model production, so this project series will benefit me a ton. Quick question- what is the best way to go about modifying the scraper so that it can scrape a much larger dataset (i.e. 5000 or 10000 data points)?",True
@noahhorsley1916,2020-05-19T21:24:31Z,1,It seems my web scraper isn't scrolling down to access new postings.  It will successfully scrape the first handful (up to 15) and then spit out this error: ElementNotInteractableException: element not interactable: element has zero size  The error appears to be coming from line 61:  job_button.click()  Does anyone know how to deal with this?  I am new to web scraping.  Thanks!,True
@noahhorsley1916,2020-05-19T20:18:27Z,1,"You can copy the entire code from Jupiter Notebook by clicking, holding, and scrolling. :)",True
@digvijayhj2137,2020-05-19T17:28:49Z,1,"Hi Ken, I started web scraping and made necessary changes to retrieve estimate_salary as Described in the video, but I failed. By the way, you have inspired a lot to me man, thank you so much. Keep posting great content, very excited for upcoming content.",True
@aditipatra6837,2020-05-18T07:49:39Z,0,I was using the jupyter notebook on Mozilla and Iâ€™m getting the driver error again and again. I tried to fix it but it shows unicodeescape error,True
@philad2079,2020-05-17T03:36:03Z,0,The text small and hard to see.,True
@rahm5596,2020-05-15T20:43:10Z,1,"Hi Ken, we're you able to scrape the 1000 jobs in one shot,  because I kept getting an error of 'element click intercepted' after the script went through a few job posts. And I googled the world and couldn't find what that error meant. Thanks for your videos they're great.",True
@lucdaher,2020-05-13T23:39:12Z,4,"Try to use the ""Raw"" button if there's one on top of the editor within the page where you want to get the code from",True
@luizfelipeportelinha9114,2020-05-06T21:56:34Z,2,"hey man, i'm from Brasil, and i'm starting a project of soccer data analysis. Your videos are realy helping me out! Thank you!",True
@dengyuantan2564,2020-05-06T00:37:50Z,1,"Hi Everyone, can anyone please assist with this error: StaleElementReferenceException: stale element reference: element is not attached to the page document   (Session info: chrome=81.0.4044.138)   I don't get this error unless I try to scrape a large number of jobs, which is weird.",True
@aakashsoni51,2020-05-04T13:25:17Z,0,"I am an absolute beginner. All this years i realised i always learnt the theory first ,the details first but i wanted to try if i can look up into a project and build curiosity and then work on basics. This really helped. Thank you. Regards , mech. Engineer.",True
@fatimaezzahraelghanemy2062,2020-04-29T10:08:03Z,1,"Hi Ken Jee, this is great tutorials! thank you so much !! that's what i'm looking for !!",True
@Chillos100,2020-04-28T15:53:38Z,1,"he Ken Jee, thnx 4 the great tutorials! really loving them.. I'm trying to replicate what you did as a way of learning (i'm still in the learning phase of programming), however when i load the page, i get a ' cookie - consent' pop-up! As a result the scraping doesn't continue (however, when i manually press 'accept cookies' it does continue). Do you know a way i can hard code this in python so that when the page opens, it automatically excepts the cookies too?",True
@jordanchow874,2020-04-28T05:05:57Z,0,"Hi Ken, thanks for the series! I'm currently at @23.50. Around halfway through running the iterations I'm receiving an error saying the element is not clickable at point (219, 653). Other elements would receive the click: <div class=""gdGrid noPad"">. Do you know why?",True
@vikshukla44,2020-04-23T08:01:50Z,0,yes I have downloaded chrome driver and saved in same folder. But chrome driver is 32bit and my laptop is 64 bit support. Please help as I'm beginner and I find really interesting your channel.,True
@vikshukla44,2020-04-22T19:00:38Z,0,"File ""C:\Users\Shukla\Documents\ds_salary_proj\glassdoor_scraper.py"", line 13, in get_jobs     options = webdriver.ChromeOptions()  NameError: name 'webdriver' is not defined     Sir I'm getting this error again and again. Please help me out",True
@vikshukla44,2020-04-22T13:37:06Z,0,"File ""C:/Users/Shukla/Documents/Glassdoor/start1.py"", line 8, in <module>     import glassdoor_scraper as gs    File ""C:\Users\Shukla\Documents\Glassdoor\glassdoor_scraper.py"", line 12     In [15]:             ^ SyntaxError: invalid syntax     i am getting this error",True
@Medeiros2920,2020-04-22T01:19:33Z,1,"Hey Ken,  really good content as always, keep the projects coming! One question, I was trying to run the script and for some reason the Salary fields were all coming in as the same salary estimate (usually the first job that was copied). Any reason why you could see this being the case.",True
@chetandesai4452,2020-04-18T06:47:52Z,0,"Hi kenn  I tried running the code in Google colab , and have even specified the path of chrome driver in environment variable ,found the following error:    PS: I have downloaded the latest chrome driver wrt to the chrome update,and have specified the exact path .    FileNotFoundError                         Traceback (most recent call last) /usr/local/lib/python3.6/dist-packages/selenium/webdriver/common/service.py in start(self)      75                                             stderr=self.log_file, ---> 76                                             stdin=PIPE)      77         except TypeError:  5 frames FileNotFoundError: [Errno 2] No such file or directory: 'C:/Users/projects/chromedriver': 'C:/Users/projects/chromedriver'  During handling of the above exception, another exception occurred:  WebDriverException                        Traceback (most recent call last) /usr/local/lib/python3.6/dist-packages/selenium/webdriver/common/service.py in start(self)      81                 raise WebDriverException(      82                     ""'%s' executable needs to be in PATH. %s"" % ( ---> 83                         os.path.basename(self.path), self.start_error_message)      84                 )      85             elif err.errno == errno.EACCES:  WebDriverException: Message: 'chromedriver' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home",True
@didijustcomment,2020-04-18T02:32:13Z,1,"Hi Ken, I'm receiving this error when I'm trying to run the program at [12:52]: ""File ""C:\Users\Niccolo\Documents\ds_salary_proj\executing code.py"", line 14, in <module>     df = gs.get_jobs('data scientist', 15, False, path, 15)    File ""C:\Users\Niccolo\Documents\ds_salary_proj\glassdoor_scraper.py"", line 18, in get_jobs     driver = webdriver.Chrome(executable_path=path, options=options)    File ""C:\Users\Niccolo\anaconda3\lib\site-packages\selenium\webdriver\chrome\webdriver.py"", line 73, in __init__     self.service.start()    File ""C:\Users\Niccolo\anaconda3\lib\site-packages\selenium\webdriver\common\service.py"", line 76, in start     stdin=PIPE)    File ""C:\Users\Niccolo\anaconda3\lib\site-packages\spyder_kernels\customize\spydercustomize.py"", line 104, in __init__     super(SubprocessPopen, self).__init__(*args, **kwargs)    File ""C:\Users\Niccolo\anaconda3\lib\subprocess.py"", line 800, in __init__     restore_signals, start_new_session)    File ""C:\Users\Niccolo\anaconda3\lib\subprocess.py"", line 1207, in _execute_child     startupinfo)  OSError: [WinError 193] %1 is not a valid Win32 application""     <--------- ERROR  Would you know a possible fix for this? Thanks always for your great content",True
@PranavArrora,2020-04-16T11:00:51Z,1,"Hey Ken, really good content, thank you so much. Just wanted to suggest a change, I guess the jobs.append code in the bottom part is supposed to be outside the if condition, by mistake you put it inside. :)",True
@radripper9398,2020-04-15T00:03:04Z,2,"Hi Ken, good video as always.  I was working on this tutorial and the scrap file worked fine yesterday. I tried scrapping more data today however the ""glassdoor_scraper.py"" file started to return an error every time I run the ""data_collection.py"" file. Perhaps glassdoor made changes on their website. I tried cloning your project from Github and it gave the same error. Could you look into this?   Error:   ElementClickInterceptedException: element click intercepted: Element <li class=""jl react-job-listing gdGrid "" data-id=""2952230826"" data-emp-id=""1405209"" data-is-organic-job=""true"" data-ad-order-id=""894020"" data-sgoc-id=""1007"" data-is-easy-apply=""true"" data-normalize-job-title=""Electrical Designer"" data-job-loc=""Middletown, PA"" data-job-loc-id=""1152197"" data-job-loc-type=""C"" data-njslv=""false"">...</li> is not clickable at point (217, 869). Other element would receive the click: <div class=""gdGrid noPad"">...</div>   (Session info: chrome=81.0.4044.92)   Thanks Ken!",True
@stinhuffine4422,2020-04-13T19:12:11Z,1,Hi! What text editor do you use for Git? Vim,True
@ursus7045,2020-04-13T11:30:42Z,1,Thanks!! Subscribed,True
@snakesnarroz,2020-04-12T05:38:41Z,0,followed this through and get an error - TypeError: get_jobs() missing 2 required positional arguments: 'path' and 'slp_time'. not clear i have these variables set properly. thanks.,True
@sagarnarula660,2020-04-11T18:44:17Z,0,"Hi Ken, I really like the Video and looking forward to this series. One question i want to ask you is that can i add this project to my resume. Please reply back to my question.",True
@HonaAfrica,2020-04-10T13:08:43Z,2,You're a star. This is a great eye-opener.,True
@jagannathanj3538,2020-04-09T22:23:47Z,1,"Hey Ken, The Data Science project series is amazing and much needed. Quick question: Just like we used 'keyword' for searching with job title, what would be the change in code if location too needs a keyword search?",True
@Cam-dz2in,2020-04-08T16:48:41Z,1,Awesome vid,True
@yoanbello6891,2020-04-07T15:04:09Z,1,"Hello is very good your channel, is possible get some remote job of data science or data analisis",True
@salikmalik7631,2020-04-07T12:22:55Z,0,Can we use web scrapping tool like (parsehub) for data collection?,True
@OliverJanShD,2020-04-07T05:52:13Z,1,thank you for the video! one question though: say this came up during an interview and I was tasked with making a scraper. Would it be OK to say to use someone else's code and provide credit for it? look forward to seeing this entire series as I'm currently in my own project-building phase for my data scientist career transition.,True
@salikmalik7631,2020-04-07T04:58:16Z,2,This is my first comment on youtube since I am using computer/Internet and It's for you Ken. You have started such a great super awesome series ( Data Science Project from Scratch ) that most of youtubers have'nt and I love it. You are such a great man.  Your Videos are very informative. I believe this series will give your channel more and more subscribers.,True
@importdata95,2020-04-07T03:56:13Z,2,"Loving this series! Really enjoyed this ""buying ingredients"" process! :p",True
@Sambungus,2020-04-07T02:06:08Z,144,"There's nothing quite like a video that shows the raw process and is practical! Thanks a ton Ken, looking forward to the rest of the series--especially the data cleaning!",True
@olutayosolana6013,2020-04-07T00:43:18Z,1,I would think that a database containing the relevant data would exist and then we could see some SQL action,True
@miguelrosales3930,2020-04-06T18:10:16Z,1,"Hi, Ken! Is it possible to use ipad when doing data science? Thank you!",True
@KenJee_ds,2020-04-06T16:49:56Z,32,"Hey Everyone - I hope you enjoyed the video! Stay tuned for Part 3: Data Cleaning that will be coming out on Wednesday 4/8. I am loving the questions and comments so far, so please keep them coming!",True
@yandelyano,2020-04-06T16:11:14Z,1,"I loved the video. Happy that I have found your announcement on reddit, looking forward for the next episode.",True
@odraodee,2020-04-06T16:06:48Z,2,"Amazing series, very well structured! Can't wait to see more!",True
@ElPapelMan,2020-04-06T15:15:59Z,3,"Do you prefer to learn data science in R or python? Very informative video, canâ€™t wait for part 3!",True
@williamguesdon400,2020-04-06T15:12:51Z,1,Great work flow example. Keep up the good work!,True
@AndrewAlarcon17,2020-04-06T15:08:21Z,2,"Great video, thanks again. I'm curious, you found pre-existing code and made edits to it as you went along. How often is this the case for you on the job or for any other data scientist? How prepared should one be to make their own data scraper? Is that something that we will bump into a lot in the future?",True
@gheitacodes4146,2020-04-06T13:44:25Z,1,Dope screen,True
@youssefbhmida8682,2020-04-06T13:03:18Z,1,Finally  :D,True
