author,updated_at,like_count,text,public
@KenJee_ds,2020-06-09T13:52:51Z,12,"Hi Everyone - It appears that this api is not working right now. People are returning 0 tweets. I will update if anything changes. Until then, please keep  an eye on this: https://github.com/taspinar/twitterscraper/issues. that is where the issues are being reported. Try these if you want some other alternatives: https://www.youtube.com/watch?v=VrZ6Uns7bYc",True
@SakshiGupta-nf1fv,2023-01-12T02:43:02Z,0,Is there any other way to return tweets as this is not working?,True
@3DPrintedEngineer,2022-04-29T21:41:23Z,1,nice big forehead,True
@cf6634,2022-04-23T03:10:55Z,2,Simply awesome!,True
@rmathur00,2022-03-09T18:54:28Z,1,AttributeError: 'NoneType' object has no attribute 'find_all' @Ken Jee can you help,True
@user-mr6gn5lj4l,2021-12-22T20:59:53Z,0,"Is this a private module, why does it give an error at the end?",True
@sumanthns1538,2021-12-14T13:34:48Z,0,AttributeError: 'NoneType' object has no attribute 'find_all'  What does the above error mean?,True
@robertwclayton6962,2021-10-12T12:11:54Z,0,"Thanks for the tutorial - super useful!  Is it possible to use the Twitterscapper module to ""pull"" tweets by their tweet ID?",True
@moonoso,2021-09-14T01:04:05Z,0,Does anyone knows how I can fix this: attributeerror: 'nonetype' object has no attribute 'find_all'? I can't find a viable solution to fix this so far!,True
@sriramr4957,2021-09-12T07:07:33Z,1,from twitterscraper import query_tweets is resulting in an error for me  (AttributeError: 'NoneType' object has no attribute 'find_all'). Can anyone help?,True
@mastifatchiyahm5484,2021-08-09T06:33:05Z,1,Is everyone still can use this module today? because my code returning 0 tweets.,True
@sathiyaraju8124,2021-07-26T15:48:40Z,0,"Hey Ken, thanks for the video. I tried this, but I couldn't gather any tweets returns only empty dataframe but no error. Can you suggest any solution?",True
@jaganjr1983,2021-06-24T08:06:04Z,1,I get ModuleNotFoundError: No module named 'scrapy.conf' for after import query_tweets. It won't properly run.,True
@miguelbenitez916,2021-05-19T15:51:55Z,0,"I have a question. In the query_tweets structure, how do I filter tweets only from certain accounts?",True
@deswill2737,2021-05-14T15:48:22Z,0,how to instead of begin and end date just give the latest one since the script started running?,True
@ChristianGardner,2021-04-16T21:41:02Z,1,This is awesome!,True
@rgm2754,2021-03-19T12:48:12Z,1,is still working?  got the error 'IMapUnorderedIterator' object has no attribute '_write_to'    Can't find  a solution,True
@nurinsyirah7847,2021-03-18T13:59:40Z,0,Why it appear SyntaxError: invalid syntax for enddate = end_date?,True
@LUCAS-lu1ii,2021-03-02T14:56:56Z,1,This is very simple yet useful example. Thanks.,True
@a_vickyp8360,2021-01-23T04:10:41Z,1,"#19: This is a great one! I will be working on this one, has been a challenge doing the scraping using the API, and seems I took the difficult approach! #66daysofdata",True
@patrickasis3360,2021-01-14T04:33:38Z,0,why nothing happened? is this not working right now?,True
@prayogame9925,2020-12-29T14:34:39Z,0,"Hi ken, Im new with python. how to instal twitter scraper? when I pip install twitterscraper, the result ""syntax error: invalid syntax""  Im using python 3.9.   btw, ur tutorial was great.",True
@adlurirohith7149,2020-11-05T08:30:04Z,0,Very much helpful,True
@banglicugaming3557,2020-10-28T09:49:40Z,0,"sorry, why i got htmlsessiin object or request_html module?",True
@AmanPratapSinghBITsindri,2020-10-14T03:29:08Z,0,"in case u r intrested from twitterscraper import query_tweets import datatime as dt import pandas as pd  begin_data = dt.date(2020,10,13) end_date = dt.date(2020,10,14)  limit= 10000 lang = 'english'  #user = realDonaldTrump  tweets = query_tweets(""vote"", begindate= begin_data, enddate= end_date,limit= limit, lang=lang) df=pd.DataFrame(t._dict_for t in tweets)",True
@preranasingh9114,2020-10-06T14:28:59Z,0,the above code gives me blank or square bracket result[],True
@adeputri8601,2020-09-18T13:28:33Z,0,"I tried to implement this code using sublime and run it on windows powershell. I got an error on line tweets = query_tweets, unexpected keyword argument begindate.",True
@ankitadixit5314,2020-09-11T12:01:05Z,0,can we add url instead of user names ?,True
@nonamed56,2020-08-29T09:46:24Z,1,I'm getting the follwing error: 'IMapUnorderedIterator' object has no attribute Please advise.,True
@MrWarwickJones,2020-08-15T01:28:28Z,0,"Hey Ken, is there a way to add multiple search queries within Python.  For example, I want to search for tweets that include the term ""Australia"" and either ""olympics OR sport"".",True
@sebastianbecerra1034,2020-08-12T18:50:01Z,1,"HI Ken, Has it worked again?",True
@ggdog007,2020-08-12T03:35:04Z,0,"Hi, Is it possible to get single tweet by the url only? I found twitterscraper.query.query_single_page(query, 'english', pos, retry=50, from_user='use_id', timeout=60, use_proxy=False), can you give an example, like ""https://twitter.com/washingtonpost/status/1293170815052152835"" and return a dictionary of info. in this tweet?",True
@andyfung9474,2020-08-04T08:01:56Z,0,Is notre dam fire a searched keywords in tweets or what does it refers to ...? And how to add the parameter of hashtag??,True
@md.hafizurrahman3585,2020-07-25T19:15:40Z,1,"This Video is really good, but it does not give 24 hours tweets.",True
@xianzhang4301,2020-07-16T02:28:20Z,1,"Thank you so much for this tutorial, it's been the most useful one for my scraper projects so far!",True
@faizankhan479,2020-07-04T14:30:36Z,0,Hi I would like to get the tweets with respect to a specific key word for a specified time period,True
@mohitnagarkoti4086,2020-07-03T09:24:49Z,1,Greate Help,True
@nirmalasoni7710,2020-07-02T13:39:09Z,0,Hey Ken thank you for this very helpful video! I'm using your code and I tried to scrap tweets for a specific user but I can't  use it for a specific user. What could the problem be there?HELP,True
@amazing-graceolutomilayo5041,2020-06-17T09:18:15Z,1,I have liked and subscribed üôÇ,True
@shubhamgarg4463,2020-06-09T06:52:49Z,1,"Hello ken,  now i am trying to scrap data but i found below issue. can you suggest me resolution.  INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=disney%20since%3A2020-04-20%20until%3A2020-04-21&l=english INFO: Using proxy 64.17.30.238:63141 INFO: Got 0 tweets for disney%20since%3A2020-04-17%20until%3A2020-04-18. INFO: Got 0 tweets (0 new). INFO: Got 0 tweets for disney%20since%3A2020-04-16%20until%3A2020-04-17. INFO: Got 0 tweets (0 new). INFO: Got 0 tweets for disney%20since%3A2020-04-18%20until%3A2020-04-19. INFO: Got 0 tweets (0 new). INFO: Got 0 tweets for disney%20since%3A2020-04-19%20until%3A2020-04-20. INFO: Got 0 tweets (0 new). INFO: Got 0 tweets for disney%20since%3A2020-04-21%20until%3A2020-04-22. INFO: Got 0 tweets (0 new). INFO: Got 0 tweets for disney%20since%3A2020-04-20%20until%3A2020-04-21. INFO: Got 0 tweets (0 new).",True
@rajivsuntharamurthy9386,2020-06-08T11:12:23Z,1,"If it's not working on your pc, try on another laptop or your friend's laptop with editing query.py. My friend is a savior!",True
@rajivsuntharamurthy9386,2020-06-07T09:56:57Z,8,"It still shows 0 tweets even when I edit in the query.py, man :(",True
@user-cy2on3gc3k,2020-06-06T14:25:46Z,1,Thank you so much for the very useful tutorials!,True
@celiaclements6581,2020-06-05T11:40:18Z,0,"This is a very well explained video! I am trying to get the tweets of one specific user, but the 'user' parameter that you mentionned doesn't seem to work ... any ideas on how I could achieve this? thanks!",True
@TheActuarialGuyRomit,2020-06-03T18:38:55Z,15,"Hi guys!  So, it seems like this has stopped working, I found the fix on Github tho,  Here's how to go about it:  This can be fixed by modifying the header dictionary in query.py from HEADER = {'User-Agent': random.choice(HEADERS_LIST)} to HEADER = {'User-Agent': random.choice(HEADERS_LIST), 'X-Requested-With': 'XMLHttpRequest'} that should fix the issue. Here's the github link: https://github.com/taspinar/twitterscraper/issues/296 Ken - will you kindly pin this comment for everyone's good?  Cheers! PS: query.py can be found typically at:  C:\ProgramData\Anaconda3\Lib\site-packages\twitterscraper",True
@jianchengshi9694,2020-06-03T16:31:59Z,1,"Thanks for the video. I run the following: tweets = query_tweets(""Trump"", begindate = begin_date,enddate=end_date,limit=limit,lang=lang)  INFO: queries: ['Trump since:2020-06-01 until:2020-06-02'] INFO: Got 0 tweets (0 new).  received 0 tweets. would you happen to know why?",True
@antoniofocella5370,2020-06-03T10:04:02Z,2,"Hi Ken, thanks for sharing the video, it's clear and gets rigth to the point. However, though I follwed each step, once I try to run the code I always get the following output: INFO: Got 0 tweets (0 new). INFO: Got 0 tweets (0 new). regardless of query, limit or language used. Do you have any idea of why this happens?",True
@md.zahirulislam5052,2020-06-03T00:37:07Z,1,"Hi, This is great tutorial,  but I am facing the below problems while run the script INFO: Using proxy 110.3.255.134:8081 INFO: Got 0 tweets for COVID%20since%3A2020-05-04%20until%3A2020-05-05. INFO: Got 0 tweets (0 new). INFO: Got 0 tweets for COVID%20since%3A2020-05-27%20until%3A2020-05-28. INFO: Got 0 tweets (0 new). INFO: Got 0 tweets for COVID%20since%3A2020-05-19%20until%3A2020-05-21. INFO: Got 0 tweets (0 new). INFO: Got 0 tweets for COVID%20since%3A2020-05-07%20until%3A2020-05-08. INFO: Got 0 tweets (0 new). INFO: Got 0 tweets for COVID%20since%3A2020-05-16%20until%3A2020-05-18. INFO: Got 0 tweets (0 new). INFO: Got 0 tweets for COVID%20since%3A2020-05-24%20until%3A2020-05-25. INFO: Got 0 tweets (0 new). INFO: Got 0 tweets for COVID%20since%3A2020-05-08%20until%3A2020-05-10. INFO: Got 0 tweets (0 new). INFO: Retrying... (Attempts left: 1) INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=COVID%20since%3A2020-05-22%20until%3A2020-05-24&l=english INFO: Using proxy 110.3.255.134:8081 INFO: Got 0 tweets for COVID%20since%3A2020-05-28%20until%3A2020-05-30. INFO: Got 0 tweets (0 new). INFO: Got 0 tweets for COVID%20since%3A2020-05-30%20until%3A Here is my codes:   from twitterscraper import query_tweets import datetime as dt import pandas as pd begin_date = dt.date(2020,5,1) end_date = dt.date(2020,6,1) limit = 1000 lang = 'english' tweets = query_tweets(""COVID"", begindate = begin_date, enddate = end_date, limit = limit, lang = lang) df = pd.DataFrame(t.__dict__ for t in tweets) df.to_excel(""tweetscrap.xlsx"") -----------------------------------------------  but all the time getting 0 results. Could you please help.  Thanks",True
@prashantnair365,2020-06-02T16:19:13Z,1,"The best video on scraping tweets. Easy to understand. However, I could scrape tweets only for a day. The next day onwards, every time I run the code, it returned 0 tweets. What could be the possible reason and how could I rectify it? The result was same irrespective of the topic or timeline. Thanks.",True
@user-kk2hn9qq8j,2020-06-02T11:39:58Z,1,"Hey this is a super helpful video, I am trying to do the same using datetime.date.today so I don't have to keep updating the day but the twitterscraper module only seems to be able to search when the date is formatted with commas and no leading zeroes as you have done - do you have any idea how to get this to work?",True
@yashodayadav4932,2020-05-30T18:22:26Z,2,i watched your video and quite i understand many things but when i hit f9 key it is showing an error : ModuleNotFoundError: No module named 'twitterscrapper Please help me ASAP,True
@anandaaransa6453,2020-05-20T17:14:29Z,0,"Hi, i am so frustated i cant import my module in my spyder, how i can get it ?",True
@user-zu3up1fz7e,2020-05-20T11:15:10Z,1,do you prefer spyder rather than pycharm?,True
@juanchen2916,2020-05-20T09:06:17Z,1,"Thank you for the useful video! I run the codes a number of times just for checking. I do successfully get the tweets, but sometimes it returns  with different numbers of tweets. Do you know why is that the case, and how to resolve it? I did not set any limit for querry_tweets.",True
@shezzbasha7985,2020-05-19T21:38:45Z,1,"Pretty cool Video (O.O), Thanx a ton :)",True
@rocwil9420,2020-05-19T16:55:59Z,0,how can I get all comments from one  tweet,True
@talhaafzal873,2020-05-18T20:15:14Z,0,"Hi, Thanks for the cool video. Can you please confirm do we need any developer account in order to get past month tweets? Also i want to extract tweets from specific location, is it possible? Further, please confirm if we can specify hashtags and keyword based search with this method.",True
@danilblackhumor,2020-05-14T12:38:51Z,0,twitterscraper username --user --csv -o name.csv - it works great. Thank you so much. But in the list are no replies. How to collect replies to the same file?,True
@rahm5596,2020-05-14T04:55:18Z,0,Can't seem to figure out how to query by twitter handle,True
@DanielS-wu4sq,2020-05-13T21:41:58Z,1,Awesome tutorial! simple and efficient! thanks a lot!!,True
@rohitbhattacharya8336,2020-05-12T10:06:25Z,0,How can I get about 75k to 100k tweets without retweets? please help me out,True
@ganeshkolase7203,2020-05-10T10:16:44Z,1,This is the best video ever on Scraping tweets from Twitter.  Is there any provision for getting tweets for a particular keyword depending on number of followers?,True
@jaaphilipe7807,2020-05-08T11:17:27Z,1,Its explained really good! Also switched to Spyder IDE now. Its way better (in my opinion) than VSCode.,True
@t_tek760,2020-05-05T04:11:07Z,1,Title of the background instrumental pls üôèüôèüôè,True
@akindefisayo3267,2020-05-02T11:17:20Z,0,How can i export the pandas DataFrame for the scraped tweeter data as CSV to save on my system memory ??,True
@sidramowlana,2020-05-01T23:21:04Z,0,"Hi, I would like to know how to get fake and real labeled news using twitterscrapper. First of all is it possible to do something like that?  I am very new to this.",True
@nattetosti,2020-05-01T12:56:24Z,1,"Hi Ken! Thank you so much for the clear explanation! When I run the code, I encounter the problem of: thread 'Supervisor' crashed: AttributeError(""'IMapUnorderedIterator' object has no attribute '_write_to'""). Do you or does someone has an idea how I can fix this? Been stuck for days and the deadline of my thesis is coming up fast... Thanks in advance!",True
@saidaggupati1549,2020-04-30T05:40:29Z,1,"Hey, can we fetch details of a user say, followers and following count through an email on twitter instead of the user name or handle?",True
@TheActuarialGuyRomit,2020-04-29T11:07:51Z,0,"Hi Ken!   How do I scrape based on hashtags, is that possible with this module?",True
@austinxu9519,2020-04-28T23:53:58Z,1,Thank you so much! Your tutorial is so helpful!!!,True
@divyaahuja8820,2020-04-21T07:50:17Z,0,@Ken Jee Thanks..It's a great video.I want to ask is it possible to scrap a hashtag data which tweet by people of particular country?,True
@lebsen1,2020-04-19T13:35:50Z,0,helped me a lot! thanks,True
@lakriakriche3093,2020-04-15T07:25:46Z,1,Thant you for this helpfull tutorial. Can you please show us how to scrap tweets of a specific account(user) ?  because i tried to add a user argument but apperently query_tweets has no argument named user,True
@firuzjuraev5383,2020-04-14T08:13:27Z,0,"Thank you for the great tutorial. But I have problems. When I run the code there are some problems with converting JSON and the code does not skip it , it reties and stack at one tweet? Can you help with it",True
@aysegulcanbaz5768,2020-04-10T08:35:22Z,1,Hey Ken thank you for this very helpful video! Using your code I tried to scrap tweets with '#bitcoin' but only got 13k tweets for a timeframe of 1 year (without a limit defined in the code). It seems very few. What could the problem be there?,True
@faxyl8348,2020-04-08T19:40:46Z,0,"How can i scrape and save, say 100 tweets yesterday, and resume scraping beyond the point today?",True
@seamushand8439,2020-04-07T20:29:26Z,1,Hi Ken - i really liked this as it avoids the complication of the API. Can you explain what is happening in line df=pd.DataFrame(t.__dict__ for t in tweets) ? I know you are converting from the tweet objects to a DataFrame but I don't understand the syntax. Thanks . Seamus,True
@anjalisantoshambat2637,2020-04-03T10:04:43Z,1,Can we get followers and the people we follow by using this. Or is there any other way for it.,True
@ahmadtf5493,2020-03-26T17:35:46Z,0,"@Ken_Jee  Thank you, for this tutorial   But when I try to scraping a data,   it's not giving me only a couple of tweets even thou I'm sure the tags I used having more than thousand of tweets, any help? Also, is Arabic is considered in this model?   Many thanks",True
@BIGn0se,2020-03-22T16:54:52Z,0,"Hi Ken, this video help me a lot, but there's an error that I get said ""Traceback (most recent call last) : "" and there's a lot of error message down below anyway to fix it?",True
@TheCruelkindness,2020-03-18T16:14:40Z,0,"Hello Ken Jee, would you be able to help? I get this error while running the code below. The error comes out as part of the output. But the number of tweets seems less even without me setting a limit.  ""ERROR: Failed to parse JSON ""Expecting value: line 1 column 1 (char 0)"" while requesting ""https://twitter.com/i/search/timeline?f=tweets&vertical=default&include_available_features=1&include_entities=1&reset_error_state=false&src=typd&max_position=TWEET-1237528655246413824-1237528662397730817&q=coronavirus%20since%3A2020-03-04%20until%3A2020-03-11&l=en""",True
@paulnnakwe,2020-03-16T16:22:02Z,1,is it possible to restrict the tweets to location?,True
@AsifMalik_1,2020-03-14T15:12:35Z,0,"Hi Ken, fantastic video, thanks. Instead of saving it as a Panda's df can the tweets be saved as a CSV file?",True
@PratikSatpathy97,2020-03-08T20:45:26Z,0,"SSLError: HTTPSConnectionPool(host='free-proxy-list.net', port=443): Max retries exceeded with url: / (Caused by SSLError(SSLError(""bad handshake: SysCallError(10054, 'WSAECONNRESET')"")))  I'm getting this error. What should I do?",True
@rafiazaheer3947,2020-03-04T12:49:51Z,0,Help needed.. i don't understand this how data is displaying in console area. what have you done after selecting code. please help as i am new to this field. TIA,True
@Dunanjay,2020-03-04T01:53:30Z,0,"Hey Ken! I love the video. Just wondering how I can filter by user? when I add user = user into the query, it returns - ""query_tweets() got an unexpected keyword argument 'user'""  Thanks again! EDIT - I did scroll down here and find the correct code for filtering by username. Is it not possible to add in the date, keywords filters along with a username? For instance, all coronavirus news from nytimes over the last 3 days. Thank you so much again!",True
@wangjiahe5382,2020-02-27T14:53:29Z,0,"Hi Ken, thanks for the tutorial! It really worked. However, after I tried to get a large amount of data (I think the limit I entered was 9999), the console says that it encountered an error involving json file. May I know how could I avoid this error? Thanks!",True
@healy4513,2020-02-12T23:02:16Z,0,"I have an error that appearance ""SSL error""!!  SSLError: HTTPSConnectionPool(host='free-proxy-list.net', port=443): Max retries exceeded with url: / (Caused by SSLError(SSLError(""bad handshake: SysCallError(10054, 'WSAECONNRESET')""))   what is the solution for that eeror, help?!!",True
@pramudyakamaljumblat8029,2020-02-12T04:04:46Z,0,"excuse me sir, how to save into json file",True
@patrickmais1,2020-02-11T22:36:40Z,0,"Good Afternoon Ken..thanks for the help in advance...watched this video and ran this code  sr_fire_tweets = query_tweets(""saddleridgefire"", begindate = begin_date_sr_fire, enddate = end_date_sr_fire, limit = limit_sr_fire, lang = lang)     returned a long error message with this at the bottom: Exception                                 Traceback (most recent call last) <ipython-input-20-1a3ea7e0be1c> in <module> ----> 1 sr_fire_tweets = query_tweets(""saddleridgefire"", begindate = begin_date_sr_fire, enddate = end_date_sr_fire, limit = limit_sr_fire, lang = lang)   /opt/anaconda3/lib/python3.7/site-packages/twitterscraper/query.py in query_tweets(query, limit, begindate, enddate, poolsize, lang)     234         logger.info('queries: {}'.format(queries))     235         try: --> 236             for new_tweets in pool.imap_unordered(partial(query_tweets_once, limit=limit_per_pool, lang=lang), queries):     237                 all_tweets.extend(new_tweets)     238                 logger.info('Got {} tweets ({} new).'.format(   /opt/anaconda3/lib/python3.7/site-packages/billiard/pool.py in next(self, timeout)    1965         if success:    1966             return value -> 1967         raise Exception(value)    1968     1969     __next__ = next                    # XXX   Exception: Traceback (most recent call last):   File ""/opt/anaconda3/lib/python3.7/site-packages/billiard/pool.py"", line 1267, in mark_as_worker_lost     human_status(exitcode)), billiard.exceptions.WorkerLostError: Worker exited prematurely: signal 11 (SIGSEGV).     Any thoughts??? Thanks in advance",True
@nikolairodriguez5147,2020-02-11T15:31:22Z,0,"What is struggle with is making this data gephi friendly... other than that, great video. I just need another step",True
@gilangmuhamadramadhan1368,2020-02-10T17:35:59Z,0,"hallo !  can u help me, how to convert the result to .csv ? thanks before , ur video so amazing !",True
@starlightmm,2020-02-06T04:48:46Z,1,"can we search the tweets query for more than 1 sentence? like in the video you just use 'notre dame fire', how if I want to search 'notre dame fire' and '#notre' is that possible?",True
@mayankshrivastava5470,2020-02-04T12:40:54Z,0,I have a csv which contains tweet id(s). I need tweets related to the id. Any help is appreciated.,True
@Rawan-fe3ty,2020-02-03T22:00:06Z,0,"Hi ken,   I got an error after run the code       raise SSLError(e, request=request)  SSLError: HTTPSConnectionPool(host='free-proxy-list.net', port=443): Max retries exceeded with url: / (Caused by SSLError(SSLError(""bad handshake: SysCallError(10054, 'WSAECONNRESET')"")))   how can i fix it ?",True
@hansgielen3511,2020-02-02T19:48:32Z,5,"Dude, this is the clearest video I've seen so far. Kudos!",True
@sebastianbecerra1034,2020-02-02T15:22:17Z,1,"Hi ken,¬† great video!. but I got an error:  AttributeError: 'Tweet' object has no attribute '_dict_'",True
@asmasiagh7558,2020-01-31T14:10:00Z,1,"Hi, Ken thank you for the video, I have a problem with this instruction:begin_date=dt.date(2019,01,01) python version3.8 does not support this syntax",True
@IgnitionBass,2020-01-30T19:12:15Z,1,"Hi Ken, I tried following your tutorial, but when I try to run everything, I get a long error message in the console.  Being a novice,  the answers on boards liek GitHub and Stackoverflow are more confusiing than anything else. Do you happen to know what the nature of this error is? Thank you for your help.  Here is the error I get :     File ""<ipython-input-1-c4ac0bf823b4>"", line 1, in <module>     from twitterscraper import query_tweets    File ""C:\Users\[username]\Anaconda3\lib\site-packages\twitterscraper\__init__.py"", line 13, in <module>     from twitterscraper.query import query_tweets    File ""C:\Users\[username]\Anaconda3\lib\site-packages\twitterscraper\query.py"", line 73, in <module>     proxies = get_proxies()    File ""C:\Users\[username]\Anaconda3\lib\site-packages\twitterscraper\query.py"", line 43, in get_proxies     response = requests.get(PROXY_URL)    File ""C:\Users\[username]\Anaconda3\lib\site-packages\requests\api.py"", line 75, in get     return request('get', url, params=params, **kwargs)    File ""C:\Users\[username]\Anaconda3\lib\site-packages\requests\api.py"", line 60, in request     return session.request(method=method, url=url, **kwargs)    File ""C:\Users\[username]\Anaconda3\lib\site-packages\requests\sessions.py"", line 533, in request     resp = self.send(prep, **send_kwargs)    File ""C:\Users\[username]\Anaconda3\lib\site-packages\requests\sessions.py"", line 646, in send     r = adapter.send(request, **kwargs)    File ""C:\Users\[username]\Anaconda3\lib\site-packages\requests\adapters.py"", line 514, in send     raise SSLError(e, request=request)  SSLError: HTTPSConnectionPool(host='free-proxy-list.net', port=443): Max retries exceeded with url: / (Caused by SSLError(SSLError(""bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')])"")))",True
@himanshuthakur37,2020-01-29T04:58:01Z,1,hey ken jee i m getting problem ImportError: cannot import name 'query_tweets' from 'twitterscraper' (D:\Anacondaprojects\twitterscraper.py) would you help me with that please and tell me how to install tweepy for spyder it says you dont have ssl tsl,True
@itzmekt2017,2020-01-23T11:16:40Z,0,I got an error ‚ÄúNo module names twitterscraper‚Äù,True
@sakshambansal4694,2020-01-06T16:14:02Z,1,"Can we include Geocodes in this? Kindly help, I'm stuck for daysüòÖ",True
@MooXodarap,2020-01-03T07:04:23Z,0,"Hey Ken, sorry to bring up an old video. Could you explain or at least direct me to information about cleaning the scraped twitter data?",True
@samderrty123,2019-12-23T19:55:20Z,0,PermissionError: [WinError 5] Access is denied   can I have help with the above error? thank you,True
@tomaszsowik8230,2019-12-05T12:25:22Z,0,"Nice video! I wonder what would be the sentiment of the comments here ;p I have a question - is there a way to get all the comments from tweets from a specific user for a given period, i.e. 2 years? Have been looking for a way to do that, but I'm yet to be experienced :/",True
@camillamandersen,2019-12-04T15:25:28Z,0,"Hey! Thanks for the video. I can see from the github page, that I should somehow be able to check which users are verified users with the twitterscraper. But I have just no idea on how I would implement that into your script. Is that something you have tried and know how to do?",True
@burakoglakc1286,2019-12-03T10:27:32Z,0,"Hi Ken,  Thank you so much your video. I have question to you. If you help me i would behappy.  Can I make a query like this with this method?   until:2019-12-01 since:2019-11-29 place:07d9cd6afd884001  Place is including city information. I want collect tweets from here.  Have nice day...",True
@katherinecaixuefen842,2019-11-18T07:18:17Z,0,Thank you for sharing! Is it possible to crawl both tweet posts and their replies using Twitterscraper for few years backdated data?,True
@wingnut0224,2019-11-13T04:32:59Z,0,Is it possible to use hours and minutes in addition to the date to get the tweets from a specific period of time? I have been trying to play with it and I am not sure if there is a particular dt.function that needs to be used.,True
@trashman6024,2019-11-10T22:43:15Z,0,Would you have a method similar to this for scraping facebook data?,True
@SwiftYMB,2019-11-07T03:14:58Z,0,"Thank you! Awesome tutorial and an amazing find. Btw could you perhaps also do a video on how to get a library of users from twitterscrapper? I tried using the author's example ""get_twitter_user_data_parallel.py"" but to no avail, kept running into problems :/ Don't know if it is just me though.",True
@redael3881,2019-11-06T15:58:57Z,0,"thank you for you video, it's helpfull, please i want to get all Trump tweets, when i run the following  :    import twitterscraper as ts ts.query.query_tweets_from_user('Danone')      i get only  the tweets for the last 2 months",True
@lareinedumonde,2019-10-30T22:32:56Z,0,"THanks for the video! It's brought me closer to my objective than anything else ;-) But, when I input this line : tweets = query_tweets(#hungergames, begindate = begin_date, enddate = end_date, limit = limit, lang = lang) it  hangs on ... (this might mean sth in python. New python user here, so I *think* it is asking for more code???) Or does using a hastag mess things up?",True
@vivigoogleaccount275,2019-10-23T05:38:48Z,0,"Hi ken, thanks for sharing. When I try to scrap Tweets, I found I only can scrap tweets up to 1 week ago. I tried to set the sartdate as 2015.01.01 and enddate is today, but I can only got Tweets from 2019.10.14 to today. How can I get the old data? Because it seems we can get much more older data using Twitterscraper. Thank you. Looking forward to your reply!",True
@imrunserge,2019-10-21T11:05:42Z,0,"Your video helped me a lot. So, thank you!",True
@inss8808,2019-10-20T04:02:19Z,0,"Any ideas on how to export the data into csv file anyone? When I try to save the data as anything other than spyderdata, I get the message ""Unable to save current workspace.  Error message:  2019-10-13 (type) to array. 2019-10-13 is my begin date.",True
@inss8808,2019-10-19T19:51:46Z,2,what version of Anaconda and Python did you use?,True
@robertobertolini2783,2019-10-18T16:19:12Z,0,"Hi Ken:  Thanks for the video.  Is it possible to scrap tweets from one username for a specific time interval?   import twitterscraper as ts import datetime as dt tweets = ts.query.query_tweets_from_user('JoeBiden')   # I would like the dates from 6-1-19 to 10-17-19: begin_date = dt.date(2019,6,1) end_date = dt.date(2019,10,17)   but query_tweets does not seem to take a username parameter. Can you please provide some assistance? Thank you for your time.",True
@katewang7504,2019-10-11T19:08:16Z,3,Thank you! I thought I will need an API or something XD,True
@miguelgasca6500,2019-09-28T19:37:42Z,0,"Hi ken i inputted the code you recommended in order to extract the tweets from only donald trump but now I am having a problem with the last command. Below is the code i used:   import twitterscraper as ts import datetime as dt import pandas as pd  begin_date = dt.date(2019,9,10)  end_date = dt.date(2019,9,20)  limit = 1000 lang = 'english'  ts.query.query_tweets_from_user('realDonaldTrump')  df = pd.DataFrame(t.__dict__ for t in tweets)   with regard to the final sentence, when i input it i am getting NameError: name 'tweets' is not defined. how do i define the word tweets? or what code should i use? I am trying to get the nice table where it shows the tweets.",True
@schalke1905,2019-09-25T08:03:29Z,0,"Hey Ken, thank you very much for your helpful video. Maybe you can help me regarding my question: How do I get all tweets from a specific user? Simply implementing the argument 'user' (...lang = lang, user = 'realDonaldTrump') leads to an unexpected keyword argument error. What am I doing wrong here?   Thanks in advance!",True
@Victor35b,2019-09-08T02:45:04Z,1,THANK YOU SOOOOOO MUCH!!!!!!!!!,True
@joaquinmorenoantuna9573,2019-08-28T21:20:33Z,0,"Hi Ken, thanks for the video. Is there a way to segment the age and the country ?",True
@Woodangtangtang579,2019-08-08T08:29:07Z,0,"hi ken,¬† great video!I have a Question.use your code , Try mine.but results have overlapping values",True
@HelicopterHatHacker,2019-08-03T22:35:47Z,0,"I want to pull protected tweets from a friend, which means I need to login.  Will something like that work with twitterscrapper, or should I just go ahead and beg Twitter for an api key?",True
@benjaminchen4367,2019-07-25T18:46:10Z,2,"Hey PSA (maybe pin this or comment this yourself) but 1.2.0 as of right now doesn't really work. It's query_tweets is broken and you're going to have to specifically install 1.1.0 (pip install twitterscraper==1.1.0) in order to use it.    Also, for anyone wondering about performance issues and harvesting tons of tweets, make use of the poolsize parameter. Poolsize controls the number of parallel scrapers you can have up at a single time. At maximum you can have one scraper per day. So for example, if you are scraping a period of 30 days, you can use poolsize=30 to get 30 parallel scrapers running at a time. If you want to harvest over a big time frame, try to harvest smaller time periods and loop through dates manually (otherwise your CPU, RAM, and internet usage will shoot through the roof). That should give you the best mix of performance and speed.",True
@mattcherne6820,2019-07-23T17:49:11Z,0,"This is amazing, thank you for the knowledge! When you're loading into the variable explorer, what are you pressing? Also how are you running the script? I got it to work a few times but it seems to stop working randomly. Thanks again for your help!",True
@katarzynadylewska9730,2019-07-16T14:13:20Z,0,"hi! great video, thanks for that :)  I have a problem with reaching the limit - do you know why can it be an issue? I set limit as 1000 and I got only 180 tweets.... (setting bigger limit gives similar results).",True
@jalipo_3604,2019-07-14T16:19:24Z,0,how can i get location ?,True
@TheSoapzie,2019-07-09T09:14:34Z,0,"One more question, if I would like to write the tweets (from this method, with a track word) to a json file how do I access the tweet info?  For example, when I want to print the tweets:   <twitterscraper.tweet.Tweet object at 0x10b0d8240>  I get something like this, which I understand but I'm not sure how to retrieve the actual information from it. Looking at API documentation, the tweet object should have attributes like 'text' and 'id' and so on. But when I try tweets['text'] I get an error instead. DO you know how I could write it into a file? (also by not using pandas as there is an issue with that library on my end currently which I haven't been able to fix unfortunately)",True
@shingosan3744,2019-07-08T21:50:30Z,0,"Hi Ken,  thanks for this great video. I am currently looking into scraping data from different accounts (e.g. @Danone). How can I scrape all tweets from a specific account?",True
@TheSoapzie,2019-07-08T08:30:54Z,0,"hi! how would we sample real time tweets? Instead of searching through a track word, can we create a sample if all publicly available tweets at the time by say by language?",True
@karlamacias4460,2019-05-10T11:29:28Z,1,"Hi! I am using your code to retrieve tweets from specific Twitter accounts...   from twitterscraper import query_tweets import datetime as dt import pandas as pd  begin_date = dt.date(2018,12,1) end_date = dt.date(2019,4,19)  limit = 12600  user = 'AleFerruzcal'  tweets = query_tweets(begindate = begin_date, enddate = end_date, limit=limit, user=user)   BUT I GOT THIS ERROR:  TypeError: query_tweets() got an unexpected keyword argument 'user'   Could you tell me, how should I take in the 'user' filter into your code?",True
@sanakousar2487,2019-04-27T10:57:37Z,0,reply me plz,True
@sanakousar2487,2019-04-27T10:48:03Z,0,i do same like you did i write code same like your but there nothing in my variable explorer. 2 hours ago courser is rotating,True
@usman112130,2019-04-25T07:47:03Z,0,How can i extract data from particular page eg. realDonaldTrump of last 2 months .... with out filtering ?,True
@a1marky421,2019-04-19T02:37:49Z,1,I'm going give this a try soon.,True
@KenJee_ds,2019-04-19T00:00:54Z,6,"To be able to see the text clearly, you have to watch the video in HD. The code is below for convenience:   from twitterscraper import query_tweets import datetime as dt  import pandas as pd    begin_date = dt.date(2019,4,15) end_date = dt.date(2019,4,18)   limit = 1000 lang = 'english'   tweets = query_tweets('notre dame fire', begindate = begin_date, enddate = end_date, limit = limit, lang = lang) df = pd.DataFrame(t.__dict__ for t in tweets)",True
