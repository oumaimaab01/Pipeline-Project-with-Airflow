author,updated_at,like_count,text,public
@alexkubbinga842,2020-07-15T06:17:00Z,0,In 2020 can just do train_test_split() from sklearn with shuffle=True,True
@NellyK01,2019-10-03T07:57:01Z,0,"I had better accuracy using train_test_split from sklearn rather than np.random.permutation, only by about 1% though",True
@utkarsharaikar816,2017-08-01T17:15:38Z,3,"To randomly select training and testing samples, scikit-learn's model_selection.train_test_split() can be used.",True
@chaopan7205,2017-05-10T10:38:28Z,2,"How about using the following to avoid the function of randomizing and manual train, test split?   from sklearn.model_selection import train_test_split X, y = Build_Data_Set() X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2) clf = svm.SVC(kernel = ""linear"", C = 1.0) clf.fit(X_train, y_train) y_pred = clf.predict(X_test) accuracy = np.mean(y_pred == y_test)",True
@anatolyalekseev101,2017-04-20T04:50:26Z,2,"Btw Accuracy alone is not enough to measure the quality of a binary classifier. If 70% of your data is uptrend, then a classifier predicting always ""up"" will yield  70% accuracy easily, but will you call it good classifier?",True
@anatolyalekseev101,2017-04-20T04:44:50Z,0,Haha seems like with your first try on permutations you caught a relatively unlikely event with chance of happening= 1 in 10 thousands :-),True
@pellepolitiet,2017-03-30T20:54:17Z,0,"You should consider training on data up to a certain date and then see if you can predict after that date. You do not want to randomize. The reason for this is that you can then test if you have found something no one else has found - there surely are many algorithms running all the time and investors investing based on  the conclusions coming out of them. So to see if you are able to beat these, you need to take the time perspective  into account.",True
@Thiedent,2017-01-19T06:18:08Z,1,"I tried reshaping the data: X = np.array(data_df[FEATURES].values) X = X.reshape(35, -1)  and i get this error  Found array with 0 samples (shape=(0, 2991)) while a minimum of 1 is required",True
@Thiedent,2017-01-19T05:19:09Z,0,"Hi, i after running this script i have received the Deprecation error about reshaping the data, thus the script will not work. I went to the other tutorial you told another commenter to go to see the explanation but it didn't really explain anything in relation to how the reshaping relates to this code. It would help immensely if you could please provide the answer or a clearer explanation, thank you.",True
@MentiSnap,2016-09-23T15:46:23Z,0,"Hi, I don´t know if you have updated this videos but I'm having some warnings when runing the script, and my accuracy is been 0.0 .  C:\Users\Ruben Melo\Documents\Projects\machine-learning\lib\site-packages\sklearn\preprocessing\data.py:167: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.   warnings.warn(""Numerical issues were encountered "" 2991  \machine-learning\lib\site-packages\sklearn\utils\validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.   DeprecationWarning) ##the one above appears the 2991 times Accuracy:  0.0   what do I need to add or change to the actual code to correct this?",True
@ManinderSingh-uj7dt,2016-05-02T06:16:07Z,0,"Anyone else get the following warning? Did I mess something up in the data creation stage?  Warning (from warnings module):   File ""C:\Users\Andrew\WinPython-64bit-3.4.3.3\python-3.4.3.amd64\lib\site-packages\sklearn\preprocessing\data.py"", line 153     warnings.warn(""Numerical issues were encountered "" UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.",True
@Drewburt100,2015-07-10T12:39:58Z,2,"Anyone else get the following warning? Did I mess something up in the data creation stage?  Warning (from warnings module):   File ""C:\Users\Andrew\WinPython-64bit-3.4.3.3\python-3.4.3.amd64\lib\site-packages\sklearn\preprocessing\data.py"", line 153     warnings.warn(""Numerical issues were encountered "" UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.",True
@gcm4312,2015-01-14T03:53:40Z,2,"I believe the SVC algorithm should not render different accuracy results when running it more than once in the same test data set, with the same parameters. There is no randomized component in SVC like you have in Random Forest, for example.",True
@TugaNaZy,2015-01-11T00:40:48Z,0,I would like to see you making some kind of RPG game in python something like a browser rpg like bitefight or what ever you feel like doing :),True
