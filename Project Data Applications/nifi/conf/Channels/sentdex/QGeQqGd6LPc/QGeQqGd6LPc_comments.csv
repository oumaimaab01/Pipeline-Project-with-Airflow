author,updated_at,like_count,text,public
@Boringpenguin,2022-07-19T23:21:56Z,0,"To merge unemp_county and get_min_wage, I think the fatest method would be to use pd.merge. The key idea is to first convert get_min_wage back to the long format with ""Year"" and ""State"" as (multi-)indices, then we can directly use them as the merge key (by setting right_index=True in pd.merge).    Something like  pd.merge(     unemp_county,     get_min_wage.stack().to_frame(),     how='left',     left_on=[""Year"", ""State""],     right_index=True )  would work.",True
@extremenoiseterron,2022-07-19T13:40:41Z,0,"As of today, the ""result"" file is a json. I can't seem to find a way to convert it to a csv. Do you have any idea? did anyone have the same problem?",True
@mikederp9612,2021-11-01T23:06:44Z,0,Miss him my pres,True
@MatRIVERAGALVEZERNESTO,2021-10-10T22:28:00Z,3,"As always, your work is very appreciated, you are really awesome! You could use tuple() instead of list() in 12:19, it's way faster, like half of the time faster, but I don't actually know if there's a disadvantage on doing this.",True
@nelohenriq,2021-08-25T18:10:35Z,0,"Having an issue at the very beggining with the [""Low.2018""] index  There's no column named like that on the dataset, nothing found to rename ""None of [Index([""Low.2018""], dtype='object')] are in the [columns]""  Can you help?",True
@osman_gedik,2021-05-23T15:51:51Z,1,"Should I continue with: https://www.youtube.com/playlist?list=PLQVvvaa0QuDfKTOs3Keq_kaG2P55YRn5v  or,   https://www.youtube.com/playlist?list=PLQVvvaa0QuDd0flgGphKCej-9jp-QdzZ3",True
@vishnuvardhan2608,2021-04-10T12:47:39Z,0,"@9:15 did that work, everybody relax, i have to check.. :) :)",True
@Denverse,2021-04-10T03:48:32Z,0,My ï£¿ M1 MBP took 33.2 seconds!,True
@KevinTempelx,2020-12-26T05:46:54Z,0,Thank you!,True
@anthonygonsalvis121,2020-09-21T01:59:42Z,0,"@Sentdex, I've been a fan of your video series ever since I found them last year.  Thanks for sharing your knowledge about Python, ML, AI, etc.  At ~15:50 in this video, you start filtering your unemployment DF for February 2015.  It appears that, rather than being arbitrary, you inadvertently thought that Feb-2015 is the latest month and year of unemployment rate data.  If so, you're mistaken.  If you further explore the unemployment data, you'll find that unemployment rates are available all the way through December 2016.  Given the presidential election politics in the US (and in any country for that matter), the unemployment rates and resulting public sentiment become most relevant/influential just before such important elections.  Therefore, a better example would have explored the correlation/covariance between the county-wise unemployment rates and the voting data as of October/November 2016.  Just to be sure, I do understand that your intent was just to show how one could find some correlation between seemingly disparate data.  Of course, the actual conclusions/interpretations from such analysis are subject to personal opinions.  Admittedly, in the grand scheme of things, it's the data frames - not the specific time frames - that matter.  Cheers!",True
@anshshrivastava9107,2020-09-07T13:31:47Z,0,IMPORT,True
@segungtp,2020-07-14T15:25:45Z,0,Your tutorials are really fantastic!! and you have a wonderful mug collection,True
@MoniqNansy,2020-06-29T03:48:51Z,0,cool coffee cup... i am smiling watching this coz it is gonna save my day!,True
@extrememike,2020-06-13T21:22:22Z,1,9:09 UsageError: Can't use statement directly after '%%time'!,True
@Luke7389,2020-05-03T14:19:30Z,0,"Would have made sense to replace the Rate with the average rate, grouped by State, then keep the unique values for State and then do the mapping of the new column? to speed up things",True
@sery152,2020-05-01T13:35:32Z,1,"I get a: ""KeyError: 'County'"", in the for loop.  Someone knows how to fix it?",True
@daniellewagner7070,2020-05-01T07:41:33Z,1,"if anyone recently had trouble importing the second dataset, try encoding the file: df = pd.read_csv(""us-minimum-wage-by-state-from-1968-to-2017\Minimum Wage Data.csv"", encoding= 'unicode_escape')",True
@rohanaggarwal8718,2020-04-30T01:21:56Z,1,"You did a great job Harrison I am having some trouble following along though I have gone through your basics a few times and have learnt them from other places too, any tips?",True
@vipul8990,2020-03-26T17:33:20Z,0,FileNotFoundError: File b'datasets/state_abbv.csv' does not exist   I am getting this error. Please can anyone help me out.,True
@monatamsi1429,2020-03-13T04:50:53Z,4,I love your sense of humor. You really love what you are doing and really appreciate your efforts mate! Thanks,True
@M45t3rJ4ck,2020-02-28T16:29:59Z,4,For anyone else that is wondering about the %%time method @ 8:04 here is the link to python docs: https://docs.python.org/3.7/library/timeit.html?highlight=time#module-timeit,True
@hugoalejandrovelezlopez3728,2020-02-06T21:12:18Z,0,"https://youtu.be/QGeQqGd6LPc?t=1641 in this part, i hava a problem, when a run this part of the code, pres16 turn into 0, and lost pres16. How can i fix that?",True
@shadid_io,2020-01-28T04:31:39Z,0,what:  inplace = true stands for ?,True
@gracemalcom7358,2019-12-19T20:41:02Z,1,the donut cup has always been one of my favorites,True
@oliviero1756,2019-11-19T22:32:47Z,0,IMPORT!!!,True
@jaykabra2587,2019-11-03T14:12:18Z,0,At what point of time is that state_abbv df created and saved. I can't find it anywhere. Also from where is it saved? Niether i am able to create such df using the given data nor i am able to find it anywhere.,True
@ali51717,2019-08-29T12:29:23Z,0,"at 20:30 you don't get screwed if you forget the double bracket [[]] even if you get a series, you will be okay and I don't know why...",True
@elghark,2019-08-28T12:49:03Z,0,"9:55 ""unemp_county['min_wage']= list(map(..........)     HOW THE HELL DID U DO SO FAST?????? I've have to wait minutes!!!!",True
@shyjoshi7158,2019-07-30T02:32:51Z,0,"The reason Mississippi has a bunch of NaNs is because the min_wage data does not have Mississippi as an index, they left that state out for some reason. min_wage.columns.unique() you will find Mississippi does not exist.",True
@dragonfilms9141,2019-07-09T04:26:26Z,0,"At 28:52, can anyone explain why county_2015.merge is used instead of pd.merge? Also what does on = [""County"", ""State""] mean?",True
@wiktor_kubis,2019-06-24T23:56:24Z,4,"If you have merge problem use 'right_index = True', 'left_index = True' instead of 'on'. And since pandas data type 'Object' indicates mixed types, you need to convert pres16['County'] to string. One way of doing this: ""pres16['County'] = pres16['County'].astype(str)"" before you change ""State"" and ""County"" to indices.",True
@adempc,2019-06-19T01:47:24Z,2,"For some reason I kept getting:   KeyError: 'County'   from:   for df in [county_2015, pres16]:     df.set_index([""County"", ""State""], inplace = True)   Couldn't figure out why... but a great video, as usual.",True
@adempc,2019-06-18T18:58:12Z,2,Muad'Dib no longer needs the weirding module I see... Pandas works for him without import!   Soon he will call the great worm and lead us to the spice.,True
@Jakob6174,2019-05-31T18:48:12Z,1,"Fantastic topic, I was actually interested to see the results as well as to learn about pandas",True
@shreyanshjainvlogs8397,2019-05-28T18:33:18Z,0,"Can anybody please help me out here, the merge is not woring in my case and giving the error : keyerror : 'County' and I am not able to get any answers on stackoverflow as well..   while running this in jupyter notebook: ------------------------------------------ all_together = county_2015.merge(pres16results,on=['County','State']) all_together.dropna(inplace=True) all_together.head()   ------------------ Error is below    keyError                                  Traceback (most recent call last) E:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance)    2524             try: -> 2525                 return self._engine.get_loc(key)    2526             except KeyError:  pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc()  pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc()  pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item()  pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item()  KeyError: 'County'  During handling of the above exception, another exception occurred:  KeyError                                  Traceback (most recent call last) <ipython-input-125-b3421fc9f954> in <module>() ----> 1 all_together = county_2015.merge(pres16results,on=['County','State'])       2 all_together.dropna(inplace=True)       3 all_together.head()  E:\Anaconda\lib\site-packages\pandas\core\frame.py in merge(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)    5368                      right_on=right_on, left_index=left_index,    5369                      right_index=right_index, sort=sort, suffixes=suffixes, -> 5370                      copy=copy, indicator=indicator, validate=validate)    5371     5372     def round(self, decimals=0, *args, **kwargs):  E:\Anaconda\lib\site-packages\pandas\core\reshape\merge.py in merge(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)      55                          right_index=right_index, sort=sort, suffixes=suffixes,      56                          copy=copy, indicator=indicator, ---> 57                          validate=validate)      58     return op.get_result()      59   E:\Anaconda\lib\site-packages\pandas\core\reshape\merge.py in __init__(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)     563         (self.left_join_keys,     564          self.right_join_keys, --> 565          self.join_names) = self._get_merge_keys()     566      567         # validate the merge keys dtypes. We may need to coerce  E:\Anaconda\lib\site-packages\pandas\core\reshape\merge.py in _get_merge_keys(self)     822                     if not is_rkey(rk):     823                         if rk is not None: --> 824                             right_keys.append(right[rk]._values)     825                         else:     826                             # work-around for merge_asof(right_index=True)  E:\Anaconda\lib\site-packages\pandas\core\frame.py in __getitem__(self, key)    2137             return self._getitem_multilevel(key)    2138         else: -> 2139             return self._getitem_column(key)    2140     2141     def _getitem_column(self, key):  E:\Anaconda\lib\site-packages\pandas\core\frame.py in _getitem_column(self, key)    2144         # get column    2145         if self.columns.is_unique: -> 2146             return self._get_item_cache(key)    2147     2148         # duplicate columns & possible reduce dimensionality  E:\Anaconda\lib\site-packages\pandas\core\generic.py in _get_item_cache(self, item)    1840         res = cache.get(item)    1841         if res is None: -> 1842             values = self._data.get(item)    1843             res = self._box_item_values(item, values)    1844             cache[item] = res  E:\Anaconda\lib\site-packages\pandas\core\internals.py in get(self, item, fastpath)    3841     3842             if not isna(item): -> 3843                 loc = self.items.get_loc(item)    3844             else:    3845                 indexer = np.arange(len(self.items))[isna(self.items)]  E:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance)    2525                 return self._engine.get_loc(key)    2526             except KeyError: -> 2527                 return self._engine.get_loc(self._maybe_cast_indexer(key))    2528     2529         indexer = self.get_indexer([key], method=method, tolerance=tolerance)  pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc()  pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc()  pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item()  pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item()  KeyError: 'County'",True
@maryamehsani7867,2019-03-26T01:54:55Z,0,"@sentdex Instead of:  act_min_wage=act_min_wage.replace(0,np.NaN).dropna(axis=1) Try: act_min_wage=act_min_wage.loc[:,(act_min_wage.mean()!=0)] Then you'll have data for get_min_wage(2015,'Texas'), get_min_wage(2015,'Flordia')!...  and bunch of other states you zeroed for the year 2015!",True
@ujjwalkumar9590,2019-03-24T19:20:44Z,0,"really sir your video is great, it help me a lot in my studies",True
@yueqian4700,2019-03-12T02:24:32Z,0,"This is certainly very helpful! Can you make a video on efficient big dataset process, like 100M plus?",True
@yousufazad6914,2019-03-08T17:47:33Z,0,eh! another mug!,True
@zperk13,2019-03-07T01:04:57Z,13,12:14 aha! my computer beat yours by 44 seconds! I'm lonely...,True
@jayanthmanklu8642,2019-03-06T14:46:28Z,0,"I created a kaggle kernel for parts 3, 4 and 5 of this series, do fork it if interested :) https://www.kaggle.com/lookageek/following-sentdex-s-eda-video-series-2",True
@Jabranalibabry,2019-03-06T09:12:05Z,0,"Dude, ur my digital master! Much learning, i do.",True
@user-no2mv1zv9r,2019-03-05T07:03:23Z,0,"at 28:15, when I run the code, it outputs ""KeyError: 'cand'""",True
@user-no2mv1zv9r,2019-03-05T06:12:24Z,0,I'm convinced,True
@user-no2mv1zv9r,2019-03-05T06:11:52Z,4,"well, after the numpy incident, I'm starting to believe that sentdex is a god from above, I mean, he gives us riches(information about programming), he helps us with our problems, and, he seems to have some mythical power over technology.",True
@user-no2mv1zv9r,2019-03-05T06:06:55Z,1,"woah, in the beginning, he did not import numpy and it still worked. hehhh????",True
@alinabeliakova2220,2019-03-04T11:15:54Z,10,"Hi Harrison, thank you so much for your tutorials. I noticed that there is someone from Istanbul plagiarizing your content. I don't know if you already know that and if it bothers you but they LITERALLY copied your course ML tutorial with Python, I think you can find them easily though google search if you wish to claim your rights. All the best, gonna proceed watching your videos now :)",True
@rchuso,2019-03-03T19:42:25Z,0,Will you also be showing how to train ConvLSTM2D models? I have such a need and haven't come across good instructions yet.,True
@mihaisabadac9631,2019-03-03T18:24:49Z,7,"Great intro to pandas, thanks a lot! Now, I have a little problem, if anyone have some advice what to look after: At the merge step I get an error that at some point says: KeyError: 'County'. I looked in the structure of both dataframes and they have this column...and all until this point is working well. I googled and got some discussions but not something to fix it. Thanks",True
@Tteigman,2019-03-03T15:37:56Z,0,"You can use the update method to map multiple inputs, just set them as the indices. See below snippet:  # Unpivot the minimum wage data that was generated and set the mapping indices on both data frames min_wage_melted = pd.melt(act_min_wage.reset_index(), id_vars='Year', var_name='State').set_index(['Year', 'State']) unemp_county_double_index = unemp_county.set_index(['Year', 'State']) # Add the column to update(must match in both data frames) unemp_county_double_index['value'] = pd.np.NaN # Update method unemp_county_double_index.update(min_wage_melted) new_unemp_county = unemp_county_double_index.reset_index() # Same results in the value column. new_unemp_county.tail()  I also wanted to add that the map method can take a Series for the mapping using the index as the keys, no need to convert to a dictionary.  Thanks so much for your tutorials! I got my start with python using your previous pandas tutorial.",True
@aidenstill7179,2019-03-03T15:01:14Z,0,How to create something like pytube???,True
@nooneknown,2019-03-03T14:00:41Z,0,do you know if it is possible to just to convolution and use another classifier on the convoluted images?,True
@Lu_Ca,2019-03-03T11:25:57Z,1,just want to say is so much better to follow u with JupiterNotebook! thanks for listening to us and for your lessons,True
@kingfsx,2019-03-03T00:56:04Z,2,Thanks for your hard work! Can you also do python together with Selenium WebDriver? :),True
@Artheno85,2019-03-02T15:01:52Z,0,"Maybe the numpy ""anomaly"" has something to do how Jupyter deals with states in the kernel. Did you execute ""import numpy as np"" in the previous notebook on the same kernel? There is really cool talk on this by Joel Grus (https://youtu.be/7jiPeIFXb6U?t=1078)",True
@MarsGamer7,2019-03-02T04:43:45Z,2,Pretty cool cup!,True
@justinsiegel2357,2019-03-02T01:29:54Z,0,It's awesome that you captured that numpy anomaly on camera. Any Idea what happened there?,True
@SeuCanal1000,2019-03-01T23:50:07Z,2,"Hey man, do a python plays with the euro truck autopilots on github",True
@sanjogh777,2019-03-01T22:13:29Z,0,"Can you please include videos about A-B testing, how to do it in Python?",True
@froop0,2019-03-01T21:29:35Z,0,"df['func_value'] = zip(*df[['col1','col2'']].apply(lambda x: func(*x), axis=1))",True
@shafiqislam5080,2019-03-01T18:53:22Z,0,Clear and helpful as like as before...  :),True
@MachineLearningwithPhil,2019-03-01T16:02:33Z,26,"Once again Sentdex delivers the goods. Thanks for this series, Pandas is a bit of a blind spot for me.",True
@samha1513,2019-03-01T15:44:51Z,0,14:00 imagine Donald Trump tweet about this lol,True
@stayinawesum,2019-03-01T15:29:42Z,0,Do u know how can i create a human voice generator (not text to speech program) or atleast is there a free tool out there? I mean there has to be right people compose music from there pc and its a sound y there is not voice generator yet,True
@sarthakthakur9545,2019-03-01T15:20:45Z,104,We don't deserve @sentdex. He's the hero we didn't ask for but needed desparately. Thanks for providing these tutorials for free instead of selling on some other MOOC platform. I'm always gonna be in your debt,True
@OrtegaDrives,2019-03-01T15:19:05Z,0,"Thanks for this. Coming from coldfusion, I need this.",True
@bogdanbibina9844,2019-03-01T15:18:59Z,4,"Your tutorial are great, but why you not try to make a recomandation engine tutorial?",True
