author,updated_at,like_count,text,public
@regal7548,2024-04-19T13:36:12Z,0,I dont know what to do with multiple datasets . For example an airbnb zip have 8 datasets. What am i supposed to do with ? Idk,True
@user-xf7oh2yq8q,2023-08-16T11:05:25Z,0,"At 8:25  Why not just use the code:  act_min_wage = pd.DataFrame()  for name, group in df.groupby(""State""):         act_min_wage[name] = group.set_index(""Year"")[[""Low.2018""]]   instead of writing such a lengthy code?",True
@sandeepreddybojja2045,2023-04-20T20:44:14Z,0,"Hello, I tried reading the minimum wage CSV file. I added the encoding to latin but still has error.",True
@rohitshankar1627,2023-03-01T18:23:35Z,0,anyone plz guide me for corr use,True
@sunnyjain4801,2021-10-06T12:24:02Z,0,Still 10:49 was best part of the entire tutorial series 😂,True
@nadyamoscow2461,2021-10-01T00:31:44Z,0,Many thanks for another amazing video.,True
@osman_gedik,2021-05-22T19:39:54Z,0,"I didnt really understand, why you took Low.2018 for the dataframe? Could you use something else? Like Low.Value or High.2018?",True
@neuron8186,2021-04-30T15:12:32Z,0,sweet home alabama,True
@steffens.1734,2021-04-22T08:58:09Z,0,KeyError: 'Low.2018' !?!??!?!?,True
@vishnuvardhan2608,2021-04-10T05:06:03Z,0,11.04 where was it.. lol,True
@techrisemedia,2021-04-03T19:47:51Z,3,"act_min_wage = pd.DataFrame()  for name, group in df.groupby(""State""):     if act_min_wage.empty:         act_min_wage = group.set_index(""Year"")[[""Department.Of.Labor.Cleaned.Low.Value.2020.Dollars""]].rename(columns={""Department.Of.Labor.Cleaned.Low.Value.2020.Dollars"": name})     else:         act_min_wage = act_min_wage.join(group.set_index(""Year"")[[""Department.Of.Labor.Cleaned.Low.Value.2020.Dollars""]].rename(columns={""Department.Of.Labor.Cleaned.Low.Value.2020.Dollars"": name}))  act_min_wage.head()",True
@programacao7879,2021-03-05T15:34:38Z,0,"On the for loop at 8:00 I get this error:  columns overlap but no suffix specified: Index(['Department.Of.Labor.Cleaned.Low.Value.2020.Dollars'], dtype='object') what should I do?",True
@tunaozates,2021-02-06T13:03:10Z,62,"For those who are watching in 2021, use 'Department.Of.Labor.Cleaned.Low.Value.2020.Dollars' instead of 'Low.2018'",True
@DewanggaPrabowo,2021-01-30T03:57:40Z,1,"That Low.2018 give me an error,  ""None of [Index(['Low.2018'], dtype='object')] are in the [columns]""",True
@giorgosmoustakidhs,2021-01-03T22:37:48Z,1,"(8:50) Today the columns have changed so....I think this it may works:  pd.DataFrame.pivot_table(df, values=""Department.Of.Labor.Cleaned.Low.Value.2020.Dollars"", index=""Year"", columns='State').head()",True
@azanshaikh7825,2020-10-18T04:32:32Z,0,Does groupby('State')  return the column name and the values in that column?  If yes then that's the only way I can make sense of the for loop that is used  5:48,True
@alexanderhill-cp8be,2020-09-07T13:44:12Z,0,I was wearing headphones and died at 10:49,True
@anshshrivastava9107,2020-09-05T14:41:31Z,0,"This may sound stupid, but what are we actually doing when we do that co-realtion thing?",True
@yschoo3239,2020-07-14T16:01:03Z,0,"min_wage_corr = act_min_wage.replace(0, np.NaN).dropna(axis=1).corr().head()   for problem in issue_df['State'].unique():     if problem in min_wage_corr.columns:         print(""we are missing something here..."")  anyone can explain what does this means again? why are we doing the for loop for? just to check if there is a problem in issue_df?",True
@Fecbar,2020-07-10T16:48:45Z,1,"At 19:35, shoulden't it be == instead of !=  ?. If data is missing why should it be equal to != ?",True
@jtafernando,2020-06-25T22:25:12Z,0,"At 8:24, is it possible to return the highest number? And how would you do it?",True
@driyagon,2020-06-19T12:46:19Z,0,"learned something new in this video, nice work!",True
@extrememike,2020-05-26T22:20:15Z,1,10:49 RAM exploding,True
@leecreighton,2020-05-11T01:11:35Z,0,"This is supposed to be a group by tutorial. It’s so frantic and buzzy that Viewers won’t be able to follow your quick turns and trains of thought. Think of what you are teaching and show examples of it, rather than chasing every thought that comes into your mind. The whole digression into the NAs is out of place.",True
@sparkycloud1514,2020-04-25T17:02:00Z,0,Thank god we didn't lose the power else we would have lost this beautiful tutorial,True
@rohanaggarwal8718,2020-04-25T00:48:46Z,2,9:08 can someone explain the code and what is going on because I am kind of just following along with no explanation. Thanks in advance!,True
@Dreso0,2020-04-21T11:25:23Z,1,"maybe it is simpler to use tail() to check if 0 data states have minimum wage in the present... great content, keep it up! :)",True
@callum7macca,2020-03-28T03:48:17Z,0,"I rate your stuff brother, I like the vibe",True
@vikasmanav3715,2020-03-15T13:12:39Z,0,"I had already set the index to 'Year' while converting the csv file. So, when I tried group[[""Low.2018""]].rename(columns={""Low.2018"":name}) instead of group.set_index(""Year"")[[""Low.2018""]].rename(columns={""Low.2018"":name}), then I get NaN in whole table. Can you explain , why?",True
@geraldgeraffe2209,2020-02-18T20:45:06Z,0,I didn't know Frankenstein had a monster mug,True
@fwladd,2020-02-18T16:57:47Z,0,"Not critical but using                 ""encoding= 'unicode_escape'""    avoids guessing.",True
@barulli87,2020-01-27T16:35:45Z,0,"all these for loops could have gotten a better explanation, otherwise, a great video",True
@yanyue0,2020-01-04T03:34:21Z,1,"issue_df = df[df['Low.2018']=0] grouped_issues = issue_df.groupby(""State"") then of course,  grouped_issues.get_group(""Alabama"")[""Low.2018""].sum() == 0 always True.",True
@hongmeilc,2019-12-16T05:40:42Z,0,"Like how you do groupby and produce a new dataframe: act_min_wage.  So I borrowed it.  Unfortunately, my case got a KeyError: ""None of ['Year'] are in the columns"".  What's wrong?",True
@yanding7691,2019-11-06T18:01:55Z,1,"Regarding the last point in this video, we are actually missing the information of ten states. You should sum the ['Low.2018'] in the original df instead of the issue_df.",True
@rodolfobrandao5364,2019-10-14T16:30:32Z,0,"Thank you so much for all the videos and tutorials, they are really helpful!",True
@tayoaderiye695,2019-10-12T19:19:31Z,0,i'm trying to use get_group( ) for multiple values,True
@JpNaN,2019-09-12T06:49:19Z,0,finally you updated  man.,True
@ali51717,2019-08-24T15:02:08Z,0,"I am not sure, if the data has been updated or so, since it is half-year later, but I checked it using the sum method and only 5 of them has 0.0 sum in the low.2018,  and Surely Texas has a minimum wage, it's some 277 or so.",True
@ashishmishra672,2019-07-26T07:13:48Z,0,This guy has some really cool coffee mugs xD,True
@gamestv4875,2019-07-19T23:48:40Z,14,"I love Pandas , they are cute and cuddly. Python Pandas on the other hand are dangerous and intimidating.",True
@solques36,2019-07-08T12:52:34Z,0,"Im getting an error reading in the csv after following your steps, it says [Errno 2] File b'datasets/Minimum Wage Data.csv' does not exist: b'datasets/Minimum Wage Data.csv'",True
@solques36,2019-07-08T12:52:29Z,0,"Im getting an error reading in the csv after following your steps, it says [Errno 2] File b'datasets/Minimum Wage Data.csv' does not exist: b'datasets/Minimum Wage Data.csv'",True
@yashchaudhari7558,2019-07-06T17:34:54Z,0,"Hello, I am new in Python Programming. At 6:20, What is the logic of using the 'rename' method? Can someone please explain it?",True
@C05Mik,2019-07-04T07:39:11Z,0,"Amazing teaching skills, thank you !  However, I'm struggling hard to understand how ""for"" loops should be used and what is the purpose of adding a second variable, such as done when writing ""for state, data in df...""  What is the difference as compared to only writing ""for state in df..."" ? I can't find the answer on the web, which means I'm probably asking a bad question. Anyway, if seomeone can help me with that, that'd be greatly appreciated.",True
@edwardwilliamsams6589,2019-06-25T01:42:41Z,0,"Hello Harrison, I am watching this video in hopes of being able to run a Panel Regression (Fama-Macbeth) with group methods. I have really run into a wall. .......If someone can please point me to the proper template for implementing this method I would really appreciate it. I know that the Linear Models library has a function Fama-Macbeth, but for some reason I cant get it to work. Thanks again for all your awesome content. Your Loyal Subscriber......",True
@michaelnyang,2019-06-21T00:10:17Z,0,"For the super long lines that goes off the screen, you may want to go to settings, then advanced setting editor and in the Notebook change code cell config to turn on line wrap.",True
@filipomazic8823,2019-06-20T05:50:42Z,1,My man sentdex getting hit bylightning and STILL finishes the tutorial,True
@shighafabdallah2318,2019-06-17T10:45:23Z,0,how many cups you have ???,True
@lisabennett3471,2019-06-12T17:28:06Z,1,"Probably the states with the missing data is because at that point they had no minimum wage.  Maybe it would be better to set it to 0. BTW, I love you video series.",True
@soundbeans,2019-06-09T19:13:30Z,1,"When you summed the grouped issues and found that minimum wage data was zero, that's because you filtered it originally to contain only zeros.",True
@Mistercapi0,2019-05-28T14:37:40Z,3,"If you don't want to drop the columns that can have some data you can still use .dropna, just use attributes (how=""all"", axis=1)  Firstly you replace all zeros with np.NaN:   act_min_wage = act_min_wage.replace(0.0, np.NaN)   Then just use .dropna(how=""all"", axis=1), how=""all"" means that only the columns that have all the values as NaNs will get romoved:   act_min_wage = act_min_wage.dropna(axis=1, how=""all"")   To make sure it worked you should have dropped all columns with names given by this for loop:   for state in df[""State""].unique():     if act_min_wage[f""{state}""].sum() == 0:         print(f""{state}"")   edit: typos",True
@MrDeking10,2019-05-28T07:56:59Z,0,How would pd.read_csv() change for a .txt or tsv file? Thanks,True
@ijajahamednabil683,2019-05-27T20:22:44Z,0,"so in the last stage when you want to weed out the states with no data at all, how do the added codes here work?  I think it works, but wanted to be sure :)   no_data_states = [] for state in act_min_wage.columns:     if act_min_wage[state].sum() ==0:         no_data_states.append(state)          act_min_wage.drop(no_data_states, axis =1)",True
@LabGecko,2019-05-21T17:28:22Z,0,"It seems that all the commentary on NaN values could have been solved by looking at the key index on https://www.dol.gov/whd/state/stateMinWageHis.htm. ... - not applicable N.A. - not available The question remains what to do with these values from a data science mindset. I'm sure this question varies for each dataset.",True
@shishirsingh1885,2019-05-16T07:40:06Z,0,what does Low.2018 does i think i missed it,True
@kennyPAGC,2019-05-07T17:30:02Z,0,@8:10 shivers in DRY,True
@takwaiwong4065,2019-04-21T05:28:01Z,0,"I do not get the for loop stuff, why is that loop printed column names and data frame of one state and then another? Can anyone explain a little bit more about that? Thanks!",True
@KirillBezzubkine,2019-04-17T14:47:34Z,0,unfortunately this tut looks like a crazy runthrough with minimum logic and mech explanation,True
@ronniecheng8892,2019-04-07T15:02:03Z,0,What is the difference between groupby and pivot table function?,True
@Andrew6James,2019-04-02T22:04:28Z,1,"Can anyone explain the following line of code and its purpose please:   'If act_min_wage.empty:              act_min_wage = group.set_index(""year)[[""low.2018]]....     Is it just to account for groups that have no data and to still add them to our new dataframe?",True
@afbdreds,2019-03-31T19:18:08Z,2,"Could someone explain to me 8:50 what's happening in ""for name, group in df.groupby(""State"")""? It's first time I saw a 2 parameter loop, so I didn't really get how it's doing what it's doing thanks",True
@aravindsivalingam3091,2019-03-25T12:26:00Z,28,"issue_df = df[df['Low.2018'] == 0] at 12:27 misses the years for the states having non-zero Low.2018 values. Texas for example, has non-zero values from 1972 onward and issue_df doesn't have that information. And since you use .sum() of the column of the dataframes derived using issue_df at 19:05 to check for non-zero values, it doesn't work.   I think this solves the issue:   issue_df = df[df['Low.2018'] == 0]    #df is the original dataframe from the csv file grouped_issues = df.groupby('State')   for state, data in grouped_issues:     if (data['Low.2018'].sum() != 0.0 and state in issue_df['State'].unique()):         print(state + ' We missed something!')",True
@DrJohnnyStalker,2019-03-21T05:23:04Z,5,"The pandas way of doing the pivot table is calling df.pivot(index=""date"", columns=""state"", value=""Low.2018""). But to get a better understanding the for loop is a nice training.",True
@maryamehsani7867,2019-03-19T03:00:42Z,0,"issue_df=df[df['Low.2018']==0] issue_df['State].unique() This returns All the states with no data in Low.2018 column for SOME years! and later you replace them with 0 and dropped those states. However, we still have  some data for some years from some of these states. For instance, we have some data for Florida from 2006-2017. Maybe we should not dropped all of the state and only dropped those with no data 1968-2017; like Alabama.",True
@anshulsharma9424,2019-03-14T18:14:48Z,2,one day you have to change your house to keep those mugs,True
@anshulsharma9424,2019-03-14T18:12:15Z,3,"what is your source of learning these things, do you read the documentation.   keep up the good work  👍",True
@736939,2019-03-13T18:26:52Z,0,I can't open this dataset it's like blocked with lock after I extract the csv file  :(,True
@beansgoya,2019-03-10T19:43:01Z,1,"i'm trying to do the trick from the last video to pivot the state names into the columns but i can't seem to figure out why my pivoted_df is only returning alabama in the DataFrame. Anyone have ideas?   piovted_df = pd.DataFrame() for state in df['State'].unique():          state_df = df.copy()[df['State']==state]     state_df.set_index('Year', inplace=True)     state_df.sort_index(inplace=True)     state_df[f'{state}_CPI.Average'] = state_df['CPI.Average']          if piovted_df.empty:         piovted_df = state_df[[f'{state}_CPI.Average']]     else:         pivoted_df = piovted_df.join(state_df[f'{state}_CPI.Average'])",True
@artcurious807,2019-03-07T02:36:43Z,0,"Python error returns are not pythonic whatsoever, it’s a strange diversion from a code that is supposed to be more intuitive, but the error handling is atrociously non intuitive.   Real python error handling would simply have an arrow pointing to the offending line of code with a very short explanation and maybe a key code error number for reference. Instead Python slams you with a thousand lines of pink byte rage that is the equivalent of cold water being dumped on you.",True
@BorisDessimond,2019-03-06T17:45:55Z,0,"I was like ""Whatever I know already how to use pandas I'll watch it 2x speed we never know."" But at 9:00 it blew my mind ahaha I never thought it could be so efficient. Damn ! Thanks.  Will watch the whole serie, so much to learn from you !",True
@chases4951,2019-03-05T00:54:36Z,0,"Out of curiosity, why do you use paperspace for these tutorials?",True
@ernestassimutis6239,2019-03-03T10:39:58Z,0,what was that explosion? lol,True
@samskyverareddy3135,2019-03-03T07:36:15Z,0,"Keep up the good work sentdex, we learn a lot from you.",True
@orirosenthal19,2019-03-02T20:58:16Z,52,"instead of the for loop  you can do: pd.pivot_table(df, values=""Low.2018"", index=""Year"", columns='State')",True
@SeamusHarper1234,2019-03-01T21:08:52Z,54,"When you write to csv, include a index=False.. That way you dont have to deal with the ""Unnamed"" column..",True
@mokus603,2019-02-28T10:31:14Z,2,I’ve been trying to introduce my colleagues to data analysis in pandas. These videos with clear instructions and easy to understand overview can make people understand the process and properties of good data analysis. Thank you.,True
@tomdarank1272,2019-02-27T20:15:14Z,0,"that ""breh"" at 2:54 was hilarious",True
@johnscott3942,2019-02-27T18:09:08Z,1,"Best video cheat sheet to Python and now Pandas as well. Bare bones cutting straight to the ""It kinda works like this"" by example. Coming in so handy right now. Thanks.",True
@ahmedhany5037,2019-02-27T18:08:26Z,0,"A bit unrelated to the video but I just have a small question: When we are talking about a regression problem in neural networks like predicting house prices, how can I have in the same model continuous values like area of the house and also have binary or categorical values like whether the house has a garden or not which can be represented as a 0 or 1 and also categorical inputs like for example for a heart disease data set we have 3 types of diabetes  we could type the 3 types as 1 , 2 , or 3 . How can I put all of those binary , categorical , continuous values in one neural network model ? By the way, this is the best pandas tutorial on the internet I love it !",True
@marcosdanieltorres7253,2019-02-27T17:02:45Z,0,"Hi everyone would you recommend the deeplearning book by Ian Goodfellow for a complete begginer? I feel lost when thinking about where I should start with these complex topics, there are so many tutorials that I feel overwhelmed",True
@milanlora,2019-02-27T16:16:59Z,0,Quick question. In the for loop we do an if statement asking whether act_min_wage is empty. If it is then we just use the df. However it isn't we join act_min_wage with df. Wouldn't this repeat rows that were already in act_min_wage.   PS. Keep up the great work!,True
@markobe08,2019-02-27T16:02:24Z,5,Another day another like! I showed this to mortals in my office. They do not understand powa (but few of us do). We'll be army for better world. You teach we reach,True
@jimmiemunyi,2019-02-27T15:41:46Z,1,award of the greatest mugs goooess tooo.....,True
@SebastianMantey,2019-02-27T14:51:13Z,3,"10:49 That’s what my head does, every time I think about what the best way is to get a data frame into the desired format.",True
@ranjeetjha1945,2019-02-27T14:31:03Z,36,The number of features pandas and numpy provides are incredible,True
@aditisharma8398,2019-02-27T14:28:52Z,0,Hii Thanks for so nice tutorials😊,True
@sufiyanpatel8106,2019-02-27T14:28:07Z,0,Awesome 👍,True
@abdulwahidgul,2019-02-27T14:27:59Z,1,Literally 3rd lol,True
