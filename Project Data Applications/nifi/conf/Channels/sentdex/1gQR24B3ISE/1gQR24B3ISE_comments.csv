author,updated_at,like_count,text,public
@4ornii4elovek,2024-01-30T12:47:48Z,0,"Hi Everyone, Is there someone who knows how to handle: RuntimeError: The size of tensor a (2) must match the size of tensor b (50) at non-singleton dimension 2",True
@UNanimiert,2023-08-10T00:36:52Z,0,"i have trouble with this error ""Found dtype Double but expected Float"" when i do the backpropagation",True
@zacharypump5910,2023-06-29T23:05:46Z,0,Random would be 10% (not 50%) when predicting across 10 classes :),True
@brennab8177,2023-02-09T17:58:25Z,0,"Loved the ""No one knows what they're doing neural networks"" spiel!  Thank you for confirming my suspicions!!",True
@hawkiyc,2022-08-28T10:38:20Z,0,"For the classifier, the loss function shall be crossentropy.",True
@nazaninmohammadrezaii2529,2022-07-30T08:14:32Z,5,"Just wanted to say It is PERFECT when you don't cut the parts which you bump into an error, because we can see the way you think through it. It helps a loootttt...",True
@tianmaru3573,2022-07-04T10:01:31Z,8,"Hi sentdex, I know I am three years late, but I want to add that there actually is a quick way of computing the output size of the convolutional layers, but it depends on multiple factors. Here, it boils down to: 128 * [50 - 4 / 2 - 4 / 2 - 4 / 2]^2 = 128 * 2 * 2, where 128 is the number of output channels, 50 is the input size, / denotes floor division and the operations in the brackets are written in order from left to right for readability. I will now try to explain, how I came up with this formula: The first thing we need to regard is the input size. Here, we have a 50x50 image. This is our starting point, the size of the resulting feature maps will (usually) never exceed the input size. The next important parameter is the kernel size of the convolutional layers. For this tutorial, you used a 5 by 5 kernel. (To understand how it will affect the input layer, you must regard other parameters like kernel stride etc., but since you used the default values, I won't explain them here) The kernel will convolute a 5x5 grid into a new value, then move to the next position, until the whole input image is processed into a so-called ""feature map"". So, how big is this feature map? Because the kernel operates on a 5x5 grid, it will start with its center aligned on pixel index index (2, 2) (index ranging from 0 to 49) and end on pixel index (47, 47). Therefore, there is a 2 pixel margin on each side, which is ""lost"" in the feature map. The resulting feature map is 2 pixels smaller than the input image on each side, resulting in a size of 46*46. I don't know if my explanation is good enough, for anyone wondering, try to find some visualizations of convolutional neural networks, it really helps to understand how they operate. The next step is maxpooling. Here, we use a 2x2 kernel. Effectively, this means that the size of our feature maps will be halved, leaving us with a 23*23 feature map. However, this was only the first convolutional layer! So, let's repeat this calculation twice: Second Layer: (23, 23) - (4, 4) = (19, 19), (19, 19) / 2= (9, 9) Third Layer: (9, 9) - (4, 4) = (5, 5), (5, 5) / 2 = (2, 2) Finally, we have to multiply the size of the feature map with the number of output channels of the final convolutional layer, which is 128.",True
@elyakimlev,2022-05-27T16:54:25Z,1,"Here is how they got to a flattened size of 4x4x50: Input image size is 28x28x1 -> conv2d (5x5 kernel, 20 features) -> 24x24x20 -> max pooling (2x2) -> 12x12x20 -> conv2d (5x5 kernel, 50 features) -> 8x8x50 -> max pooling (2x2) -> 4x4x50.  Here is how you got to 2x2x128: Input image size is 50x50x1 -> conv2d (5x5 kernel, 32 features) -> 46x46x32 -> max pooling (2x2) -> 23x23x32 -> conv2d (5x5 kernel, 64 features) -> 19x19x64 -> max pooling (2x2) -> 9x9x64 -> conv2d (5x5 kernel, 128 features) -> 5x5x128 -> max pooling (2x2) -> 2x2x128.  You get those numbers when doing calculations on paper first :)  * this is considering you use a padding of 0 (no padding) and a stride of 1.",True
@rbaleksandar,2022-03-28T11:36:24Z,1,PyTorch (2022) now offers a flatten function from what I recall.,True
@Woofka74,2022-02-09T11:50:53Z,2,"How to calculate input size of first fully-connected layer. To do it you have to understand what happening with matrix size during each operation. Layer have have kernel 5x5 and padding = 0. That means that layer will cut 2 pixels from each side reducing matrix size by 4 in each dimension. Also max pool 2x2 will reduce matrix size in half. In our case we have: Input image is 50x50 Conv2d(1, 32, (5, 5))  |  50x50x1 -> 46x46x32 max_pool2d(x, (2, 2))  |  46x46x32 -> 23x23x32 Conv2d(32, 64, (5, 5))  |  23x23x32 -> 19x19x64 max_pool2d(x, (2, 2))  |  19x19x64 -> 9x9x64 Conv2d(64, 128, (5, 5))  |  9x9x64 -> 5x5x128 max_pool2d(x, (2, 2))  |  5x5x128 -> 2x2x128 Now we know size of the matrix (2x2) and we defined the number of channels (128) before, so we can define input size of fc1. 2x2x128 = 512",True
@executerruler3531,2022-01-30T06:44:11Z,0,"bro it shows error like ""Found dtype Double but expected Float"" what should I do now?",True
@arxzero1915,2021-12-02T15:32:47Z,0,What would the 4th dimension usally be? Something like time? So how a 3d model changes in a specific timespan or something like that?   Great videos so far btw!,True
@larry8306,2021-10-21T05:43:25Z,0,Thanks!!!!! I finally found which sentence I missed!,True
@cschandu123,2021-09-30T10:25:36Z,1,"Question: How did they get 4*4*50 .  Answer:  28*28 Input Image Step1: After 1st Convolution layer with Kernel size 5, output becomes 24x24  Step2: Max Pool makes this as 12x12 Step3: Second convolution Layer with Kernel size 5 makes it 8x8  Step4: Max Pool makes it half that is 4x4  and since second convolution layer output is 50, hence there are 50 of these 4x4 features. Hence the number 4*4*50",True
@angelferhati,2021-09-14T11:37:56Z,0,i use kaggle for training deep learning models,True
@arindam96,2021-08-31T18:56:29Z,0,Just finished all the 8 videos in this playlist. Loved it. Hope you make more of these pytorch videos.,True
@arindam96,2021-08-31T09:07:02Z,1,"This is a function to calculate the output image shape after conv + maxpool using this function instead of doing a dummy run   def conv_layer_shape(in_shape, kernel_shape, pool_shape, filter_list, stride = 1, padding = 0):   from math import floor   """"""         The function to add two Complex Numbers.            Parameters:             in_shape: (Width x Height x Depth) tuple of the input image              kernel_shape: (Width x Height x Depth) tuple of the input kernel             pool_shape: pooling layer shape              filter_list: list of output_channels in all the conv layer in sequence             stride: Stride taken by the kernel, Default is 0.              padding: Padding if any done on the input image.                    Returns:             out_shape = get the output shape of the conv layer after pooling for passing through FC layer   """"""   in_w, in_h, in_d = in_shape   kernel_w, kernel_h = kernel_shape   pool_w, pool_h = pool_shape    for no_of_filters in filter_list:      # output conv layer shape      out_w = ((in_w - kernel_w + 2*padding)/stride) + 1     out_h = ((in_h - kernel_h + 2*padding)/stride) + 1     out_d = no_of_filters      # after pooling shape     out_w = floor(out_w / pool_w)     out_h = floor(out_h / pool_h)     # out_d same as before     in_w, in_h, in_d = (out_w, out_h, out_d)    return (out_w, out_h, out_d)   use this to call the above function to calculate the shape  Here we enter the 50x50 input image size and assuming the kernel size is same for all  If we change the kernel size for different conv layers we can have a list of kernel sizes and iterate through these too Filter size list is simply the out_channel value in all the conv layer in sequence. conv_layer_shape( in_shape=(50,50,1), kernel_shape=(5,5), pool_shape=(2,2), filter_list=[32,64,128])  Output of the above is: (2,2,128)",True
@enodatube,2021-08-29T04:09:21Z,0,"I will add here what I did to understand what is happening with the different convolutional layers   The kernel of size 5 when you slide across a 50 px image will stop at 46th pixel (46-50 is 5px).  2x2 Max pooling over a 19 px  will stop at 18th cell with 9 max pooling values. This shows why the way the size of the image is getting reduced. Hope this helps others.   the result:  before conv1 torch.Size([1, 50, 50]) after conv1 torch.Size([32, 46, 46]) after max pool torch.Size([32, 23, 23]) after conv2 torch.Size([64, 19, 19]) after max pool torch.Size([64, 9, 9]) after conv3 torch.Size([128, 5, 5]) after max pool torch.Size([128, 2, 2])  the code:  def convs(self,x):          if self._to_linear is None:              print(f""before conv1 {x[0].shape}"")          x = self.conv1(x)         if self._to_linear is None:              print(f""after conv1 {x[0].shape}"")          x = F.max_pool2d(F.relu(x),2,2)         if self._to_linear is None:              print(f""after max pool {x[0].shape}"")          x = self.conv2(x)         if self._to_linear is None:              print(f""after conv2 {x[0].shape}"")          x = F.max_pool2d(F.relu(x),2,2)         if self._to_linear is None:              print(f""after max pool {x[0].shape}"")                  x = self.conv3(x)         if self._to_linear is None:              print(f""after conv3 {x[0].shape}"")          x = F.max_pool2d(F.relu(x),2,2)          if self._to_linear is None:              print(f""after max pool {x[0].shape}"")             self._to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2] #x is coming as abatch x[0] is just one element in the batch          return x",True
@dr.mikeybee,2021-07-29T02:30:37Z,0,Love the dark mode!,True
@alyeasin3367,2021-06-17T14:27:15Z,1,"x = x.view(-1, self._to_linear) this line isnt executing,  its saying : AttributeError: 'NoneType' object has no attribute 'view'",True
@jeroenhielkema7605,2021-05-03T20:59:26Z,0,"may i give you a tip? Please stick to dark mode or light mode, cuz the switching between the github page and jupyter blinded me xD not all eyes adjust so well ;)",True
@baranaldemir5570,2021-04-15T23:59:46Z,0,I think instead of MSE we need to use Binary cross entropy as a loss function. And sigmoid function on the output layer. Please correct me if I am wrong.,True
@albertopezzotta5803,2021-03-19T16:08:15Z,0,"People can (and do) go deep into the math of NNs, and do understand fundamental principles. Saying that ""nobody knows how NNs actually work"" sounds a bit of an overstatement to me and adds a layer of mystification that is not very helpful. This being said, great tutorials!!",True
@executeabi8220,2021-03-14T19:21:01Z,0,"Hi, What differences must be made when using a video dataset as opposed to an image dataset. So for video classification, i.e the HMDB1 dataset.",True
@Kaszanas,2021-02-23T12:16:22Z,0,The numbers You are talking about around 16:44 is the information about the dimension of the input data after all of the operations that change its dimension multiplied by the number of channels that the last conv layer outputs so let's say (following the PyTorch example): conv1 input 28x28 -> output 24x24 (from 1 channel to 20 channels) maxpool input 24x24 -> output 12x12 (number of channels stays the same) conv2 input 12x12 -> output 8x8 (from 20 to 50 channels) maxpool input 8x8 -> output 4x4 (number of channels stays the same)  so then the Linear layer expecting a flat input will be the dimensions of the last layer 4x4 times the number of channels 50: 4x4x50  EZ PZ It only took me through around one hour of research and reading people's weird explanations and tutorials to finally discover that.  The problem is that part of the logic that changes the input dimensions is not placed within the __init__ and makes the calculation harder...,True
@BadeAndenB,2021-02-20T15:24:52Z,3,"Anyone else getting a ""RuntimeError: The size of tensor a (2) must match the size of tensor b (50) at non-singleton dimension 2""? Have something changed since the video was posted? edit: Nvm! I'm the dummy :D All my trains and tests were pointed at X... Long live copy paste",True
@N3Wk1d5,2021-02-19T16:07:10Z,0,I love you so much,True
@sauravpandey599,2021-02-10T14:19:27Z,0,But how can x be 4 dimensional?,True
@davidcull5983,2021-01-31T22:26:55Z,0,"16:10, solved without cheating XD in fairness for anyone following along, I'd encourage you to pause when theres an error and try to resolve it yourself, it'll get you used to identifying the problems, believe me, it makes it easier further down the line when you're not following a guide. Sentdex, awesome videos, please keep up the work",True
@jokerkaro8917,2021-01-11T10:29:06Z,0,"The forward method with troch.flatten looks like this:  def forward(self,x):         x = F.max_pool2d(F.relu(self.conv1(x)),(2,2))         x = F.max_pool2d(F.relu(self.conv2(x)),(2,2))         x = F.max_pool2d(F.relu(self.conv3(x)),(2,2))           x = torch.flatten(x,start_dim=1, end_dim=-1)         x = F.relu(self.fc1(x))                  x = self.fc2(x)                  return F.softmax(x,dim=1)",True
@sbrahma0,2021-01-08T18:47:15Z,0,"I found out that there is a flatten function in Pytorch but not sure enough whether that automatically get the dimension to flatten. If anyone knows anything about it, please let me know.",True
@dhusor9633,2021-01-06T17:49:13Z,0,output=(n-f+2p)/s +1,True
@Oregonian1989,2021-01-02T06:53:36Z,0,"Thank you so much for wonderful lectures! I have one question, why is the train_X, train_y etc. use ""negative"" val_size?  Thank you!",True
@louisfernandez2689,2020-12-15T12:15:00Z,0,why do we want the input for the conv layer to be between 0 and 1?,True
@DarkRedman31,2020-11-28T09:51:59Z,1,34:59 little tip : you can add a boolean to a number so you can do correct += predicted_class == real_class,True
@DarkRedman31,2020-11-28T09:28:48Z,0,11:42 for the linear part it's simple to do self._to_linear = x[0].size because it already does that calculation for you.,True
@bohdankhv,2020-11-03T22:07:38Z,0,How does the neural network work? 20:58,True
@shaktisd,2020-10-02T08:14:26Z,0,Why not train_test_split at 23:34,True
@devpatel5597,2020-09-29T01:02:53Z,0,how can i train this. Do i just keep running it?,True
@swastikjena4605,2020-07-28T16:18:37Z,2,Gonna reach 1Mil soon!!!,True
@chaozhou9731,2020-07-25T18:03:54Z,1,"I do not think it is a good idea to use MSE loss for classification problem because MSE is built for regression problem. In the book PRML, it has justified the natural rise of cross-entropy loss in classification problem.",True
@mationplays1500,2020-07-14T18:29:52Z,0,"I get the error:  val_acc, val_loss = fwd_pass(X.view(-1,1,32,32).to(device), y.to(device)) TypeError: NoneType object is not iterable  does anyone have a clue Thanks!",True
@anilsarode6164,2020-07-07T17:57:02Z,0,"To know about F.softmax(x,dim=1) see this link the accepted answer :https://stackoverflow.com/questions/52513802/pytorch-softmax-with-dim/52518139",True
@sadaf243,2020-06-28T20:01:20Z,1,how do you put your jupyter notebook in dark mode,True
@mationplays1500,2020-06-25T12:58:29Z,0,RuntimeError: Given input size: (128x1x1). Calculated output size: (128x0x0). Ouput size is too small. Does anyone also had this error. I commeted the conv3 out and then this error accured The size of tensor a (5) must match the size of tensor b (10) at non-singleton dimension 1  Thank you for your help,True
@abhinavtembulkar4464,2020-06-20T19:36:06Z,0,Awesome video,True
@theoriginalplanet1757,2020-06-13T10:59:13Z,0,"Here's how to work out the size of the output of the convolutional layers instead of using the _to_linear hack:  (Assuming you are using 1 channel here - the first parameter to Conv2d)  Each convolution outputs a shape (1, outputs, image-size - kernel-size + 1, image-size - kernel-size + 1)  So a 50x50 image with a kernel size of 5 would output (1, outputs, 46, 46)  This makes sense if you think about it. A sliding window of x in an image of size x gives you one option. Add another pixel and you get two options. So it is image-size - x + 1. This assumes you are using a stride of 1 (the amount it is sliding along by each time).  The relu function doesn't change the shape.  With the max_pool pools the results are again aggregated using sliding windows. There is a 2x2 window and the stride is the same as the kernel size (2), so this time the number of outputs is inputs / 2 as we are sliding two cells at a time.  So now the output is (1, outputs, 23, 23)  Repeat this for the next 2 layers and you get  (1, 64, 19, 19) # conv 23 - 4 = 19 (1, 64, 9, 9) # max pool 19 / 2 = 9 (1, 128, 5, 5) # conv 5 = 9 - 4 (1, 128, 2, 2) # max pool 2 = 5 / 2  If you flatten 128 x 2 x 2 you get 512 which is the size that was calculated for the Linear layers.",True
@jojo22823,2020-06-01T20:12:02Z,1,"Hi, I am coming from a C/C++ background and I get a little lost by what python assumes and executes without prompt. Can someone tell me how the network is feeding data forward without the forward function ever being called? I'd have assumed you would need a line saying net.forward(x)?  I thought maybe python assumes the function to use based on the parameters past but both convs and forward have jsut the x parameter? what am I not understanding?",True
@pranavbudhwant9259,2020-05-24T19:05:07Z,0,"We actually do need activation functions, as they allow the network to learn a non-linear function. If we did not use activations, it would be like a simple linear classifier and thus won't work as expected. Moreover the final layer requires an activation function like softmax to convert the outputs to a probability distribution (values sum to 1) so that it is comparable to the one-hot encoded target that we're passing. Also loss function that is generally used for classification problems is the cross-entropy loss which is kind of a measure of dissimilarity between two distributions and if our target is a probability distribution then we should scale our outputs to be a probability distribution as well, and softmax just guarantees that.",True
@aderojuisrael3237,2020-05-23T09:23:33Z,0,This tutorial has really helped please how can I print out the features extracted,True
@dhyeyadesai7773,2020-05-20T18:45:28Z,0,"I am getting 48% accuracy.  Even with 3 epochs, my loss isnt going down. Its constant at 0.25000 I also verified this by copy-pasting your code from your website, didnt work Can you help?",True
@DeDean16,2020-05-18T15:55:51Z,7,"18:35 The reason why activation functions are used is to make the neural network a nonlinear function. If the entire network consisted of just linear functions, then the best function that your neural network is going to represent is a linear function. If that works for your problem, you should be using linear fitting methods instead of neural networks.",True
@soumyajahagirdar6708,2020-05-16T13:51:54Z,0,"I am getting an error called 'NoneType' object has no attribute 'view', how can i solve this problem?  batch_X = train_X[i:i+BATCH_SIZE].view(-1, 1, 50, 50) it's for this line",True
@dhusor9633,2020-05-15T22:42:21Z,0,Plz make this video again using torch.flatten() method..,True
@sagesy9774,2020-05-07T20:06:06Z,0,"Wait I don't get it, you never called the forward method/function",True
@Kanephan,2020-05-06T14:02:35Z,2,"what is the point of the ""forward"" method if its never used?",True
@codejunky9831,2020-05-05T01:08:58Z,0,nice skull cup! :),True
@amansaini8573,2020-04-23T08:56:40Z,2,"getting runtime error at loss.backward() what to do ??? RuntimeError: expected dtype Double but got dtype Float (validate_dtype at ..\aten\src\ATen\native\TensorIterator.cpp:143) (no backtrace available)",True
@Bornleadr,2020-04-18T04:35:42Z,0,"I am getting the following error while training the model:   RuntimeError: The size of tensor a (2) must match the size of tensor b (50) at non-singleton dimension 2  and it points out the loss_function but I don't see any problem there. Here is my code:   BATCH_SIZE = 100  EPOCHS = 1  for epoch in range(EPOCHS):     for i in tqdm(range(0, len(train_X), BATCH_SIZE)):         #print(i, i+BATCH_SIZE)         batch_X = train_X[i:i+BATCH_SIZE].view(-1, 1, 50, 50)         batch_y = train_y[i:i+BATCH_SIZE]                  net.zero_grad()         outputs = net(batch_X)         loss = loss_function(outputs, batch_y)         loss.backward()         optimizer.step()          print(loss)   Can anyone point me out what am I doing wrong here?",True
@Victrix40,2020-04-07T18:27:33Z,0,"Hello, there is something I don't understand :  net_out = net(test_X[i].view(-1,1,50,50))[0]  In the previous  line, why should put the index [0] ? isn't the output already a tensor like (0.23 , 0.77) (for example) ?",True
@openroomxyz,2020-04-05T15:32:53Z,0,"Why are you using X, y .. big X, and small y it's very easy to confuse them?",True
@openroomxyz,2020-04-05T15:06:44Z,0,"What are optimizer, like Adam ?",True
@martinmartin6300,2020-04-04T17:57:17Z,0,"I'm not into pytorch at all but isn't the batch implementation wrong as you call optimizer.step() in the inner loop? I suspect that optimizer.step() is doing the parameter update. I might be wrong but if this is the case, then when you are doing batching, what you really want is to update parameters after each batch rather than after each example.",True
@martinmartin6300,2020-04-04T17:41:03Z,0,"One note: If you have only two classes, it is better to have a single output neuron/value. I recommend to use a simple sigmood function which provides something between 0 and 1 which can be interpreted as a probability already. The nice thing is that you can use an optimized threshold in here. Once your training is done, you can search for the threshold which delivers the best accuracy for the training and or test set (be sure to keep some additional validation set of you optimize here for test set, too). This way, you get a pretty neat binary classifier.",True
@martinmartin6300,2020-04-04T14:55:55Z,0,"Also, I wanted to mention that the lack of a ""flatten"" function can be good as it forces the programmer to come up with an own way which means that he is at least aware of how this works. There might be  a problem regarding ""flatten"" as this is not unambigious. This can be done arbitrarily. As long as you stay with the exact same framework, this does not matter at all but I often find that people do not even know how the data is processed by the network... Question to some guy who passed me a bunch of neural network parameters to be implemented in a C model: ""How did you do the flattening exactly?"" ""Uhhh, I don't know; used the flatten function."" Great.",True
@martinmartin6300,2020-04-04T14:52:07Z,0,"Regarding the switch from convolutional part to fully connected part: I think it is OK to assume that whoever uses neural networks knows the theory behind it. My rule is: If you don't understand what you are using, don't use it! It might get someone into a lot of trouble if it doesn't work out and he doesn't know why because he doesn't have any clue what he is doing... That said you must analyze how the image sizes changes from layer to layer. The numbers which you are passing to the Conv2d layers are just the number of input and output images to/from this layer. If you are doing 5x5 convolutions and use the ""inner convolution"" mode, the image size reduces by 4 in both, X and Y dimensions (you take kernel dimension size minus 1). E.g. if you have 64x64 images as input to the convolutional layer, you end up with 60x60 images at the output (assuming 5x5 kernels). If this layer provides 50 output images, you have a total of 60x60x50 output pixels. In the one example that you have shown, it seems as though 4x4 is the size of the output images at this particular convolutional layer. Thus, this is multiplied by 50 which is the number of output images. You do not need to pass fake data to determine this. It is better if your code can handle this on it''s own based on the theory.",True
@martinmartin6300,2020-04-04T14:31:59Z,0,"Hey, with the convolutional layers: It really depends on your data. If you go for image stuff, sure convolutional layers are the natural choice. Generally, if your features (which are pixels in images) must underlie some sort of locality principle because otherwise it does not make sense to use convolutional layers at all. Therefore, if you have derived a bunch of own features which are more or less independent of each other via some preprocessing (e.g. for other types of classification), you must use something else.",True
@teetanrobotics5363,2020-04-02T09:09:14Z,0,Could you please create a GitHub account and put the code there?,True
@FMAPR,2020-04-01T05:25:02Z,0,Can you please make a shirt with your rant in 20:50 ? Loved it.,True
@tarasvoitsitskyi1072,2020-03-31T05:28:39Z,2,Why MSE loss is used for classification here?,True
@babayaga4329,2020-03-30T21:36:09Z,0,my face when I didn't make typo and sentdex did,True
@DHTSciFiArtist,2020-03-29T22:47:18Z,0,These videos have taught a valuable lesson. To take with a can of salt any predictions that in 20 to 40 years we will have sentient AI. It's pretty hard to make an image comparative program let alone A sentient android.,True
@DHTSciFiArtist,2020-03-29T22:43:16Z,0,when I initiate cell 8 i get this error    My cell https://gyazo.com/f8ee811fcdd5dc66f7e64e7487bd25ec   The error: https://gyazo.com/9524d7992181c46602e518801d7974fd  https://gyazo.com/9524d7992181c46602e518801d7974fd   What am I doing wrong.,True
@iOLlVER,2020-03-28T19:07:29Z,37,"THIS IS HOW TO CALCULATE THE FLATTEN INPUT SIZE:  In your case each: - Conv2D layer output size is (InputSize - KernelSize + 1) => (InputSize + 4). Attention, this only applies for stride=1 and padding=0 - MaxPool2D layer output size is floor(InputSize/PoolSize) => floor(InputSize/2). Attention, this only applies for stride=KernelSize and padding=0  For your case you start with 50x50 image size, then: 50x50x1 --conv2d--> 46x46x32 --pool--> 23x23x32 --conv2d--> 19x19x64 --pool--> 9x9x64 --conv2d--> 5x5x128 --pool--> 2x2x128  This way you get 2x2x128 as input for the FC-layer which is 512 inputs in total",True
@cedric1731,2020-03-21T21:28:28Z,0,"Just by looking through some of the data manually, you see there is some serious junk in it... Love it... ^^ E.g. There is a Yahoo label declared as a dog which obviously is not the case because they are not cute...",True
@ManpreetSingh-ew8qs,2020-03-19T13:46:01Z,1,"if i have 3 color channel do i need to put self.conv1=nn.Conv2d(3,32,5)? please help",True
@fireheart__7,2020-03-17T10:45:20Z,0,"""expected dtype Double but got dtype Float""........... I am repeatedly getting this error message in the segment where we backpropagate. i.e. loss.backward(). [32:51 in this video]. Please help!",True
@mohitpandey5190,2020-03-15T07:38:27Z,0,"could have liked it twice, but sadly there is no option.",True
@kareemjeiroudi1964,2020-02-29T16:39:17Z,0,See the mathematical formula of softmax to understand what this dim argument is doig,True
@vadympasko100,2020-02-29T15:45:07Z,18,Thanks for the tutorial! A little advice regarding code style:  instead of  x[0].shape[0]*x[0].shape[1]*x[0].shape[2]  better make  np.prod(x[0].shape),True
@ironmantooltime,2020-02-23T15:17:15Z,0,"I ran this with an NVME on a quad core laptop and speed was much faster than here. I think the IO was the dependency, not CPU/GPU, but heh.",True
@jorenvangoethem343,2020-02-17T00:13:18Z,0,"is your cpu just rather slow or is it because you are also recording at the same time, i just ran this on a laptop and  got way faster results and it is just a 9th gen i7 laptop cpu",True
@DrlGSN,2020-02-15T16:11:56Z,0,"Hello, thank you for this amazing video. I just wanna ask if we can use Dataload from Torch to create batches.",True
@VVV-wx3ui,2020-01-29T13:56:39Z,3,Its totally a new chapter to me after trying out the Keras to do the same. Wonderfully done Sentdex.    Google Colab is good to start with for free GPU.,True
@supergo1108,2020-01-29T07:52:12Z,4,"After training, how we save the model trained, for later predictions? could we use things like pickle?",True
@mkliu1882,2020-01-14T05:15:56Z,1,"Hi, @sentdex. Thanks for your video, very informative.   I am still a bit confused about the dimensionality of the convolution operation, could you clarify a little bit more?  For the self.conv1, if I take a 50*50 pixel image, what's the dimension of the 32 convolution outputs? I assume each of them is still an N*N array, but N<50? How are these 32 convolutions operation defined and performed in PyTorch?   For the convs part, if I understand correctly, the dimension of the convoluted and rectified 2d array, i.e. F.relu(self.conv1(x)) should be reduced by half after the max_pool2d operation. But since conv2 only cares about the number of input channels instead of the dimension of the input 2D array for each channel, it still goes through, right?     Cheers",True
@amranimohamedchakib7537,2020-01-02T17:42:50Z,0,it's one why?,True
@amranimohamedchakib7537,2020-01-02T17:42:26Z,1,i didn't understand the input size of 1st conv layer,True
@farukarslan2000,2019-12-28T10:12:04Z,0,"hi, if we use epoch=5 for example, is accuracy calculation return the last epoch accuracy or total or average  accuracy of all epoch?",True
@grizzle8911,2019-12-27T01:36:54Z,1,"Sentdex, your tutorials are fantastic ... but there is one  thing I must know... Where do you get all your mugs from? You have a new one each video! They're great!",True
@abhishekswain2502,2019-12-23T20:20:55Z,0,I just simply build the network and print out the shape of 'x'  before the first fully connected layer in the forward method and then pass through random data. Then multiply everything except the batch dimension.,True
@angrwl,2019-12-17T21:38:40Z,0,"what to do if when running the command, X = torch.Tensor([i[0] for i in training_data]).view(-1,50,50), python throws the error that  'not enough memory: you tried to allocate 21751740000 bytes. Buy new RAM!'? Should I just wait for doing it over gpu",True
@rajcivils,2019-12-17T06:55:35Z,1,There is a function to flatten.  torch.flatten(),True
@theai1813,2019-12-14T16:10:03Z,0,Thanks Sir <3,True
@haahee8420,2019-12-09T17:40:17Z,1,"In the forward function you can put print(x.shape) after every step to see what is happening:   print(x.shape) x = F.relu(self.conv1(x)) print(x.shape) x = F.max_pool2d(x,2,2) print(x.shape) ... etc...   It helps a lot to see what is going on.    Also a very simple way to get the right number without calculating it yourself is you can just put a random number in the fc1 input, and after running the code it will throw an error and tell you it expected value 126548 or whatever instead so you can just copy it and paste.",True
@aravinddoss4127,2019-12-04T20:03:46Z,0,https://pytorch.org/docs/stable/_modules/torch/nn/modules/flatten.html,True
@twanh8985,2019-12-03T21:29:10Z,0,"I am getting the error:      X = torch.Tensor([i[0] for i in training_data]).reshape(-1,50,50) TypeError: not a sequence   Google can't help Does anyone know a solution?",True
@maciejrogala5928,2019-12-02T21:42:42Z,0,Why we dont have to use: with torch.no_grad(): when we normalize the input (division by 255)?,True
@anneest,2019-11-29T21:51:04Z,0,"Dude, what's with the cups?? :-P Hihi, great class, I appreciate your informal tone, and (sorry) I was a bit giggling at your paint graphics. I love your general explanations, it's very intuitive and helps a lot. The kind of material I will remember without having to re watch the vids half a million times....  @sentdex : If you revisit the github pytorch example link you show in your vid,  you'll see that there is now a FLATTEN method: https://github.com/pytorch/examples/blob/master/mnist/main.py (this is as is, November 19th, 2019)",True
@AkashChauhan-hq5ly,2019-11-23T05:38:33Z,0,"Hey, When I run the same code, my training loss after one epoch is 0.0 hence the accuracy on the test set is 100. Should I not be worried?",True
@rajcivils,2019-11-21T05:16:07Z,3,What about padding. I think you missed that. Will you cover it in some other video. And what about decaying learning rate. Are you going to teach those how to do that in pytorch.üòÄ,True
@slinky7355,2019-11-14T17:30:51Z,0,"The ordinal number for zero is 0th or zeroth. Also 1 is ""first"" not ""firstith"" lol.",True
@user-vp9rr9gi6n,2019-11-11T07:25:34Z,0,I think U can use Numpy's flatten just to get the input shape? Not sure.,True
@yasmineguemouria9099,2019-11-11T00:33:39Z,0,"does anyone have an idea why instead of having only one progress bar that is incremented i keep having 100 progress bars for 1% 2%... 100%? I'm also using jupyter notebook (i googled it but it seems to work fine for other people, one suggested solution was using tqdm.notebook but ""ModuleNotFoundError: No module named 'tqdm.notebook' """,True
@MohammedAlnakli,2019-11-11T00:28:53Z,1,I have created a function to calculate the output size of the Convolution layer:  https://gist.github.com/malnakli/6882357f4834337f9f9e6b95aa97e7ab,True
@nimahamidi6521,2019-11-07T21:12:06Z,1,"Also, you are using MSE for binary classification, which is not a good idea. The reason adding the activation layer at the end doesn't change anything is because of the wrong loss. If you use a cross_enthropy loss, then you will need a softmax (in this case a sigmoid layer) for your binary classification.",True
@nimahamidi6521,2019-11-07T20:52:45Z,0,"Regarding the last layer and flattening layer, if you are implementing a CNN, your input size should be all the same. That's why you know the size ofthe last dense layer. The size for the dense layer depends on input size and you can simply calculate the size from input size. If you are going to implement a fully convolutional network, then we won't have a dense layer and no need for flattening the last layer.  https://www.quora.com/How-is-Fully-Convolutional-Network-FCN-different-from-the-original-Convolutional-Neural-Network-CNN",True
@indivarmishra6119,2019-11-06T07:47:58Z,1,Sir your channel to me is like Doctor protons show to Sheldon on Big Bang Theory üíì,True
@tbjasun,2019-10-22T11:42:35Z,2,"Does anyone else have a RuntimeError from the line ::X = torch.Tensor([i[0] for i in training_data]).view(-1, 50, 50)?  I get an error stating that the shape '[-1, 50, 50]' is invalid for input of size 122235400. HELP!",True
@eranbamani8080,2019-10-20T11:27:43Z,0,"<> in forward(self, x)       26   def forward(self, x):        27     x = self.convs(x) ---> 28     x - x.view(-1, self._to_linear)    RuntimeError: The size of tensor a (2) must match the size of tensor b (512) at non-singleton dimension 3      29     x = F.relu(self.fc1(x))       30     x = self.fc2(x)      Someone can help me please with this error.",True
@esysss,2019-10-18T15:56:28Z,0,I've got 100% accuracy did I somehow cheated? how can I tell?,True
@faridalijani1578,2019-10-17T13:10:58Z,0,why don't u apply batch_size on testing? u are going through all testing images in here whereas in training you had a batch_size = 100.,True
@gizmoriderfulye8007,2019-10-16T13:49:17Z,0,is python really efficient language enough for stuff like that? I mean in terms of processing power,True
@RabeezRiaz,2019-10-16T11:44:32Z,12,"For anyone using tqdm, the plain interface (`from tqdm import tqdm`) is made to be used in terminal applications which is why it messes up in notebooks especially with printing going on inside the loop. Use `tqdm_notebook` instead.   Also for things like the training loop, nested progress bars work really well: for epoch in tqdm_notebook(range(EPOCHS)):     for i in tqdm_notebook(range(0, len(train_X), BATCH_SIZE), leave=False):         # do stuff here",True
@hiteshvaidya3331,2019-10-16T01:57:33Z,0,"For those who do not have access to any GPU, Google Colab is the best option. You get unlimited free access to tesla GPU. I guess there is just a cap on the amount of data that you could store on drive. But for normal learning experiments I doubt if that cap would ever be crossed. so, all the best!",True
@tonihuhtiniemi1222,2019-10-15T16:27:19Z,0,When running epoch: RuntimeError: _thnn_conv2d_forward not supported on CPUType for Byte ? Thanks!,True
@2009alshaibani2008,2019-10-14T17:50:42Z,0,"I am running this code in my PC, but I faced an error""input and target shapes do not match: input [100 x 2], target [100 x 50 x 50]"" could you help me to solve this error. please.",True
@damianshaw8456,2019-10-12T20:12:53Z,0,"Small point and doesn't really matter but in Python 3  when ever we divide an int or  float by an int or a float using ""/"" we get a float. So we no longer need to worry about X/255.0 vs X/255 as long as X is an int or float we get the same answer.",True
@jgudiel2972,2019-10-12T07:25:51Z,0,"Why (54x54x16)? With 224 pixels per side, the kernels and pooling layers result in  (((224‚àí2)/2)‚àí2)/2=54.5  which rounds down to 54 pixels per side.",True
@blackberrybbb,2019-10-10T19:31:06Z,7,i ve been waiting for you to correct conv123üòÇwhich you finally did at 16:31!,True
@mahery_ranaivoson,2019-10-10T18:39:39Z,0,"Great tutorial, I have arrived at this point at the end. So am just wondering whether you could implement the UNet model using pytorch for image segmentation from scratch. That would be very helpful for some researchers. Anyway, thanks for making great effort for the community for free. Keep it up.",True
@billfujimoto5905,2019-10-10T06:59:31Z,16,"Regarding the issue with flattening the conv layer, I used the torch.flatten() function which cleans things up a bit.  The torch.flatten function is in the convs function which makes the forward function just a bit cleaner:       def convs(self, x):         x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))         x = F.max_pool2d(F.relu(self.conv2(x)), (2,2))         x = F.max_pool2d(F.relu(self.conv3(x)), (2,2))         x = torch.flatten(x, 1, -1)         if self._to_linear is None:              self._to_linear = x.shape[1]         return x          def forward(self, x):         x = self.convs(x)         x = F.relu(self.fc1(x))         x = self.fc2(x)         return F.softmax(x, dim=1)",True
@billfujimoto5905,2019-10-10T04:55:48Z,3,"Looking forward to the next installment regarding GPU operations.  I tried to wade thru the PyTorch documentation but I eventually gave up. BTW, I use Google Compute Platform which comes with a $300 credit for new users, this precludes use for crypto mining.  The cost is only around $0.45 per hour for a virtual machine of 8 CPUS and 1 Nvidia P4 GPU, 200 GB storage, preemptable.  This of course is not the highest performance GPU but a lot faster than my laptop!",True
@nlrprogramming9359,2019-10-09T23:21:33Z,19,Remember when you had sub 50k subs and did the Image Recognition with Python series. Now we are writing PyTorch and +700k subs. Damn.,True
@Nova-Rift,2019-10-09T23:11:37Z,0,"Hi Sentdex, I have a very large nationwide client that wants me to build and implement facial recognition software for them. I'll offer you 10% of my company if you want to join our team of 5. This is very real. You can google me, I've founded many successful companies, such as Fluzzletube.",True
@camdenparsons5114,2019-10-09T19:13:40Z,0,will you make a video training a transformer model?,True
@gouravkolhatkar3623,2019-10-09T05:18:55Z,1,Can you please make a video on best Laptop or what kind of laptop needed for AI ML or DL,True
@bdindial,2019-10-09T01:59:16Z,1,PyTorch RNN !!! with Time Series please and thank! Keep it up,True
@madaragrothendieckottchiwa8648,2019-10-08T21:15:32Z,0,Very Nice,True
@frigginnobody,2019-10-08T21:10:33Z,45,"Regarding 6:25, the way I do this (I guess this only works with latest versions of pytorch) is to have a flatten layer at the forward step and print the shape of it,  before adding the fully connected layers. The we explicitly running the forward function with a sample input. I find it easier and straight forward than other methods. By the way, another great series. Thanks a lot.  For eg, in this case  class Net(nn.Module):     def __init__(self):         super().__init__()         self.conv1 = nn.Conv2d(1, 32, 5)         self.conv2 = nn.Conv2d(32, 64, 5)         self.conv3 = nn.Conv2d(64, 128, 5)          self.pool1 = nn.MaxPool2d((2, 2))         self.pool2 = nn.MaxPool2d((2, 2))         self.pool3 = nn.MaxPool2d((2, 2)) # commenting out fc layers, replace value with our output #         self.fc1 = nn.Linear(value, 512) #         self.fc2 = nn.Linear(512, 2)          def forward(self, x):         x = F.relu(self.conv1(x))         x = self.pool1(x)         x = F.relu(self.conv2(x))         x = self.pool2(x)         x = F.relu(self.conv3(x))         x = self.pool3(x)         x = x.flatten(start_dim=1) # flattening out         print(x.shape) # printing the shape of the flattened output #         x = F.relu(self.fc1(x)) #         x = self.fc2(x) #         return F.softmax(x, dim=1)      net = Net() net.forward(torch.randn(1, 1, 50, 50)) # passing a sample input (random)   this will give us an output ""torch.Size([1, 512])"" in which 512 is the value we are looking for, replace value with 512 and we are good to go. Hope this helps.",True
@bkmakhoba,2019-10-08T19:53:00Z,1,Would be great if you did you RNN cryptocurrency using pytorch this time! Also think rather use LSTM would make for a great tutorial!,True
@sethkitchen6775,2019-10-08T18:57:40Z,0,"Can someone explain why he uses 1 in the first Convolutional Layer ? Seems like it should be 50 or 50,50 or 2500 based on the image size?",True
@ronaldronald8819,2019-10-08T16:37:26Z,1,"So happy I found your excelent tutorial, just getting into this stuff. Dont want to give my old laptop a headache .. Is the Jetson Nano a good option to use instead?",True
@zkristic,2019-10-08T15:31:31Z,0,"So which one do you prefer currently? Keras with TensorFlow backend, or PyTorch?",True
@reinerheiner1148,2019-10-08T11:05:29Z,0,Hey sentdex could you do a benchmark on current gen ryzen vs intel on scientific computing? I know in the past amd was bad but this was supposed to change this gen. Esp. When it comes to nwural networks and machine learning.,True
@nurzhan051184,2019-10-08T04:14:42Z,11,every video with new cup ‚òïÔ∏èüòÖ,True
@simondresa,2019-10-08T00:02:08Z,0,love your videos!,True
@elisabethdoyon107,2019-10-07T22:05:03Z,2,"Great video again! I like that you leave the typos and corrections... if we can catch them while you code, that's just a nice way to confirm we understand what you were trying to achieve.",True
@junlinlim8524,2019-10-07T21:09:03Z,0,37:20 jupyter was still running the cell after you shift entered. prolly should have interrupted the kernel first,True
@TheUggeli,2019-10-07T20:45:02Z,2,x.flatten(),True
@TrackLab,2019-10-07T18:19:54Z,0,"Wouldnt the code be transformed into a GPU usable cloud instantly, as soon as you have pytorch with cuda installed? I run pytorch over cuda, and the whole code runs on my GPU if i am not mistaken. Without any code change.  Or maybe I am wrong and I do need to define the GPU usage manually, not sure. Edit: Shouldnt the whole code run on GPU with this 1 line? ""torch.cuda.set_device(0)""",True
@ass8ash,2019-10-07T17:52:50Z,0,Nice! Waiting for the next one!,True
@abdulrashid1621,2019-10-07T17:36:34Z,28,Please do a RNN related video in this series,True
@abrhaleifrezghi1944,2019-10-07T16:26:33Z,0,Keep doing the great job man!,True
@matejzorek781,2019-10-07T15:49:53Z,4,Why don't you use binary cross entropy instead of MSE??,True
@thomasmicic6265,2019-10-07T15:13:29Z,0,"Simple flatten module...   class Flatten(nn.Module):     def forward(self, input):         return input.view(input.size(0), -1)",True
@shivavsk6178,2019-10-07T15:12:04Z,0,Hi there man I am currently following your intro into your deep learning with Keras and tf!! Couple of things to point out in the 3rd exercise where you use CNN to classify dogs and cats !! It will return a error because X Is a numpy array and Y is a list think it‚Äôs a version issue  Also my local machine is really struggling!! Planning to get into colab!! But the datasets are large and my upload speed is terrible üòî,True
@girish7914,2019-10-07T14:51:13Z,0,ek no !!!,True
@sainco3036,2019-10-07T14:43:55Z,0,thanks.,True
@chinmoyjyotikathar8793,2019-10-07T14:29:56Z,224,"You can actually calculate the output size of the last Convolution Layer that is fed as input into the Linear Layer.  Let's take the example from PyTorch's mnist example from github you have shown at 5:38 Let's Consider one dimension of the image as all operations are symmetrical across both width and height.   Initially image size, W = 28 Kernel Size, k = 5 Stride , s = 1 Padding, P = 0   The formula for the number of outputs to the next layer of conv2d is: O = { (W - k + 2*P)/s } + 1 So, number of pixels/features after first conv2d layer  = { (28 - 5 + 0)/1 } +1 = 24   Next, we apply a maxpool of size (2,2) hence reducing the size by half accross both dimensions of image So o/p size after 1st maxpool layer = 24/2  = 12   Next, we apply another conv2d layer with same values. So size of output layer via similar calculations  = 8 Next, apply one more pool layer, we have o/p size = 8/2 = 4   Finally, we have k = 50 in the last conv2d layer, so i/p size to Linear Layer  = image volume * #  filters = 4 * 4 * 50",True
@vijayabhaskarj3095,2019-10-07T14:27:54Z,2,"Love the series as always, You could calculate the no. of units used in linear layers like Sebastian Raschka does https://github.com/rasbt/deeplearning-models/blob/master/pytorch_ipynb/cnn/cnn-basic.ipynb",True
@noahkasmanoff6366,2019-10-07T14:27:08Z,2,"Bought a rasp pi this summer and learned how to program it with your tutorials, and then a week ago learned I had to switch over from TensorFlow to Pytorch and these videos have been crazy useful.  Thanks so much!!",True
@sak8485,2019-10-07T14:08:32Z,3,"For the folks who cannot afford cloud GPUs just go to Google and search Google colab, all you need is a Google account and you can get access to a Tesla k40 or something else for 12 hrs along with 12 GB ram. Everything within your browser, so no more excuses to learn.",True
@erickgm8467,2019-10-07T13:46:00Z,0,Great job! I recommend it to all my friends here in Brazil! Thanks!,True
@SakyTalks,2019-10-07T13:35:05Z,16,Loving this series so far. I've been picking up this side of engineering slowly and your videos are much appreciated. üëèüëèüëè,True
