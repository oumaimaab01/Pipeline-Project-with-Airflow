author,updated_at,like_count,text,public
@litttlemooncream5049,2023-11-22T03:10:48Z,0,thanks,True
@ander300,2023-09-16T17:48:25Z,0,"Part 10 of Neural Net from Scratch, about analytical derivatives??? Please bring the series back!",True
@aladinmovies,2023-05-25T17:27:49Z,0,How much operations can make 1 GPU 3090? And how to calculate how much operations needs programm? Thanks for answers!,True
@devilmix85,2023-05-05T05:40:39Z,0,Can you make a video on Gated Linear Units?,True
@MrRadziu86,2023-05-01T10:37:27Z,0,"How would you compare its performance to Hugging Chat (open assistant), WizardLM, StableVicuna and other open LLMs and chats?",True
@randytesla7596,2023-05-01T00:36:55Z,0,ChatGPT sent me to your channel. Lol,True
@knusperkekskekskeks,2023-04-30T11:03:11Z,0,have you asked it about Tiananmen Square?,True
@Yashu_mm,2023-04-28T15:54:20Z,0,btw you look like jesse pinkman who graduted college .,True
@rikvermeer1325,2023-04-26T11:09:53Z,0,You are really good at explaining this; subscribed!,True
@fitybux4664,2023-04-24T01:39:59Z,0,"GLM-130B vs Vicuna? Any opinion on that? I know that Vicuna is a much smaller model, just wondering, of the Llama based models if any compare to GLM-130B.",True
@TheMagicMooshroom69,2023-04-23T20:06:14Z,0,"I know you put out your video discussing the NNFS Part 10 about a year ago, but have you got any updates on that series at all? :)",True
@zeuglcockatrice4633,2023-04-22T17:18:01Z,0,"can you make a video about using ai to reverse engineer code? I used bing chat to do it with some simple c++ functions, I gave it the assembly code and it gave me back the function. It only works with simple stuff but in the future it might be able to generate entire software",True
@jaysonp9426,2023-04-22T10:35:24Z,0,"I asked it ""which world leader looks the most like Whinny the Pooh."" I'm dead now.",True
@TiagoTiagoT,2023-04-22T01:17:17Z,0,Why people seem to hesitant to allow the negative side of the activation function to have similar magnitude as the positive side? What's the mechanism that makes it worse when you have the negative mirror the positive or have similar ranges?,True
@aa-xn5hc,2023-04-20T09:28:58Z,0,"What about ""open assistant""?",True
@MrTheKeiron,2023-04-20T07:53:43Z,0,"0:55 ""It's shockingly good for its size""  Thats what she said",True
@toromanow,2023-04-20T02:00:28Z,0,Newbie question what can you do with this model that you can't do with OpenAI? Why would I use it over OpenAI?,True
@joshmabry7572,2023-04-19T23:41:17Z,0,"What is the context size of the model? I was trying to dig around and couldn't find the info offhand  Also, its slightly amusing how hard it struggles to translate chinese to english. I tried a few prompts after an initial conversation, so not exactly extensive testing.  ""The translation of ‚ÄúÂêÑËá™ÁöÑ‚Äù to English characters is ‚ÄúÂêÑËá™ÁöÑ‚Äù.""",True
@MetaverseAdventures,2023-04-19T12:18:37Z,0,"Everyone is so focused on being the ChatGPT killer, that they are not looking at the very real dangers of what we have already on society.",True
@Unknown-ki8yk,2023-04-19T10:02:43Z,0,I guess this will be China's answer to the west. This seems like it has great potential.,True
@CrocodilesDen,2023-04-19T09:48:35Z,0,Bro you‚Äôve lost so much weight üôåüèΩ,True
@josephvanname3377,2023-04-19T08:15:30Z,0,Reversible computing is the future of computing.,True
@arunachalpradesh399,2023-04-19T03:30:06Z,0,you forgot 'OPEN ASSISTANT' its the best,True
@nodvick,2023-04-19T01:17:18Z,0,4 3090's...,True
@list1726,2023-04-17T20:11:57Z,0,Thank you for posting. Keep up the good work,True
@theoistic7002,2023-04-17T06:51:04Z,0,"to run yes... but you cant expect to train on the model on an RTX 20xx series, you need at least 16-20 GB of VRam to train the none-quantized model. cuz after you quantize it, you kinda lock the model. at least thats the rule for LLaMa .. which although is different, same quantization rule applies.",True
@gwky,2023-04-17T05:13:51Z,5,"LLMs seem hype until you start chatting with so many of them and realize they can't keep a conversation for more than a few lines... Even story writing models seem to start hallucinating. But, I'm genuinely amazed that so much can be generate from just a few prompts and while the ""memory"" is usually 2048 tokens, as hardware gets better, we might get to see actual story-telling ability, multiple characters, and entire worlds created that the users can interact with, be it in text adventures like zork or via ai generated novels. At the moment, I've tried every tool out there, and the most popular 6B/13B/20B models. It's still garbage after a few prompts, but sometimes it does remember the context and leaves me genuinely impressed. It's like an abusive relationship, most of the time it's crap, but you learn to cherish the good moments.",True
@SkimFelBon,2023-04-16T10:04:20Z,0,"Hi @sentdex, what tool you are using to highlight PDF's?",True
@joshheller1439,2023-04-16T01:05:47Z,0,What technology jobs haven‚Äôt the greatest risk of depreciating faster as a result of AI? (Reflecting quickly it feels like ALL could be replaced much like repetitive actions with robotics),True
@Shaunmcdonogh-shaunsurfing,2023-04-15T20:18:26Z,0,Thanks goodness for this channel!,True
@vioradata,2023-04-15T17:52:37Z,0,"If it is from Chinese universities, the tech should be used by Baidu's Wenxinyiyan, a so-called competitor of ChatGPT. The product is so bad that Baidu even cancelled the press conference because so many Chinese netizens made laugh of its conversations lol I always keep close to Chinese tech circle. A reliable source also said even ChatGPT is from Chinese team. I was astonished when I heard of it. I'm still observing. Will see. :)",True
@codechimps,2023-04-15T09:42:15Z,1,This is such a solid video we need more of these when it comes to AI today.,True
@draken5379,2023-04-15T09:13:32Z,0,"These open source models are great, but then dont even come close to GPT3.5, let alone 4.",True
@mysticaltech,2023-04-14T22:58:43Z,0,"Man, the server racks behind you, so dope! Thanks for sharing about this valuable model.",True
@hexburner4157,2023-04-14T16:52:12Z,0,jesse?,True
@harriehausenman8623,2023-04-14T15:21:22Z,0,What about OpenAssistant?!,True
@harriehausenman8623,2023-04-14T14:54:08Z,0,I'm pretty sure the derivative of GeLU has at least ONE zero üòâüòÑ WolframAlpha says ‚âà -0.752461710697740‚Ä¶,True
@digidope,2023-04-14T14:45:28Z,0,Good quality + local running = 2025. All current local LLM's are 1-5% quality of GPT4,True
@trFirzen,2023-04-14T10:37:38Z,0,makes a post request to ChatGPT in the background,True
@aloo_explains,2023-04-14T06:30:15Z,0,"GELU's are being used quite alot in models like, GPT-3, BERT.",True
@rileykramer3642,2023-04-14T01:17:10Z,0,3090s are like $1500 new. itd only be like 6k for a setup like that. id personally wait for 5000 series to see if they up the vram. im guessing we will see a 32gb 90 series model.,True
@TheRealMcNuggs,2023-04-13T22:37:57Z,5,"Will you ever continue the ""Neural Networks from scratch"" series? Was really looking forward to backpropagation.",True
@uae7001,2023-04-13T21:31:51Z,0,"Did you try LLaMA AI language model¬†which leaked online recently, i like it and will compare it with this",True
@abuslume4169,2023-04-13T19:53:36Z,0,"My guess is that this bot's context is a little too limited, but it'd be interesting to see how this bot would fare in the same test Microsoft did with AutoGPT.",True
@CMAZZONI,2023-04-13T19:19:56Z,0,Could this model be used for semantic search?,True
@li-pingho1441,2023-04-13T17:43:19Z,0,awesome!!!!,True
@fnegnilr10,2023-04-13T16:25:35Z,0,"Wow, this talk is fantastic! Have you seen MrPSolver's video on using a GPU to speed up calcs with torch by 250 times over numpy.",True
@piotrt4220,2023-04-13T08:56:28Z,0,"It's cheap, and like ChatGPT it can't do math and physics calculations properly. In fact, it's even worse.",True
@freecode.ai-,2023-04-13T07:22:46Z,0,Could a botnet train an LLM at the same level these big companies do?,True
@nandafprado,2023-04-12T21:56:22Z,0,"I like getting this LLMs and test them in another language they weren't trained in, so I played with using it to answer me in portuguese and you could see the memory limitation there but it was still ok for its model size.",True
@clydecmcelroy4638,2023-04-12T11:21:25Z,0,"I wonder how many article titles and video titles are going to contain the words ""chat GPT killer"".",True
@creativedolt,2023-04-12T10:51:18Z,0,"The output of ChatGLM seems to often have chinese charaters mixed in with English text. eg. if you ask ""What is backpropagation?"", then words like ""accuracy"", and ""gradient"" show up in chinese. Doesn't anyone else run into such issues? Doesn't that change the utility of the model for non-chinese speakers?",True
@jackcollins4422,2023-04-11T23:02:55Z,0,Seems like scaling laws are suggesting that less is more..!,True
@homataha5626,2023-04-11T18:45:01Z,0,Thank you for the video. Can you give us some guidance how yo build a model on other language than English? I am interested in building a model for persian texts.,True
@jurelleel668,2023-04-11T09:36:29Z,0,"Do multimodal tasks, image tasks, mathematics tasks for the glm 6-b in English. Thanks",True
@jurelleel668,2023-04-11T09:32:32Z,0,Awesome video mate.  Sentdex please do a chat gpt glm-6b tasks review,True
@Dyas777,2023-04-11T08:56:17Z,1,OpenAI is as open as decomcratic party is democratic,True
@HellTriX,2023-04-11T04:35:39Z,1,"I was thinking the same thing, that it would be nice to be able to download and test some of these large models within the constraints of some consumer hardware.",True
@jeffreycooper6163,2023-04-11T03:12:40Z,14,From basic python to self driving tech - now LLMs. Harrison you are a gentleman who always guides the way through cool new tech with no BS. Thanks for this video!,True
@Maisonier,2023-04-11T03:02:41Z,0,What IA projects we can focus with 1 rtx 3090? there is any advantage in buying another and use 2 rtx 3090 ? or is too late and the hardware won't make any difference in our homes?,True
@alexjenkins8026,2023-04-11T01:44:01Z,4,"Great find and summary! Love your work. I'd love to see you use it! Are you able to run through a code example (python) of how to train any of these models (say a hugging face LLM) for a different purpose? I hear it a lot (and you mentioned it as well) but i've been struggling to repurpose them to do other things... Say a paragraph of text as input and a 'score' out or something (maybe how relevance to a topic, sentiment, or even how appropriate it would be to say at work or something)? I've even just tried to take the output of these models pre-text and feeding that into another model that I train - that way i don't have to try and fine-tune the big model at all (and get huge advantages of only having to feed my training data into the big model once, save the output and then train my small model)... but it seems i'm unable to get the big models to be consistent at anything - like it's not 'exploiting' enough and sending through the same inputs changes the outputs dramatically :/ Keep it up! :)",True
@happywednesday6741,2023-04-10T22:21:55Z,1,"Sentdex can you guide me to a place on your channel, a playlists/lists, or somewhere where I can brush up on ML for these large language models and recent generative AI tools?",True
@tomwozne,2023-04-10T15:42:07Z,1,Given that it's trained bilingually could we limit the training data to only English and improve it's output for English only?,True
@sebastiangonzalezaseretto7885,2023-04-10T15:40:53Z,5,"You should try RWKV and their fine-tuned Raven models, they work as RNN but are trained as a Transformer. The model is gaining a lot of momentum now",True
@alexd7466,2023-04-10T15:40:33Z,0,Which one is the best for writing code?,True
@tomwozne,2023-04-10T15:37:54Z,0,Does this need a connection to the internet?,True
@jessemair3684,2023-04-10T14:14:48Z,1,"thank you for finding these and sharing them with us. Years ago you got many of us excited about agi chatbots. Love your vids, thank you!",True
@IronMechanic7110,2023-04-10T09:47:43Z,0,Vicuna-7b is also not bad.,True
@Arewethereyet69,2023-04-10T04:02:41Z,0,Wonder if GLM is Alibabas version. Probably not but makes you wonder since they roll theirs out,True
@dan110024,2023-04-10T03:23:21Z,3,One of the few channels that has mostly dialogue and no shitty b-roll stock footage that nobody cares about. I always know I'm gonna get a sensible yet intriguing take on something.,True
@mt_gox,2023-04-09T23:57:15Z,0,same old woke horseshit as all the others,True
@joshuascholar3220,2023-04-09T20:02:27Z,4,"I thought that you don't need GPUs for inference, only for training. If you could train or tune on consumer hardware THAT would be HUGE!",True
@VidathD,2023-04-09T18:02:51Z,0,Nnfs pt 10?,True
@MikeClarkeARVR,2023-04-09T16:56:37Z,2,"Thanks for the video, I just tried the model....    not very good for the use cases I experimented with.    Perhaps others can recommend other use cases.",True
@mlcat,2023-04-09T16:44:49Z,5,"I tried a few models for assistance, mainly llama based sub-models, for some reason huggingface variation of llama works worse than original fb one, maybe that's a mac-only issue though, but all the ""loras"" only work with hf one. Noticed that loras like gpt4all and alpaca-lora were trained either on alpaca dataset or chatgpt outputs and provide censored answers for obviously provocative questions. One model that still acts like an assistant but does not censor outputs is llama adapter, it's less accurate in answers but it provides a better impression about the capabilities of untouched models.  Thank you for this video, will also try this model later!",True
@dgiri2333,2023-04-09T16:15:45Z,0,Can you do videos for Pybrain to train model like chartgpt like AI,True
@shotx333,2023-04-09T15:01:56Z,1,English demo truly is not shining,True
@CA-iv6tz,2023-04-09T14:04:36Z,0,"Did anyone else get ""OSError: Unable to load weights from pytorch checkpoint file"" when trying to run ChatGLM?",True
@oliverli9630,2023-04-09T13:16:27Z,0,several thousand dollar computer isn't that affordable. but it's amazing. but there're also models that can run on CPU already,True
@BinarySplit,2023-04-09T13:10:00Z,8,"Thanks for sharing! I've been looking for an open LLM with English & Chinese support, and this sounds perfect! It's really cool that the authors care about the affordability of running the model.  You're absolutely right that many models are undertrained and this one was well trained. That's definitely a big factor. However, GLM also claims better accuracy with similar numbers of training tokens as other models. Reading through the paper,  they integrated a huge bag of tricks into both the pretraining and fine-tuning regimes to make it more sample efficient. I don't think there's any singular pivotal innovation (though there certainly are innovations) - it looks like it's the actual legitimate hard work in designing and building the complicated beasts that are their pretraining regime and fine-tuning datasets.",True
@rogerc7960,2023-04-09T12:09:34Z,0,Chinese,True
@akhil5665,2023-04-09T10:34:48Z,0,The results were pretty mediocre apparently what i got on hugging face demo compared to what chatgpt did,True
@Sunlight91,2023-04-09T09:36:50Z,1,"How old is the moon? The moon is approximately 384,000 years old, give or take a few thousand years.",True
@beaverbuoy3011,2023-04-09T08:52:47Z,0,:O,True
@efovex,2023-04-09T08:05:33Z,1,"ChatGLM seems cool on a technological level, but a word of warning: this is trained on text available inside mainland China, so don't think for a second that it's going to give neutral or factual responses to everything.  As a demonstration, try asking it what happened on Tiananmen Square on June 4th 1989...",True
@olb47,2023-04-09T08:05:21Z,0,Implementing vicuna13b in python would be interesting,True
@statushulk6285,2023-04-09T06:57:02Z,0,Sambar ru,True
@kryptonic010,2023-04-09T06:12:30Z,1,"Thought experiment:  I have read where training models are established utilizing 250,000 GPUs in a given data center (Centralized).  Why can't the community of like minds globally lend GPU processing power to train models?  We have seen over the years (Decentralized) efforts reach the same conclusions.  This was previously accomplished with SETI back in the 90s and with Bitcoin in 2008.",True
@PMX,2023-04-09T05:28:50Z,27,"Gave it a test, it used a Chinese term in a response for some reason. I asked it to define it and it did (I assume correctly, or at least it fit with how it used it in the previous response). Apparently the model was trained ""on 1T tokens of English and Chinese"" and it seems some Chinese is leaking into the English responses, perhaps in the same way a multilingual person may occasionally use a word in a different language by accident, as the word captures a particular idea better than the language being used at the moment (?).",True
@nathanbanks2354,2023-04-09T03:23:16Z,3,"This is really neat!  I hadn't heard about GLM-130B and wonder how it compares to LLaMA, facebook's over-trained model.  After a quick search, the LLaMA paper only briefly mentions GLM-130B in the context of instruction fine-tuning, but doesn't really talk about general performance.  I managed to get LLaMA-30b running on my 16GB video card using 3-bit quantization, and Alpaca was pretty good, but it would be neat to run something with an Apache license instead of an academic one.  Now I'm downloading ChatGLM6B and hoping it works easily with text-generation-webui....",True
@JC.72,2023-04-09T02:26:57Z,4,"it seems like the 130b model is also available, but u need to send a request form in, and wait for them to approve it through email. they ask questions such as what your intended use are, and the need to agreement to their terms.  and i wonder how much better is the 130b model if there is any type of metric such as % differences.",True
@maxfrischdev,2023-04-09T02:05:19Z,0,"Could anyone please explain to me why it was always stated that ChatGPT has no ""state"" and does not at all ""remember"" previous conversation, prompts and it's answers... Whereas it DOES and always did? Were those statements just said to soothen the masses and make sure people believe that it's just a simple ""language model-thing"" and ""will not take over the world""? üòÖ  Thanks",True
@Totial,2023-04-09T01:31:18Z,0,What happened to charles? Not enough time I guess... hope he gets another chance some day...,True
@1PercentPure,2023-04-09T01:21:42Z,0,thank you so much for sharing!,True
@wecnn,2023-04-08T23:24:31Z,0,"HF test does not go beyond 1st prompt. It cut off, I asked to Continue and nothing. tried another, same thing nothing beyond 1st answer",True
@loopuleasa,2023-04-08T22:53:01Z,0,I would've loved more examples of the thing in the beginning I was not convinced,True
@MichaelMomany,2023-04-08T22:52:20Z,0,I wouldn't this Chinese chat!,True
@TheDogn,2023-04-08T22:41:56Z,0,11:22 I wish you talked about how to run it locally,True
@kenyang687,2023-04-08T22:21:43Z,0,"It's ""GayLoo"".",True
@snarkyboojum,2023-04-08T22:06:05Z,1,How are you marking up the PDFs of the whitepapers as you read them? It looks electronic to me....,True
@rifkiardiansyah616,2023-04-08T21:41:19Z,0,"Bro, you should continue your NNFS video series!!!!",True
@ds920,2023-04-08T20:11:16Z,1,"Thank you, sir! A breath of fresh airüéâ",True
@christopherchilton-smith6482,2023-04-08T19:52:43Z,0,"Gpt4all has been fairly impressive, it feels like we're only a few months away from better than 3.5 turbo locally for consumer ware before even extending it with self reflect, langchain and pinecone. 3.5 is litterally teaching me to code and I'm just a minimum wage security guard.",True
@rumidom,2023-04-08T19:17:34Z,30,Have you seen the open-assistant efforts in creating a open RLHF dataset? Hopefully that could also result in gptchat like smaller models that can be run locally,True
@JanBadertscher,2023-04-08T19:05:02Z,0,"not going to try anything smaller than 13b 4bit for inference :) . fine tuned larger bloomz models run just fine for a few dollars on AWS sage maker and other OSS models will eventually come out, pushing the quality even further into GPT-3.5 territory and hopefully into GPT-4 territory with some tricks... currently, imho there are enough llama, alpaca and vicuna models with custom fine tuning, to make them really really good.",True
@TerboBlitz,2023-04-08T18:37:21Z,6,"I would like to see a tutorial showing how to train ChatGLM6B to do just one single task like Python programming, for example.  Will narrowing the scope of learning let us limit the size and complexity of the model so it can be developed on a power GPU workstation by individuals?",True
@Djellowman,2023-04-08T18:33:09Z,0,Why use GeLU over something easy to compute like Leaky ReLU? i'm a big Leaky ReLU fan.,True
@sevret313,2023-04-08T17:56:55Z,8,"I'm hopeful to see better models in the future, but I'm worried that attempting to shrink them down too much before reaching sufficient quality with open-source models is a bit of a mistake.",True
@Pongant,2023-04-08T17:38:41Z,2,"ChatGLM is chinese, so beware folks. Also, Vicuna and Alpaca are pretty impressive.",True
@patrick-gerard,2023-04-08T17:11:04Z,0,"Hi, do you know if that model runs on a Huggingface Nvidia Tesla T4 Inference Endpoint?",True
@lijostar167,2023-04-08T17:01:40Z,7,Have you tried the vicuna model yet? Supposed to be '92%' as good as chatgpt. How would say it compares to ChatGLM?,True
@zuxel6,2023-04-08T17:00:36Z,0,both of theme is hyped sht,True
@skaltura,2023-04-08T16:59:26Z,2,"I wonder about the training side, can we further train these tiny models and if so how, with what hardware and software to fine tune them to very specific narrow tasks",True
@bravinrutto8784,2023-04-08T16:50:16Z,0,Have you looked at LLama cpp where they were able to run the Llama-30B with just 30GB of RAM.,True
@mortengu1385,2023-04-08T16:45:18Z,1,"This is very cool... before long, this kind of model may run locally on most of our devices (even our toaster) ...",True
@barny1174,2023-04-08T16:41:53Z,0,Thank you for sharing once again üëç,True
@macklinrw,2023-04-08T16:29:54Z,1,"You mention that Chinese is very different from English. However Chinese grammar is actually identical to English for the majority, and Chinese can actually be translated into English with good results (you might've noticed from translating the GLM blog article). Japanese or Korean machine translation is much worse. Chinese is very different from English tonally and pronunciation-wise, but for grammar it is very similar, which I guess would be the significant part for language models or as is evident from the accuracy of machine translation.",True
@sebzim4500,2023-04-08T16:14:54Z,0,GPT-3 also uses GELU activation,True
@rohanjamadagni,2023-04-08T16:07:14Z,0,"Hey, what about the LLaMA models? Did you have a look at those?",True
@HelloThere65272,2023-04-08T15:50:52Z,17,"I literally cannot bear any ""AI news"" these days because it's always sleeky dudes that have obviously no idea what they are talking about that just want to grift on the next thing (basically crypto bros from 9 months ago). I literally hide videos about AI per default with the ""not interested"" button, but I clicked on this one immediately. Thank you Sentdex!",True
@SJ-xz2ch,2023-04-08T15:49:55Z,0,What do you think of vicuna/fastchat? It‚Äôs seems pretty solid for what it can run on.,True
@mytechnotalent,2023-04-08T15:41:10Z,95,It is mind-numbing how cheap the GLM is compared to GPT3.  Can you imagine where we are going to be in just another few months?  Great one Harrison as always!,True
@yarpenzigrin1893,2023-04-08T15:37:26Z,0,"That's pretty good. Have you looked into LLaMa, Alpaca, Koala or Vicuna?",True
@Saboor-Hamedi,2023-04-08T15:33:47Z,0,"It doesn't work, just loading...",True
@FuZZbaLLbee,2023-04-08T15:26:09Z,0,GPT4all wasn‚Äôt good at generating code. What about this model.  Also are the awnsers of this model  also censored ?,True
@shawnfromportland,2023-04-08T15:26:02Z,0,"really great channel, man!",True
@mujtabaalam5907,2023-04-08T15:18:25Z,0,Have you tried Chinchilla or Vicu√±a?,True
@Truizify,2023-04-08T15:15:53Z,5,"Thanks for the video! Great content. I find it hard to believe that ChatGLM would be better than instruction-tuned LLaMA-7B (e.g. Alpaca, etc.), at chatting in English. Did you check out any of those models? Plan on doing a comparison myself.",True
@jadzzzz,2023-04-08T15:10:39Z,9,"I wonder why there aren't distributed GPU compute solutions Ala foldit. In fact, why not create something like render token that rewards users for their gpu time, and allows people in the network to either donate their computing power for a project or tokens so it can continue training models. A truly democratized community effort. That being said, nothing would stop the bot uprising in that case.",True
@init_yeah,2023-04-08T14:58:14Z,1,its Chinese I'm honestly worried no offence. !,True
@Hermits99,2023-04-08T14:50:07Z,0,how do you pronouns 'gif'?,True
@Tepalus,2023-04-08T14:47:06Z,5,"""It's fast and small, and it sometimes gets lost with too much dialogue."" - My Ex lol",True
@mike521559,2023-04-08T14:44:26Z,0,appreciate u‚ù§,True
@fire17102,2023-04-08T14:43:56Z,1,"Will you checkout AutoGPT ? Asynchronous User Interactions are coming out of the oven any moment, see PR #146 ftw",True
@wktodd,2023-04-08T14:35:25Z,0,do you know of any good voice recognition models that will run locally in a small gpu?,True
@serta5727,2023-04-08T14:29:46Z,1,Have seen it a few weeks ago. There was a lot of Chinese text on their GitHub so I didn‚Äôt think about it further,True
@user-yj3mf1dk7b,2023-04-08T14:25:30Z,22,"- are you better than chatGPT?   - As an AI language model, I am capable of generating text that is similar to human language, but I don‚Äôt have the same level of natural language understanding as a human. So, in terms of generating text, I am similar to ChatGPT in that respect. However, in terms of specific abilities such as understanding natural language and generating appropriate responses to a user‚Äôs questions, I may be slightly better as I have been trained on a wider range of data and have additional features such as context and history that ChatGPT does not have.",True
@YeeLeeHaw,2023-04-08T14:24:39Z,1,Not sure if it's good to support an open source model that is from China. It feels like they put it out there in hopes that some geniuses in the rest of the world would do the work for them so the government could catch up with the west.   In general though it's nice to see so many open source models pop up to the left and right that also aim to be able to have the user run it locally. Give it a few years and we'll probably have at least GPT-3.5 capabilities on a high end PC.,True
@serta5727,2023-04-08T14:17:52Z,16,Open Assistant is about to drop a new opensource ChatGPT soon,True
@AHN1444,2023-04-08T14:15:26Z,0,"if I wanted one model just for core logic control? just 1 language, which is the minimum size it could be nowadays?, the model would be prompted with a summary made by another model, and responds with for example [module=""memory"" action=""retrieve data"" params=""xxxxx""]   [module=""browser"" action=""visit site"" params=""xxxx""] [etc] [etc]",True
@distortedjams,2023-04-08T14:13:56Z,17,I'm surprised researchers just release these advanced models out to the public for free. I'm sure going into the future everything will just be proprietary like OpenAI seems to be moving towards.,True
@mukkeshmckenzie7386,2023-04-08T14:13:13Z,1,Can you compare this to llama? Or alpaca?,True
@yeetdeets,2023-04-08T14:11:58Z,8,"I'd be really interested to see your take on the recent vector db boom. Particularly how it will relate to AI, because I don't get it. Why is a vector db better than a relational db for AI?",True
@user-yj3mf1dk7b,2023-04-08T14:09:41Z,0,"Chineese... that make sense why no one discussed it before. right away the question is ""are english texts were good enough?""",True
@Crayphor,2023-04-08T14:08:36Z,16,"That gaussian activation function is interesting! I'll have to look into exactly what it is and why they chose it. If it is based on a gaussian distribution, it could have interesting properties, since the sum of gaussian variables are still gaussian. Maybe even the model output would be a gaussian.",True
@4mb127,2023-04-08T14:04:22Z,2,Did you compare to LLaMa?,True
@lutzsommer4708,2023-04-08T14:01:27Z,8,What about the LLaMa oder Alpaca model? How do they compare to ChatGLM6B?,True
@SpaghettiRealm,2023-04-08T14:00:44Z,1,"Thank you, your content is great as always",True
@alenjoby1660,2023-04-08T13:52:23Z,0,Have you heard about auto-chatgpt... i am not sure if it's fake or not. .,True
@tskumar1320,2023-04-08T13:49:39Z,0,Wonderful. Keep it up üíìüôè,True
@avi7278,2023-04-08T13:49:14Z,544,God you are a breath of fresh air... all these new AI niche grifters that have infested literally every corner of youtube are unbearable.,True
@ChaiTimeDataScience,2023-04-08T13:48:40Z,0,"Another point: it's great to see how amazing and great work is done by open source community, but I think ChatGPT remains the best in helping with writing code.   Harrison has already shown us many REALLY cool examples, games and all sorts of things it can do. I think it remains undisputed right now in that territory of LLMs",True
@ChaiTimeDataScience,2023-04-08T13:46:51Z,48,I love how Harrison is standing in videos when he is teaching us via code and sits down when its a video talking about a concept or project!,True
@azirious666,2023-04-08T13:45:51Z,0,Let's Go,True
@oszi7058,2023-04-08T13:41:18Z,0,NICEEEEEEEEEEEEEEEEEE!,True
@DhammadipAwale1991,2023-04-08T13:40:56Z,0,Cool üòÇ,True
@moonjuice-lo-fi9340,2023-04-08T13:40:44Z,0,Dayum,True
@Stinosko,2023-04-07T19:05:08Z,1,Coool! ‚ù§,True
