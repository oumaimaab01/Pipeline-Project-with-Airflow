author,updated_at,like_count,text,public
@user-zr2js5vs8b,2024-04-06T05:08:38Z,1,Ready go copy that ‚ù§,True
@mudassarm30,2023-06-19T18:07:03Z,0,Creating a chatbot with Deep Learning and TensorFlow ... and you have spent 5 lectures on basics of python ... I think your lectures should start from this lecture 6,True
@asonofyah4341,2022-05-07T05:04:10Z,0,"Is anyone else having an issue with finding the ""test.from"", ""test.to"", files after running? I only see a database file that was created in my project folder.",True
@casperswayze4988,2022-04-01T18:11:35Z,0,"i am getting this error for 2017-09 as no such table parent_reply.  need help here. tried putting parent != 'False' as below: df = pd.read_sql(             ""SELECT * FROM parent_reply WHERE unix > {} AND parent NOT NULL AND parent != 'False' AND score > 0 ORDER BY unix ASC LIMIT {}"".format( last_unix, limit), connection)  still not working",True
@Old_SDC,2021-12-18T17:09:55Z,0,For later 9:50,True
@herbertrafael8001,2021-04-01T02:20:29Z,0,Does the bot really give coherent answers if you only use train.from and train.to with less than 1000kb?,True
@c.b.t6738,2020-10-27T20:22:53Z,0,f strings were introduced in python after this tutorial ....,True
@zombiesalad2722,2020-10-14T07:37:29Z,0,">if you have less than 100K pairs then I wouldn't suggest following along. I only have 4K pairs, and I guess it's going to be a disaster.",True
@kynnguyen46,2020-10-06T03:33:52Z,2,"Hi guys, if you have this problem:  last_unix = df.tail(1)['unix'].values[0] IndexError: index 0 is out of bounds for axis 0 with size 0  Actually, I don't know exactly how to fix this, but you should use the file ""RC_2015-05"" for your project link: https://files.pushshift.io/reddit/comments/ scroll and select ""RC_2015-05.bz2"" This is a RAR file, so it's only 5.6 GB, if you unzip it, that file is 32GB. Make sure you have enough free disk space on your computer. Enjoy.",True
@dimasokva8673,2020-05-21T19:04:18Z,1,"why all my ""parent"" parts are null ? can u help me pls :(",True
@koushikdas9285,2020-05-10T07:32:28Z,0,"I run this code but it shows this type of errors how can i fix this problem.    Traceback (most recent call last):    File ""C:\Program Files\Python38\lib\site-packages\pandas\io\sql.py"", line 1586, in execute     cur.execute(*args, **kwargs) sqlite3.OperationalError: no such table: parent_reply  The above exception was the direct cause of the following exception:  Traceback (most recent call last):   File ""C:\Users\Kausik\sqlite\sqlite-tools-win32-x86-3310100\chatbotProject\create_training_data.py"", line 17, in <module>     df = pd.read_sql(""SELECT * FROM parent_reply WHERE unix > {} and parent NOT NULL and score > 0 ORDER BY unix ASC LIMIT {}"".format(last_unix,limit),connection)   File ""C:\Program Files\Python38\lib\site-packages\pandas\io\sql.py"", line 406, in read_sql     return pandas_sql.read_query(   File ""C:\Program Files\Python38\lib\site-packages\pandas\io\sql.py"", line 1633, in read_query     cursor = self.execute(*args)   File ""C:\Program Files\Python38\lib\site-packages\pandas\io\sql.py"", line 1598, in execute     raise ex from exc pandas.io.sql.DatabaseError: Execution failed on sql 'SELECT * FROM parent_reply WHERE unix > 0 and parent NOT NULL and score > 0 ORDER BY unix ASC LIMIT 5000': no such table: parent_reply",True
@whistlingasoline999,2020-04-24T02:31:33Z,3,"So whenever I run this code I get this error:   Traceback (most recent call last):   File ""(python file name)"", line 18, in <module>     last_unix = df.tail(1)['unix'].values[0] IndexError: index 0 is out of bounds for axis 0 with size 0  I thought it might have something to do with the specific month I downloaded for the reddit comments, but I've tried 3 different files now (2019-09, 2017-10, and 2015-06) to no avail. I also literally tried copying and pasting the code from pythonprogramming to make sure I had it right, and I still can't get it to work. Any ideas? I'm using PyCharm with Anaconda if that matters.",True
@nikhilambavaram6006,2020-04-16T20:55:04Z,1,pandas.io.sql.DatabaseError: Execution failed on sql 'SELECT * FROM parent_reply WHERE unix > 0 and parent NOT NULL and score > 0 ORDER BY unix ASC LIMIT 5000': no such table: parent_reply can someone help,True
@anirbanghosh6328,2020-04-04T08:16:42Z,0,"40 mil rows read, 3.3 mil paired rows, and its still running, but i cant wait anymore",True
@vk1094,2020-02-16T08:28:55Z,0,"has anyone prepared the db whole night was spent, but got only like 100000 pairs approx 60mb of db. If anyone has Db please share",True
@RRKS_TF,2020-01-10T10:36:44Z,0,"i keep getting a Index error, IndexError: index 0 is out of bounds for axis 0 with size 0. (  line 16, in <module> last_unix = df.tail(1)['unix'].values[0] IndexError: index 0 is out of bounds for axis 0 with size 0 )",True
@pemessh,2020-01-05T09:06:32Z,3,They say in machine learning you spent 60 - 70 percent of your total time in preprocessing the data. I couldn't agree more. This is part 6 of 9 and we are still haven't got into machine learning/dl yet.   Love your content. Regards from Nepal üôè,True
@PavanKumar-jc1qn,2019-11-14T22:26:24Z,0,Can I create a tensorflow input datapipeline using tf.data with some databases as backend. Most of the resources have either .tfrecord or .csv.,True
@EranM,2019-11-14T10:39:12Z,0,11:52 line 36,True
@fgvcosmic6752,2019-08-16T22:26:57Z,0,Ah. I was.... using 40000 pairs.....,True
@rahul7charan,2019-06-21T06:13:25Z,0,"#Error    #sentdex ===================================================================================== IndexError                                Traceback (most recent call last)  <ipython-input-15-e9c45b51a028> in <module>       19         df = pd.read_sql(""SELECT * FROM parent_reply WHERE unix > {} and parent NOT NULL and score > 0 ORDER BY unix ASC LIMIT {}"".format(last_unix,limit),connection)       20   ---> 21         last_unix = df.tail(1)['unix'].values[0]       22        23         cur_length = len(df)    IndexError: index 0 is out of bounds for axis 0 with size 0  =====================================================================================   -->> 1). I am getting this error, can you help me out.         2). After doing some research, I have found that in my 2007_08.db file parent column contains all NULL values, so not able to read it by pandas.    3).  Where I am doing wrong.",True
@mockingbird3809,2019-06-13T10:18:40Z,0,"Here is the Better Way:   with open(f""{'train.to' if test_done else 'test.to'}"",""a"",encoding=""utf8"") as f:    for content in df['parent'].values:     f.write(content + ""\n"") with open(f""{'train.from' if test_done else 'test.from'}"",""a"",encoding=""utf8"") as f:    for content in df['comment'].values:     f.write(content + ""\n"")",True
@GrymmSunbane-xi7nr,2019-06-09T08:18:57Z,0,I HAVE BEEN WORKING MY ASS OFF TO FIX THIS STUPID ERROR FOR 3 DAYS NOW AND NO LUCK! Pandas and LITERALLY ANY OTHER MODULE treats the database as if its empty. Why? I confrimed that the data IS in the database file. But I guess it isn't. Even though I can open it elsewhere and LOOK RIGHT THE FUCK AT IT.......................Somebody please help me,True
@danieldossantos5868,2019-05-30T11:23:41Z,0,"line 20, in <module>     with open('test.from', 'a', encoding='utf8') as f: PermissionError: [Errno 13] Permission denied: 'test.from'",True
@subratode7086,2019-03-28T15:44:33Z,0,"i hv edited one part            df = pd.read_sql(""SELECT * FROM parent_reply WHERE unix > {} and parent_id NOT NULL AND parent_id!='False'AND score > 0 ORDER BY unix ASC LIMIT {}"".format(last_unix,limit),connection)         if df.count==0:                last_unix = df.tail(1)['unix'].values[0]             cur_length = len(df)   after executing the modified file i am getting the results but the results never seems to stop   it goes on...from thousands,...to millions..... i am also getting the files but the are of 0bytes   could u plizz help me.. in solving this problem it would be nice of you plizzzzz i nd help",True
@subratode7086,2019-03-27T16:18:39Z,0,how to solve the index eerror plizz help me,True
@amineboujida1276,2019-01-21T03:14:38Z,0,"Could you please share the modified data , the data you'll feed directly to the model cause when i'm uncompressing the 1 month it gives me a Unix executable , please help thank you",True
@GuilhermeDias801,2018-12-31T08:02:03Z,0,"Hello sir, i'm very interested in your project, and 'im trying to do it myself, but i need my chatbot more ""scientific"", so i was trying to select wich comments will show up using the filter on the SLQ browser, manually removing unacessary comments. But thats a lot of data, cause i got the 1.7Bi comments data, and removing by hand is a little bit tedious, and i can't figure out how to do it directly on python, so if you can help me with this will be very nice. And one more thing, I was trying to do all the data on a same Data Base File, but i can't figure out how to do it too, i reached at the point that the program just do every single month, but it saved  separately and I want everything on a same DBF to make a really cool chatbot. Please help me!!!",True
@amitsinha8328,2018-11-06T08:07:54Z,0,Whenever i am running the program it is not creating the 'train.from' and 'train.to' file. Please help,True
@felixisaac,2018-10-28T08:09:48Z,1,how to install pandas?,True
@buckiez,2018-10-12T05:12:07Z,1,"0:25 damn, I only had 99,999 pairs.",True
@StockResearchHub,2018-09-30T12:53:57Z,5,Error: IndexError: index 0 is out of bounds for axis 0 with size 0 for the line last_unix = df.tail(1)['unix'].values[0] does anyone has a solution,True
@AlexSage,2018-09-29T15:16:03Z,0,"I have an idea but I need a team of coders like sentdex to create the most powerful AI, otherwise it'll take several decades to create something that can be accomplished within half a year... None of the currently leading AI's have such thought process... However, I don't want anyone other than the team to know about what's being built... Who wants to venture in the potential trillion dollar project? Why trillion because everyone will need this, just like the internet...",True
@Daedalus257,2018-09-22T20:22:25Z,0,I tried to run the create_training_data script and the TO and FROM files were not created. What am I doing wrong?,True
@balamanikandanjayaprakash6378,2018-08-26T05:50:01Z,0,"hi am getting this error while reading from database could anyone help me please Traceback (most recent call last):   File ""C:\Users\maney\AppData\Local\Programs\Python\Python35\lib\site-packages\pandas\io\sql.py"", line 1378, in execute     cur.execute(*args) sqlite3.OperationalError: disk I/O error  During handling of the above exception, another exception occurred:  Traceback (most recent call last):   File ""C:\Python27\programs\FileCreation.py"", line 23, in <module>     df = pd.read_sql(""SELECT * FROM parent_reply WHERE unix > {} and parent NOT NULL and score > 0 ORDER BY unix ASC LIMIT {}"".format(last_unix,limit),connection,engine)   File ""C:\Users\maney\AppData\Local\Programs\Python\Python35\lib\site-packages\pandas\io\sql.py"", line 381, in read_sql     chunksize=chunksize)   File ""C:\Users\maney\AppData\Local\Programs\Python\Python35\lib\site-packages\pandas\io\sql.py"", line 1413, in read_query     cursor = self.execute(*args)   File ""C:\Users\maney\AppData\Local\Programs\Python\Python35\lib\site-packages\pandas\io\sql.py"", line 1390, in execute     raise_with_traceback(ex)   File ""C:\Users\maney\AppData\Local\Programs\Python\Python35\lib\site-packages\pandas\compat\__init__.py"", line 404, in raise_with_traceback     raise exc.with_traceback(traceback)   File ""C:\Users\maney\AppData\Local\Programs\Python\Python35\lib\site-packages\pandas\io\sql.py"", line 1378, in execute     cur.execute(*args) pandas.io.sql.DatabaseError: Execution failed on sql 'SELECT * FROM parent_reply WHERE unix > 0 and parent NOT NULL and score > 0 ORDER BY unix ASC LIMIT 5000': disk I/O error   first time it stopped in 625000 with this error but i had 2.5 million pairs. and i couldn't make a copy of the database file too.  i have opened question in stackoverflow so that everyone gets benefitted please help. https://stackoverflow.com/questions/52023660/disk-i-o-error-when-reading-from-sql-into-python",True
@user-gw8ce1ew1c,2018-08-07T02:00:59Z,1,"i cant fix this too..: pandas.io.sql.DatabaseError: Execution failed on sql 'SELECT * FROM parent_reply WHERE unix > 0 and parent NOT NULL and score > 0 ORDER BY unix ASC LIMIT 5000': no such table: parent_reply  when i checked project's db file, it was empty So I replaced it with a db file created from the previous video, but this time I didn't print anything.",True
@dandingooo3914,2018-07-30T11:12:43Z,1,"I got this error when I ran. Anyone else?   numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88",True
@biswadeepupadhyay180,2018-07-05T08:02:52Z,0,what is the application you are using to view those To and FROM files?,True
@grimmeeh,2018-06-23T15:14:08Z,0,"Been trying on and off to find out whats wrong, cant figure it out(im new to python) can u please help me   -> 18         last_unix = df.tail(1)['unix'].values[0]      19         cur_length = len(df)      20   IndexError: index 0 is out of bounds for axis 0 with size 0  why am i getting this?? o.O",True
@piotrekgor18,2018-06-13T19:47:54Z,2,Wouldn't that be better if you allowed parent comments to have multiple children instead of updating the existing one?,True
@grimmeeh,2018-06-05T20:28:26Z,1,"---> 18         last_unix = df.tail(1)['unix'].values[0]      19         cur_length = len(df)      20   IndexError: index 0 is out of bounds for axis 0 with size 0  why am i getting this?? o.O",True
@grimmeeh,2018-06-05T11:38:46Z,0,"How many rows did you read in? My computer is super slow and i only got 4,6 million rows in 4 hours??",True
@pranaymarella2260,2018-05-29T09:18:32Z,0,What is the point of having the if not and the else loop? I don't understand. Could you please expand?,True
@yashwanth59,2018-05-23T13:58:52Z,3,my test.from and test.to do not have same number of lines. Is anyone else having this problem?,True
@Kokobong1337,2018-05-09T00:51:13Z,0,So i'm havin this error with the pandas.read_sql where it says no such table even though the table exists :s tried running everyithing all over again (with deleting the previous database) and still didn't work. Anyone here can enlight me please ?,True
@Penguinz-fr1mu,2018-05-06T08:28:41Z,1,How can I see what percentage has finished processing?,True
@aarooshpandoh3660,2018-04-18T15:05:44Z,1,"what does test.from , test.to and train.from, train.to do",True
@damenstravels9810,2018-04-15T23:27:06Z,0,"Project won't compile with ""encoding='utf-8'"" says that this parameter does not match the required arguments... any suggestions? Thanks!",True
@pritishsinha8647,2018-04-11T06:31:32Z,0,I am getting empty test.from test.to train.from and train.to. Files are empty and so the sizes are 0kb. Help me out please,True
@violanteandre,2018-03-15T20:43:54Z,2,"I'm having the issue below. I'm using a different dataset (2018-01). When I created the sqlite db I got ""Total Rows Read: 91500000, Paired Rows: 443,854"" so I got a decent amount of pairs (less than I thought). I browsed the db and I have parent_reply, parent, comment, etc. I have a lot of NULL values in parent column. Any help would be awesome, thanks!    File ""<ipython-input-12-ee71ff4a3508>"", line 20, in <module>     last_unix = df.tail(1)['unix'].values[0]  IndexError: index 0 is out of bounds for axis 0 with size 0  Github https://github.com/aviolante/Chatbot_Example/blob/master/Chatbot_Example.py",True
@shobhamourya8396,2018-03-12T07:40:20Z,1,"Very cool! I got 394497 parent-comment pairs in train files.  Had to tweak the sql a bit, added condition parent != 'False' as below: df = pd.read_sql(             ""SELECT * FROM parent_reply WHERE unix > {} AND parent NOT NULL AND parent != 'False' AND score > 0 ORDER BY unix ASC LIMIT {}"".format( last_unix, limit), connection)",True
@shubhamgoyal7596,2018-03-10T20:51:33Z,6,can you upload train.from train.to test.from test.to files at pythonprogramming.net,True
@anakritika3559,2018-02-17T06:36:26Z,0,"File ""C:\Program Files\Python35\lib\site-packages\pandas\io\sql.py"", line 1409, in execute     cur.execute(*args) pandas.io.sql.DatabaseError: Execution failed on sql 'SELECT * FROM parent_reply WHERE unix > 0 and parent NOT NULL and score > 0 ORDER BY unix ASC LIMIT 5000': no such table: parent_reply   i am getting this error.  Please help",True
@codemaverick69,2018-01-16T15:34:18Z,2,"Hello Harrison, thanks for this amazing tutorial. I'm encountering this error:  lastUnix = dataFrame.tail(1)['unix'].values[0] IndexError: index 0 is out of bounds for axis 0 with size 0 . How do i get about it. tried all that i know.",True
@TheBus1234,2018-01-15T13:05:44Z,0,WOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOW RESPECT ...,True
@diptiranjandash8877,2018-01-12T06:05:12Z,0,hello @sentdex  ! can you please share the github link ?,True
@Juice669669,2018-01-05T20:34:58Z,0,"there is a new list for november 17 but after 900000 lines I get an error stating that score doesnt have a type so I cant do score >= 2, I will print those rows to see what the deal is",True
@BDYH-ey8kd,2018-01-01T19:22:46Z,0,Hmm.. the programming doesnt flow organicly. U dont write from top to bottom in 1 go. In the first few u made small methods after it became aparant u needed them. Here u already make the last unix before needing it :(,True
@tejdeeps,2017-12-29T18:35:28Z,1,your SQL statement should be this as there is no column name parent.   SELECT * FROM parent_reply WHERE unix > {} and parent_id NOT NULL and score > 0 ORDER BY unix ASC LIMIT {} .  The correct column name is parent_id.   and did the same mistake in writing test.from and train.from,True
@markstraatman8780,2017-12-29T01:46:46Z,0,did you get a standing-workdesk? (a workdesk you can work at standing upright),True
@muhamedessamai1494,2017-12-23T09:27:58Z,0,"Guys i really need help at this .. i run this code on Ubuntu python 2.7 ... and it run normally without bugs but it gives me nothing seems like it did nothing ... it doesn't even print or create that 4 files ...  import sqlite3 import pandas as pd import io  timeframes = ['2015-01']  for timeframe in timeframes:  connection = sqlite3.connect('/media/meracoda/Private/1st term 3rd mecha/RC_2015-01.db' ) c = connection.cursor() limit = 5000 last_unix = 0 cur_length = limit counter = 0 test_done = False  while cur_length == limit:  df = pd.read_sql(""SELECT * FROM parent_reply WHERE unix > {} and parent NOT NULL and score > 0 ORDER BY unix ASC LIMIT {}"".format(last_unix,limit),connection) last_unix = df.tail(1)['unix'].values[0] cur_length = len(df)  if not test_done:     with io.open('test.from','a', encoding='utf8') as f:         for content in df['parent'].values:             f.write(content+'\n')      with io.open('test.to','a', encoding='utf8') as f:         for content in df['comment'].values:             f.write(unicode(str(content))+'\n')      test_done = True  else:     with io.open('train.from','a', encoding='utf8') as f:         for content in df['parent'].values:             f.write(content+'\n')      with io.open('train.to','a', encoding='utf8') as f:         for content in df['comment'].values:             f.write(unicode(str(content))+'\n')  counter += 1 if counter % 20 == 0:     print(counter*limit,'rows completed so far')",True
@PhotoSlash,2017-12-22T14:05:18Z,0,what's the difference between test files and train files? test files contain DB paired parent and comment tables but i don't understand where train files datas are picked from,True
@panospa,2017-12-19T03:35:53Z,0,"After thousands of successful writing iterations, I get a PermissionError: [Errno 13] Permission denied.  There's no consistency to the error other than it typically occurs after 300,000 rows or so (no specific cutout).  I stumbled on a similar stack question whose responses suggested ""maybe some ""bug"" when trying to write to the same file too ""often"""" - any other ideas/suggestions by any chance?",True
@rj-nj3uk,2017-12-17T05:11:27Z,0,Please zoom in text on editor is too small.,True
@DariusMo,2017-12-11T16:29:40Z,4,i cant fix this: pandas.io.sql.DatabaseError: Execution failed on sql 'SELECT * FROM parent_reply WHERE unix > 0 and parent NOT NULL and score > 0 ORDER BY unix ASC LIMIT 5000': no such table: parent_reply,True
@FalcoGer,2017-12-10T21:21:35Z,0,"what is pandas. why not more in code comments? i mean, you explain everything, but for someone not having the time to look through the code and figuring things out from there, it'd be nice to write some in comments for variables and stuff. why do you use """"blah {} blah {} blah {}"".format(""1"", ""2"", ""3"")? I think it disconnects the whole string and makes it hard to read, especially with long strings such as those queries. ""blah "" + ""1"" + "" blah "" + ""2"" + "" blah "" + ""3"" is much easier to read. also if you insert something, or delete something you have to adjust at two points, and with complex strings and no comments and no line breaks in your code this might take you a few seconds. imagine you want to insert ""1.5"" in between ""1"" and ""2"". first you have to change the string itself to include a {} and then you have to go to the end, figure out what's what, perhaps even in something like format(arg[0], arg[1], arg[5], arg[3], str(function(val))), and where it is in the string, or count the ""{}"" in the string before the position where you want to insert, then put it there. it's a nightmare that can be easily avoided by just concatinating your string together. so why bother with .format()? it seems like a bad design choice to me. I mean just with your last_unix and limit it took you 5 seconds to double check if you remembered everything. and that wasn't even an overly complex string. on the other hand, why do you do content + '\n'? and not ""{}\n"".format(content)? also what's with all the single quotes? it's common practice to use single quotes for single characters and double quotes for strings of characters. why are they the same in python, and why does no one care for the convention that's used in nearly every other programming language that has strings and characters? Why do you make a database if you are just gonna dump all those strings back into two files anyway?",True
@binksbiz8911,2017-12-06T03:43:15Z,0,Can we read directly from bz2 files without first decompressing them?,True
@BeepDerpify,2017-12-04T15:27:58Z,4,"I keep getting this error:   File ""C:/Users/[username]/PycharmProjects/MLchatbot/create_training_data.py"", line 18, in <module>     last_unix = df.tail(1)['unix'].values[0] IndexError: index 0 is out of bounds for axis 0 with size 0  I'm not sure what is wrong. It might be my database - I'm using a month of 2017 instead. There was only one difference as far as I know and that was 'name' was now 'id' in the data. Also when I ran the transaction program I didn't get any paired rows on my counter out of millions of comments.  Any idea what I might be doing wrong?",True
@39fredy,2017-12-04T02:51:40Z,0,"How long should making these training and test files take ? My database has 16 million entries (3 months worth of Reddit data) the print statement has only printed once (so between 100k-200k entries have been written to the files) and its been running for about 3-4 hours, this seems a little too long. What could be going on ?",True
@johnhackley7054,2017-12-03T13:43:15Z,8,"<FML> In def format_data(data): I typed '/n' and '/r' instead of '\n' and '\r'.  I fully populated the database twice and generated the test & train files multiple times trying to find my errors.  Finally, I was like, ""do I have to use \ to escape the \n and \r?"" and that's when I noticed I used the wrong slash. </FML> Anyways, thanks for the great tutorials!  I've enjoyed so many of them.",True
@AnimeshBasak,2017-12-03T10:08:48Z,0,I have done the previous segment and I am eager to know how many more videos will be coming till the project is completed?,True
@zhengqunkoo,2017-12-03T09:56:25Z,2,"Running this without LIMIT only consumes 512mb RAM, and takes 6 seconds. Ran this on SQL database  of 1.6gb.",True
@thanga511,2017-12-03T09:10:40Z,0,"Waiting for  a Chatbot with Deep Learning, Python, and TensorFlow p.7",True
@saurabhjadhav6496,2017-12-03T07:43:48Z,0,How to deploy a chat bot written in python to a website using google firestore with using firestore cloud database?,True
@AhmadM-on-Google,2017-12-03T04:53:37Z,2,"great work buddy, pal. wait thats not how it works xD",True
@HellTriX,2017-12-03T04:07:05Z,2,"@sentdex  Your videos are top notch. Out of all the coding videos on youtube, you are probably at the top with your ability to code quickly, speak fluently, explain what your doing, and not adding ""umm, uh,, uh, to every sentence you say"" It is quite refreshing.",True
@zhengqunkoo,2017-12-02T23:49:51Z,0,Is it safe to drop all parent NULL rows from our SQL database? What's the purpose of keeping those rows?,True
@Thales418,2017-12-02T21:14:51Z,12,I just unsubscribed!!!!        So I could subscribe again! Great Channel!,True
@mylifebeflyffable,2017-12-02T18:31:03Z,1,I am really hyped for the next videos in this series. Great work my friend!,True
@julianodbz,2017-12-02T17:58:51Z,2,Is that Snowden?,True
@shivaraj-bh,2017-12-02T17:10:46Z,0,"I paused at 10:55 and saw that ur 2015-5 db is 110,168kb and I have been running it from past 3 days and my 2015-01 db has reached 645,000kb .... It's probably gonna take another 18-20 days to store database of entire month....",True
@darshild5853,2017-12-02T16:53:46Z,0,"I've learned a great deal from your videos. Big thanks for that!  Also, wondering if you could make a quick one about how to automate running a python script (ex: every day at 1PM) from scratch at some point?",True
@sumitaggarwal9477,2017-12-02T16:17:07Z,1,"awesome video as always.........right now i am following your ML and pandas video series they are awesome as well please.....keep doing what you are doing, one more thing........is Edward Snowden your brother or something?",True
@DeveloperPA,2017-12-02T15:59:00Z,1,I have a question. Why did we make the sql database of every comment with score and such previously when we could have made these to/from files from the start? Are we ever going to look back to that database or were we just using it as a step to make the to/from files easier to make?,True
@walidmujahid,2017-12-02T15:32:43Z,3,It is out! I was checking your channel everyday just in case an email was not sent.,True
@Semyazi,2017-12-02T15:16:58Z,53,I wish I could like this twice.,True
@RiteshKumarMaurya,2017-12-02T15:13:48Z,1,"Hi Harrison, Great video. Can you please provide the Trained Model?",True
@xarifsowad849,2017-12-02T14:18:22Z,0,ohhhh awesome.....Harrison u are so much excited...like me...haha,True
@sak8485,2017-12-02T13:49:17Z,1,Can you make videos on Data Structures with python,True
@charleswinthrop71,2017-12-02T13:45:28Z,0,Yay! This really improved my mood!   But one little question: Is it possible to filter the data to exclude certain keywords from the training data?,True
@umangkr257,2017-12-02T13:32:23Z,11,What took you so long man?? Was eagerly waiting for the video,True
@metehan23804,2017-12-02T13:31:21Z,7,"Super awesome series, as always. Thanks a lot!",True
