author,updated_at,like_count,text,public
@nikosmparoutis221,2021-04-28T15:31:28Z,0,Now it is per character for Natural Language.,True
@trs_4612,2020-12-07T04:48:54Z,0,can we incorporate in Xcode to make iOS apps? swift package has something similar but does not support the language i want (vietnamese,True
@palakjain2505,2020-08-17T07:12:17Z,0,Did you pip install anything?,True
@rawahamuhammad7805,2020-08-04T12:34:55Z,3,The way he kept hitting 4x spaces instead of a tab really pissed me off.,True
@christianancheta7230,2020-05-29T07:36:05Z,0,If you do the math the label detection is 4x the price as the natural language API. Vision costs 4x more...,True
@QuenAxii,2020-04-23T21:31:50Z,0,"For anyone still wandering: 1000 characters equal at least 1 unit (800 chars = 1 unit, 1000 chars = 1 unit, 1300 chars = 2 units ...)",True
@RhinoTurner1991,2019-12-13T21:14:04Z,0,"Not sure if this is a change since you uploaded this video or if you ever found it but 1 unit is based on the number of documents sent to the API. If the document has more than 1,000 unicode characters then it is considered multiple units one per 1000 characters. https://cloud.google.com/natural-language/pricing#pricing_units",True
@spellweavergeneziso,2019-11-04T18:27:08Z,0,'Is it not obvious that python is the best programming language of them all?' ^^THIS^^,True
@lalithshankar8647,2019-10-22T15:54:03Z,0,"HI, i am getting this error any idea on what to do?   File ""<stdin>"", line 1, in <module> AttributeError: 'tuple' object has no attribute 'score' >>> for e in entities: ...     print(e.name, e.entity_type, e.metadata, e.salience) ...  Traceback (most recent call last):   File ""<stdin>"", line 2, in <module> AttributeError: name",True
@GodisGreater01,2019-10-16T18:07:05Z,0,What do you think would be better for PDF ocr. Google cloud or aws textract?,True
@petersamoaa8535,2019-05-30T06:46:18Z,0,Sorry but your code doesn't work with me  it rise this error  module 'google.cloud.language' has no attribute 'Client',True
@MAamirMursleenPakistan,2019-04-20T20:06:37Z,0,"How can I save the file into excel with each separate column for each value, Sir?",True
@ashutoshtiwari3785,2019-02-23T19:41:09Z,0,What os are you using?,True
@syednooruddin4136,2018-11-26T07:25:49Z,0,"how do i save file, i mean CTRL+ what?",True
@le3ronjam3s43,2018-09-10T14:42:25Z,3,If anyone is getting the: has no Client() error. Try: client = language.LanguageServiceClient(),True
@patrickadjei9676,2018-08-24T21:09:56Z,3,You're smart an all but your explanations are bad especially for people trying to understand instead of copy and pasting...,True
@xMacTac,2018-07-11T13:42:31Z,1,en TITIES,True
@jrM5492,2018-07-07T04:20:02Z,0,"In the new google nlp doc, tried with entity analysis. returned error: NameError: global name 'six' is not defined",True
@harmanpreetsingh-xq7wy,2018-06-08T02:40:03Z,0,can upload a video using google cloud speech to text API ?,True
@carlosaguilar6246,2018-05-16T15:56:20Z,3,"This code works with de actually functions of natual language  from google.cloud import language from google.cloud.language import enums from google.cloud.language import types  def language_analysis(text):  client = language.LanguageServiceClient()  document = types.Document(content=text,type=enums.Document.Type.PLAIN_TEXT)   sent_analysis = client.analyze_sentiment(document=document)  print(dir(sent_analysis))  sentiment = sent_analysis.document_sentiment    ent_analysis = client.analyze_entities(document=document)  entities = ent_analysis.entities  return sentiment, entities  example_text = 'is it not obvious that python is the best programming language' sentiment, entities= language_analysis(example_text) print(sentiment.score,sentiment.magnitude)  for e in entities:  print(e.name, e.type, e.metadata, e.salience)",True
@saurabhrathor5145,2018-04-08T08:00:35Z,0,Great video. It is really easy to learn from your video as compared to reading from Documentation. I have also updated the code as per new API structure. You can find that in - https://github.com/saurabhrathor/GCloud_ML_API_experiment,True
@jians9107,2018-04-03T13:04:40Z,1,"Fixes for the new Google Cloud API:  from google.cloud import language  def language_analysis(text):         client = language.LanguageServiceClient()         document = language.types.Document(content=text, type='PLAIN_TEXT')         sen_response = client.analyze_sentiment(document=document, encoding_type='UTF32')         sentiment = sen_response.document_sentiment         ent_response = client.analyze_entities(document=document, encoding_type='UTF32')         entities = ent_response.entities         return sentiment, entities  example_text = ""Thank you""  sentiment, entities = language_analysis(example_text) print(sentiment.score, sentiment.magnitude)  for e in entities:         print(e.name, e.salience)",True
@yozora4895,2018-03-22T03:21:25Z,0,Is it possible to upload the code into a interactive web page?,True
@junkmail75034,2018-02-15T16:09:57Z,0,"Thank you for this tutorial. The API has changed a lot since your video, especially regarding how a client is instantiated.  This is my natlangex.py and screen output that I copied straight from terminal:  kxxxxx75034@nlp-2:~$ sudo apt-get install htop kxxxxx75034@nlp-2:~$ sudo su  root@nlp-2:~/gcloudstuff# sudo apt-get update root@nlp-2:~/gcloudstuff# sudo apt-get install python-pip root@nlp-2:~/gcloudstuff# sudo piop install google-cloud  -- go to API Manager, create apikey. upload that apikey to GC home dir.  copy of my code natlangex.py:    from google.cloud import language from google.cloud.language import types from google.cloud.language import enums def language_analysis(text):     client = language.LanguageServiceClient()     document = types.Document(content=text, type=enums.Document.Type.PLAIN_TEXT)     sent_analysis = client.analyze_sentiment(document=document).document_sentiment #    print(dir(sent_analysis))     sentiment = sent_analysis     ent_analysis = client.analyze_entities(document).entities     entities = ent_analysis     print(dir(entities))     return sentiment, ent_analysis example_text = 'Kimberly Guifoyle is a lawyer who also works for Fox News in New York City. She is smart, eloquent, and beautiful. At the same time she can also be funny and witty.' sentiment, entities = language_analysis(example_text) print(sentiment.score, sentiment.magnitude) for e in entities:     #print(e.name, e.entity_type, e.metadata, e.salience)     print(e.name, e.type, e.metadata, e.salience, e.metadata.get('wikipedia_url', '-'))   root@nlp-2:~/gcloudstuff/natlangex# python natlangex.py  ['MergeFrom', '__class__', '__deepcopy__', '__delattr__', '__delitem__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__le__',  '__len__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'add', 'extend', 'pop', 'remove', ' sort'] (0.5, 1.600000023841858) (u'Kimberly Guifoyle', 1, <google.protobuf.pyext._message.ScalarMapContainer object at 0x7fb8657646c0>, 0.9132684469223022, u'https://en.wikipedia.org/wiki/Kimberly_Guilfoyle') (u'Fox News', 3, <google.protobuf.pyext._message.ScalarMapContainer object at 0x7fb865764710>, 0.043365780264139175, u'https://en.wikipedia.org/wiki/Fox_News') (u'New York City', 2, <google.protobuf.pyext._message.ScalarMapContainer object at 0x7fb865735710>, 0.043365780264139175, u'https://en.wikipedia.org/wiki/New_York_City') root@nlp-2:~/gcloudstuff/natlangex#",True
@asmaturki5637,2018-01-08T07:25:40Z,0,thank youuu please keep doing videos :D :D,True
@karmaalab5373,2018-01-04T07:29:56Z,0,"AttributeError: module 'google.cloud.language' has no attribute 'Client' and after changing Client to LanguageServiceClient() client = language.LanguageServiceClient() i'm still getting this error DefaultCredentialsError: Could not automatically determine credentials. Please set GOOGLE_APPLICATION_CREDENTIALS or explicitly create credential and re-run the application. For more information, please see https://developers.google.com/accounts/docs/application-default-credentials.",True
@suileungmak9325,2017-11-23T03:10:20Z,1,I find an error as follow: client = language.Client() Error: no attribute of Client  any idea how to solve it ? thanks,True
@khaledbook,2017-08-28T13:51:52Z,0,the unit is 1000 charter witch is around 200 word I thing it is around 0.0005 cent a word if we consider the word average is 5 characters  https://cloud.google.com/natural-language/pricing,True
@benjaminlee3135,2017-07-26T13:01:48Z,0,"Pricing units  The Cloud Natural Language API is priced using units of measurement known as text records. A text record may contain up to 1,000 Unicode characters within the text content sent to the API for evaluation. Text in excess of these 1,000 characters counts as additional record(s). Prices are expressed in dollars per 1,000 text records.  Prices for usage of the Cloud Natural Language API are computed monthly based on which feature of the API is used, and how many text records are evaluated using those features. These prices are noted in the table below.",True
@aNdrew-vr6qx,2017-07-06T10:42:10Z,0,"Hi, I am interested to learn how to use Google Speech API with python code, could you please make a tutorial for this? :D Thank you in advanced. :D",True
@chineshdoshi5120,2017-03-23T20:48:55Z,0,very descriptive video !!! Why you are using nano ?? IS there any specific reason ?,True
@example.com.,2017-03-22T13:18:03Z,1,"17:36 こんにちは is equal to ""hello"". I'm Japanese and Mathematician of CVPR.",True
@jonathonfulbright8002,2017-03-22T00:48:53Z,13,"Titles man, Price/1000 units",True
@derekh989,2017-03-21T18:08:59Z,21,"Thank you for all of your work and tutorials. I've learned (am learning, rather) an entirely new skill set and potentially career path thanks large in part to the content you put out. Many, many thanks.",True
@simocennetten5239,2017-03-21T16:26:28Z,2,thank you so much you changed my life bro,True
@wyomingar,2017-03-21T16:04:26Z,2,"The Cloud Natural Language API is priced using units of measurement known as text records. A text record may contain up to 1,000 Unicode characters within the text content sent to the API for evaluation. Text in excess of these 1,000 characters counts as additional record(s). Prices are expressed in dollars per 1,000 text records.  Prices for usage of the Cloud Natural Language API are computed monthly based on which feature of the API is used, and how many text records are evaluated using those features. These prices are noted in the table below.",True
@karimjerbi7284,2017-03-21T15:54:48Z,0,you tyyype fiiiiiiiiiiiiiiiiiii111!!!!!!rst,True
