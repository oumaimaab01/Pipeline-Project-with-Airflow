author,updated_at,like_count,text,public
@neel5602,2022-07-21T15:15:11Z,1,"I have same code as above in the video but I get 4 clusters from 0 to 3, and every time it's accuracy changes , and sometime I get '1' for one of the cluster , Can any one describe why this happens ? It will be very helpful if anyone help..",True
@jairajsahgal5062,2021-09-30T10:14:25Z,0,Thank you,True
@saurabhtripathi62,2021-02-27T12:12:17Z,0,nice not many ppl take cluster online as the r not good in it.,True
@decode0126,2020-08-30T13:47:36Z,0,i got a group where none of the passengers survived !!!,True
@godfist9333,2020-08-06T06:44:29Z,1,money can buy life huh :3,True
@abhisheks.2553,2020-07-21T14:46:59Z,0,"hi, where can i find the text code? or if you have Github sir can you please share Sir",True
@hectorlinomauvecinjunior6621,2020-04-11T18:41:33Z,0,Someone know how i can calculate the width of every single feature have on the cluster classification  ?,True
@user-kg7uc4vk8l,2020-04-06T21:30:13Z,0,why my result only show 20 or 30 count instead of 1300? Too few for a reasonable result.,True
@stevethach3340,2020-03-18T19:11:50Z,1,Anyone having a problem where n_clusters_ != 3?     Mine is showing 8. Thanks!,True
@VascoCC95,2019-12-05T20:40:59Z,1,"The fare is not necessarily the cost of one ticket but it can represent multiple tickets. I was wandering through the data and found that multiple ticket ID's where the same and had the same fare. This may represent, for instance, one father buying tickets for a family of 5, thus grossly multiplying the price of one single ticket by 5",True
@lsraeI7,2019-11-05T21:57:08Z,3,For some reason the simple operation cited below was taking almost a minute to compute in my machine (never really had any performances issues so far)  for i in range(len(X)):     original_df['cluster_group'].iloc[i] = labels[i]  so instead I substituted that bit of code for  original_df['cluster_group'].iloc[:] = labels  and now it runs in a second. Just in case anyone is having the same trouble,True
@spicyLEGO,2019-08-07T12:33:52Z,2,"9:11 Only 3.6 survival rate, not great not terrible",True
@ingram010,2019-06-12T20:59:35Z,0,Anyone know where the written tutorials are?,True
@majtales,2019-01-04T16:52:36Z,0,"I dont get the expression written @6:37. First we are comparing a whole column with a data type in the parenthesis, then whatever the resulting boolean value is we are using it as the column index of the original_df ???",True
@amdreallyfast,2018-12-03T16:32:58Z,0,"I found a quirk with sklearn's MeanShift. I ran it in a loop, trying to get multiple results on a single run of the program, but it got the same results on every iteration. I run the program again and it gets different results than the first run of the program, but every iteration was the same. I tinkered with moving the classifier inside the loop and setting to None afterwards to make sure it died, I dropped the ""cluster_group"" column after every run, I set the ""survival_rates"" dict to None to make sure it died, but nothing changed. Still different results on each program run, but the same results on every iteration.  Any idea how to get around this?",True
@petersun06,2018-09-19T23:39:26Z,2,ppl with 100% survival rates are all aliens. We've just proven the world is run by reptiles.,True
@jnturef2037,2018-07-03T06:32:25Z,0,"Why you code this ,uses excel you can get all evaluations .",True
@michiokaku101,2018-06-14T12:46:42Z,0,why in my IDe i cant see all the columns printed? also in my terminal isee only 4 columns and for the rest i got ....,True
@jasmeetsingh4516,2018-04-19T13:39:07Z,0,Where can I find your code in text format?,True
@KathrechaKrushn,2018-03-12T17:52:03Z,1,n_clusters = len(cluster_centers) this seems better,True
@erv993,2018-02-21T03:15:04Z,0,"Hi, thanks for your videos, you awesome! Instead of iterate through the df, you can user original_df['cluster_group'] = pd.Series(labels) for adding new column",True
@shubhamrane2918,2017-12-28T17:31:57Z,0,Can you please upload a video on logistic regression,True
@maxkcng860729,2017-09-27T02:57:47Z,3,"Hi Mr. Sentdex,  really like all of your videos, it is fun to watch and most importantly very practical.  out of curiosity, wonder what motivate you to do this ML series tutorial and nice enough to share it to all of us?  this might sound like silly question but how do we instruct (or how do we know if) python is specifically look for the ""rate of survival"" instead of ""percentage of people that like cheese burger""?",True
@seversonb,2017-09-07T18:49:25Z,0,"It looks like the clusters have really unequal numbers of people in them. 10, 1280, and 20 Your algo seems to only be able to predict well the outcome for 30 out of 1300 people!  Am I seeing that correctly?",True
@revanttiwari4669,2017-07-20T12:23:28Z,1,"n_clusters_ = len(np.unique(labels)) survival_rates = {} for i in range(n_clusters_):     temp_df = original_df[ (original_df['cluster_group']==float(i)) ]     #print(temp_df.head())      survival_cluster = temp_df[  (temp_df['survived'] == 1) ]      survival_rate = len(survival_cluster) / len(temp_df)     #print(i,survival_rate)     survival_rates[i] = survival_rate      print(survival_rates)   somebody help me understand this!!! thank you",True
@ryanshrott9622,2017-03-16T14:35:43Z,0,Great vid Harrison!,True
@bf2825,2017-02-08T16:45:43Z,1,"My value is print like this. LOL {0: {...}, 1: {...}, 2: {...}, 3: {...}}",True
@Trvgn,2016-12-13T22:01:03Z,0,"Shouldn't you remove correlated columns? pclass and fare are correlated. I wonder whether this is the reason you get this 3 group classification as output, since you would be counting this twice.",True
@loderunnr,2016-10-19T20:36:12Z,4,"Is there a way for K-Means or MeanShift to find what features matter the most in the classification? Could we find, using a clustering algorithm, without randomly digging as we did in this tutorial, if ""class"", ""sex"" or ""fare"" matter more than another feature?",True
@Grepoan,2016-09-26T23:01:42Z,2,"Hello Sentdex,  Excellent work thus far. I look forward to the NN's coming up!  On this example, I am either awesome or broken; and I lean towards the latter.  I re-ran the example a dozen times and consistently get 4 clusters (every time!).  I started with your code from https://pythonprogramming.net/mean-shift-titanic-dataset-machine-learning-tutorial/ and added only the ""original_df"" and ""suvival_rate(s)"" sections -- nothing else. One of my classes has a 100% survival rate -- need to learn that trick for my next boat ride.  My clusters - PClass Labels - Survival rates are as follows:  0 [1 2 3] 36.9% 1 [1] 100% 2 [1] 73.9% 3 [3] 10.0  Have you or others experienced this?  Note that the mean of my pclass labels is 2.29 for every cluster.  I'm worried that I screwed something up in the pre-processing.  I copied the titanic.xls file the link provided in the code, which I copied from the host website: https://pythonprogramming.net/mean-shift-titanic-dataset-machine-learning-tutorial/  Thank you!  edit: I took the code straight off of https://pythonprogramming.net/mean-shift-titanic-dataset-machine-learning-tutorial/ (all the way to the end) and changed nothing, but got 4 clusters",True
@andrelip1,2016-07-20T04:11:06Z,0,If you could upload a simple GIST  after you record the video would be really nice.,True
@gcm4312,2016-07-05T18:13:21Z,7,"instead of the pattern ""for i in range(len(x))"" you could use the enumerate() function. In this case:  for i, label in enumerate(labels):         original_df['cluster_group'].iloc[i] = label",True
@jonatanisse6362,2016-07-04T20:17:30Z,28,"My man, youÂ´re a true legend. Been watching your videos none stop for the last couple of weeks, all your machine learning and Quantopian episodes. You got your self another subscriber on your website. You deserve all the credit you can get! Keep up the awesome job!",True
@theropoy9371,2016-07-03T12:03:14Z,3,Can you pls make a tutorial about how to make a chat bot?,True
