author,updated_at,like_count,text,public
@tcgvsocg1458,2021-03-17T15:23:07Z,0,Sound really bad explaination really but...your only one to do this so...,True
@XXXCitizenX,2021-01-28T19:37:39Z,0,"Is there a reason why its ""ascii"" and not 'ascii' ?",True
@ShermanSitter,2020-10-16T05:00:57Z,0,"""It's pee pee .net for the cool kids"" ...that is why we love this guy.  :)",True
@angelally_,2020-06-02T11:00:53Z,1,To fix your error I think there should be written:  resp = requests.request.get(url),True
@jeetshah8513,2020-04-13T18:45:40Z,0,Does p.map by default have start() and join()???,True
@jeetshah8513,2020-04-13T18:37:35Z,0,Hey pls reply for this How will you use multipleprocessing for each function in a(b(x))?? Also like for a(b(c(x))) like making each function too fast.??? Pls help!!!!,True
@norrow7047,2020-01-16T12:57:44Z,0,list comprehension should be renamed to list incomprehensibles,True
@AB-sq6cu,2019-12-16T15:53:28Z,0,Hey I got Couldn't find a tree builder with the features you requested:lxml error  How to solve it??,True
@lukexu4845,2019-11-21T01:52:40Z,0,Surely if you just hop onto random sites you're gonna get a virus,True
@dsinghr,2019-09-18T14:30:20Z,0,why would you not use an IDE. Code editors such as they don't auto complete properly and this thing that you are using looks prehistoric,True
@vaastavmishra2035,2019-07-20T18:12:00Z,0,"when I am Running  the program first it says 'NoneType' object has no attribute 'startswith' likely got none for links, so we are throwing this. Then it shows a lot of errors and it is collecting no links.Please help Sir.",True
@wholehorse5827,2019-07-12T17:42:31Z,1,Dang can't a web spider like this used to maybe corrupt other websites?!,True
@imrul66,2018-11-07T08:17:28Z,1,data = [url for url_list in data for url in url_list]  TypeError: 'NoneType' object is not iterable  help please!,True
@morphman86,2018-10-10T18:45:42Z,0,"You may wanna store the link in the process itself, instead of when all the processes are done. And also check that archive when starting a process, to make sure you have not already crawled it. Otherwise, it's an excellent beginning scraping script.",True
@AkhilesFish,2018-10-05T08:59:48Z,0,"Hi. I have abt 20K pages to parse. How to enumerate jobs done, or how to estimate remaining  jobs using Pool?",True
@MindaugasV,2018-09-08T11:54:12Z,0,Great explanation. KISS principle.,True
@jaden-ik6ti,2018-08-31T18:43:42Z,0,can you get malware from this,True
@mischajohal5604,2018-08-10T18:49:19Z,1,"When I try to write to the urls.txt file, the only thing in there comes up as [ ] (an empty list). Why is this happening, and what can I do to fix it?",True
@kasheeshprabhudesai8996,2018-07-30T06:51:33Z,0,Invalid URL 'None': No schema supplied. Perhaps you meant http://None?,True
@MrNaesme,2018-07-12T16:11:15Z,0,"Dang it, my spider tried buying a bunch of Cisco routers.... >:/",True
@TheMku23,2018-07-10T18:00:06Z,0,I keep getting this error  Invalid URL '<function random_starting_url at 0x104581e18>': No schema supplied. Perhaps you meant http://<function random_starting_url at 0x104581e18>?,True
@Jeacom,2018-06-06T02:03:06Z,0,He doesnt knows what's mawarebytes? that antivirus we try when avast fails.,True
@budhathokibijaya6636,2018-03-22T08:49:27Z,1,"why ascii encoding is needed, i thought nowdays we only use unicode(utf-8)",True
@arlenalem,2018-02-11T12:01:34Z,0,"HI, Thanks for all you  great videos, Here my questions , I'm  using  multiprocces, Process A to read data by serial  port from a gyrocope sensor (the data is coming constantly)  and and another process ""B"" in order to read received data from module  sensor magnetometer (the data is coming constantly) , till now i have two process, and I'm thinking to have one more process C, which will use the data from gyroscope and magnetometer and make some operations, what could be the best way to  implement a shared data (like FIFO) which will be filled by A and B process, and this shared data will read by process C. I hope someone can help, I would appreciate your  comments and suggestions and shared experience.",True
@luckyluuk8788,2017-12-03T18:48:46Z,0,"My computer said there existed no urls.txt file, so I went back to the write tutorial and found out I had to add f.close() in the with statement. After that, it works!",True
@shandatecrisovet,2017-08-14T11:24:30Z,1,"pls help , the program wont run after midway, likes it stops running after showing few exceptions",True
@dude2260,2017-08-06T17:22:48Z,2,data = [url for url_list in data for url in url_list] TypeError: 'NoneType' object is not iterable   Getting this error,True
@srisu8946,2017-07-07T03:22:48Z,1,also how do you open up url.txt in windows os?,True
@srisu8946,2017-07-07T03:19:33Z,0,"in the url.txt, i'm pretty sure the very last url in the document in not a 3 letter url....",True
@cupajoesir,2017-06-09T20:05:56Z,0,1st random url is http://cdw.com a major distributor ... hahaha ... i know i know all three letter urls are taken... but still ...,True
@fastundercoverkitgoogle7381,2017-06-07T13:11:59Z,32,"Here I was, one video away from the OOP tutorials and you pulled me into the rabbit hole of the bs4 mini-series Damn you, sentdex",True
@ravitejakondisetty,2017-03-08T01:58:18Z,1,"Hey,   Your videos are very very valuable. They help me a lot.  I tried to execute the entire program. But when I open the urls.txt, I find an empty list every time. Is there anything that can be done? Any suggestions would be really helpful. Thanks.",True
@santiagopardal8439,2017-01-24T19:50:31Z,0,"Help pls!!  Traceback (most recent call last):   File ""C:\Users\santi\Desktop\Python\Test.py"", line 54, in <module>     main()   File ""C:\Users\santi\Desktop\Python\Test.py"", line 47, in main     data = [url for url_list in data for url in url_list]   File ""C:\Users\santi\Desktop\Python\Test.py"", line 47, in <listcomp>     data = [url for url_list in data for url in url_list] TypeError: 'NoneType' object is not iterable",True
@tomasemilio,2017-01-14T18:41:57Z,0,"Sentdex: Very clear tutorial, instead of using requests I use Selenium + BS4, Can you use multiprocessing for many webdrivers? (I also use PhantomJS). I created a great app for visiting LinkedIn profiles , which requires login and also scrolling down (dynamic content) which I find very easy to do with Selenium , then get all the links.  IT IS SO SLOW THOUGH.",True
@ConHenry,2016-12-13T14:44:41Z,0,Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?,True
@banksy8619,2016-12-01T09:56:57Z,6,"data = [url for url_list in data for url in url_list]  we can replace that with   data = sum(url_list, [])",True
@asiddiqi123,2016-11-23T07:54:09Z,0,Those who are new into scraping can read this blog post of mine:  http://blog.adnansiddiqi.me/6-things-to-develop-an-efficient-web-scraper-in-python/,True
@isilanes,2016-11-22T20:17:16Z,9,"Very nice video, congratulations. Comments:  1) You could use a set to avoid repetitions in the URLs you gather 2) You do ""[link for link in parse_us]"". This is just ""parse_us"". 3) Maybe it would be worth mentioning that you made the amount of concurrent processes (pool size) and amount of starting URLs equal (50), but it needn't be, and making them different would be quite interesting (digest a list of 50 URLs using 4 processes, so that each time one process ends the next URL in the list is processed).",True
@maxiewawa,2016-11-22T09:44:51Z,0,Really enlightening. I wish I understood it all.,True
@nic5146,2016-11-18T06:34:20Z,2,"When I try import requests, I get ""ImportError: No module named 'requests'"". Plz Help",True
@aikimark1955,2016-11-17T15:14:02Z,0,It would be nice to see the CPU activity when you run this.,True
@riseoftech4k332,2016-11-17T12:06:52Z,0,as BS lol,True
@graywolf2600,2016-11-17T02:50:17Z,2,When should one use multiprocessing vs the threading module?,True
@AJG6150,2016-11-17T00:59:57Z,5,why wasn't the list comprehension statement [url for url in url_list for url_list in data]? I would have thought it would go from the smallest to largest data structure (from each url to the url_lists to 'data'),True
@manthatsawesoem,2016-11-17T00:22:58Z,2,Could you make a tutorial on how to implement material design into the Django blog from the Django tutorial series?,True
@NisseHult101,2016-11-16T19:31:52Z,1,Webcrawling random sites like this might be frowned upon by some sites or ISP:s especially if your application is not complying with the robots.txt convention for such webcrawlers. You may want to see http://www.robotstxt.org/ or https://en.wikipedia.org/wiki/Robots_exclusion_standard for info on this. Cool example though.,True
@ThanosKalegias,2016-11-16T19:00:10Z,0,this is cool for  colleting as many e-mail address as you can :),True
@myztic123,2016-11-16T16:47:39Z,2,why do you use Idle instead of Pycharm or Visual Studio? the auto complete is much worse and i'm not even sure if debugging is possible,True
@idobenamram3743,2016-11-16T15:48:19Z,0,that was awesome,True
@chrisharrel8837,2016-11-16T15:06:01Z,10,ulrlib.parse.urljoin() is great for properly concatenating hrefs with the base domain. Your handle_local_links function will handle most links though.,True
@khaled4913,2016-11-16T14:56:04Z,0,شكرا,True
