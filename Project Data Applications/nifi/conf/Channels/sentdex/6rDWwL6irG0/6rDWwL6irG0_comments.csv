author,updated_at,like_count,text,public
@VascoCC95,2019-12-08T23:48:35Z,0,"Also I don't believe the problem is just the size of the dataset as we are encoding only 423 words out of 18 thousand different words composing the lexicon. Instead of increasing batch size we'd better reduce the NN size by reducing the layers' size (as someone said, this model is overfitting) and increase the input vector size by including more words. I created a simple CNN on my own to detect if a Lego F1 model is present in a 100x100 picture or not. With only 400 examples of pos and neg (200 + 200) it reached accuracy of 97% being able to distinguish the Lego car from some pictures of the actual F1 car it was inspired on. So it's not only about the data, but also how we encode it and read it.",True
@VascoCC95,2019-12-08T23:36:59Z,0,My values of loss and accuracy are very weird... The accuracy seems independent to the loss and has always the same values.,True
@VascoCC95,2019-12-08T23:33:05Z,1,TensorFlow moved to API 2.0 so you may have to replace tf.??? by *tf.compat.v1.???*,True
@kadblue2000,2019-10-15T19:00:56Z,0,great video!!,True
@JCSMOOTH345,2019-10-01T20:55:57Z,0,how to I put midi file data into the network,True
@Ghasakable,2019-06-12T12:00:42Z,0,"To those who will face the error of : 2315, in _ensure_xent_args      ""named arguments (labels=..., logits=..., ...)"" % name)  ValueError: Only call `softmax_cross_entropy_with_logits` with named arguments (labels=..., logits=..., ...) use this:   tf.nn.softmax_cross_entropy_with_logits(logits = prediction, labels=y)",True
@haseebarshad7451,2019-06-08T22:45:32Z,0,"x = tf.placeholder('float', [None, len(train_x[0])]) IndexError: list index out of range   people facing this error should look out for the following things: you should have commas in your line     train_x = list(features[:,0][:-testing_size]) and the train_y lines as well     make sure you get a pickle file with the size of 130+ MB's. In my case when i tried to print my train_x[0] the array was simply empty. I hope this is helpful to all and have a nice day :D",True
@HelloNewMe1996,2019-05-18T15:19:02Z,0,how to train a real time data ?,True
@user-jc4oi1xg1z,2019-03-29T21:57:26Z,0,"ValueError: Only call `softmax_cross_entropy_with_logits` with named arguments (labels=..., logits=..., ...)",True
@subratode7086,2019-03-22T13:13:55Z,0,train_neural_network(x)       its showing value error,True
@feliznesh3157,2019-02-28T12:47:13Z,0,"logits and labels must be broadcastable: logits_size=[100,2] labels_size=[100,423] so I changed to sigmoid instead of softmax with n_classes = 1 and proceded to confuse the hell outa of myself",True
@sharaniyer3804,2019-02-03T07:54:43Z,0,How to get a sample code used in this video?,True
@fanel1900toamna,2018-08-24T00:51:19Z,0,"@sentdex I ran into some unicode issues while trying to load the sentiment set from a pickle so I used the json module instead since we're saving pure data (not dumping a whole class instance):  import json      with open('saved/sentiment_set.json', 'w', encoding=""utf8"") as datafile:         json.dump([x_train, y_train, x_test, y_test], datafile)  ...      with open('saved/sentiment_set.json', 'r', encoding=""utf8"") as f:         [x_train, y_train, x_test, y_test] = json.load(f)  Funnily enough the json file only takes up 21.6 MB in size and the data inside it is mostly zeros. Because the arrays contain mostly zeros, we can convert them to sparse matrices so they take substantially less space.  *Doing this the data takes up only 148KB (quite a decrease from the 140MB for the pickle).* Here's how to do it:  from scipy.sparse import csr_matrix, save_npz  # Create lists x_train, y_train, x_test, y_test = create_feature_sets_and_labels('data/pos.txt', 'data/neg.txt')      # Convert lists to sparse matrices [x_train, y_train, x_test, y_test] = list(map(csr_matrix, [x_train, y_train, x_test, y_test]))  # Save sparse matrices save_npz('saved/x_train.npz', x_train) save_npz('saved/y_train.npz', y_train) save_npz('saved/x_test.npz', x_test) save_npz('saved/y_test.npz', y_test)  .... To load data use:  from scipy.sparse import load_npz  # Load sparse matrices x_train = load_npz('saved/x_train.npz') y_train = load_npz('saved/y_train.npz') x_test = load_npz('saved/x_test.npz') y_test = load_npz('saved/y_test.npz')  # Convert sparse matrices back to numpy arrays (use i.toarray().tolist() for lists) [x_train, y_train, x_test, y_test] = list(map(lambda i: i.toarray(), [x_train, y_train, x_test, y_test]))",True
@fanel1900toamna,2018-08-24T00:14:58Z,0,"@sentdex Here's a different way of getting the data in batches (it's the same thing you're doing but with a for loop):  -> assuming the following structure:  train_neural_network({         ""train"": {""x"": np.array(x_train), ""y"": np.array(y_train)},         ""test"": {""x"": np.array(x_test), ""y"": np.array(y_test)},     })  -> you can then write code like so:  N, D = data['train']['x'].shape              for i in range(N // batch_size):                 x_batch = data['train']['x'][i * batch_size:(i * batch_size + batch_size), ]                 y_batch = data['train']['y'][i * batch_size:(i * batch_size + batch_size), ]",True
@arturmuellerromanov4438,2018-07-14T07:38:34Z,0,"I have a ValueError. Output:  423 WARNING:tensorflow:From C:\Users\Artur\Desktop\Tensorflow_Basic_2.py:49: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version. Instructions for updating:  Future major versions of TensorFlow will allow gradients to flow into the labels input on backprop by default.  See @{tf.nn.softmax_cross_entropy_with_logits_v2}.  Traceback (most recent call last):   File ""C:\Users\Artur\Desktop\Tensorflow_Basic_2.py"", line 80, in <module>     train_neural_network(x)   File ""C:\Users\Artur\Desktop\Tensorflow_Basic_2.py"", line 69, in train_neural_network     _, c = sess.run([optimizer, cost], feed_dict = {x:batch_x, y:batch_y})   File ""C:\Users\Artur\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\client\session.py"", line 900, in run     run_metadata_ptr)   File ""C:\Users\Artur\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\client\session.py"", line 1111, in _run     str(subfeed_t.get_shape()))) ValueError: Cannot feed value of shape (100, 423) for Tensor 'Placeholder:0', which has shape '(?, 784)'",True
@connorbarrick3975,2018-06-26T02:12:10Z,1,"Update: Fix to code to not raise errors or deprecation warnings: use this for the Cost function instead: cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits_v2( logits=prediction, labels=y) )  and change initialize_all_variables to tf.global_variables_initializer",True
@connorbarrick3975,2018-06-26T02:01:52Z,1,"Hey boss, deprecation strikes again:   ValueError: Only call `softmax_cross_entropy_with_logits` with named arguments (labels=..., logits=..., ...)  please advise",True
@BilguunsparKO,2018-05-28T01:34:59Z,0,Accuracy: 0.60037524,True
@leoerdos8414,2018-05-14T12:27:19Z,1,"Also, can you teach TensorFlow's high level APIs (like keras and data)?",True
@leoerdos8414,2018-05-14T12:26:42Z,0,I think it would be good to apply the softmax function to the output layer,True
@yasirraza8930,2018-04-27T16:10:09Z,0,"I have a dataset of ASL(American Sign Language) in which 3000 images per letter and i am going to train my model by the help of tensorflow codelabs using this script ""python -m scripts.retrain \ --bottleneck_dir=tf_files/bottlenecks \ --how_many_training_steps=? \ --model_dir=tf_files/models/ \ --summaries_dir=tf_files/training_summaries/""mobilenet_1.0_224"" \ --output_graph=tf_files/retrained_graph.pb \ --output_labels=tf_files/retrained_labels.txt \ --architecture=""mobilenet_1.0_224"" \ --image_dir=tf_files/dataset"". Can any one tell me how many steps i have to choosen for the accurate predictions?",True
@polzai7274,2018-03-27T02:03:07Z,0,hmmmm can it implement on windows?,True
@chiragkarkera6072,2018-03-21T19:47:42Z,0,will it show probabilityof positiveness?,True
@sashaanksekar441,2018-03-19T12:34:36Z,0,"I am getting this error message. ValueError: setting an array element with a sequence. for this line _, c = sess.run([optimizer, cost], feed_dict={x: batch_x, y: batch_y})  NOTE: I am using a different dataset. my dataset consists of 1044 images with 2 classes. with 835 images in the training data and the rest in test data   Can someone please help me out",True
@karankatiyar8858,2018-03-13T02:39:39Z,0,"logits and labels must be same size: logits_size=[100,2] labels_size=[100,1]   [[Node: SoftmaxCrossEntropyWithLogits_16 = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](Reshape_48, Reshape_49)]]   [[Node: Mean_18/_11 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_353_Mean_18"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]   facing this issue ..can anyone pls suggese",True
@karankatiyar8858,2018-03-12T22:58:56Z,4,"Cannot feed value of shape (100,) for Tensor 'Placeholder_2:0', which has shape '(?, 11173)'  Hi, I an facing this error ..Dont know what to do ..I have done exactly as mentioned in the tutorial Can anyone please help",True
@tanmayfuse1747,2018-03-02T08:57:01Z,0,How to save model after training,True
@tedp9146,2018-02-27T21:16:08Z,5,"hmm an error in this part: x = tf.placeholder('float', [None, len(train_x[0])]) IndexError: list index out of range  What i did before, in the feature file, was changing   'features = np.array(features)'  to  ' features = np.matrix(features)', bc it gave me an error. and train_x comes out of features so that might be the error but i dont know how to fix it :(",True
@hipoojan,2018-02-08T04:46:31Z,0,"i did as you did but i didn't get any file .pickle , why is that ?",True
@ThisIsNotMyHandle,2018-01-21T20:23:07Z,0,"I have followed the tutorials upto this point and I think something has happened to NLTK w.r.t. amount of data. First of all, my resulting pickle is 581M, instead of the ~150M you got. However, my accuracy is .86!  At first I thought my computer was breaking since it took forever to train (in comparison to your video) but then I realized my pickle was almost 5x the size.  I'm appending my training outputs for clarity.  Epoch: 0/10 Loss:922465.5037002563 Epoch: 1/10 Loss:130920.22280168533 Epoch: 2/10 Loss:73765.47201442719 Epoch: 3/10 Loss:58773.93998336792 Epoch: 4/10 Loss:54513.08183884621 Epoch: 5/10 Loss:46202.26174592972 Epoch: 6/10 Loss:42605.30013346672 Epoch: 7/10 Loss:37500.50630950928 Epoch: 8/10 Loss:33196.662793278694 Epoch: 9/10 Loss:30039.254771083593 Accuracy: 0.8644598126411438",True
@iqbalwidodo496,2017-12-29T02:06:38Z,0,"does anyone know how to  output the predicted value(label) in this tutorial instead of accuracy? lets say i want to see how the output if i input the train_x[0],",True
@Sajalmistry10,2017-12-22T05:26:39Z,0,"Traceback (most recent call last):   File ""/Users/sajalmistry/PycharmProjects/untitled7/deepnet_flow.py"", line 11, in <module>     train_x, train_y, test_x, test_y = create_feature_sets_and_labels('pos.txt', 'neg.txt')   File ""/Users/sajalmistry/PycharmProjects/untitled7/deep_own.py"", line 64, in create_feature_sets_and_labels     lexicon = create_lexicon(pos,neg)   File ""/Users/sajalmistry/PycharmProjects/untitled7/deep_own.py"", line 16, in create_lexicon     contents = f.readlines()   File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/encodings/ascii.py"", line 26, in decode     return codecs.ascii_decode(input, self.errors)[0] UnicodeDecodeError: 'ascii' codec can't decode byte 0xc3 in position 4645: ordinal not in range(128)     Process finished with exit code 1  help me out guys",True
@riseshrox,2017-12-17T05:13:33Z,2,The same code ran for 15 mins and gave me an accuracy of 84%. Does anyone know why this could happen?,True
@faribakhoshghalbvash6671,2017-12-04T21:10:20Z,0,What is the learning rate here?,True
@jamesavery3110,2017-11-21T01:08:28Z,0,I got 91% accuracy?,True
@AilenProof,2017-11-10T17:43:23Z,0,"I used the code from the video and from your website, everything is working fine (the training) but the lines  epoch_loss += c  and   print('Accuracy:', accuracy.eval({x: test_x, y: test_y}))  crash the script it doesn't give me any errors in the console, it just aborts my script. Perhaps it's the shape of the dataset that's causing the print error and the shape of c that's causing the epoch_loss error?",True
@eplanti,2017-10-30T03:33:53Z,39,its funny how the views just drop off the farther the tutorials go,True
@jonathanmay256,2017-10-24T17:32:21Z,0,"I think you'd see a large accuracy improvement if you were to invoke the POS tag when lemmatizing your featureset.   The POS tag determines the context of the word in addition to its lettered form. For instance, it will classify the words ""care"" as a noun and ""care"" as a verb into different elements of your lexicon.   NLTK has a function that adds context to the words of a sentence based on its own learning library (I suppose this is sort of cheating) that can be called with nltk.get_pos(),  Going to try adding this to the create_sentiment_featureset now.  NOTE: It will make the lexicon significantly bigger.",True
@IstiyakHossainPro,2017-10-22T20:02:58Z,0,"Thanks, finally it works <3 it gives me Accuracy: 0.604128    in same Epoch Numbers and data you provided in your https://pythonprogramming.net/ why its happening ??? Curious mind wants to know just :D :P",True
@ahmadfitri6035,2017-10-15T11:17:49Z,0,why is the loss value print a very large number? what is the unit for that. is it percentage?,True
@eyes.of.lenses183,2017-10-13T20:59:11Z,1,"Hmm.  I get this message: Cannot feed value of shape (423,) for Tensor 'Placeholder:0', which has shape '(?, 423)' But im not really sure and i still struggle with this Tensor-thinking ^^  Does anyone has had a similar problem here? thanks guys :)",True
@Red_Devil_-es1rt,2017-10-05T15:50:31Z,0,"logits and labels must be same size: logits_size=[100,2] labels_size=[100,423]. I can't find a fix to this error. I have tried everything other people have coimmented any help?",True
@gmailaccount437,2017-10-01T14:09:54Z,0,"In your pythonprogramming.net code what is the f_fum':n_nodes_hl for hidden_1_layer?   x = tf.placeholder('float') y = tf.placeholder('float')  hidden_1_layer = {'f_fum':n_nodes_hl1,                   'weight':tf.Variable(tf.random_normal([len(train_x[0]), n_nodes_hl1])),                   'bias':tf.Variable(tf.random_normal([n_nodes_hl1]))}",True
@Jake3D,2017-09-09T22:19:53Z,0,"I keep getting a really long error, I cant figure it out. I have run the example code and still get the error. Here is the part the keeps repeating: tensorflow.python.framework.errors_impl.InternalError: Blas GEMM launch failed : a.shape=(100, 784), b.shape=(784, 500), m=100, n=500, k=784   [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=""/job:localhost/replica:0/task:0/gpu:0""](_arg_Placeholder_0_0/_7, Variable/read)]]   [[Node: Mean/_15 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_384_Mean"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]  Caused by op 'MatMul', defined at: I skipped the high numbered code, theses are the lines actually in the code:  line 71, in <module>     train_neural_network(x)  line 43, in train_neural_network     prediction = neural_network_model(x)  line 29, in neural_network_model     l1 = tf.add(tf.matmul(data,hidden_1_layer['weights']), hidden_1_layer['biases'])",True
@felipesilveira6501,2017-09-01T19:12:21Z,0,Sorry ?! Where is create_sentiment_featuresets.py ? Tks,True
@stefanvasilev8948,2017-08-29T12:28:04Z,1,"When i run my neural network it just doesn't print out the progress in training, but i could see that my gpu is working! What could be the problem, please help!",True
@dude2260,2017-08-26T11:04:23Z,0,"my files combined were 1.2 mb and pickle was 580 mb and i used hm_lines = 100000 and got 85% accuracy , i am not getting what is happening",True
@duncanngacha1747,2017-08-21T07:50:58Z,2,"ValueError: Cannot feed value of shape (423,) for Tensor 'Placeholder:0', which has shape '(?, 423)'  I don't know how to solve this",True
@ritesh_,2017-08-04T20:08:42Z,0,Hey I'm getting Accuracy: 1.0 why ??,True
@parthshah9898,2017-08-03T10:22:48Z,0,I ran 30 epochs and got an accuracy of 96.60%,True
@probabilityfilter,2017-07-31T01:39:12Z,2,"For those using Jupyter Notebooks.............. Jupyter notebook does not allow access to another notebook. Here are some workarounds: * lazy solution: copy paste the MNIST NN code from previous video in this Notebook and remove references to MNIST * slightly better solution: convert the ""create_sentiment_featureset""  file from "".ipynb"" to "".py"", drop it into the working folder and u would  be good * proper solutions: https://stackoverflow.com/questions/44336087/jupyter-notebook-import-ipynb-file-and-access-its-method-in-other-ipynb-file http://jupyter-notebook.readthedocs.io/en/latest/examples/Notebook/Importing%20Notebooks.html",True
@revanttiwari4669,2017-07-23T07:40:02Z,0,"Sir,I have a problem that i can understand your videos and the code but i am not confident that i can apply them....what should i do ?please suggest",True
@poornachandra1603,2017-07-23T06:21:24Z,0,"423 Traceback (most recent call last):   File ""create_sentiment_featuresets.py"", line 77, in <module>     train_x, train,y, test_x, test_y = create_feature_sets_and_labels('pos.txt', 'neg.txt') ValueError: not enough values to unpack (expected 5, got 4)  Anybody with  a fix to this error?",True
@brajbhushanpatidar5649,2017-07-23T05:21:34Z,0,"you explained  awesome everything,  but one thing  i didn't get is that we did whatever  training , testing and so on , what is its use practically,  means after testing what would i do with this model.",True
@sonalivv,2017-07-20T16:29:16Z,0,"Hi, I am new to both, python and ML so I apologize if this question looks very basic. The files (pos.txt & neg.txt) are in s3. I am loading these files to RDD and I get an error when I pass the RDD to create_feature_sets_and_labels, because obviously it is expecting a string. How can I pass the contents of these files to the function? Any pointers would be helpful!",True
@arjunsinghyadav4273,2017-07-05T03:02:10Z,0,Accuracy = 90% Epoch = 2 Lexicon_words = frequency less than 2000 and more than 30.,True
@bellasun3820,2017-07-04T14:54:28Z,14,"I got two errors and the way to fix them is listed below: 1. for ""tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(prediction,y) )"" is deprecated,  and the right form is ""tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y))""; 2. ""tf.initialize_all_variables()"" is deprecated as well,  and should be transformed to "" tf.global_variables_initializer() """,True
@Bozojimmy,2017-06-17T05:29:58Z,4,"HI im getting below error  InvalidArgumentError (see above for traceback): logits and labels must be same size: logits_size=[37,2] labels_size=[1,37]  do i need to onehotencode y?",True
@clickaws2654,2017-06-14T14:15:57Z,0,"when this code is written  in jupyter notebook  the following error is shown : ModuleNotFoundError                       Traceback (most recent call last) <ipython-input-29-bb73d57abb3f> in <module>()       2 #from tensorflow.examples.tutorials.mnist import input_data       3 #mnist = input_data.read_data_sets(""/tmp/data/"", one_hot = True) ----> 4 from create_sentiment_featureset import create_feature_sets_and_labels       5 import pickle       6 import numpy as np  ModuleNotFoundError: No module named 'create_sentiment_featureset'  ###can you tell me hw to solve it",True
@zetadimensions,2017-06-05T00:57:38Z,10,You really have a tendency to use long names you can't remember :),True
@saarlevy9891,2017-06-04T05:20:58Z,0,"I got over 90% accuracy with the exact same code, am I overfitting somehow?",True
@daksh6752,2017-05-31T17:20:41Z,0,"Shit, I still got 96% Accuracy instead of 58. I crosschecked but mnist wasn't there, I guess I trained it much more than you that's why. I did 20 Epochs and it went up there.",True
@nikhilmalhotra101,2017-05-26T07:01:12Z,0,"Hey cool video sentdex. With a simple neural network and on a CPU , if you increase the hm_epochs to 20, the results cross 60% . Its not much but then we are talking about 2-3 percentage increases at any time",True
@nikhilmalhotra101,2017-05-08T11:52:16Z,0,Great Article. The law of diminishing return is natural because of lack of data as is evident. I just wanted to try the same model and same data and tried 30 epochs. It is at this level that the returns are really diminished  I guess we can have around 30 epochs to train the model which would see a marginal gain of about 2% in the accuracy of the model ... Great article though !!!,True
@pinkeeyadav4915,2017-04-29T07:34:15Z,0,can anyone tell me how to manipulate the above code if i have data in csv format with 100 classes and 200 features,True
@coleskinker3733,2017-04-13T00:32:24Z,0,Hey man awesome videos! Quick question: does the API require input tensors to be flattened to 1d tensors in order to correctly feed into a placeholder?,True
@himanshumakharia7657,2017-04-01T21:50:56Z,1,"I keep getting the error Typeerror: object of type 'numpy.float64' has no len(), referring to the line  x = tf.placeholder('float', [None, len(train_x[0])]) anyone know where this is could be coming from?",True
@RicardoCosta-kx8jz,2017-03-30T10:33:08Z,0,"Hi people, first of all thanks for this tutorials, they are really great! I'm getting this error:  ValueError: Shape must be rank 2 but is rank 1 for 'MatMul' (op: 'MatMul') with input shapes: [423], [423].  i can´t understand why, i think i'm doing everything right. Someone can help me pls?",True
@g_oti3601,2017-03-25T10:30:40Z,0,Len(train_x[0]) = 483 right? Size of the lexicon.,True
@FuyangLiu,2017-03-24T19:20:00Z,1,"Hey guys, I think the video's code got some overfitting situation. As used only one layer but just 200 length vector and I could reach test accuracy on 0.65 (and in the video it is 0.58).   Also for me the accuracy on training batch is on 0.85-0.94 for the last (4th or 5th of epoch), for the first or second epoch the training batch is 0.6-0.7",True
@DavidRelihanMusic,2017-03-23T16:54:27Z,0,These tutorials are brilliant.  Would anyone be able to help me to use the model built in this tutorial?  I can't figure out how to pass a string into the network to classify it.  I've posted a question on Stackoverflow to ask for help.  Thanks in advance:  http://stackoverflow.com/questions/42950991/tensorflow-using-neural-network-to-classify-positive-or-negative-phrases,True
@hdpasd123lol,2017-03-14T01:30:07Z,1,"I got 94% by adding another layer and 200 more neurons per layer, and keeping the epochs at 10 :)",True
@malicorx,2017-03-13T21:14:01Z,0,"hi,  first of all thanks a lot for all the info, it's really appreciated and helped me a lot.  i've finally got this sample to run, it was a pretty mean error for me to fix, so maybe others have problems with the tutorial as it is now, too.  so here's the fix:  cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(prediction,y) )  must be changed to this, given you use a new tensorflow (1.x.x)  cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(logits=prediction,labels=y) )  ---  now a question: i've got a dataset with x features and a single result (0 or 1) for each, and i want the net to learn it, but in a way that it not  solves it in a way where the overall guesses match best, but in a way that the net only takes into account entries of which it is really really certain. (so in the end, when the net is done, and i ask it for the value of a new entry, i want it to either answer ""it's 0 (or 1) with a great certainty"" or ""i'm not sure"" )  could anyone give me a pointer in how i could do this / where i should read or even better a working example somewhere ?  thanks",True
@halfbakedc00kie,2017-03-12T23:03:54Z,0,"So when I create batch_x and put it into the feed_dict, it tells me that it is the wrong shape (100, 500). 500 is my vector size, and 100 is the batch size. I guess it needs to be flat (None, 500) but you haven't done any extra steps to achieve this that I can see. Anyone have an idea?",True
@Ai_Monk,2017-03-11T20:11:24Z,0,"Got more than 70% accuracy with these 10K data samples..by using slight different lexicon (which i felt should have been more accurate): def create_lexicon(pos,neg):     lexicon=[];     l2=[]     for fi in [pos,neg]:         with open(fi,'r') as f:             contents = f.readlines();             lexicon=[]             for l in contents[:hm_lines]:                 all_words=word_tokenize(l.lower());                 lexicon+=list(all_words);         lexicon = [lemmatizer.lemmatize(i) for i in lexicon];         w_counts = Counter(lexicon);         for word in w_counts:             if 300>w_counts[word]>20:                 l2.append(word);     #lexicon = [lemmatizer.lemmatize(i) for i in lexicon];     #w_counts = Counter(lexicon);     l3=[];     for i in range(len(l2)):         if l2[i] not in l3:             l3.append(l2[i]);     return l3;",True
@emanuelaliaci1858,2017-03-11T12:35:58Z,0,I reached an accuracy of 96%. How come? I used your same data.,True
@s.mohammadmostafavii.6917,2017-02-21T08:37:41Z,0,"Trying with TF 1.0 on Winx64 Traceback (most recent call last):   File ""C:/Users/m/TUT50.py"", line 82, in <module>     train_neural_network(x)   File ""C:/Users/m/TUT50.py"", line 55, in train_neural_network     cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(prediction,y) )   File ""C:\Users\m\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\ops\nn_ops.py"", line 1578, in softmax_cross_entropy_with_logits     labels=labels, logits=logits)   File ""C:\Users\m\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\ops\nn_ops.py"", line 1533, in _ensure_xent_args     ""named arguments (labels=..., logits=..., ...)"" % name) ValueError: Only call `softmax_cross_entropy_with_logits` with named arguments (labels=..., logits=..., ...)",True
@wunderlust7252,2017-02-15T15:15:33Z,0,"train_x = list(features[:,0][:-testing_size]) IndexError: too many indices for array  Getting the above error",True
@DanielWeikert,2017-02-07T19:27:29Z,0,Thank you sentdex. Great videos. Hope to see even more of tf and nn in the future. Still am a beginner but want to delve into this topic. Are you running this on you gpu? I got a Radeon Graphic card so i use my cpu and it takes way to long to run this.,True
@mickboe1,2017-02-06T08:20:58Z,0,"Hey sentdex, What cost function should i use when comparing 2 arrays when training your neural network how to sort  ?",True
@pratik6447,2017-02-05T15:01:31Z,0,"Hi Sentdex, (1) What this model is doing? Is this classifying every word as positive or negative sentiments?                        (2) Since we have created lexicon from the data set itself, is it right thing to do?",True
@vishalrajput9856,2017-01-23T15:56:46Z,4,"InvalidArgumentError : logits and labels must be same size: logits_size=[100,2] labels_size=[100,423], how to solve this?",True
@thedeliverguy879,2017-01-19T10:11:01Z,0,"I got this ""InvalidArgumentError (see above for traceback): Incompatible shapes: [1066] vs. [9596]"" when running argmax.. BTW , I'm feeding the data into the mnist example on the official tensorflow mnist tutorial and changed the placeholder and weights..",True
@sitientibus,2017-01-16T09:41:16Z,0,"I can't go through because of this error: ""list index out of range"", pointing to the line x = tf.placeholder(""float"", [None, len(train_x[0])]). Does anyone know how to solve it?",True
@TheCanon03,2016-12-22T12:59:14Z,1,"I am getting : ValueError: setting an array element with a sequence. for the line : _, c = sess.run([optimizer, cost], feed_dict = {x : epoch_x, y : epoch_y})  Been trying to resolve for the past 2 days. Thanks in advance .",True
@ricebastard,2016-12-10T22:08:52Z,27,"If you want to load the pickle instead:  train_x, train_y, test_x, test_y = pickle.load(open(""sentiment_set.pickle"",""rb""))  ""pickle me this"" https://cdn.drawception.com/images/panels/2013/3-6/QCcTgFrz96-2.png",True
@AkshayAradhya,2016-12-04T16:30:24Z,2,"I am getting this weird error*  *ValueError: Cannot feed value of shape (423,) for Tensor 'Placeholder:0', which has shape '(?, 423)'*  it occurs on the line  *print(""Accuracy :"", accuracy.eval({x:test_x, y:test_y}))*  Any help would be appreciated",True
@vineetkaushik5044,2016-11-24T23:08:01Z,0,I am implementing a binary classifier and my accuracy is quite unstable and keeps changing every time I run the program. Please help!,True
@nandanthor,2016-11-08T19:34:23Z,0,"I think you touched on this earlier (and I understand you are using this for learning purposes) but this is an excellent example of overcomplicating, over-processing, and the current trend of throwing neural networks at any problem.  Using count vectorizer and multinomial naive bayes, you can get accuracy around 80% in a much simpler and faster way.  Great tutorial, though, I really appreciate you showing how to code everything from scratch, as opposed to using the built-in tensorflow functions and showing how we could adjust all of this for our own purposes.  Excellent!",True
@adewolekayode6148,2016-10-31T13:58:09Z,0,"Thank you for this great video. Please can you share an idea or code on how to convert a csv file e.g feature 1, feature 2, ...., feature n, class to a format that can be applicable to this model? Thanks.",True
@chrisv5330,2016-10-21T03:13:13Z,0,"Hi sentdex,  Do you know how to turn a tensorflow program (written in python) into a standalone executable? I'm interested in deploying a tensorflow program I wrote to a server which doesn't have tensorflow (and maybe not even python) installed on it.",True
@ThatExBow,2016-09-11T21:43:08Z,1,"Hey sentdex,  I have this error: File ""create_sentiment_featuresets.py"", line 70, in <module>     train_x,train_y,test_x,test_y = create_feature_sets_and_labels('pos.txt','neg.txt')   File ""create_sentiment_featuresets.py"", line 50, in create_feature_sets_and_labels     lexicon = create_lexicon(pos,neg)   File ""create_sentiment_featuresets.py"", line 18, in create_lexicon     all_words = word_tokenize(l.lower())  I'm pretty sure I imported nltk correctly. I have python2, and I had to download panlex_lite manually through a ZIP file and drag it into nltk_data because it wasn't downloading with Terminal.",True
@indrajitkalita9398,2016-09-09T06:32:17Z,0,Really like your way of teaching and your video.But my problem is how can I create Image dataset like MNIST.I have 1000 of fruit images.I want to do the classification.How can I do this by using above code or by using autoencoder,True
@RaoufGnda,2016-08-30T01:18:45Z,1,"Thanks for the tutorial, your awesome work is priceless.",True
@hello2tly,2016-08-25T06:13:47Z,0,Shouldn't we use tf-idf and remove stop words before we feed vectors into the NN?,True
@johncusack3646,2016-08-24T20:09:14Z,1,feed_dict performance is much worse than using a que(see below). Will you be showing how to use a que instead of a feed_dict since you will be working with a larger data set?  https://github.com/tensorflow/tensorflow/issues/2919,True
@ta1708,2016-08-24T16:54:25Z,0,"HI, I like your videos and I thing you should make tutorial on Pickle module for Python it would help me a lot.",True
@billboe9784,2016-08-24T15:15:11Z,1,Love your vids.  An accuracy of ~50% could mean that the network is stuck in a local minimum and guessing just one class label all the time.,True
@WalterBurkholder,2016-08-24T15:12:49Z,0,"awesome stuff, looking forward to the next videos.",True
@quitenerdy1,2016-08-24T15:02:41Z,0,appreciate the time in making these videos,True
