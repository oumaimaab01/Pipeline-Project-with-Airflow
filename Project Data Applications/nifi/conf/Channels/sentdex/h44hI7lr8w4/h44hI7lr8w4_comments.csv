author,updated_at,like_count,text,public
@joxa6119,2022-04-26T02:56:00Z,0,How do we know that the positive dataset is starting from [1900:] and for negative is from [100:] ? is this an assumption or what?,True
@jyotis2903,2020-07-29T01:56:31Z,0,"hi, Nice video !! I tried implementing it but for my scenario, the accuracies are pretty high!! like  LR_Classifier accuracy % :  80.0 SGD_Classifier accuracy % :  80.0 SVC_Classifier accuracy % :  84.0 LinearSVC accuracy % :  81.0  nlkt NB accuracy % : 77.0 MNB_classifier accuracy % : 77.0 Brn_Classifier accuracy % :  77.0 Is it possible ? Or I have done something wrong !!  I am using python version 3.7",True
@sameerzahid3544,2020-04-07T16:24:56Z,0,The mistake is that you are using an unshuffled data set on training. You should not do that. Use a shuffled data for training and unshuffled for testing when checking for bias.   This is because the model learns to first always predict negative and once it starts seeing all positive it then learns to always predict positive.,True
@GelsYT,2019-04-14T05:43:14Z,0,where is the part of the code where we identify if the word is positive or negative? when the random.shuffle(document) was not removed yet,True
@GelsYT,2019-04-14T05:36:23Z,0,What does fileid mean? please answer meee :( thank youuu,True
@GelsYT,2019-04-14T05:26:23Z,0,I got here 'plot': True so it means that plot exists in words? which the condition saids (w in words) right?  what's the difference between the document variable and the word_feature  variable?,True
@mohamadrezabidgoli8102,2019-01-07T09:23:25Z,1,"SGD stuck in local minima, as the last 1000 samples were positive, So it thinks that everything that is positive. You need to shuffle the training data. The argument that in the case of shuffling the accuracy must be the average of 0 and 100  percent is wrong as well. Cause in this case the algorithm is finding a better minimum. Like always, Thanks for this awesome tutorial series.",True
@matteogoretti8014,2018-12-08T16:28:17Z,1,"Guys I don't know but in both cases i get almost 80% accuracy (82 with positive, 81 with negatives), i have the same script of the video and i know that the only part that is changing is the first naiveBayes classifier (the one saved with pickle) so is just I got a lucky caso of saving a good NBClassifier or else? because in all older script/videos that classifier always get the higher accuracy. Can someone explain it to me?",True
@EranM,2018-10-22T11:40:50Z,0,Confusion Matrix.  . .,True
@pierre-henrybaudin9104,2018-07-12T11:00:00Z,22,Your stochastic gradient descent is returning 'positive' all the time because you stopped shuffling the data. SGD goes through training examples one by one and makes rather big steps down the gradient so it needs to be provided with the actual distribution.,True
@TimeKnowledgePower,2018-04-28T20:32:06Z,0,"some of your guys posted errors, to fix them you should be able to copy and paste his code from  https://github.com/PythonProgramming/NLTK-3----Natural-Language-Processing-with-Python-series/blob/master/nltkvid17.py",True
@raiyanyahya,2018-03-01T09:17:07Z,0,i get statistics.StatisticsError: no unique mode; found 2 equally common values... please help,True
@thesuavedeveloper7532,2018-01-25T13:27:04Z,4,Mine comes around 89 -90 % every single time.. pos or neg,True
@frigginnobody,2017-12-21T06:11:36Z,1,"Can somebody please explain the math once again.  We are training with 3000 examples. So is it the case that the first 1000 is negative and rest 2000 positive, or is it like the first 1000 is negative, then next 1000 positive - followed by another 1000 negative examples?",True
@darinam6013,2016-12-13T18:23:04Z,7,How to deal with multiclass data classification (not just positive/ negative)?,True
@theCanadian808,2016-12-05T03:01:44Z,0,anyone know how to improve checking the positive negative seems to be a lot more accurate,True
@mega6699,2016-10-19T15:22:45Z,2,"It is important to have a balanced training set, like this: training_set = featuresets[100:1900] In this case there will be no 100% accuracy for no algorithm:  Naive Bayes: Pos: 76.0 Neg: 84.0 MultinomialNB: Pos: 77.0 Neg: 86.0 BernoulliNB: Pos: 76.0 Neg: 84.0 LogisticRegression: Pos: 83.0 Neg: 75.0 SGDClassifier: Pos: 93.0 Neg: 62.0 SVC: Pos: 79.0 Neg: 91.0 LinearSVC: Pos: 82.0 Neg: 74.0 NuSVC: Pos: 85.0 Neg: 86.0  Also negative texts will not always win (as the data above shows). The bias in the training data was the cause for the bias in the result.",True
@ottawareviews5616,2016-05-22T20:19:25Z,0,Really Helpful videos......Thanks a lot Much Appreciated. I would really like to know how to use this to identify gender of person from their name or other identifiers.,True
@manudotc,2016-01-03T09:38:02Z,0,"Amazing tutorial...thanks for sharing... I am on Py 2.7.6 and was able to reproduce most of the steps except for when I tried to calculate the accuracy of the voted_classifier with all the classifiers as arguments (except Gaussian). I am getting  `no unique mode; found %d equally common values' % len(table)`  I then removed NuSVC and ran   `voted_classifier = VoteClassifier(classifier,MNB_classifier,BernoulliNB_classifier,LogisticRegression_classifier,SGDClassifier_classifier,SVC_classifier,LinearSVC_classifier)`  Runs fine and I am getting about 76% accuracy...any thoughts ?",True
@vaibhavarora3389,2016-01-01T21:30:44Z,0,Why not use Fscore ?,True
@alchemication,2015-12-30T17:00:33Z,1,"Awesome series man! The 2 things I've learned recently, which could help here are: 1. train/test split from sklearn (it will always give you a reproducible randomised and stratified train/test datasets) and 2. confusion matrix (which will tell you where exactly your algo's are having issues, especially useful for binary problems). Thx!",True
@William-B,2015-06-03T01:56:13Z,0,"It isn't clear to me why 0-1900 would be a positive training set but 100-2000 would be a negative training set. If my ""documents"" list is shuffled, the resulting featuresets list should also be random.",True
@William-B,2015-06-03T01:50:50Z,1,You must have some oddity in the data you've pickled.  I'm getting 60-70% consistently for SGDC,True
@Tom-qs5ob,2015-05-17T17:01:55Z,0,Another Great Video! How Did I Ever Code Without You!,True
