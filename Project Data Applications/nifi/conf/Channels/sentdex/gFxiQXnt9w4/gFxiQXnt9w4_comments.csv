author,updated_at,like_count,text,public
@didactic4386,2022-07-27T22:35:46Z,0,22:37 LMAOO,True
@rowan404,2022-01-08T19:22:38Z,0,"""Some word I've never seen before"" *1 minute later* ""This is a family-friendly tutorial.""  Oh, you sweet summer child...",True
@lostboy5775,2021-02-04T10:27:55Z,0,22:37 hahaha I can't stop laughing xD. Me neither hahaha,True
@andrewscholz3098,2020-10-27T15:52:36Z,1,I can't seem to get the Tensorboard projector to load. Whenever I got to the projector tab it shows nothing but white. How do I get it to load?,True
@bedprogrammer,2020-10-18T07:53:17Z,0,i googled the word that you never saw before in your life. It led me to a website which is blocked in my country. I wonder what that website is can anyone tell me?,True
@aysershuhaib478,2020-08-24T23:01:05Z,0,"Thanks for the series, but I'm having this issue when i run python inference.py : module 'nmt.nmt.inference' has no attribute 'get_model_creator' and I checked inside nmt.inference file and the function is not there.",True
@adithiyasreenivasan5808,2020-05-08T10:03:26Z,0,hey my code is buffering a lot do you have any answer to this,True
@mem69,2019-11-22T18:09:33Z,0,How can i get my Tensorboard Projector to load with labels instead of numbers,True
@EranM,2019-11-14T13:09:53Z,0,is it possible to tokenize by n-grams ? 1-gram is words,True
@neilgeorge6227,2019-10-14T21:12:09Z,0,How much did it roughly cost on Paperspace?,True
@senzozikal3749,2019-10-02T02:22:53Z,0,I just tried this. Getting errors. Lots of errors because of deprecated packages.,True
@sameekshasaboo7192,2019-06-05T05:28:14Z,0,"Cant find the Models directory from your GitHub, due to which not being able to train using TensorBoard. Please resolve this asap as on a deadline to complete a project.",True
@josephrejive4081,2019-05-08T02:53:17Z,0,"For datasets such as MNIST, we usually need multiple epochs (sometimes 10) to create a good classifier. Why do we only need to train this model for 1 epoch? How can the NMT model learn some of the nuances of English in only 1 epoch? Is it because we have a lot of data?",True
@peterogbazghi1803,2019-04-24T00:38:27Z,0,"Hi there, am trying to do this in my Mac book, which clearly donâ€™t have the gpu power. what are the parts of this series that I need to do on Paper space. I am desperate.",True
@Gme612,2018-12-03T08:17:04Z,0,can this model be used to train a chatbot in a non roman language like turkish?,True
@monsuramayeen4149,2018-12-01T09:35:07Z,0,Does the code varies depending on the dataset?,True
@manjunathhampole9399,2018-10-27T02:12:56Z,0,What is the difference between dev_prefix and test_prefix in the settings.py file? I put my own train.from and train.to files but im getting confused on where to specify my test.from and test.to files in settings.py file.,True
@manjunathhampole9399,2018-10-27T01:14:40Z,0,"Hello, I am unable to get the TensorBoard to popup, can someone explain on what to do? I followed the steps to "".../model"" and opened terminal and all. Im unable to open it.",True
@namansharma6247,2018-08-03T20:32:27Z,0,Please help. it says Could not find a version that satisfies the requirement nmt (from versions: ) No matching distribution found for nmt Cant install nmt,True
@biswadeepupadhyay180,2018-07-30T06:35:01Z,0,"Alright! The model has already been trained once. Meanwhile I have some new well more precisely bigger datasets that i want my model to train with. Now the thing is I don't want  my model to lose out on anything it has already learnt . So the only sweet-dream way I'm lookin forward to is retraining my model. Now comes the question of the decade, How to do That! Please help.",True
@jrM5492,2018-06-17T17:10:00Z,1,how to load the projector data?,True
@salonitiwariinolas,2018-04-10T19:02:07Z,1,"Hello! Great series! I'd be glad if someone can help me. I ran train.py using FloydHub's cloud GPU. Though the ""job"" completed successfully, there were no checkpoint files created in the model/train_log. All it has is the projector_config.pbtxt file.",True
@randriakotonjanaharytolotr6249,2018-04-09T17:37:20Z,2,"20:32 Dude, it shows 33 seconds per steps and you reached 59300 steps, which means that it has been training for: 59300*33 s =1,956,900 seconds or 543.58 hours or 22.64 days. Is that true or there is something I am missing?",True
@Darkzzzz99,2018-03-28T09:05:58Z,0,Does anyone know how many epoch do I need to train a decent chatbot?  I am training it with a 2.5m pairs datasets.,True
@stephenwalker700,2018-03-24T12:59:07Z,1,Mine is still learning but couldnt resist skipping to the next video! Enjoying the series,True
@bori499,2018-02-28T14:42:08Z,1,what exactly is an epoch??If you could just explain. I searched the web but am not happy with the description.,True
@tejapolisetty3806,2018-02-25T14:32:41Z,0,Can you please tell again like how to calculate no. of epochs.  epochs = Number Of Example / Set size .         Where have you configured that Set Size. Thank you.,True
@vineethsai1575,2018-02-08T14:12:10Z,2,"my bleu score is always at 0.00 , please help what am i doing wrong ?",True
@xNoCommentGamesx,2018-02-06T16:54:00Z,1,"I have currently got 100 responses from my chatbot, but I'd say the best part of 85 responses are '[deleted]'?",True
@8o8inSquares,2018-01-31T14:34:04Z,0,"Alright for some reason, it trains but the BLEU is always 0.00, what's the problem here?",True
@SuperMURALI81,2018-01-13T08:19:11Z,2,"When should I stop training the model.What is the convergence point. These are my results:  ""global step 4400 lr 0.001 step-time 1.73s wps 4.07K ppl 82.76 gN 7.38 bleu 2.27"".  BLEU doesn't seem to increase and my ""test_ppl"" (Perplexity) is around 54.",True
@robokishan,2018-01-12T20:02:54Z,0,Why tensorflow docs are hard to understand. It seems like i should move to keras bcz its 3rd day and i am stuck at decoder in nmt how did you build it so fast wow.  Keras is so easy took me just 3 hours to do embeddings,True
@omarsalama6312,2017-12-21T16:48:06Z,0,i got this error    '''Fatal error in launcher: Unable to create process using  /after run this command tensorboard --logdir=train_log,True
@PhotoSlash,2017-12-20T14:26:36Z,0,"what if you want to ask for time or weather or for a timer? is this achievable with tensorflow? using datasets is useless for these purposes, how can i mix virtual assistant features with this chatbot?",True
@SG-rx1ck,2017-12-17T15:36:09Z,0,"I have two quick questions for anyone seeing this:  First, how do we go about changing the learning rate? Is the best way to change settings.py before re-running prepare_data.py?  Secondly, earlier in the series we split our raw data into training and test data. The training data is being used, obviously, but do we not use the test.(to|from) files that we created earlier? This isn't really important; I'm just curious.",True
@shivaraj-bh,2017-12-13T15:10:54Z,0,"How do I get over this error? I am getting this as soon as my vocab.size goes over 30000 raceback (most recent call last):   File ""C:\Users\sbh69\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 1323, in _do_call     return fn(*args)   File ""C:\Users\sbh69\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 1302, in _run_fn     status, run_metadata)   File ""C:\Users\sbh69\Anaconda3\lib\site-packages\tensorflow\python\framework\errors_impl.py"", line 473, in __exit__     c_api.TF_GetCode(self.status.status)) tensorflow.python.framework.errors_impl.InvalidArgumentError: indices[1,6] = 28174 is not in [0, 20003)          [[Node: dynamic_seq2seq/decoder/embedding_lookup = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[""loc:@embeddings/decoder/embedding_decoder""], validate_indices=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](embeddings/decoder/embedding_decoder/read, dynamic_seq2seq/decoder/transpose_1/_85)]]  During handling of the above exception, another exception occurred:  Traceback (most recent call last):   File ""train.py"", line 18, in <module>     tf.app.run(main=nmt.main, argv=[os.getcwd() + '\nmt\nmt\nmt.py'] + unparsed)   File ""C:\Users\sbh69\Anaconda3\lib\site-packages\tensorflow\python\platform\app.py"", line 129, in run     _sys.exit(main(argv))   File ""C:\Users\sbh69\PycharmProjects\ML\Chatbot\better_model/nmt\nmt\nmt.py"", line 539, in main     run_main(FLAGS, default_hparams, train_fn, inference_fn)   File ""C:\Users\sbh69\PycharmProjects\ML\Chatbot\better_model/nmt\nmt\nmt.py"", line 532, in run_main     train_fn(hparams, target_session=target_session)   File ""C:\Users\sbh69\PycharmProjects\ML\Chatbot\better_model/nmt\nmt\train.py"", line 266, in train     sample_tgt_data)   File ""C:\Users\sbh69\PycharmProjects\ML\Chatbot\better_model/nmt\nmt\train.py"", line 140, in run_full_eval     eval_model, eval_sess, model_dir, hparams, summary_writer)   File ""C:\Users\sbh69\PycharmProjects\ML\Chatbot\better_model/nmt\nmt\train.py"", line 71, in run_internal_eval     summary_writer, ""dev"")   File ""C:\Users\sbh69\PycharmProjects\ML\Chatbot\better_model/nmt\nmt\train.py"", line 420, in _internal_eval     ppl = model_helper.compute_perplexity(model, sess, label)   File ""C:\Users\sbh69\PycharmProjects\ML\Chatbot\better_model/nmt\nmt\model_helper.py"", line 453, in compute_perplexity     loss, predict_count, batch_size = model.eval(sess)   File ""C:\Users\sbh69\PycharmProjects\ML\Chatbot\better_model/nmt\nmt\model.py"", line 251, in eval     self.batch_size])   File ""C:\Users\sbh69\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 889, in run     run_metadata_ptr)   File ""C:\Users\sbh69\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 1120, in _run     feed_dict_tensor, options, run_metadata)   File ""C:\Users\sbh69\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 1317, in _do_run     options, run_metadata)   File ""C:\Users\sbh69\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 1336, in _do_call     raise type(e)(node_def, op, message) tensorflow.python.framework.errors_impl.InvalidArgumentError: indices[1,6] = 28174 is not in [0, 20003)          [[Node: dynamic_seq2seq/decoder/embedding_lookup = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[""loc:@embeddings/decoder/embedding_decoder""], validate_indices=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](embeddings/decoder/embedding_decoder/read, dynamic_seq2seq/decoder/transpose_1/_85)]]  Caused by op 'dynamic_seq2seq/decoder/embedding_lookup', defined at:   File ""train.py"", line 18, in <module>     tf.app.run(main=nmt.main, argv=[os.getcwd() + '\nmt\nmt\nmt.py'] + unparsed)   File ""C:\Users\sbh69\Anaconda3\lib\site-packages\tensorflow\python\platform\app.py"", line 129, in run     _sys.exit(main(argv))   File ""C:\Users\sbh69\PycharmProjects\ML\Chatbot\better_model/nmt\nmt\nmt.py"", line 539, in main     run_main(FLAGS, default_hparams, train_fn, inference_fn)   File ""C:\Users\sbh69\PycharmProjects\ML\Chatbot\better_model/nmt\nmt\nmt.py"", line 532, in run_main     train_fn(hparams, target_session=target_session)   File ""C:\Users\sbh69\PycharmProjects\ML\Chatbot\better_model/nmt\nmt\train.py"", line 223, in train     eval_model = model_helper.create_eval_model(model_creator, hparams, scope)   File ""C:\Users\sbh69\PycharmProjects\ML\Chatbot\better_model/nmt\nmt\model_helper.py"", line 157, in create_eval_model     extra_args=extra_args)   File ""C:\Users\sbh69\PycharmProjects\ML\Chatbot\better_model/nmt\nmt\attention_model.py"", line 61, in __init__     extra_args=extra_args)   File ""C:\Users\sbh69\PycharmProjects\ML\Chatbot\better_model/nmt\nmt\model.py"", line 97, in __init__     res = self.build_graph(hparams, scope=scope)   File ""C:\Users\sbh69\PycharmProjects\ML\Chatbot\better_model/nmt\nmt\model.py"", line 284, in build_graph     encoder_outputs, encoder_state, hparams)   File ""C:\Users\sbh69\PycharmProjects\ML\Chatbot\better_model/nmt\nmt\model.py"", line 377, in _build_decoder     self.embedding_decoder, target_input)   File ""C:\Users\sbh69\Anaconda3\lib\site-packages\tensorflow\python\ops\embedding_ops.py"", line 325, in embedding_lookup     transform_fn=None)   File ""C:\Users\sbh69\Anaconda3\lib\site-packages\tensorflow\python\ops\embedding_ops.py"", line 150, in _embedding_lookup_and_transform     result = _clip(_gather(params[0], ids, name=name), ids, max_norm)   File ""C:\Users\sbh69\Anaconda3\lib\site-packages\tensorflow\python\ops\embedding_ops.py"", line 54, in _gather     return array_ops.gather(params, ids, name=name)   File ""C:\Users\sbh69\Anaconda3\lib\site-packages\tensorflow\python\ops\array_ops.py"", line 2590, in gather     params, indices, validate_indices=validate_indices, name=name)   File ""C:\Users\sbh69\Anaconda3\lib\site-packages\tensorflow\python\ops\gen_array_ops.py"", line 1843, in gather     validate_indices=validate_indices, name=name)   File ""C:\Users\sbh69\Anaconda3\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 787, in _apply_op_helper     op_def=op_def)   File ""C:\Users\sbh69\Anaconda3\lib\site-packages\tensorflow\python\framework\ops.py"", line 3076, in create_op     op_def=op_def)   File ""C:\Users\sbh69\Anaconda3\lib\site-packages\tensorflow\python\framework\ops.py"", line 1561, in __init__     self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access  InvalidArgumentError (see above for traceback): indices[1,6] = 28174 is not in [0, 20003)          [[Node: dynamic_seq2seq/decoder/embedding_lookup = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[""loc:@embeddings/decoder/embedding_decoder""], validate_indices=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](embeddings/decoder/embedding_decoder/read, dynamic_seq2seq/decoder/transpose_1/_85)]]",True
@FalcoGer,2017-12-10T22:27:43Z,0,here I thought I might learn how to set up such a network,True
@vasudevand519,2017-12-10T21:09:05Z,0,"Hi sentdex, Excellent videos and text tutorials for Chatbot with TF. Running the Training module for 2015-03 month data from reddit",True
@barkhababbar1789,2017-12-10T12:38:13Z,0,Hi Sentdex amazing videos. I have been following this series and was developing chatbot alongside. When is the next video of this series coming up. REPLY,True
@Dr.Pinnacle,2017-12-10T08:22:55Z,0,i get the hyper link for tensor board but i can't open it. I've a Macbook pro I don't have a GPU.,True
@shivaraj-bh,2017-12-09T21:35:36Z,0,"I am getting this error when I run inference.py what could be the reason? Traceback (most recent call last):   File ""inference.py"", line 273, in <module>     answers = process_questions(question)[0]   File ""inference.py"", line 234, in process_questions     answers_list = inference_helper(prepared_questions)   File ""inference.py"", line 163, in start_inference     inference_object = do_start_inference(out_dir, hparams)   File ""inference.py"", line 47, in do_start_inference     hparams = nmt.create_hparams(flags)   File ""C:\Users\sbh69\PycharmProjects\ML\Chatbot\nmt-chatbot-master\nmt-chatbot-master/nmt\nmt\nmt.py"", line 344, in create_hparams     num_intra_threads=FLAGS.num_intra_threads, AttributeError: 'NoneType' object has no attribute 'num_intra_threads'",True
@senior5904,2017-12-09T12:26:26Z,0,That cmd trick :3 Happy to see you put it to use <3,True
@urbanmeznar9453,2017-12-08T20:58:28Z,0,I wonder what that word meant,True
@gyanendrokh,2017-12-08T07:46:51Z,0,"Hi Sentdex!!! I followed this series but I got lost somewhere in the middle. If you have time Please start a series based on NMT. Preparing the dataset and all, I can't understand much. Or if you have some other resource please suggest.",True
@shivaraj-bh,2017-12-08T02:15:01Z,0,What if I uncomment batch size...will I require 8gb of vram to support batch size of 128,True
@MasterBrothers661,2017-12-07T15:11:56Z,0,"I think you meant encoder vectorizes tokens , not tokenize. You need to provide tokens to encoder.",True
@shivaraj-bh,2017-12-07T06:18:47Z,0,Can you make a video explaining prepare_data.py,True
@mekafinchi,2017-12-07T04:24:33Z,2,Would you be able to take 2 fresh untrained instances of a deep neural network chatbot and have them train on each other? I want to see what happens but probably wouldn't be able to set it up myself,True
@elabeddhahbi3301,2017-12-06T17:27:07Z,1,can u do a network programming,True
@Dahandla,2017-12-06T16:53:31Z,0,"Thank you for your tutorials ,I really find them helpful.  Have a question , I have been trying to follow along with the series .After running  tensorboard --logdir=train_log/ There is a message "" Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.""? Also When loading TensorBoard and looking at the projector, the points are listed by index and not by label.  Under the DATA section says 27 tensors found  embedding/decoder/embedding...  What would I do to have them listed by label ?  I did the training locally, in my model Dir I have translate.ckpt-17000.index ,meta and data-00000-of-00001.  thanks",True
@ashissamal8251,2017-12-06T15:22:32Z,0,Thanks for the nice tutorial . Could you please describe more on data preparation   for training and testing . And data source  to build  the model,True
@kun312008,2017-12-06T15:16:55Z,0,"Hey, where can I find encoder.tsv for metadeta in TensorBoard Projector?",True
@peterkmm100,2017-12-06T14:07:03Z,3,aaaand you are ad banned! ;)  obviously a rare case of the algo jealouse syndrom (AJS).,True
@Dr.Pinnacle,2017-12-06T03:06:42Z,0,when can I except next tutorial about interacting with chatbot?,True
@shivaraj-bh,2017-12-05T23:29:03Z,0,I am getting this error when I run train.py : 2017-12-06 04:42:59.609325: E C:\tf_jenkins\home\workspace\tf-nightly-windows\M\windows-gpu\PY\36\tensorflow\stream_executor\cuda\cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_TIMEOUT 2017-12-06 04:42:59.609550: F C:\tf_jenkins\home\workspace\tf-nightly-windows\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_event_mgr.cc:203] Unexpected Event status: 1  Can someone help me figure out what this could be?,True
@shivaraj-bh,2017-12-05T23:03:54Z,0,I was thinking as to why while creating database u avoided large answers. Is it because they are tough to train or u wanted to avoid it. Just in case if I wanted to build a nn which would answer questions to me and if the answer is long will it give me a result or would I need a lot of computational power to help it run the model.,True
@its_me7363,2017-12-05T21:47:36Z,0,"Hi sentdex, I am getting an error related to data analysis tutorial as while checking matplotlib or numpy in cmd shows 'numpy'/'matplotlib' is not recognized as an internal or external command, operable program or batch file though I have set path in environment variables. Moreover, after importing these libraries, program showing the same error.   Can u help me? Show less REPLY",True
@thanga511,2017-12-05T12:04:26Z,0,I liked it first and then started watching it :) i know you are awesome :),True
@codethings271,2017-12-05T11:26:00Z,2,Its fucking amazing,True
@chaopan7205,2017-12-05T11:05:42Z,33,"22:37, lol",True
@retiber1,2017-12-05T08:27:20Z,6,"Man, could you write a python code that will automatically ""like"" all your videos?",True
@jushkunjuret4386,2017-12-05T05:27:30Z,1,"Hey Harrison, thanks for the tutorial!!  But I ran into a problem: the trian.py is ran on a Ubuntu 16.04 LTS with python3.6, GeForce GTX 1080  But it terminated with error: OOM when allocating tensor with shape[512,96554]  I think there is a batch size parameter is set too large, and I need to tune it to smaller one.  Did you encounter any similar problem or have any idea what's going on?  Thanks so much!",True
@jondoe6608,2017-12-05T04:58:31Z,0,love your tutorial,True
@MariusNiveriHH,2017-12-05T02:17:34Z,12,It would be interesting to see if you'd let Charles speak with himself. I mean it should be easy to map the output as the next input for 20 lines or something like this,True
@mpanetta755,2017-12-05T01:38:15Z,1,"Hey sentdex, I'm loving this tutorial series. It was perfect timing as I've been researching IBM and Microsoft's chatbot and AI offerings.   I do have a question about this part: Are we able to 'pause' and restart the training? So if I'm on step 1000, can I stop the script, restart the script, and then pick back up where I left off? I am starting on paperspace for now but may want to move my model to a different place in the future.   Thanks!",True
@maximmikhaylov3234,2017-12-05T00:57:45Z,3,"Thanks for the tutorial, sentdex! I have a few questions: 1. What Paperspace instance are you using to train your current model (the one that is still training in the video)? 2. How much disk space does the training data for that model takes? 3. Any specific reason why you went with TF for this project? I find Keras sufficient for high-level architectural choices. And if some low-level tweaking is required, I personally find PyTorch a bit more intuitive compared to TF.",True
@theocachet6496,2017-12-04T23:22:41Z,0,"Hi guys, I have trouble by training on my GPU. I only have 1Gb of VRAM I know this is not a lot but I still want to try to train locally. Even when I put ""2000"" for vocab_size I keep get the OOM error. Do you guys have an idea of how I can overcome this problem? Any parameters that I could change to reduce GPU memory use?",True
@Mezklador,2017-12-04T22:48:16Z,2,"As I watch all these series of videos, I have to ask a question: do you work standing 'up' in front of your computer? because it seems a very odd angle of camera view. It reminds me a video here on YT about Linus Torvald working the same way...",True
@SecondSight,2017-12-04T22:37:03Z,0,"im trying to understand this, so are you basically mapping input sequences of tokens to output sequences of tokens, the probability of a certain set of reddit top comments having a certain set of response comment tokens? im looking at the translation picture, and i can see how you can map english text -> french text, red -> blue, but with english > english its like, just mapping blue -> blue sort of? so like one set of english words > another set of english words? also, does it muck up grammar or are the words usually combined in a coherent way? is there a way to deal with this? it would be cool if it could understand when youre talking about a person, or an object, or a place, and so on, and not just token mapping?",True
@ashrf8050,2017-12-04T21:50:49Z,0,thank you very much,True
@cicikus1549,2017-12-04T21:38:24Z,0,please make a pygame spritesheet making and how to use it in animation with keys,True
@mylifebeflyffable,2017-12-04T20:14:52Z,0,Could you maybe explain the settings in more detail? For example the Vocab size (which you mentioned shortly in your last video) and the test size,True
@xarifsowad849,2017-12-04T20:10:00Z,0,love Harrison only for this that you make me understand easily about those cool weirdo stuff,True
@mylifebeflyffable,2017-12-04T20:07:50Z,1,This video did clarify the meaning of a lot of things. Thanks,True
@cacz2200,2017-12-04T19:09:52Z,65,22:37 haha me neither : 'D,True
@umangkr257,2017-12-04T18:47:04Z,1,while running train.py it throws index out of range . why?,True
