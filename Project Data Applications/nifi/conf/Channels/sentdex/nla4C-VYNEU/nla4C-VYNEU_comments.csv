author,updated_at,like_count,text,public
@joxa6119,2022-04-25T06:40:41Z,0,The voting is bagging ensemble right?,True
@aliseylaneh4268,2020-12-17T18:27:56Z,0,"Hey It's the end of 2020 and I started this course and it's really helpful but I got a problem which is related to SGDClassifier which happens when the program reaches out to the line where the accuracy of SGDClassifier is going to be calculated:  Traceback (most recent call last):   File ""c:\Users\alise\Desktop\twitter-data-scraper\nltk-sentdex\test.py"", line 86, in <module>     (nltk.classify.accuracy(SGDClassifier_Classifier, testing_set))*100)   File ""C:\Users\alise\AppData\Roaming\Python\Python37\site-packages\nltk\classify\util.py"", line 91, in accuracy     results = classifier.classify_many([fs for (fs, l) in gold])   File ""C:\Users\alise\AppData\Roaming\Python\Python37\site-packages\nltk\classify\scikitlearn.py"", line 80, in classify_many     X = self._vectorizer.transform(featuresets)   File ""C:\Program Files (x86)\Python37-32\lib\site-packages\sklearn\feature_extraction\_dict_vectorizer.py"", line 289, in transform     return self._transform(X, fitting=False)   File ""C:\Program Files (x86)\Python37-32\lib\site-packages\sklearn\feature_extraction\_dict_vectorizer.py"", line 150, in _transform     feature_names = self.feature_names_ AttributeError: 'DictVectorizer' object has no attribute 'feature_names_' Been searching for 1 hour but didn't find anything because I don't anything about sci-kit learn :)",True
@pooydragon5398,2020-10-23T08:51:15Z,0,Why is the accuracy changing even though the code is the same ?,True
@abdelkhalik.aljuneidi,2020-01-17T08:10:08Z,0,"it is clear that you have no experience in NLTK, BUT your course is great for beginners",True
@anajab01,2019-08-15T03:43:49Z,0,"I want to thank you, I was really lost in sentiment analysis and the use of classifiers. I got the base to acheive my ""text mining"" course.",True
@GelsYT,2019-04-11T14:39:32Z,0,"I have warnings like this  C:\Users\LENOVO\PycharmProjects\sentdexTutorialsNLP\venv\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.    FutureWarning)  LogisticRegression accuracy percent:  83.0  C:\Users\LENOVO\PycharmProjects\sentdexTutorialsNLP\venv\lib\site-packages\sklearn\linear_model\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.    FutureWarning)     I think it has something to do with the parameters",True
@GelsYT,2019-04-11T13:23:09Z,0,so the SklearnClassifier() always needs of a na√Øve_bayes algorithm? as a parameter?,True
@mengshen4077,2018-10-08T01:36:24Z,0,"Very good tutorial!  I've been learning nltk but now I meet some problems when incorporating with sklearn. it seems sklearn provides completely different w2v method from nltk. error occurs when I use nltk to include bigram for trainning... also, does sklearn provides any methods like show_most_informative_features?  thanks!",True
@TonyJaeger,2018-05-29T20:57:07Z,0,"Hi Dex!  How can I write my own text, and see how it is classified by my classifier? I tried nltk.classify.accuracy(classifier, text) where the classifier was the original naive bayes, and the text is a string like ""Best movie ever!""... it always returns ""neg"" though.",True
@samikhan38232,2018-05-14T18:25:26Z,1,Question: how can we find the CONFUSION MATRIX and also ROC of these classifiers.,True
@priyankasonisoni927,2018-03-07T11:19:51Z,0,how to Find all locations / cities / places in a text ??,True
@kushshri05,2018-02-26T04:33:42Z,0,Do results vary from OS to OS... because I am using MAC and getting results like: Original Naive bayes algo Accuracy:  88.0 MNB classifier algo Accuracy:  84.0 BNB classifier algo Accuracy:  83.0 Linear Reg classifier algo Accuracy:  77.0 SGD classifier algo Accuracy:  81.0 SVC classifier algo Accuracy:  82.0 LSVC classifier algo Accuracy:  75.0 NUSVC classifier algo Accuracy:  81.0,True
@raiyanyahya,2018-02-21T06:22:38Z,0,"Hi Harrison,  I used the positive and negative txt files which were provided and got a good accuracy % of ~80 % but when i chose a different data set both negative and positive texts being 4 mb each my accuracy dropped to ~ 60% . Can you please please help me on this or recommend another approach ?",True
@thesuavedeveloper7532,2018-01-25T11:32:41Z,0,Rewards to anyone who can actually make a for loop for that! O.O,True
@zobairhussain1276,2018-01-09T17:54:05Z,0,"MNB_classifier accuracy percent: 82.0 BernoulliNB_classifier accuracy percent: 80.0 LogisticRegression_classifier accuracy percent: 81.0  D:\Soft\Anaconda3\lib\site-packages\sklearn\linear_model\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.   ""and default tol will be 1e-3."" % type(self), FutureWarning)  SGDClassifier_classifier accuracy percent: 81.0 SVC_classifier accuracy percent: 80.0 LinearSVC_classifier accuracy percent: 81.0 NuSVC_classifier accuracy percent: 86.0   sir, it shows extra this lines. I don't know why. can you tell me please. thanks",True
@shivangisharma592,2017-10-02T08:12:22Z,7,sir ! u teach so well and u are smart as well! feels good when u chuckle :D,True
@dude2260,2017-09-24T17:53:40Z,0,all my classifiers are giving same accuracy every time why is this happening  ?,True
@zimttrolle6196,2017-09-08T22:14:09Z,0,why are u loading from naivebays.pickle? You are not saving anything there. As I remember u have commented it out.,True
@simonchan2394,2017-08-14T12:37:50Z,1,Has anyone been able to solve the code for the GaussianNB?,True
@VISHALBHARATMORE,2017-07-28T18:36:52Z,0,"I am facing following error while executing code.  : -  File ""/usr/local/lib/python2.7/dist-packages/nltk/classify/scikitlearn.py"", line 69, in __init__     self._encoder = LabelEncoder()  NameError: global name 'LabelEncoder' is not defined   I tried to find some solutions on google. Most of suggestions are related to upgrading Numpy or Sci-kit learn. I have tried this ,but it's not working.",True
@mushtaque87,2017-07-20T16:38:00Z,0,"I am getting too similar accuracy   ('Naive Bayes Algo acuracy percent :', 46.0) Most Informative Features                   sucess = False             neg : pos    =      1.0 : 1.0 ('MNB_classifier Algo acuracy percent :', 46.0) ('Bernoulli_classifier Algo acuracy percent :', 46.0) ('Logistic_classifier Algo acuracy percent :', 46.0) ('SGDC_classifier Algo acuracy percent :', 46.0) ('SVC_classifier Algo acuracy percent :', 46.0) ('Linear_classifier Algo acuracy percent :', 46.0) ('NuSVC_classifier Algo acuracy percent :', 46.0)  Anyone has seen this ... Whats wrong  .  Edited : Somethimes I get this also   ('MNB_classifier Algo acuracy percent :', 0.0) ('Bernoulli_classifier Algo acuracy percent :', 0.0) ('Logistic_classifier Algo acuracy percent :', 0.0) ('SGDC_classifier Algo acuracy percent :', 100.0) ('SVC_classifier Algo acuracy percent :', 0.0) ('Linear_classifier Algo acuracy percent :', 0.0) ('NuSVC_classifier Algo acuracy percent :', 100.0)",True
@seanboothby7792,2017-05-09T05:39:15Z,0,"Not sure exactly where I went wrong, but all of the algos reported incredibly high accuracy.  Any reason why this may be? Even SVC classifier accuracy at 0.85. Could it be variance?  Thanks in advance, appreciate these videos.",True
@rajjad,2017-04-17T12:43:31Z,0,so this is how far I could go.. because I was unable to install scipy using pip because it required numpy+mkl and that I think is not available for Python 3.5,True
@VishalKumar-eb7sp,2017-03-12T19:42:59Z,0,"It is showing error          C:\Python34\python.exe C:/Users/RakeshS/PycharmProjects/NLTK9/Scikit-Learn.py Traceback (most recent call last):   File ""C:/Users/RakeshS/PycharmProjects/NLTK9/Scikit-Learn.py"", line 7, in <module>     from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB   File ""C:\Python34\lib\site-packages\sklearn\__init__.py"", line 57, in <module>     from .base import clone   File ""C:\Python34\lib\site-packages\sklearn\base.py"", line 10, in <module>     from scipy import sparse   File ""C:\Python34\lib\site-packages\scipy\__init__.py"", line 61, in <module>     from numpy._distributor_init import NUMPY_MKL  # requires numpy+mkl ImportError: cannot import name 'NUMPY_MKL'  Process finished with exit code 1 why?? I am not able to get clone & sparse.",True
@HimanshuKumar-dz1rb,2017-02-12T19:48:04Z,0,Posted Code on GitHub. Link:https://github.com/HimanshuKumar111/nltk Along with all the pickle files. Thank you sentdex for your support,True
@agraneebanerjee305,2017-01-28T16:16:05Z,1,Sir i am having problem at installing scipy ..please help me out..,True
@HARSHITAGUPTAharshi,2016-12-22T12:52:10Z,0,"Hey, I am poor at short cuts.Please tell me how to add something at the start of multiple lines simultaneously (like you do comment) on LINUX.",True
@sabr9906,2016-11-14T11:27:57Z,3,"Interesting how we can merge modules, indeed!  Just one tip:  Usually when we try to select the best classifier, e.g. the best model - this process called Model Selection. And also it's better to have some def method with that class instance in parameter. Smth like this:  def classifier(c_instance):      c_instance.train(training_set)      print ""%s accuracy percent: %s"" % (c_instance.__name__, nltk.classify.accuracy(c_instance, testing_set))  for c in [Classifier1, Classifier2, Classifier3]:    c_instance = c()  # will use default params    classifier(c_instance)",True
@srinidhiskanda754,2016-11-12T17:51:23Z,0,thank you so much i was looking for this information how nltk play along with scikit. what is your opinion on tools like gensim or word2vec how can we use along with nltk or scikit learn,True
@nishchalalagh7554,2016-11-10T19:19:50Z,2,Having trouble downloading scipy...,True
@mega6699,2016-10-19T10:44:05Z,9,"I used 3000 most frequent words as features (chnaged one line in the code as suggested in the comments to the part 12) and the results of classifiers are much more consistent, all very close to 82%: ('Original Naive Bayes Classifier accuracy percent:', 82.0) ('MNB_classifier accuracy percent:', 86.0) ('BernoulliNB_classifier accuracy percent:', 82.0) ('LogisticRegression_classifier accuracy percent:', 80.0) ('SGDClassifier_classifier accuracy percent:', 82.0) ('SVC_classifier accuracy percent:', 81.0) ('LinearSVC_classifier accuracy percent:', 78.0) ('NuSVC_classifier accuracy percent:', 82.0)  SVC is not worse than others in this case.",True
@hskleo,2016-09-22T08:43:20Z,0,"Hi sentdex, so sorry to bring any trouble. But I have difficulty installing scipy, could you pls kindly assist? Thanks a lot.  ===============error message===============  C:\Users\lilong>pip install scipy Collecting scipy   Using cached scipy-0.18.1.tar.gz Installing collected packages: scipy   Running setup.py install for scipy ... error     Complete output from command d:\python3\python.exe -u -c ""import setuptools,  tokenize;__file__='C:\\Users\\lilong\\AppData\\Local\\Temp\\pip-build-ls81lcxh\ \scipy\\setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read(). replace('\r\n', '\n'), __file__, 'exec'))"" install --record C:\Users\lilong\AppD ata\Local\Temp\pip-va61blnp-record\install-record.txt --single-version-externall y-managed --compile:      Note: if you need reliable uninstall behavior, then install     with pip instead of using `setup.py install`:        - `pip install .`       (from a git repo or downloaded source                                release)       - `pip install scipy`   (last SciPy release on PyPI)",True
@RaoufGnda,2016-08-23T16:13:38Z,0,NameError: global name 'LabelEncoder' is not defined,True
@Kghimire,2016-08-07T16:56:40Z,1,"please replay its urgent   >>> from nltk.classify.scikitlearn import SklearnClassifier  (This is executing ) >>> from sklearn.naive_bayes import MultinomialNB,BernoulliNB (Error on executing this)  Traceback (most recent call last):   File ""<pyshell#1>"", line 1, in <module>     from sklearn.naive_bayes import MultinomialNB,BernoulliNB   File ""C:\Program Files\Python34\lib\site-packages\sklearn\__init__.py"", line 56, in <module>     from . import __check_build ImportError: cannot import name '__check_build'  Please help me out.",True
@ollz365,2016-08-06T13:23:34Z,0,"I keep getting a memory error, any help?",True
@adarshsodani1,2016-07-28T06:05:41Z,3,"While using   >>> from nltk.classify.scikitlearn import SklearnClassifier  (This is executing ) >>> from sklearn.naive_bayes import MultinomialNB,BernoulliNB (Error on executing this)  Traceback (most recent call last):   File ""<pyshell#1>"", line 1, in <module>     from sklearn.naive_bayes import MultinomialNB,BernoulliNB   File ""C:\Program Files\Python34\lib\site-packages\sklearn\__init__.py"", line 56, in <module>     from . import __check_build ImportError: cannot import name '__check_build'  Please help me out.",True
@RealMcDudu,2016-06-04T16:47:08Z,0,"A question: given the features that you chose why is there any difference between the ""regular"" Naive Bayes, the multinomial one, and the Bernoulli one? Since you only choose a subset of 3000 common words, and from them you just ask - did they appear (once or more) =1 or didn't appear (at all) = 0 - this seems basically like a Bernoulli naive-bayes. A multinomial NB would actually count the frequency of each word and take that into account. I don't understand how there can be different results???  Update: from what I could understand from the nltk documentation, it seems like it is a multinomial Naive Bayes, but again - I still don't understand why would it have any effect if the features are all ready ""bernoulli-zed""",True
@khushmeeet,2016-04-17T12:13:19Z,0,Who would you compare nltk with spaCy? Which one's better?,True
@randallreed9279,2016-04-09T20:31:26Z,0,So you mention in an offhand way that you could use a for loop to change all these classifiers. But googling I haven't been able to figure out how you would do that. Can you say how you would do that?,True
@FinallyAFreeUsername,2016-01-21T23:19:54Z,7,Why does your dog keep staring at us?,True
@yuvishachaf,2015-11-06T07:06:50Z,0,"Thanks for such great tutorials. One Q: when you use the multinomial naive bayes, dont you need to use word count (freq) rather than binary representation used only for the Bernoulli model?",True
@AnthonyRBarberini,2015-10-01T10:32:33Z,0,"Cant figure out why I seem to be missing parts of sklearn when I should have the most recent version..  I followed your video on adding via pip, went to the download site and got the correct 32bit version whl file; everything appears to install without a hitch and I'm able to ""import sklearn"" by itself from command prompt; but if I try how you have it.. ""from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB "" it won't work and I get ""ImportError DLL failed to load ; specified module could not be found.""  Any ideas what's going on here and how to fix it?",True
@Rochbenritter,2015-09-08T18:04:56Z,1,"Ok solved (just forgot the import :P).  Nevertheless with the Gaussian NB I get to following error: ¬†File ""/home/USER/Dropbox/PycharmProjects/NLTK/NLTK_P15.py"", line 74, in <module> ¬† ¬† GNB_classifier.train(training_set) ¬† File ""/usr/local/lib/python3.4/dist-packages/nltk/classify/scikitlearn.py"", line 117, in train ¬† ¬† self._clf.fit(X, y) ¬† File ""/home/USER/.local/lib/python3.4/site-packages/sklearn/naive_bayes.py"", line 164, in fit ¬† ¬† X, y = check_X_y(X, y) ¬† File ""/home/USER/.local/lib/python3.4/site-packages/sklearn/utils/validation.py"", line 444, in check_X_y ¬† ¬† ensure_min_features) ¬† File ""/home/USER/.local/lib/python3.4/site-packages/sklearn/utils/validation.py"", line 334, in check_array ¬† ¬† copy, force_all_finite) ¬† File ""/home/USER/.local/lib/python3.4/site-packages/sklearn/utils/validation.py"", line 239, in _ensure_sparse_format ¬† ¬† raise TypeError('A sparse matrix was passed, but dense ' TypeError: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.  Someone got an idea or could post it to stackoverflow in a ""real"" question?",True
@cintiacamachobadillo2844,2015-07-09T17:42:57Z,0,"just an observation: the numpy unoptimized version doesn't work with scipy, I had to uninstall it and install the normal version. -.-'",True
@Stefanslaapt,2015-06-04T17:10:30Z,0,"If i want to use this on Dutch dataset, would that be possible? And if not, can you suggest a resource which gives me the opportunity to do this? Thanks in advance!",True
@unquenchedsoul,2015-06-02T07:21:41Z,0,"Suppose I want to classify a text, which will be better : Using nltk wrapper for scikit or scikit itself as it uses only numerical data?",True
@wild24duc,2015-05-22T11:26:08Z,1,"hi I use python 3.4 32-bits but when I install sklearn for python 3.4 32-bits and I run your code , there was an error ""ImportError: cannot import name '__check_build' ¬†"".¬† Is there any way to solve it? Thanks.",True
