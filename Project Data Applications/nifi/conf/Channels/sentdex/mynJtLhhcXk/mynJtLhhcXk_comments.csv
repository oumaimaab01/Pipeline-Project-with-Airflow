author,updated_at,like_count,text,public
@zardouayassir7359,2021-03-18T09:29:08Z,0,"In the current doc they say: ""tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=logits)"", so I think that using tf.nn.softmax_cross_entropy_with_logits(prediction, y) is incorrect because position of arguments is incorrect. I think that swaping them by using tf.nn.softmax_cross_entropy_with_logits(prediction, y) may work!",True
@EverythingTechWithMustafa,2020-03-21T15:39:56Z,0,Is it like rolling hashes but no hashing?,True
@purvanyatyagi2494,2020-03-16T15:52:50Z,0,can we use a keras layer in the model along with the tensorflow layers. pls tell,True
@keremalidogan5518,2019-11-24T12:45:27Z,0,"I am no expert on this, but I think I know why dropout has negative effect.  Since we are only training the data and not testing on another batch, dropout is ineffective. With dropout, I think you are supposed to have lower accuracy on training set but a higher accuracy on testing set.   Thanks",True
@karthiks991,2019-09-29T07:34:33Z,0,"Sir, if I want to add an adaboost classifier for the features extracted using CNN how would you do that?.... solution for this?",True
@AhmedGamal-jk7xn,2019-05-14T20:44:47Z,1,"can any one please help, i run this code and i get accuracy 10.3% and the epoch loss values are in negative",True
@43SunSon,2019-05-07T17:46:35Z,0,Why you didn't apply reluLayers after each conv layers?  I think this is necessary or I am wrong?  thanks.,True
@43SunSon,2019-05-07T16:51:23Z,0,"can someone tell me, why strides=[1,1,1,1], not just one 1?  Whats meanning of four 1 here?  the same as strides=[1,2,2,1], just move 2 each time, but why 1,2,2,1 ?  Thanks.",True
@burak_gulmez,2019-03-26T18:04:10Z,0,How did tensorflow understand the values that changes for the optimization? Where did you write it in the code? Where did you indicate the weights are the values that changes to the program?,True
,2018-12-21T08:56:48Z,1,"fc = tf.nn.relu(tf.matmul(fc, weights['W_fc']) + biases['b_fc'])   Exception has occurred: ValueError Shape must be rank 2 but is rank 1 for 'MatMul' (op: 'MatMul') with input shapes: [?,3136], [3211264].  Anybody get that?",True
@pwcloete8022,2018-10-05T16:33:45Z,0,"Hi, I ran the code of this turorial, and ended up with a very good error value (945.23), but the accuracy evaluation was horrible? Accuracy of 14.67% (without dropout) and 30.4% (with dropout). That doesn't make sense (nevermind the good error but bad accuracy)... any suggestions how this could be? I literally followed the tutorial word for word (except the using the cross_entropy_with_logits_v2 now)",True
@NgodingPython,2018-07-14T15:10:44Z,1,"Hi Harisson,  I learned a lot from this video,  i have a question, why you didn't use activation function (e.g : relu) for each convolutional layers ?",True
@IdontneedanIpod,2018-07-05T04:40:54Z,0,"Hey Sentdex,  I find that when I run this code in the IDLE,  I get the warnings I normally get (the previous tutorial on RNNs worked perfectly) but then the code exits and gives me no output, it looks like this:  >>>   RESTART: C:\Users\Connor\PycharmProjects\Machine Learning Tutorials\Machine Learning Tutorial 57 (2) - Convolutional Neural Networks.py  WARNING:tensorflow:From C:\Users\Connor\PycharmProjects\Machine Learning Tutorials\Machine Learning Tutorial 57 (2) - Convolutional Neural Networks.py:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version. Instructions for updating: Please use alternatives such as official/mnist/dataset.py from tensorflow/models.  # (more warnings)   WARNING:tensorflow:From C:\Users\Connor\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\contrib\learn\python\learn\datasets\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version. Instructions for updating: Please use alternatives such as official/mnist/dataset.py from tensorflow/models.  =============================== RESTART: Shell =============================== >>>   What could be wrong here?",True
@AnkitSingh-hb2mn,2018-06-04T12:02:15Z,0,How do think about the sizes of matrix that we get after each convolution and input to FC layer? any insights as to how to think about it?,True
@moorthysathishkumar1529,2018-05-25T01:25:02Z,0,How to create CNN for own image set and how can I visualize each convolutional layers output?,True
@MrZouzan,2018-04-08T23:52:56Z,0,I got a question!!! Should you turn off dropout when you test the network?,True
@sudhanshukumar1558,2018-04-04T16:07:33Z,0,"Cool , keep up with the good work",True
@JonSeanOfYarina,2018-03-29T20:35:57Z,3,"This will give you an error now.  cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(prediction, y)) Use instead.  cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y))  sess.run(tf.initialize_all_variables()) Should be replaced with  sess.run(tf.global_variables_initializer())",True
@manojagarwal3441,2018-03-19T16:36:53Z,0,i have doubt regarding line number 23 to 27    My doubt is that  if i am not getting wrong our input is a 28* 28 matrix  and we have 10 classes to predict  then how we calculated the the number of inputs and outputs to and from hidden layers like 1 and 32 in layer 1 32 and 64 for layer 2 fully connected layer 7*7*64  please harrison if you can add a detailed video on same that will be highly helpful,True
@karthikl5354,2018-03-15T18:45:15Z,0,Y u didn't apply any activation function at output layer?,True
@cubetastic3386,2018-03-13T14:29:14Z,0,I don't understand. Why do we even have that data argument in the function neural_network_model(data) in the regular neural network? I don't see it being used anywhere!,True
@cubetastic3386,2018-03-13T10:18:45Z,1,"What? No ""What is going on everybody, and welcome to part 13 of our Deep Learning with Neural Networks, TensorFlow, and of course Python Tutorial Series""?",True
@Nusiq,2018-02-22T18:59:30Z,1,I have GTX 1060 3GB. I keep getting warnings saying that I could get better performance If I had more memory :(,True
@funkupgamer5364,2018-02-13T15:30:59Z,1,then how we will test on another image.. like give a image to the model to predict...,True
@nidhipriyajha2017,2018-01-30T13:45:30Z,0,Hello Sir!! I want to use this code for my own dataset not MNIST dataset so can you please tell me how do I import my own dataset in the code. I am a beginner in this field kindly help me out. Thanks in advance,True
@danielsebastian1295,2018-01-28T06:55:11Z,1,"Can someone explain how he came up with 5*5, 5*5, then 7*7*64?",True
@SamRaisbeck,2018-01-09T17:08:08Z,4,"Does anyone know if the number of output features for each convolution is arbitrary? Like if you pick 32 for the first layer, must it be 64 for the second, and 1024 nodes for the fully connected? Is there some ratio involved?",True
@ArunSingh-mx6wg,2017-12-26T18:30:20Z,0,What's use of baises of conv1 n conv2??,True
@kheireddinedaouadi7010,2017-12-20T02:02:49Z,0,"thanks for this awesome tutorial, i ask to you if i would do a classification with cnn with my own feature which code i will use.",True
@mohamedamin3240,2017-12-16T21:20:25Z,0,"if we want to test the network ,only evaluate it and print the accuracy ?",True
@brandenstrochinsky2865,2017-12-07T14:10:45Z,0,Awesome video!,True
@MuradAlQurishee,2017-11-29T20:17:42Z,0,"You did a good job. For multiple classifications of images, what can we do?",True
@goncalosan-payo8860,2017-11-28T13:12:43Z,6,How do you know that after 2 convolutions the image size is 7*7? Is there any mathematical formula to calculate this?,True
@sebek128,2017-11-20T08:33:57Z,0,"Isn't it true that if You optimize cost, which is calculated by mean of difference of logits and labels, You would end up with quite large errors on individual outputs, some positive some negative, it is just mean of those that is close to 0 ?  I have got cost reduced to 0, but my accuracy is very low ( 0.1 - 0.4 ) What should I do to improve it?",True
@mstanojevic118,2017-11-19T16:12:07Z,2,I was wondering why stride has 4d and what does -1 in reshape mean and this is very well explained here: https://stackoverflow.com/questions/34642595/tensorflow-strides-argument,True
@jonathanmay256,2017-10-30T16:08:58Z,0,"For those wondering, transpose just swaps rows and columns.   So for instance: if you have a 10x4 matrix (of 10 rows, 4 columns), the transpose of that matrix will be a 4x10 matrix (of 4 rows, 10 columns).   Another way to think of it is just switching the indices of list. So, m[2,4] transposed will be addressed as m[4,2].",True
@tintr.9619,2017-10-18T09:43:02Z,0,"i have the code and have an error at  def train_neural_network(x):      cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(prediction,y) )  ------------> ValueError: Only call `softmax_cross_entropy_with_logits` with named arguments (labels=..., logits=..., ...)  what error is that ?",True
@KB-jt5cr,2017-10-07T15:08:57Z,0,How can we use convolusional  neural network for only extract features and train SVM on these features?,True
@douglasoak7964,2017-10-02T09:54:17Z,0,This code doesnt work anymore,True
@douglasoak7964,2017-10-02T09:03:21Z,0,"out of curiosity why did you write y = tf.placeholder('float') rather than tf.placeholder(tf.float32); question not meant as criticism, just wondering",True
@douglasoak7964,2017-10-02T03:37:15Z,0,Dropout helps prevent over fitting and you should use 0.5 for training.,True
@pingshiyu,2017-09-10T00:04:05Z,1,"I still don't fully get the [a,b,c,d] parameter's meaning - what exactly does c and d, the 'input channel' and 'output channel / features' mean? How exactly is a list of numbers going to do the 'convolution' for us? Is everything else done by tensorflow and this sort of parameters is simply for notation?",True
@arjunkrishna8873,2017-09-04T19:28:12Z,0,i have gtx 950m 2gb and i can run maximum 9 epox  through this code,True
@arjunkrishna8873,2017-09-04T18:47:35Z,0,"hey all,the code in the video is wrong because he omitted the biases for conv1 and conv2 layer and also usually we have a  relu layer after each conv layer.he  corrected  the code in his website.",True
@deepquest,2017-09-01T11:55:38Z,2,At fully connected layer at the place of 1024 can we take any number as we want  ? Or there is any caculation behind for taking these numbers.,True
@debanjansengupta6606,2017-08-27T04:25:29Z,0,Can you create tutorial series on PyTorch? It seems more Python like than Tensorflow.,True
@PradyMj,2017-08-17T22:14:30Z,0,"Hi Harrison,   I have 16GB Ram and GTX 960M , i7 processor. But when I am running this piece of code in Anaconda its getting ResourceExhaustedError: OOM, after running all 9 Epoch. I thought GTX 960M was good enough for handling this. Any idea whats wrong with it? Or I still need more GPU to run this code? ( Yes I am aware of using it in batches).   And last but not the least: Your tutorials are the best around the internet. YOU ARE THE BEST. Please keep them coming. :)",True
@MrPpppp55555,2017-07-19T11:54:46Z,0,"I missed the way you usually start the video.  ""what is going on everybody"".. Other than that.. Brilliant video as usual.",True
@mlcramer,2017-07-09T20:44:07Z,1,"Great series as always, love all the videos you do!!!  This is a minor point, I haven't looked far back in the comments, so if someone pointed this out already, apologies. I am pretty sure you are supposed to use 'keep_prob' as a passed parameter to the feed_dict, that way you can use dropout only while training, and then not use it when actually evaluating the nn. See the example on the tensor flow page: https://www.tensorflow.org/get_started/mnist/pros -- Notice that the feed_dict has the parameter keep_prob: 0.5 for training and keep_prob: 1.0 for the evaluation. I am pretty sure if you are using dropout during the evaluation, you are not taking full advantage of the final layer you've trained.",True
@nickmcneely5601,2017-06-22T02:54:01Z,0,"If your second conv layer feeds into a couple of recurrent layers, would that be better or worse than just having conv layers?",True
@jrmo1421,2017-06-20T07:24:58Z,0,"Is there a way to split up the training and testing, when I try to run this on my gpu, which unfortunately only has 2gb of ram, it is able to finish the training, then it immediately crashes.",True
@sapiranimations,2017-06-10T22:18:34Z,0,why do you do the biases manually? There is a function called tf.nn.addBias(tensor t) or something like that,True
@007himu,2017-06-07T05:05:09Z,0,Any Github link for the code?,True
@mounirmallek3255,2017-06-02T21:55:10Z,0,What hardware configuration are you running this code on ? mine is sooo slow ! what would be ideal ?,True
@farshidrayhan8496,2017-05-11T17:50:53Z,0,Where does the number 1024 come from why it dimension mismatch when i change it ? Actually it says dimension mismatch for any change of the values such as filter size pool size .. Pls help me understand the relation among them  .what would be the changes if i wanted to 12 filters in conv1 ?,True
@anirbanghosh7987,2017-05-04T01:25:25Z,0,"Hi, I tried to run the code but it is failing due to memory error whenever i added the conv net. but a simple hello world program through tensorflow is working. So i  think my tensorflow is installed correctly. Can you suggest me a way to see how much memory should i need to evaluate a computation graph or how much memory does my designed computation network is going to take? any pointers would be helpful",True
@jobrown04,2017-04-13T13:39:32Z,2,"Whenever I implement your code, my kernel dies. I'm using Windows, Anaconda, Spyder and Python 3.5.  Any ideas why folks?",True
@pigzrulez,2017-04-13T07:25:10Z,2,is the keep_prob placeholder being used at all?,True
@luckek1354,2017-04-11T03:08:01Z,0,"Someone may have already chimed in on this, but dropout is what is commonly refereed to as a regularization technique. Regularization techniques are used to improve generalization in deep networks, for anyone who was curious :)",True
@deogratiasmzurikwao1038,2017-04-06T16:43:56Z,0,"Hi, I am trying to use this tutorial in a different dataset.I have a data set which contains images of hand written A-Z,a-z and 0-9,totalling 62.So my label size is 62,each image 30*30 pixels.I use almost the same codes as in this tutorial,the only difference is at the image size(30*30) and W_fc1 = weight_variable([4 * 4 * 64, 1024]).I got an error at correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1)) which is due to incompatible shape,'correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))'.Any idea to fix this will be appreciated.",True
@nataliakl6373,2017-03-11T06:39:59Z,2,"Thanks for the tutorial, that's really helpful! But could you explain please for what reason keep_prob placeholder was declared?",True
@MrNeverYou,2017-03-08T05:56:03Z,0,Great tutorial! Thanks!  But i got killed instead of the accuracy printed after finish running the code. What does that mean?,True
@chirazbenchaabane8354,2017-02-25T01:31:22Z,1,please i need more informations about fully connected layer. thanks,True
@sukumarhonkote9936,2017-02-18T15:43:30Z,7,can you do a tutorial on genetic algorithm? there is no tutorial on this on YouTube.,True
@urvishnakum914,2017-02-09T06:30:10Z,0,"sir  , it is possible to make the cnn with the kaggle image dataset because this mnist dataset is already in bin format but what about real life image dataset and kaggle compition dataset how to deal with the real image dataset ?  i request you to  make one tutorial for kaggle image dataset and predicting the object in realtime please.",True
@sidrahjunaid1219,2017-02-04T17:42:46Z,0,how can we use one class as an input in CNN?,True
@saumilshah1743,2017-01-25T12:46:17Z,0,How can I use this trained model to detect digits from any image (I mean other than 28x28 image size). How can I carry out process if image does not contain only a single number. Detecting where digits are located in an image and find out which digit it is?,True
@burakbiyikli,2017-01-17T02:58:46Z,0,"Calculating the accuracy of the model with this code seems to max out my ram (6GB), is there an easy work around for this? As when it hits my computer's RAM limit the program grinds to a halt. EDIT: potential Solution in replies here",True
@eliethesaiyan,2017-01-02T09:32:38Z,0,"thanks for the amazing videos,it would be great if you could explain more on each parameters of strides and padding.",True
@NighttimeJuneau,2016-12-27T11:27:49Z,4,"Since this was uploaded, the argument ""kstrides"" was renamed to ""ksize"" for max_pool. tf.nn.max_pool(data, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=""SAME"")",True
@parthshah9898,2016-12-02T01:02:30Z,0,after successfully running 9 epoch the process gets killed any particular reason?,True
@twks123,2016-11-30T04:26:01Z,0,which parts need to be changed if we were doing say RGB three channels images? just the shaping parameters or new functions would be required?,True
@Salamimalicum,2016-11-27T12:57:46Z,0,great! though my pc takes 5 min for 1 epoch,True
@jackma3599,2016-11-22T05:58:17Z,13,"hey, may I ask why is 7*7 in the wights of the fc layer? Does is always 28//4?",True
@MrFromEurope,2016-11-21T16:20:55Z,0,You forgot to use the biases in conv1 and conv2 right?,True
@MrFromEurope,2016-11-21T16:05:28Z,0,H! Thank you so much for your videos! My question is: How would the code change if you had colored images? Thanks again!,True
@carlosancassani5715,2016-11-20T03:58:14Z,0,"Hi Harrison, thanks for your videos. I have a (naive) question, what about if I want to save trained weights for future tests so that I don't have to train every time?",True
@aryopradiptagema6677,2016-10-25T16:18:54Z,0,"hi, great video @sentdex!! i want to ask you about whether or not we can use string as the label of the training and testing data. Because i cannot do it using tf.placeholder(tf.string, shape). Is there any way to do it? Because i use a dataset that use char like 'a' - 'z' as the label. Thanks!!",True
@anhvth7342,2016-10-22T08:21:49Z,3,"Can somebody tell me what is -1 means here [-1,28,28,1]. I understand 28x28 is the size of images and 1 is num of channel.",True
@mrrodbruno2809,2016-10-09T19:47:45Z,0,I believe the reason they define those functions like that is so if you want to implement tensorboard it is already set up to do it.,True
@Renardbardhi1,2016-10-08T20:24:33Z,0,"Sentdex thank you very much for your help. I followed your instruction and I created an array that contains multiple arrays for my training part. However,  how can I create those two command  x = tf.placeholder('float', [None, 784]) and y = tf.placeholder('float') for my test and train part. Because I'm working with images(with different content) and not handwriting images maybe are different from mnistÂ library.  The command mnist.train.next_batch(batch_size) should I change the ""mnist.""  to np.array().train.next_batch(batch_size) and also for ({x: mnist.test.images, y: mnist.test.labels})) I should put my array instead mnist. Thank you very much for your time",True
@BoIoko,2016-10-05T02:07:17Z,0,Thanks for the tutorial. I appreciate the use of same variables names.,True
@MattCamp,2016-10-03T19:26:26Z,1,can you make a tutorial on creating your own dataset for Tensorflow? I am having the hardest time trying to structure my data to work with it... Thanks!,True
@Renardbardhi1,2016-09-30T22:18:19Z,0,If I want to input data  images and not mnist library for train what I should do?,True
@inigoalonso2694,2016-09-28T18:52:53Z,0,"Thanks for the video, it was awesome. Could you make a video explaining how to use word2vec in tensorflow?",True
@Arjun-jt7yb,2016-09-28T11:51:26Z,12,"You forgot to implement relu and biase in convolutional layer before applying pooling. proper code  should be like this....  conv1 =  tf.nn.relu( conv2d(x,weights['W_conv1']) + b_conv1 ) conv1 =  maxpool2d(conv1)  conv2 =  tf.nn.relu( conv2d(conv1,weights['W_conv2']) + b_conv2 ) conv2 = maxpool2d(conv2)  And Thanks for amazing tutorials..You are awesome..",True
@RaoufGnda,2016-09-27T14:24:02Z,0,"is it possible to apply the same concept in Part8 to 11 and 13..or even more interesting to combine them both in one model (11,13)..? and are you going to cover it may be.?",True
@billymonday8388,2016-09-24T16:46:39Z,0,nice tutorials!  one question(irrelevant to coding) is there a way to simulate neurons with logic gates?,True
@jacobskowronek3609,2016-09-22T22:54:53Z,1,"Will you be covering something like Deep Q, where reinforcement learning is being combined with deep learning?",True
@acelere,2016-09-22T22:32:49Z,0,Great tutorial! Thanks! Your computer runs sooooo much faster than mine LOL!,True
@schoneschone,2016-09-21T17:20:27Z,0,"You go thru the docs for dropout and it shows keep_prob and you end up using keep_rate, why? what is keep_prob placeholder used for then? Also where are the biases['b_conv1'] and biases['b_conv2'] used?  Lastly, in the previous RNN tutorial I asked about that and you addressed it in this video, so thank you.  However, it was the last bit in the RNN tutorial that I was confused about - the tf.split() for which i did not find a numpy equivalent.  Thanks for these absolutely great tutorials!",True
@BiggFanDDD,2016-09-20T15:04:52Z,0,Loving the tutorials... Bought a MSI 1060 just to follow along!,True
@DodovNes,2016-09-20T14:03:36Z,30,"Why didn't you add biases b_conv1 and b_conv2 to convolutional layers? Considering the pretty good result, do we have to create them at all? (Sorry for the noob question)",True
@angrybird29,2016-09-20T13:47:29Z,0,cool stuff.,True
@rahulahuja4113,2016-09-20T13:27:22Z,0,"Hi there, is it possible in convolutional nn to have recurrent layer(from RNN tutorial) instead of classification layer? Basically i want to combine cnn and rnn.",True
@CariagaXIII,2016-09-20T12:51:15Z,3,glad we have this kind of tutorials here,True
