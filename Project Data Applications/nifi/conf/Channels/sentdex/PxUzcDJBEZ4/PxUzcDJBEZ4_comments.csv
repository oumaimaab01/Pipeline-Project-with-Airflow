author,updated_at,like_count,text,public
@unpatel1,2021-10-09T03:55:42Z,0,What an amazing video series!!!! Thank you sentdex for all these video tutorials.,True
@vladk9152,2021-08-26T11:18:12Z,0,Better also add cointegration if you want to pair trade,True
@hummingbirdkitchen6916,2021-07-01T04:28:42Z,1,I used this one line to generate heatmap. What's the benefit of going through so much code? Am I missing something? plt.imshow( df_corr) plt.show(),True
@desiquant,2021-05-07T12:38:24Z,0,never imagined heatmap was so painful a few years back.,True
@isaakimaliev5584,2021-03-04T16:15:42Z,0,File 'sp500_joined_closes.csv' does not exist,True
@michaelschneck6161,2020-09-04T13:12:45Z,0,please ignore my earlier question about where to find your code-I found it.,True
@michaelschneck6161,2020-09-04T08:53:10Z,0,I figured that I should post what I get in order to help clarify.  By the way I use SPYDER.      MMM  ABT  ABBV   ABMD  ACN  ATVI  ...  XYL  YUM  ZBRA  ZBH  ZION  ZTS Date                                         ...                                 1/10/2000  NaN  NaN   NaN  20.50  NaN   NaN  ...  NaN  NaN   NaN  NaN   NaN  NaN 1/10/2001  NaN  NaN   NaN  19.25  NaN   NaN  ...  NaN  NaN   NaN  NaN   NaN  NaN 1/10/2002  NaN  NaN   NaN  15.94  NaN   NaN  ...  NaN  NaN   NaN  NaN   NaN  NaN 1/10/2003  NaN  NaN   NaN   4.13  NaN   NaN  ...  NaN  NaN   NaN  NaN   NaN  NaN 1/10/2005  NaN  NaN   NaN  14.42  NaN   NaN  ...  NaN  NaN   NaN  NaN   NaN  NaN  [5 rows x 505 columns],True
@michaelschneck6161,2020-09-04T08:42:51Z,0,"First let me say that this is a wonderful series and you are a gem.  I have a couple of questions: 1.  Have you posted anyplace the code that you show on your videos.  2.  When I run the code for this video, my results are strange.  The initial rows are all just one data point with the dates going strange.  When it gets down to 1000+ rows the data look normal to me.  Secondly my program is not retrieving apple data.  It will retrieve and plot other stocks like MMM.  Any thoughts?  Thanks in advance",True
@Nico-rl4bo,2020-07-12T22:18:52Z,0,Ehrenmann,True
@ayushjain4262,2020-07-11T18:33:19Z,0,"Hello, I am getting this error please help ""RemoteDataError: No data fetched for symbol MMM using YahooDailyReader""",True
@temen1167,2020-06-06T16:01:57Z,0,Banks lost  correlatoin due to  2008 disaster  which hit   financial sector way stronger then average company.,True
@TG-qb3pm,2020-05-18T17:33:20Z,0,#SENTDEX YOU ARE THE BEST! GRANDE SENTDEX!,True
@joneasterbrook1379,2020-05-18T09:15:01Z,8,"this code works 2020-5-18   import bs4 as bs import datetime as dt import matplotlib.pyplot as plt from matplotlib import style import numpy as np import os import pandas as pd from pandas_datareader import data as pdr import pickle import requests import yfinance as yf  style.use('ggplot')  yf.pdr_override   def save_sp500_tickers():     resp = requests.get('http://en.wikipedia.org/wiki/List_of_S%26P_500_companies')     soup = bs.BeautifulSoup(resp.text, 'lxml')     table = soup.find('table', {'class': 'wikitable sortable'})     tickers = []     for row in table.findAll('tr')[1:]:         ticker = row.findAll('td')[0].text.replace('.', '-')         ticker = ticker[:-1]         tickers.append(ticker)     with open(""sp500tickers.pickle"", ""wb"") as f:         pickle.dump(tickers, f)     return tickers   # save_sp500_tickers() def get_data_from_yahoo(reload_sp500=False):     if reload_sp500:         tickers = save_sp500_tickers()     else:         with open(""sp500tickers.pickle"", ""rb"") as f:             tickers = pickle.load(f)     if not os.path.exists('stock_dfs'):         os.makedirs('stock_dfs')     start = dt.datetime(2000, 6, 8)     end = dt.datetime.now()     for ticker in tickers:         print(ticker)         if not os.path.exists('stock_dfs/{}.csv'.format(ticker)):             df = pdr.get_data_yahoo(ticker, start, end)             df.reset_index(inplace=True)             df.set_index(""Date"", inplace=True)             df.to_csv('stock_dfs/{}.csv'.format(ticker))         else:             print('Already have {}'.format(ticker))  def compile_data():     with open (""sp500tickers.pickle"", ""rb"") as f:         tickers = pickle.load(f)      main_df = pd.DataFrame()      for count, ticker in enumerate(tickers):         df = pd.read_csv('stock_dfs/{}.csv'.format(ticker.replace('.', '-')))         df.set_index('Date', inplace=True)          df.rename(columns = {'Adj Close':ticker}, inplace=True)         df.drop(['Open','High','Low','Close','Volume'], 1, inplace=True)          if main_df.empty:             main_df = df         else:             main_df = main_df.join(df, how='outer')          if count % 10 == 0:             print(count)     print(main_df.head())     main_df.to_csv('sp500_joined_closes.csv')  def visualize_data():     df = pd.read_csv('sp500_joined_closes.csv')     # df['AAPL'].plot()     # plt.show()     df_corr = df.corr()      print(df_corr.head())     data = df_corr.values     fig = plt.figure()     ax = fig.add_subplot(1,1,1)      heatmap = ax.pcolor(data, cmap=plt.cm.RdYlGn)     fig.colorbar(heatmap)     ax.set_xticks(np.arange(data.shape[0]) + 0.5, minor=False)     ax.set_yticks(np.arange(data.shape[1]) + 0.5, minor=False)     ax.invert_yaxis()     ax.xaxis.tick_top()      column_labels = df_corr.columns     row_labels = df_corr.index      ax.set_xticklabels(column_labels)     ax.set_yticklabels(row_labels)     plt.xticks(rotation=90)     heatmap.set_clim(-1,1)     plt.tight_layout()     plt.show()   visualize_data()",True
@maple7538,2020-04-10T23:17:01Z,0,"ax = fig.add_subplot(1,1,1,aspect=1) allows for a squared heatmap.",True
@pritamsarkar3371,2020-03-12T22:21:44Z,0,PCA rocks,True
@marcbertolino5411,2020-02-25T04:13:18Z,1,Do you memorize all of this or do you use the documentation ?,True
@julianasosa7064,2020-01-30T20:47:11Z,0,Dude fucking grate work +. Love it. You are amazing !!!,True
@ninachetty4574,2020-01-20T03:42:27Z,2,"Why am I getting a ""TypeError: Object of type ndarray is not JSON serializable"" when I add the lines ""heat_map = ax1.pcolor(data1, cmap=""RdYlGn"") fig.colorbar(heat_map)""? How can I fix this?",True
@NoToBusinessCasual,2020-01-06T04:21:21Z,0,I am running this in Spyder and the X & Y tick labels are creating just a grey band of superimposed text. Can we make these labels very small in font?,True
,2020-01-05T20:34:52Z,1,"Sorted heatmap for better visualization  mean = df_corr.mean(0).sort_values()       df_sort_row = pd.DataFrame()     for ticker in mean.index:         df_sort_row = df_sort_row.append(df_corr.loc[ticker])       df_sort_col = pd.DataFrame()     for ticker in mean.index:         df_sort_col = df_sort_col.join(df_sort_row[ticker], how='outer')       df_corr = df_sort_col",True
@ShreyAroraev3,2019-12-26T20:39:14Z,0,"hey, do we really need like half of the plot, cuz its just gonna be a mirror image of the other half along the corr = 1 line, right? could that help with the time??",True
@tonihuhtiniemi1222,2019-12-05T02:04:46Z,0,"2:03 ""...we'll make more money if our graphs look good.."" hahaha fucking sentdex! <3",True
@gregrosen1518,2019-10-22T23:03:36Z,0,"When I try to plot df['AAPL'].plot() why do I get ""ValueError: view limit minimum 0.0 is less than 1 and is an invalid Matplotlib date value. This often happens if you pass a non-datetime value to an axis that has datetime units""?",True
@JpNaN,2019-09-07T18:38:26Z,13,"dont write this stuff when you plot df_corr use seaborn 1- pip install seaborn 2-import seaborn as sns 3-sns.heatmap(df_corr,annot=True,cmap=RdYlGn) plt.show()",True
@jingyao6409,2019-08-23T17:23:59Z,0,will you update your code? some of the code you wrote is no longer working in new version of pythons.,True
@fengchen3492,2019-08-21T06:44:51Z,0,one question: how to get the 5 minutes trading data?,True
@ovidiuc4,2019-08-09T13:42:36Z,1,"Love your videos. But, I'd like to make what I hope to be a constructive criticism: the variable names need to be clearer. It's just unnecessarily difficult to read the code wih all that df, ax, np, plt, df_corr, pd etc. What's wrong with the full words these replace? I assume you do it because you use an editor without code hints, but still... since the purpose is educational,  readability should matter.",True
@rafaelnogales5368,2019-08-05T08:29:44Z,1,"Do you have a link to this in github I would like to make it with new data, maybe I can update your code and make you a pull request",True
@freetube7767,2019-07-25T13:19:02Z,1,"Had to use:  def visualize_data():  df = pd.read_csv('sp500_joined_closes.csv')  df['AAPL\n'].plot()  plt.show()  in order to mitigate :  Traceback (most recent call last):   File ""/usr/lib/python3.5/site-packages/pandas/core/indexes/base.py"", line 2656, in get_loc     return self._engine.get_loc(key)   File ""pandas/_libs/index.pyx"", line 108, in pandas._libs.index.IndexEngine.get_loc   File ""pandas/_libs/index.pyx"", line 132, in pandas._libs.index.IndexEngine.get_loc   File ""pandas/_libs/hashtable_class_helper.pxi"", line 1601, in pandas._libs.hashtable.PyObjectHashTable.get_item   File ""pandas/_libs/hashtable_class_helper.pxi"", line 1608, in pandas._libs.hashtable.PyObjectHashTable.get_item KeyError: 'AAPL'  During handling of the above exception, another exception occurred:  Traceback (most recent call last):   File ""p00008_1.py"", line 104, in <module>     visualize_data()    File ""p00008_1.py"", line 101, in visualize_data     df['AAPL'].plot()   File ""/usr/lib/python3.5/site-packages/pandas/core/frame.py"", line 2927, in __getitem__     indexer = self.columns.get_loc(key)   File ""/usr/lib/python3.5/site-packages/pandas/core/indexes/base.py"", line 2658, in get_loc     return self._engine.get_loc(self._maybe_cast_indexer(key))   File ""pandas/_libs/index.pyx"", line 108, in pandas._libs.index.IndexEngine.get_loc   File ""pandas/_libs/index.pyx"", line 132, in pandas._libs.index.IndexEngine.get_loc   File ""pandas/_libs/hashtable_class_helper.pxi"", line 1601, in pandas._libs.hashtable.PyObjectHashTable.get_item   File ""pandas/_libs/hashtable_class_helper.pxi"", line 1608, in pandas._libs.hashtable.PyObjectHashTable.get_item KeyError: 'AAPL'",True
@henrikvaher697,2019-07-04T11:32:47Z,5,This is amazing. Thank you for your great contributions to the internet.,True
@saiakhil4640,2019-07-01T05:05:29Z,0,"Hi Can anyone help me, I Downloaded the stock data for 11 companies and i calculated covariance and correlation for each date. but i want to caluculate covariance of the data anually i.e group the data by year and caluculate pct_change (that is what i think can some one help me)",True
@vitorborges2878,2019-04-17T15:27:11Z,2,"You're a monster dude, every single doubt i have about python in the finance world you have a whole freaking video about it. Respect.",True
@MR-sq7iu,2019-03-07T20:40:47Z,1,If you just do the last 2 years of data the correlation isn't nearly as high.  FYI you can set start time and end time to calculate the last 2 years or whatever you want.   start = dt.datetime.now() - dt.timedelta(days = 2 * 365) end = dt.datetime.now()  you can change the parameter in the dt.timedelta to reflect whatever data length you want,True
@alihanucar,2018-10-27T22:48:25Z,0,why my y axis is just show 5 stocks x axis shows 500 stockss,True
@buups,2018-09-25T07:44:09Z,0,"Hello sentdex, Me and a friend want to do a project making an index ourselfs. And we  have choosen some stocks but I saw a comment that said Yahoo finance doesn't work anymore so can we still use that or is google finance a better option for this project?We want 15 stocks or something so not that much put it on our own website and make a index ourselfs is this possible with these tutorials because we are both very new to programming.",True
@petealwayslovesu,2018-09-05T07:35:59Z,12,"import bs4 as bs4 import pickle import requests import datetime as datetime import os import matplotlib.pyplot as pyplot import numpy as numpy from matplotlib import style import pandas as pandas pandas.core.common.is_list_like = pandas.api.types.is_list_like import pandas_datareader.data as data   style.use(""ggplot"")   # save standard & poor's 500 ticker list  def save_sp500_tickers():     response = requests.get(""https://en.wikipedia.org/wiki/List_of_S%26P_500_companies"")     soup = bs4.BeautifulSoup(response.text, ""lxml"")     table = soup.find(""table"", {""class"": ""wikitable sortable""})     tickers = []     for row in table.findAll(""tr"")[1:]:         ticker = row.findAll(""td"")[0].text         tickers.append(ticker)      with open(""sp500tickers.pickle"", ""wb"") as file:         pickle.dump(tickers, file)      print(tickers)      return tickers   # save_sp500_tickers()   # fetching sp500  def morning_star():      if not os.path.exists(""stock_data_frames""):         os.makedirs(""stock_data_frames"")      with open(""sp500tickers.pickle"", ""rb"") as file:         tickers = pickle.load(file)      start = datetime.datetime(2000, 1, 1)     end = datetime.datetime.now()      count = 0     count_e = 0     no_such_tickers = []     for ticker in tickers:         count += 1         print(str(count) + "". "" + ticker)          if not os.path.exists(""stock_data_frames/{}.csv"".format(ticker)):             while True:                 try:                     data_frame = data.DataReader(ticker, ""morningstar"", start, end)                      if str(data_frame.head()):                         data_frame.to_csv(""stock_data_frames/{}.csv"".format(ticker))                         count_e = 0                         break                 except Exception as e:                     count_e += 1                     print(str(count_e) + "". "" + ticker + "" "" + str(e))                      # no such tickers in morningstar                     # ['ANDV', 'BKNG', 'BHF', 'CBRE', 'DWDP', 'DXC', 'EVRG',                     # 'JEF', 'TPR', 'UAA', 'WELL']                     if count_e >= 10:                         no_such_tickers.append(ticker)                         print(no_such_tickers)                         count_e = 0                         break         else:             print(""already have {}"".format(ticker))   # morning_star()   # merge sp500  def merge_data():     no_such_tickers = ['ANDV', 'BKNG', 'BHF', 'CBRE', 'DWDP', 'DXC', 'EVRG',                        'JEF', 'TPR', 'UAA', 'WELL']      merged_data_frame = pandas.DataFrame()      with open(""sp500tickers.pickle"", ""rb"") as file:         tickers = pickle.load(file)      for i, ticker in enumerate(tickers):         if ticker in no_such_tickers:             continue         data_frame = pandas.read_csv(""stock_data_frames/{}.csv"".format(ticker))         data_frame.set_index(""Date"", inplace=True)         data_frame.rename(columns={""Close"": ticker}, inplace=True)         data_frame.drop([""Symbol"", ""Open"", ""High"", ""Low"", ""Volume""], 1, inplace=True)          if merged_data_frame.empty:             merged_data_frame = data_frame         else:             merged_data_frame = merged_data_frame.join(data_frame, how=""outer"")          if i % 10 == 0:             print(i)      print(merged_data_frame.head())     merged_data_frame.to_csv(""joined_sp500.csv"")   # merge_data()   # sp500 correlation table  def visualize_data():     data_frame = pandas.read_csv(""joined_sp500.csv"")     # data_frame[""AAPL""].plot()     # pyplot.show()     data_frame_correlation = data_frame.corr()     print(data_frame_correlation.head())      dataa = data_frame_correlation.values     fig = pyplot.figure()     ax = fig.add_subplot(1, 1, 1)      heat_map = ax.pcolor(dataa, cmap=""RdYlGn"")     fig.colorbar(heat_map)     ax.set_xticks(numpy.arange(dataa.shape[0]) + 0.5, minor=False)     ax.set_yticks(numpy.arange(dataa.shape[1]) + 0.5, minor=False)     ax.invert_yaxis()     ax.xaxis.tick_top()      colum_lables = data_frame_correlation.columns     row_lables = data_frame_correlation.index      ax.set_xticklabels(colum_lables)     ax.set_yticklabels(row_lables)     pyplot.xticks(rotation=90)     heat_map.set_clim(-1, 1)     pyplot.tight_layout()     pyplot.show()   visualize_data()",True
@theJESUSofcallofduty,2018-02-14T22:12:58Z,0,"whenever I graph the ('sp500_joined_closes.csv') file (yes I had to use 'close' because I used google finance api) I get everything as a 1.0 positive correlation even though when you open up the 'sp500_joined_closes.csv' file it clearly shows that the data is different.  has anyone else experienced this issue, and if so how did you solve it?  Thank you in advance.",True
@wunzeli,2017-12-01T20:02:51Z,1,"For anyone who wants to follow dhiransh's advise to calculate the correlation table with daily stock returns, just change the beginning of the visualize_data function to:  def visualize_data():  df = pd.read_csv('sp500_joined_closes.csv')  df.set_index('Date', inplace=True)  df_corr = df.pct_change().corr()  Other than that the code can stay the same :)",True
@simasjanusas1766,2017-10-21T14:51:53Z,1,"Hi, I got the following error: ""AttributeError: module 'numpy' has no attribute 'arrange'""  in  ax1.set_xticks(np.arrange(data1.shape[1]) + 0.5, minor=False)  Can someone please help me out with this?",True
@lecioufs,2017-08-10T21:27:22Z,1,"Nice video! (as always!)   Congrats! @sentdex, do you like to use seaborn?  import seaborn as sns sns.heatmap( df.corr() )  #  that would save you a lot of work!!",True
@woo-jinchokim6441,2017-08-08T23:01:14Z,0,"you are amazing, thank you so much.  keep it up !",True
@simonchan2394,2017-07-26T20:05:17Z,0,Excellent video. Thank you.,True
@kennyPAGC,2017-07-17T16:25:23Z,2,what's the minor argument for?,True
@tongbogeng7348,2017-06-27T01:57:25Z,0,"I'm new to Python and have learned a lot here! Thanks a lot!  When I did this I got an error, it didn't stop running tho:   RuntimeWarning: invalid value encountered in less   cbook._putmask(xa, xa < 0.0, -1)  I guess it was the data but how could correlation be out of range of -1 to 1?   Anyone has any idea? Thx. I got the heatmap stil but with no ticknames. No idea either.",True
@Anthonypython,2017-06-16T09:02:18Z,3,"cmap=plt.cm.RdYlGn doesn't work anymore, what is the alternative/updated way? I tried the plt.cm.colors.colormap('RdYlGn', N=256) and it ran but error out on me. so nothing displayed in the graphing area just a box.  Edit: fixed it for those of you who run into his problem, just do cmap='RdYlGn' and it will work just fine.",True
@caldwellfans,2017-06-08T00:33:28Z,0,"For numpy shape on a 2d array it returns (row, column), for 3d array it is (page, row, column). Great videos though!",True
@seanbird5335,2017-04-29T10:45:37Z,0,"Hey you mentioned paid services in this video (when referring to the df_corr=df.corr()) can you please elaborate? Love the vids, I do wonder how you are so good at this..",True
@MsJacknes,2017-04-23T02:26:14Z,0,I get UnboundLocalError: local variable 'df_corr' referenced before assignment when trying to run the code at 03:20,True
@naman15111993chawhan,2017-03-23T15:29:10Z,1,can anyone help me with a command line which will return the minimum value of the correlation table or their column and index name.,True
@cfoch3,2017-02-20T00:20:41Z,1,"""En un momento""? Did you say that?",True
@zcrib3,2017-02-09T11:51:36Z,0,"Python 3.6  Following your script I get an error:  ax.set_xticks(np.arange(data.shape[0] + 0.5, minor=False))  TypeError: 'minor' is an invalid keyword argument for this function  No labels. So I just got rid of (minor=False). Got labels. What does it affect?",True
@MrStickdog,2017-02-02T11:37:51Z,12,"I love your videos, thanks for doing them",True
@adityahardrocker,2017-02-01T02:28:41Z,1,"Thanks so much for these tutorials. Though I am an active investor, I probably learned more about pandas and ts data analysis than how to get rich. :)",True
@sandeepvk,2017-01-31T10:32:20Z,0,should i learn python or do I go in web development....I feel web development is somewhat boring - making simple site - but I love pattern recognition and doing something useful with it -,True
@legel93,2017-01-30T19:20:39Z,0,Wow this is so impressive! Thank you! :),True
@lawrencefernandes3311,2017-01-29T13:38:44Z,4,"As dhiransh stated, the correct form to calculate Pearson's correlation coefficient is between stock returns. So, first you'll need to calculate the daily returns of the stocks: Adj Close - Previous Day Adj Close.",True
@dhiransh,2017-01-24T20:36:41Z,86,"just one thing - in finance we calculate correlations between stock returns and not stock prices,as returns tend to follow normal distribution and prices don't",True
@nicolasharvie7833,2017-01-24T01:31:29Z,9,"Thanks for the great content. Banks are probably negatively correlated to other stocks as their profitability increase when interest rates increases, while other's usually fall.",True
@kuatroka,2017-01-23T18:39:59Z,0,"Thanks! Very nicely explained the correlation use case. I wonder if I wanted to say,  calculate percentage change between the high and the low of the day of all and every asset and then bin the data into sections like [+1%], [+2%], etc and see if there is a pattern of the price action for then next days from 1 to 5. Would I also need to use correlation technique or it would need to be something different?",True
@radixvinni,2017-01-23T18:08:24Z,1,"Thanks, I was going to look for correlations in my portfolio and you saved my time.",True
@pasettodavide,2017-01-23T16:22:20Z,4,Impressive! and that's all I can think right now,True
@MrIgorbpf,2017-01-23T16:15:22Z,0,"Love u, man! Great video!",True
