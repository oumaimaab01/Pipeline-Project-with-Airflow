author,updated_at,like_count,text,public
@John845,2024-05-02T00:21:54Z,0,"If you've made it this far congrats! Also, if you are lost in the math and how it works, never forget one thing. For Vladimir Vapnik, the formulation of the idea / intuition for the SVM algorithm and then the eventual completion of it, that was a 25 YEAR journey.  He formulated the idea of SVM in the 1960s in the USSR, then upon emigrating to the US, finalized SVM in the 1990s at Bell Labs.  SVM is literally Vladimir's life work. You will NOT grasp it in an afternoon. If you don't understand all the math or the intuition behind it, don't feel bad. This may take most people years to make sense of it.   If you grasp the CONCEPT of what SVM is doing, THAT is the most important thing here. Knowing where to use SVM in the real world and the best use cases for it, that is what an ML engineer does and what ML engineers get paid a lot of money for. The underlying implementation may vary from framework to framework (Tensorflow, Pytorch, Scikit Learn, etc) so its not super important, especially when starting out.",True
@Dhruvbala,2024-01-31T11:48:57Z,0,"Based on the setup, you're only solving for w vectors where all components are equal (or negation)?",True
@foreveryoung1678,2022-12-15T05:08:52Z,0,"As mentioned in the video, adding a couple of breaks will slightly increase the performance by failing fast. For me, it went from 10-12s fit to around 5s with these breaks.                           for i in self.data:                             for xi in self.data[i]:                                 yi=i                                 if not yi*(np.dot(w_t,xi)+b) >= 1:                                     found_option = False                                     break                                     #print(xi,':',yi*(np.dot(w_t,xi)+b))                             if not found_option:                               break",True
@annursystem207,2022-03-31T03:48:09Z,0,sir please make subtitles so i can read it.  or please send to my email sir,True
@majidkamiyab6731,2021-10-21T05:23:11Z,0,"This was a very innovative code for me. One small bug though, it cannot find the vector for parallel to X or Y axis datas. like [[-1,1],[-1,2]] and [[1,1],[1,2]]",True
@yasminehentati2169,2021-09-19T12:10:45Z,0,hi thank you for this amazing video <3 <3 can you send me  the code plz,True
@minhtrihuynh9813,2021-09-17T04:15:14Z,0,"Thank you for your video; even if it is 5 years ago, your instructions are really good and useful to me. I have a question. I believe latest_optimum should be a positive value, such that variable w iterates all range from (0, latest_optimum) make more sense. It should be something like this: latest_optimum = np.abs(opt_params[0][0]) + 2* step.",True
@elderofzion,2021-09-09T13:01:49Z,0,number of views declining with every next video.,True
@cemalyildirim4529,2021-06-10T12:43:18Z,0,Has ayone implemented a weighted SVM using LIBSVM?,True
@cemalyildirim4529,2021-06-05T18:43:42Z,0,What about a radial kernel?,True
@zesvyaayvesez2849,2021-02-14T20:20:42Z,0,wild guess: k is for khÃ´l,True
@neuron8186,2021-01-12T16:41:41Z,0,okay  i need to watch again to get it completely,True
@viniciusVS8v,2020-10-12T01:12:57Z,0,something went wrong prntscr.com/uxf31r,True
@shauryavardhan7225,2020-05-16T19:09:05Z,4,"It's okay if you are not able to understand at first. This the highest quality content available  out there. Online courses and other youtube channels makes you feel good by taking short cuts and directly implementing algorithms. Whereas sentdex here is taking the road less traveled , the raw algorithm implementation.",True
@daliamokhtar1764,2020-04-15T18:34:19Z,0,"def hyperplane(x,w,b,v):             return (-w[0]*x-b+v) / w[1] why do we divide (-w[0]*x-b+v)  by w[1]",True
@SuperIronwire,2020-03-12T13:13:58Z,0,Why set latest_optimum = self.max_feature_value*10 to start iterating to find the optimal w? what's the logic behind?,True
@SuperIronwire,2020-02-26T02:12:06Z,2,"Beg your(anyone's) explanation about how (-w[0]*x-b+v) / w[1] is from? Sentdex said is a simple algebra combination, but I just can't figure it out.",True
@xiaoyang4521,2019-12-27T03:54:04Z,0,"I think there is a mistake made in the tutorial. If you change the training set value to {-1:np.array([[1,7], [2,8], [3,8],]),1:np.array([[5,1],[6,-1],[7,10],])}. The last positive point replaced by [7,10] instead of [7,3], then you'll see the hyperplane being drawn with this algorithm is clearly wrong. I think it's because the step_down value are set proportional to (x1, x2) in w. Which results in shifting NOT rotating the hyperplane. Shouldn't step down value be only adjusting the x1/x2 ratio?",True
@williambrandon5146,2019-12-20T08:56:22Z,2,please tell me I'm not the only one who debugged this for almost an hour,True
@savin1999,2019-12-18T04:08:19Z,0,The last step is too slow in my laptop. Did you use some other kernel to get the result faster?,True
@meirgoldenberg5638,2019-12-17T18:00:24Z,0,"The following simple data_dict produces a list index out of range error: data_dict = {-1: np.array([[500,   9]]), 1: np.array([[284, 185]])}. I got the code verbatim from pythonprogramming.net",True
@becauseiwanttoanime9541,2019-09-22T15:37:13Z,0,22:13 best moment XD love you,True
@huseyincansimsek9675,2019-08-29T13:01:50Z,0,"I am taking   iyilestirme_secimi=iyilestirilmis_sozluk[kurallar[0]]  IndexError: list index out of range .How can to fix this error.",True
@ahbarahad3203,2019-08-15T17:04:01Z,0,17:36 RIP headphone users,True
@antonburenko2852,2019-07-21T21:55:09Z,2,"Hopefully it can be helpful. That are thing, that would have helped me at the beginning:  - try to change features to see w and b changes (e.g. all x values +50) - w and b are values that form the decision line and here only x=y or x=-y with a shift , see p.23 8:00 - do not think as I did that w is the direkt vektor to the begining of the decision line - our plot is not a square - looking the theorie videos a couple of times more :D  I'm open for your corrections",True
@prakharsankrityayan1300,2019-06-26T08:07:30Z,0,'k' cause black ends in k.,True
@hussainshirazi2826,2019-05-05T12:38:56Z,0,what do we have to do to change fit(data=data_dict) parameter to an array?,True
@sarangaram7216,2018-12-25T13:04:48Z,0,The function predict is not called anywhere in the code .. how and where does this happen?,True
@shubhankarpoundrik8001,2018-12-05T07:05:37Z,5,"Why must w be of form [x,x] or [x,-x] etc . This implies that the hyperplane must always be at a 45 degree angle with the axes. Why cant it be of the form [x,y] where |x| != |y|.",True
@mihmilon,2018-10-16T05:15:07Z,0,"First of all, I like to thank you for the video. It really helps. Can you find accuracy for your prediction?",True
@luctiber,2018-10-15T15:17:45Z,0,"I have to confess I get lost in translation @ this point ... I understand the words, phrases are understood but the connection is not happening in my brain.....",True
@petersmiley9979,2018-07-19T18:38:24Z,0,"When you were wondering if the [3, 8] was 1.0 because it was rounded after the last optimization, it was. Although it was pretty darn close. optimized a step[1 7]  :  4.799999999999098 [2 8]  :  4.799999999999098 [3 8]  :  3.9999999999992486 [5 1]  :  3.199999999999399 [ 6 -1]  :  5.599999999998948 [7 3]  :  3.199999999999399 optimized a step [1 7]  :  1.5199999999992362 [2 8]  :  1.5199999999992362 [3 8]  :  1.1999999999993876 [5 1]  :  1.6799999999992516 [ 6 -1]  :  2.639999999998798 [7 3]  :  1.6799999999992516 optimized a step [1 7]  :  1.2239999999999465 [2 8]  :  1.2239999999999465 [3 8]  :  1.000000000000098        <--------- [5 1]  :  1.015999999998539 [ 6 -1]  :  1.6879999999980846 [7 3]  :  1.015999999998539",True
@migkillerphantom,2018-07-18T23:11:11Z,0,"The algorithm seems to draw a decision boundary, but the other two lines are what seems to be a distance of 1 apart no matter what I do. I'm not sure where the error is. I even tried copy pasting your code and got the same results.",True
@vishuvashishtha5197,2018-06-29T20:28:26Z,1,"@sentdex Can I get the text file for this code of yours mine of showing error in the line where  norms = sorted([n for n in opt_dict]) as IndexError: list index out of range after it has printed ""Optimized a step"" for once.",True
@gamingbugs9296,2018-06-11T06:57:18Z,1,Must see that beginners are also here.,True
@sahebedadboud4553,2018-06-02T16:05:28Z,0,"I am new in Python and I am watching your tutorials from beginnig. here I have a problem. when I run the code, everything looks ok, but not my db and 1 and -1 heperplane. they don't fit my datapoints correcltly. I checked three times, and everything is like your code, but I don't know what is the problem. can somebody help me?  here is the my plot: https://ibb.co/gcBA5y  as you can in the plot the hyperplanes and the db doesn't fit well and the code classifies new pointgs wrong as well.",True
@rajivkumar8160,2018-05-12T19:42:09Z,0,how do we  thread the code i.e the while loop part ?,True
@Arik1989,2018-03-22T08:45:04Z,2,"I'm about a year late, but I think the main reason the steps take so long is that the function keeps the range boundaries of b a constant scalar, while always taking smaller steps. If you add another ""latest optimum"" for b as well as w, and use it as a range boundary in the for loop, it's a lot more efficient.",True
@hamzashahidification,2018-03-19T17:55:24Z,0,"I'm getting this error.  step_sizes = [self.max_feature_value * 0.1,  TypeError: can't multiply sequence by non-int of type 'float' on this step_sizes = [self.max_feature_value * 0.1,                       self.max_feature_value * 0.01,                       self.max_feature_value * 0.001]",True
@piyushthakur8056,2018-01-20T07:21:29Z,0,"opt_dict[np.linalg.norm(w_t)]=[w_t,b] throws an error TypeError: list indices must be integers or slices, not numpy.float64 How do i counter this? Please help.",True
@IleaCristian,2018-01-14T21:29:54Z,0,I get the same error as @ibok kegbo If you change a bit the training data it doesn't work anymore...,True
@nederlandas,2018-01-08T10:20:33Z,2,"in visualize data_dict needs to be self.data, since data_dict is not defined there. Idk how the heck it worked for you...",True
@JohanSebastianCorn,2017-12-22T02:16:10Z,0,can someone explain to me why it is -1 or 1 for the support vector lines or margin lines?,True
@laminldibba9495,2017-12-16T00:19:52Z,0,"I have followed the videos and done the same thing but i have an error in def hyperplane(x,w,b,v): it tells me syntax error and i su",True
@pushkardeshpande7389,2017-12-13T21:39:21Z,0,I really like your videos cz they are very easy to grasp. Although this topic is a little difficult to present without a lot of complexities I would suggest you to take one simple dataset and develop the algorithm based on that. There are a lot of things going on in this video so it has become a little complex to follow,True
@SumNeuron,2017-12-05T12:38:39Z,5,"This is fine for a toy example. You do also mention at the onset that this is not production quality. You do not mention, however, that by restricting w = [wi, wi], you are preventing yourself from finding the optimal hyperplane (with a few exceptions). In fact if you expand the hyperplane equation w.x + b = 0, where x = [x1, x2] or as people are more familiar with in 2d x, y, you get wi*x + wi*y + b = 0. Solve for y to get y =( -wi * x - b) / wi which simplifies to y = -x - b/wi. In short,  this will always yield a hyperplane with a slope of -1. You are saved in your example because of the four transforms, which will allow for a positive slope of 1. I would suggest making an updated video (this is over a year old now) which actually searches on w, rather than praying that your data (should it be linearly separable) is so via a slope of 1 or -1",True
@davidtemael1307,2017-11-01T13:33:32Z,0,man! be blessed,True
@jadetan6330,2017-10-27T08:27:45Z,0,dont know if you get this enough but thank you!! Your written notes on pythonprogramming.net is super helpful as well! Love from Singapore!,True
@TheAniketyevankar,2017-10-21T09:41:35Z,1,"One theory is CMYK color space was invented by an Indian and in hindi black is 'Kaala', so they named 'K' for Kaala or Black.",True
@areejalmohanna5482,2017-10-19T08:44:27Z,0,How can i get the source code if that possible,True
@isalvage1,2017-09-15T09:42:58Z,0,"I get this message when I run it ================================================================= C:\Python27\python.exe C:/Users/Owner/PycharmProjects/untitled1/ml1j.py optimized a step. Traceback (most recent call last):   File ""C:/Users/Owner/PycharmProjects/untitled1/ml1j.py"", line 126, in <module>     svm.fit(data=data_dict)   File ""C:/Users/Owner/PycharmProjects/untitled1/ml1j.py"", line 71, in fit     opt_choice = opt_dict[norms[0]] IndexError: list index out of range  Process finished with exit code 1 ================================================================ what am I doing wrong?",True
@tongbogeng7348,2017-09-11T21:59:02Z,0,anyone got issue like mine: Support_Vector_Machine object has no attribute 'ax'? I don't know where I am wrong...It showed the the def visualize part has problem but I checked and they were totally same...Harrison's code run well tho,True
@yusha4865,2017-09-09T08:06:15Z,0,"thank!!   I want to ask:  Traceback (most recent call last):   File ""/Users/shark/Documents/ML/dataset/myfile08SVM.py"", line 135, in <module>     svm = Support_Vector_Machine()   File ""/Users/shark/Documents/ML/dataset/myfile08SVM.py"", line 10, in __init__     if self.visualization: AttributeError: 'Support_Vector_Machine' object has no attribute 'visualization'  How to deal with this problem? thanks and good luck!",True
@Jake3D,2017-09-06T11:17:44Z,0,My graph had the plot lines only at the top right and I couldn't figure out why. Went over the code multiple times. Glad  you post it or else I'd never have found the Error. when I copied self.max_feature_value = max(all_data) to self.min_feature_value = min(all_data) I didn't change the 2nd max to min. I must have looked at that line a dozen times or more. I even went side by side line by line and couldn't see it. Saved the code from your written tut and ran that to make sure I wasn't missing a module or had a computer error. When that ran correctly I had to copy each section and replace my code. Once I narrowed down the section my error was finally clear. LOL,True
@user-theroom101,2017-07-13T18:39:52Z,0,"hey, do you uploading source code?",True
@dishanilahiri9536,2017-06-22T07:49:28Z,2,What exactly does this value represent? return (-w[0]*x-b+v) / w[1],True
@grayjphys,2017-06-18T06:16:06Z,1,could you show me how to parallelize the parts of the code you were talking about please?,True
@dorsolomon7251,2017-06-14T15:03:54Z,0,Is there  a good way to Measure accuracy like in the classification algorithm or the regression?,True
@ehsanchowdhury5581,2017-05-26T13:55:44Z,0,"Nice helpful tutorial!!!  Can anyone please explain my mistake, pls?   norms = [sorted([n for n in opt_dict])] opt_choice = opt_dict[norms[0]]-->>error occurs here self.w = opt_choice[0] self.b = opt_choice[1] latest_optimum = opt_choice[0][0]+step*2  the error is: TypeError: unhashable type: 'list'  The code snippet is at the end of the fit() method of our SVM class. Pls help.",True
@sharathchandra8510,2017-04-09T14:38:08Z,0,"why is w of the form [a,a]? it can be [a,b] , I am asking why both values in w are same?",True
@borutsvara7245,2017-04-04T19:35:05Z,0,"Nice video! I have a question; according to which criteria you are optimizing w&b. I mean, you told to minimize ||w|| and to maximize b. As minimum can be found on a single single value are you looking for min (||w|| - b) ?",True
@TheNeo724,2017-02-09T19:23:11Z,2,"nice video.  But i have a question is it normal that the slope of the hyperplane is every time 1 or -1. If you take data points like (data_dict = {-1:np.array([[1,1], [2,1], [3,1],]),1:np.array([[1,4],[2,4],[3,4],])}) it looks really strange.  Why is there no optimization for the perfect slope of the hyperplane.",True
@solahai,2017-02-08T16:38:31Z,0,"Hello Harrison  A question for you! I have trained SVM model and tested with half of the labeled data. Is there a way to validate the model with a hold-out sample? By hold-out sample, I mean a dataset that has independent values as inputs but does not have determined dependent values as outputs. What I want to get is classification and a number indicating confidence level.  Thanks in advance.",True
@mpegoeri5050,2017-01-17T19:47:19Z,0,from matplotlib import style ImportError: cannot import name style why i have this error cause matplotlib is missing  or ?? i am using python2.6  .... should i have to upgrade ?,True
@mpegoeri5050,2017-01-12T19:39:51Z,0,nice video well done ! can i have the python code to try some examples?,True
@kunal2701,2016-12-30T17:35:51Z,53,"Even you explain everything line by line, however at some point, it gets too complicated and I had to repeat from the beginning. I suggest that you explain the implementation of algorithm using a program overview or program flow diagram and then refer that to explain while writing the codes.",True
@martinc3907,2016-11-23T03:32:37Z,0,"Great video on the SVM, Harrison. Very good presentation in showing how the theory can be implemented.",True
@prakashchandra90,2016-08-01T11:19:45Z,0,Support vectors are allowed to have slop of +1 or -1. So there may be linearly separable data which can not be separated  with these fixed two slop.,True
@wunderlust7252,2016-07-29T15:52:16Z,3,"I got an error --> ""IndexError: list index out of range "" for line  ""  opt_choice = opt_dict[norms[0]]""",True
@leepat9226,2016-07-05T10:27:14Z,1,"First of all, I have been follow this series for quite some time and thank you very much for the great tutorials sentdex!  I am quite weak in mathematics currently and I just played around the SVM example for the whole day trying to plot out the intermediate steps hoping to help understand the mathematics behind.  I tried another data set here:  data_dict = {-1:np.array([[1,7],     [2,8],     [3,8],]),     1:np.array([[7,8],     [8,3],     [9,7]])}  And the result seems not so correct (definitely there should be a more tends to vertical hyperplane), is it related to the transform? Since I still not yet full grasp the math on SVM so I am guess the angle of the line is related to the transform?",True
@piti118,2016-06-24T19:24:50Z,10,"Why restrict w to be of the form [a, a]?",True
@narayana1043,2016-06-20T05:32:02Z,2,"can you please explain, how you got to choose the initial values for w, b_range_multiple and b_multiple.",True
@RealMcDudu,2016-06-17T10:37:56Z,1,"I have some reservation about our w - the way we program it, it will always be (a,a) shape, meaning the slope (between our features, x1 and x2, for any of our vectors) will always be equal to 1. This is not necessarily a good choice for the slopes of our vectors. For example, if our data set would look like this: {1: [(1,1),(2,1.5),(3,2)], -1: [(3,0),(4,0.5),(5,1)]} the slopes of our support-vectors and decision boundary should be 0.5, and not 1. This difference in our w's can of course change our predictions.",True
@ManlyYip,2016-05-29T17:16:42Z,0,great video! I learned so much from you!,True
@GregorDe9000,2016-05-28T19:48:54Z,19,"Black is 'k' because it is K in CMYK color space (used when printing), and it's K there because it is the last letter of word 'black', and that's so it's not confused with color Blue (in RGB color space used with displays).  Thanks for these educational videos, got me interested in machine learning - there are sooo many practical applications.",True
@tshepisomokoena1751,2016-05-28T13:55:22Z,2,what a G.,True
