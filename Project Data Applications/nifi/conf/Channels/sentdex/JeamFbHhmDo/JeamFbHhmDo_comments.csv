author,updated_at,like_count,text,public
@MrJastus,2023-11-25T01:21:42Z,0,I have just recently decided to learn deep learning and these tutorials are still some of the best I have found. The code is redundant enough that it works today with very little updating,True
@nik7867,2022-06-23T21:21:00Z,0,"Couldn't find test train and shuffled files with that link ,they've only got 2 files in that Gdrive link ,can anyone help?",True
@markd964,2020-01-27T07:24:02Z,0,hidden_layer1 should initially use 2683...we all get a bit 'dylsexic' sometime!,True
@anandsinghyt,2019-11-19T16:54:51Z,1,"InvalidArgumentError: Matrix size-incompatible: In[0]: [32,230], In[1]: [2638,500] Getting above error while running neural net program. Any help????",True
@5pellcast3r,2019-09-15T07:07:50Z,0,the only sentdex video that i didn't like much. but meh have to put in the struggle,True
@jppradoleal,2019-07-21T01:15:25Z,1,Sorry by reviving it but 2638 nodes in the input layer comes from where ? I receive an error but my code runs with 49% accuracy when i change it to 32,True
@anirudhbharadwaj4900,2019-04-02T02:17:36Z,0,Why did you change the weight to '2638' from len(train_x[0])?,True
@vishnuchalil154,2019-02-25T06:59:16Z,0,"Hey sendex,  First of all thanks for the tutorial. I downloaded the code and run it for the training script ""using-the-neural-network.py'. But there was an error in Adam optimizer.  ValueError: No gradients provided for any variable, check your graph for ops that do not support gradients, between variables [""<tf.Variable 'Variable:0' shape=(2638, 500) dtype=float32_ref>"", ""<tf.Variable 'Variable_1:0' shape=(500,) dtype=float32_ref>"", ""<tf.Variable 'Variable_2:0' shape=(500, 500) dtype=float32_ref>"", ""<tf.Variable 'Variable_3:0' shape=(500,) dtype=float32_ref>"", ""<tf.Variable 'Variable_4:0' shape=(500, 2) dtype=float32_ref>"", ""<tf.Variable 'Variable_5:0' shape=(2,) dtype=float32_ref>""] and loss Tensor(""Mean:0"", shape=(), dtype=float32).   can anyone explain this error?  Thanks in advance.",True
@sanjaykhanssk4530,2019-01-22T06:28:32Z,0,hey harrison:  I have a little confusion here:  batch_size = 32 ///////////////////////////// 1600000---> why you declared this value for total batches total_batches = int(1600000/batch_size) ///////////////////////////// hm_epochs = 10,True
@adityask277,2018-12-20T02:34:34Z,0,"Hey sentdex,  I love most of your videos, but this video confused me the most. Tried a lot of editing, Still was of no use",True
@fanel1900toamna,2018-08-24T20:30:22Z,0,Using sparse matrices I managed to *get the size down from 19.6GB (1 csv file) to 26.7MB (2 npz files).* I've created a repo at https://github.com/ColdFire87/sentdex-tensorflow-tutorial for whoever is interested in the code.,True
@fanel1900toamna,2018-08-24T02:33:31Z,0,To fix the <'charmap' codec can't encode character '\x9a' > just use <encoding='latin-1'> everywhere you open a file,True
@fanel1900toamna,2018-08-24T02:31:06Z,1,Some tweets do contain ::: inside them. To get around that use:  tweet = ' '.join(line.split(':::')[1:])  # in create_lexicon  and  # in convert_to_vec parts = line.split(':::') label = parts[0] tweet = ' '.join(parts[1:]),True
@DerpRenz,2018-08-13T17:29:16Z,2,anyone else keep getting 49.3%?,True
@Daniel-to5jd,2018-07-26T18:55:28Z,0,"Fuck, i don't have gpu and my computer is old  :(  , so, I have to find ways to go deep learning with small datasets, could someone recommend me something?, while I save money to buy a GPU and better gear.",True
@theycallmemorphine,2018-07-05T10:53:31Z,0,"Hey sentdex, I have a problem with working this on jupyter notebook. Below is the error. Please reply.  INFO:tensorflow:Restoring parameters from /Users/tejasreddy9/Documents/PyNotebooks/Sentiment140/model.ckpt --------------------------------------------------------------------------- InvalidArgumentError                      Traceback (most recent call last) /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)    1321     try: -> 1322       return fn(*args)    1323     except errors.OpError as e:  /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata)    1306       return self._call_tf_sessionrun( -> 1307           options, feed_dict, fetch_list, target_list, run_metadata)    1308   /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata)    1408           self._session, options, feed_dict, fetch_list, target_list, -> 1409           run_metadata)    1410     else:  InvalidArgumentError: Expected to restore a tensor of type float, got a tensor of type int32 instead: tensor_name = Variable   [[Node: save_1/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_INT32, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save_1/Const_0_0, save_1/RestoreV2/tensor_names, save_1/RestoreV2/shape_and_slices)]]  During handling of the above exception, another exception occurred:  InvalidArgumentError                      Traceback (most recent call last) <ipython-input-28-2af062145130> in <module>() ----> 1 use_neural_network(""He's an idiot and a jerk."")  <ipython-input-27-d409d33abef2> in use_neural_network(input_data)       6     with tf.Session() as sess:       7         sess.run(tf.global_variables_initializer()) ----> 8         saver.restore(sess,""/Users/tejasreddy9/Documents/PyNotebooks/Sentiment140/model.ckpt"")       9         current_words = word_tokenize(input_data.lower())      10         current_words = [lemmatizer.lemmatize(i) for i in current_words]  /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/training/saver.py in restore(self, sess, save_path)    1800     else:    1801       sess.run(self.saver_def.restore_op_name, -> 1802                {self.saver_def.filename_tensor_name: save_path})    1803     1804   @staticmethod  /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)     898     try:     899       result = self._run(None, fetches, feed_dict, options_ptr, --> 900                          run_metadata_ptr)     901       if run_metadata:     902         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)  /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)    1133     if final_fetches or final_targets or (handle and feed_dict_tensor):    1134       results = self._do_run(handle, final_targets, final_fetches, -> 1135                              feed_dict_tensor, options, run_metadata)    1136     else:    1137       results = []  /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)    1314     if handle is None:    1315       return self._do_call(_run_fn, feeds, fetches, targets, options, -> 1316                            run_metadata)    1317     else:    1318       return self._do_call(_prun_fn, handle, feeds, fetches)  /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)    1333         except KeyError:    1334           pass -> 1335       raise type(e)(node_def, op, message)    1336     1337   def _extend_graph(self):  InvalidArgumentError: Expected to restore a tensor of type float, got a tensor of type int32 instead: tensor_name = Variable   [[Node: save_1/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_INT32, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save_1/Const_0_0, save_1/RestoreV2/tensor_names, save_1/RestoreV2/shape_and_slices)]]  Caused by op 'save_1/RestoreV2', defined at:   File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py"", line 193, in _run_module_as_main     ""__main__"", mod_spec)   File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py"", line 85, in _run_code     exec(code, run_globals)   File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py"", line 16, in <module>     app.launch_new_instance()   File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/traitlets/config/application.py"", line 658, in launch_instance     app.start()   File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelapp.py"", line 486, in start     self.io_loop.start()   File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/platform/asyncio.py"", line 127, in start     self.asyncio_loop.run_forever()   File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py"", line 422, in run_forever     self._run_once()   File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py"", line 1432, in _run_once     handle._run()   File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/events.py"", line 145, in _run     self._callback(*self._args)   File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/platform/asyncio.py"", line 117, in _handle_events     handler_func(fileobj, events)   File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/stack_context.py"", line 276, in null_wrapper     return fn(*args, **kwargs)   File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py"", line 450, in _handle_events     self._handle_recv()   File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py"", line 480, in _handle_recv     self._run_callback(callback, msg)   File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py"", line 432, in _run_callback     callback(*args, **kwargs)   File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/stack_context.py"", line 276, in null_wrapper     return fn(*args, **kwargs)   File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py"", line 283, in dispatcher     return self.dispatch_shell(stream, msg)   File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py"", line 233, in dispatch_shell     handler(stream, idents, msg)   File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py"", line 399, in execute_request     user_expressions, allow_stdin)   File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/ipkernel.py"", line 208, in do_execute     res = shell.run_cell(code, store_history=store_history, silent=silent)   File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/zmqshell.py"", line 537, in run_cell     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)   File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 2662, in run_cell     raw_cell, store_history, silent, shell_futures)   File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 2785, in _run_cell     interactivity=interactivity, compiler=compiler, result=result)   File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 2903, in run_ast_nodes     if self.run_code(code, result):   File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 2963, in run_code     exec(code_obj, self.user_global_ns, self.user_ns)   File ""<ipython-input-19-416a2593f909>"", line 1, in <module>     saver = tf.train.Saver()   File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 1338, in __init__     self.build()   File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 1347, in build     self._build(self._filename, build_save=True, build_restore=True)   File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 1384, in _build     build_save=build_save, build_restore=build_restore)   File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 835, in _build_internal     restore_sequentially, reshape)   File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 472, in _AddRestoreOps     restore_sequentially)   File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/",True
@ishanmadan8935,2018-07-04T10:22:02Z,0,"Hi , in the preprocessing script, when I run it I seem to be getting a train_set.csv file with only negative sentiment[1,0] tweet samples (with around 13k such samples).   Also in the main script where you've trained the neural nw, why did u put 2638 as the number of inputs allowed into the layer at a time?(shouldn't it be the size of the individual training sample?). I'm getting a matrix multiplication error cuz of that.  Also I'm getting the following error while saving/restoring the tf var Expected to restore a tensor of type float, got a tensor of type int32 instead: tensor_name = Variable   [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]].  Any help on the above issues is much appreciated , thanks :)",True
@kalpitshah933,2018-06-30T08:45:15Z,0,what is the significance of encoding = 'latin-1' here ?,True
@NiteshKumarChaudhary,2018-06-27T10:25:57Z,0,"If you are facing the problem : ""'charmap' codec can't encode character '\x9a' in position 10: character maps to <undefined>"" then introduce the line of code as below (-->)                  tweet = line.split(',')[-1]                 outline = str(initial_polarity) + ':::' + tweet           --->outline = str(outline.encode(""utf-8""))                 outfile.write(outline)",True
@arsalanraza7700,2018-04-15T13:09:55Z,0,"Thanks sentdex and Hi Everyone!  In the saving-restoring file during testing, an error occurs and i am unable to find any solution to it. *Code copied from text-based tutorial on **https://pythonprogramming.net/data-size-example-tensorflow-deep-learning-tutorial/* Error: Expected to restore a tensor of type float, got a tensor of type int32 instead: tensor_name = Variable In comments same error is mentioned. However, unresolved. Please guide! I checked with StackOverflow and Github... cannot find a solution to this issue.",True
@chiragmodi3,2018-04-07T12:47:00Z,0,"Hi, How did you classify the sentiment into positive and negative? Could you please give a clear view on that? Thanks!",True
@kaileyprivate2420,2018-03-27T15:41:10Z,0,"Hey Sentdex, love the tutorials, but I have one question about the preprocessing in the init_process. Aren’t you deleting/missing a lot of data by saying; tweet = line.split(',')[-1] I saw quite some tweets that contained comma’s, hence it was splitting the tweets in multiple sections as well and only taking the last part of the tweets. I used the following instead, don’t it’s the most optimal way but it prevented the tweets starting half way through the sentence. with open(fin, buffering=200000, encoding=""latin-1"") as f:     csvReader  = csv.reader(f)     for row in csvReader:         initial_polarity = row[0]         tweet = row[5]",True
@justinbarry1888,2018-03-03T02:57:01Z,1,Can some of you reply with your running times for 1 epoch? I'm using a GTX1080 and I've been running the first epoch for close to 20 minutes now. Still haven't gotten to the second epoch. Does it take this long for anyone else?,True
@TheFefiiiii,2018-02-23T20:25:37Z,0,"i ran the fist script i copied and pasted from your site, and this is what it gives me   Traceback (most recent call last):   File ""/home/starrboy/Desktop/PreProcessingData.py"", line 67, in <module>     create_lexicon('train_set.csv')   File ""/home/starrboy/Desktop/PreProcessingData.py"", line 47, in create_lexicon     with open(fin, 'r', buffering=100000, encoding='latin-1') as f: FileNotFoundError: [Errno 2] No such file or directory: 'train_set.csv'",True
@chiviado,2018-02-05T16:02:44Z,0,"While testing the Trained model, with the model.ckpt and the lexicon.pickle, i got the following error regarding loading the pickle information:  lexicon = pickle.load(f) _pickle.UnpicklingError: invalid load key, '\xe2'. I don't get it, specially as it seems it is related to the way the pickle was created.",True
@sergiorinaudo3069,2018-01-30T02:30:53Z,0,"Hi, thanks for your videos! I am getting an error when I run the preprocessing_data.py code: 'ascii' codec can't encode characters in position 12-14: ordinal not in range(128) I tried different solutions, but none worked. Do you know what is the problem?",True
@ChopinFlutist,2018-01-16T15:18:57Z,0,"Using the checkpoint you provided in the website, the NN  doesn't seem to work at all :)  Negative: He's an idiot and a jerk. Positive: This was the best store i've ever seen. Negative: This was the best store i've ever seen. I loved it so much. I will definitely come back! Negative: I love the way you do things so nicely Negative: I love you, I love you, I love you, I love you, I love you, you're the best thing in the world Negative: I love it, I love it, I love it, I love it, I love it  Positive: fuck you piece of shit, you're the best at making things crappy  Positive: fuck you piece of shit, I would kill you if I could Positive: fuck you piece of shit, you're an asshole, an idiot a jerk and I hate you Negative: what a dirty asshole you are. it would be better if you would hide yourself and never come back",True
@yuema6927,2018-01-06T19:57:12Z,1,Amazing tutorial! I am using Python 3.6 and kept seeing the following error: 'charmap' codec can't encode character '\x9a' in position 10: character maps to <undefined> Resolved by using codecs to open the sentiment-140 csv files initially.,True
@jamesavery3110,2017-11-21T19:36:35Z,2,"I ran 10 and then 15 epochs , both times were 49.3% accuracy with loss of 1.0. Am I doing something wrong?",True
@ahmadfitri6035,2017-10-15T12:58:39Z,0,"Dude, you are a legend. you really save me man!!!!!!!",True
@stephenstanton6860,2017-10-12T11:53:57Z,0,"I love your series, but could you please start giving the actual link to the code in your description?  It sometimes gets a bit annoying trying to search around not knowing where the code is.",True
@aniketdhar1579,2017-09-27T11:47:02Z,0,"I am saving and restoring the model in the same way (with path fixes applied), but the testing phase seems to throw me random results to the same input string. I have a slightly modified version of the problem using a lstm cell and with 3 classes in stead of 2. So, the output confidence randomly selects one of the three for same input on consecutive runs. Is the model saved properly? If not, how to handle it? I mean shouldn't we be able to get the saved values of weights and biases from our trained model?",True
@ColinRies,2017-09-18T02:25:12Z,3,"I always get this error when running the preprocessing script: ""'charmap' codec can't encode character '\x9a' in position 10: character maps to <undefined>"". I copied the script from the pythonprogramming.net site, so it's not an error of mine. The generated train_set_shuffled.csv works, but the lexicon is just 2KB big, instead of your 41KB. I tried different encodings for opening the files, but none of them does the job. Please help, I'm stuck...  BTW, while training the network (with your lexicon), my GPU usage basically stays at 1-2%, like normal desktop use, but the VRAM usage is almost 10GB. Also it doesn't finish the whole batches for each epoch, but stops at 1221 / 50000 and then just moves on to the next epoch.",True
@nicokaiser2417,2017-08-21T10:59:32Z,0,"First, thanks for the awesome tutorial!  Unfortunately at the last line of the test_neural_network() function where accuracy should be printed I get the following error:  ValueError: setting an array element with a sequence.  Does anybody know how to fix that?",True
@TOCZEKX,2017-07-30T20:17:02Z,0,You are making one of the best tutorial videos i've ever seen.  Greetings from Poland!,True
@DanielTompkinsGuitar,2017-07-17T03:46:39Z,0,Have you tried joblib from scikit-learn instead of pickle? It allows for further compression (although I think the read/write takes more memory) and can result in a significantly smaller file size.,True
@cloudwithfarooq8083,2017-07-16T17:02:26Z,0,"really nice tutorials.Thanks a lot.I am new to python and ML.I have a list of codes (UNSPSC) which categorize everything into their own codes.sample below:  Level 1 Level 1 Description Level 2 . Level 3  Level 3 Description Level 4 Level 4 Description Full level 4 code 10 Live Plant & Animal Material & Accessories & Supplies 10 Live animals 15 Livestock 01 Cats 10101501 10 Live Plant & Animal Material & Accessories & Supplies 10 Live animals 15 Livestock 02 Dogs 10101502 10 Live Plant & Animal Material & Accessories & Supplies 10 Live animals 15 Livestock 04 Mink 10101504 10 Live Plant & Animal Material & Accessories & Supplies 10 Live animals 15 Livestock 05 Rats 10101505 10 Live Plant & Animal Material & Accessories & Supplies 10 Live animals 15 Livestock 06 Horses 10101506 10 Live Plant & Animal Material & Accessories & Supplies 10 Live animals 15 Livestock 07 Sheep 10101507 10 Live Plant & Animal Material & Accessories & Supplies 10 Live animals 15 Livestock 08 Goats 10101508   Now I have 50k of the above which I think would be the labels.Secondly, I have transaction data which will vary10 million plus etc which have multiple columns. eg: farm animal cats. this should be put into code 10101501  I want to know should I use deep learning for this. Basically I want to create a classifier to classify transactions into the codes above.",True
@arunaldo6149,2017-06-18T18:14:26Z,0,Great works by you.Big thanks for that. Could you please provide the source code/link to it.,True
@dmitrinyy,2017-06-16T11:25:41Z,3,"I got a lot of errors with tensorflow 1.2.x when using the neural network  Errors like:  NotFoundError (see above for traceback): Key Variable_6 not found in checkpoint   [[Node: save/RestoreV2_6 = RestoreV2[dtypes=[DT_FLOAT], _device=""/job:localhost/replica:0/task:0/cpu:0""](_arg_save/Const_0_0, save/RestoreV2_6/tensor_names, save/RestoreV2_6/shape_and_slices)]]  After a lot of research and trial and error i figured out that it had something to do with tensorflow upgrading to a new checkpoint format.   There are 2 solutions:  -  easiest: change in the Use Neural network script saver = tf.train.Saver()  to   saver = tf.train.import_meta_graph('./model.ckpt.meta') Downside is that you have to run the training  - If you want to use the preprocessed model.ckpt on the site force TF to use the old checkpoint format: change the saver commands in the train_neural_network script to: saver = tf.train.Saver(write_version = saver_pb2.SaverDef.V1) saver.save(sess, './model.ckpt', global_step = step)  credits to: https://stackoverflow.com/questions/41048819/how-to-restore-a-model-by-filename-in-tensorflow-r12  I used the 1st solution and works like a charm for me now",True
@annelaure3974,2017-06-14T12:38:36Z,2,"Hey Sentdex!  First of all, thank you so much, your tutos are so great!  I just have a little problem while runing this one, i've got this 'Invalid Argument Error', i can't get rid of : 'InvalidArgumentError (see above for traceback): Matrix size-incompatible: In[0]: [32,0], In[1]: [2638,500]'  As I've understand it, the matrix the second layer give to the output is not in the right format, but I can't manage to change that.  Thank you so much for your help!  I can paste the whole 30 lines description of the error if needed...",True
@mrinalmathur8185,2017-06-14T11:23:05Z,0,"Hey sentdex,  hey, thankyou for all your tutorials. i tried implementing your code but it is only giving me an accuracy of 0.4 -0.5, its not even reaching 0.75. Kindly help me with issue. for better use i increased the epochs to 60, but even then accuracy is not increasing.",True
@tobiarighi4018,2017-05-25T20:48:57Z,0,"Hi, great tutorials man! I can't find the code of this tutorial in pythonprogramming.net, Can somebody give me the actual link? Thanks ;)",True
@mrinalmathur8185,2017-05-24T14:40:41Z,0,"Great tutorial :) i have one doubt, I tried making making user input the sentence but it gives error everytime. Can you tell me how to do it?",True
@abhi6631,2017-04-26T22:07:40Z,0,"while running the script that uses the network  saver.restore(sess,""model.ckpt"")  line is giving error: tensorflow.python.framework.errors_impl.NotFoundError: Key Variable_6 not found in checkpoint   [[Node: save/RestoreV2_6 = RestoreV2[dtypes=[DT_FLOAT], _device=""/job:localhost/replica:0/task:0/cpu:0""](_recv_save/Const_0, save/RestoreV2_6/tensor_names, save/RestoreV2_6/shape_and_slices)]] can anyone help?",True
@danielantoniodasilva383,2017-04-11T22:17:32Z,3,"Great tutorial. I would like to make just a contribution. In Tensorflow 1.0:  tf.reduce_mean (tf.nn.softmax_cross_entropy_with_logits (forecast, y), should be: tf.nn.softmax_cross_entropy_with_logits (logits = forecast, labels = y)  And sess.run (tf.initialize_all_variables ()): Sess.run (tf.global_variables_initializer ())",True
@Gertjuhhh93,2017-04-11T09:07:18Z,0,"What is the f_fum for at lines 33, 37 and 41? visible  at 23:08",True
@rufiromang,2017-04-10T13:35:46Z,0,"thanks for this tutorial. really get me to understand how to build a neural network. After I am done, I play with it a bit and notice the following: 1. i can use the neural network with the same sentence and not getting consistent answer (positive or negative for same sentence) 2. I input non english language and also get swing answer between positive and negative. I suppose the lexicon should be all zeros if I input non english. then why the result still swings?  please let me know your comment?",True
@laughtpp,2017-04-10T00:10:05Z,0,love your tutorials. thank you!!,True
@ammmy4u54,2017-03-27T15:11:40Z,2,"I am getting the following error when i run the code: Matrix size-incompatible: In[0]: [32,58], In[1]: [2638,500] at line  _, c = sess.run([optimizer, cost], feed_dict={x:np.array(batch_x),y:np.array(batch_y)})",True
@sandeepinuganti8791,2017-03-14T07:04:36Z,0,TensorFlow doesn't work with AMD GPU? can anyone help me?,True
@Jakesters,2017-03-13T22:09:15Z,38,"Hey sentdex,  Firstly, thank you for the videos.  I've found these machine learning tutorials to be quite informative and easy to get through.  I was a little surprised by this video.  It's the first one in the series where so much code was done outside of the video.  While I understand a lot of the code may not be as important, most of my understanding comes from writing it out as you do in the video.  This helps with context and grasping the ideas behind it more.  Unfortunately this video left me lacking on information and led me to feel as though I'd missed a video.  Just a bit of constructive criticism.  Thanks again!",True
@anmol9096,2017-03-01T01:40:16Z,1,"You can keep track of the step by creating a global_step by using 'tf.contrib.framework.get_or_create_global_step()' . This way you can also keep track of the epoch. When total steps you mentioned for the training are finished, you can just increment a num_epoch variable and print out the epoch you just finished.",True
@glongoria8004,2017-02-23T11:49:48Z,5,"If someone is having troubles with restoring the 'model.ckpt' file try this instead: saver.restore(sess, './model.ckpt') source:  http://stackoverflow.com/questions/42053709/unsuccessful-tensorslicereader-constructor-failed-to-find-any-matching-files-fo  BTW, the error shown is: NotFoundError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model.ckpt",True
@temblabub,2017-01-02T10:01:47Z,4,"First I would like to say, your tutorials are awesome!! :) I really enjoy watching it!  I have a question for the function create_lexicon. Is there a reason why you do this ""content += ' '+tweet""? The string gets freaking long ;) But I think the lexicon is also generated the correct way if you do this ""content = tweet"". Am I wrong?",True
@coolfishzxx,2016-12-25T05:12:39Z,0,"I tried to use (sess.run(tf.argmax(prediction.eval(feed_dict = {x:[temp]}),1))) to run some image recognition, however, the program became slower and slower when i used the command repeatedly, in addition, the memory usage was constantly  increasing. checked and did not find anywhere in the loop that could cause memory leakage, not sure which part is wrong. thanks!",True
@kbinkows,2016-12-05T09:13:22Z,0,"When I run the training of the network (on CPU) inside linux on virtual box, the windows task manager shows only about 20% CPU utilization - is that expected?",True
@kbinkows,2016-12-05T08:50:31Z,3,"I downloaded model.ckpt and the pickle file and I'm getting an error message, when trying to restore variables, running only function 'test_neural_network()':   ""NotFoundError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model.ckpt   [[Node: save/RestoreV2_5 = RestoreV2[dtypes=[DT_FLOAT], _device=""/job:localhost/replica:0/task:0/cpu:0""](_recv_save/Const_0, save/RestoreV2_5/tensor_names, save/RestoreV2_5/shape_and_slices)]] ""  Were those file created for GPU ? I have CPU atm.",True
@anubhavanubhav7651,2016-11-21T21:01:33Z,0,"Hi sendex,  Can you please explain the reason behind using random.shuffle(). I did not get through the reason what you have explained in your video.?",True
@oscarcastanedamunoz,2016-11-17T03:16:00Z,0,"Hey sentdex, aren't there better Learning algorithm that use much less data to get the same results?",True
@herp_derpingson,2016-10-01T15:57:22Z,0,I think Saver is just a file writer handle. So it is just declared outside the session.,True
@ahmedelsafy9323,2016-09-26T16:41:43Z,1,"Thanks for the great tutorial, I am wondering about what type of GPU you recommend to buy to train the network with, can I also use a GPU as external hardware for my laptop   Thanks",True
@GuillermoValleCosmos,2016-09-20T10:59:20Z,1,"I think you messed the labeling up:  in the preprocessing, init_process function you do  `if initial_polarity == '0':      initial_polarity = [1,0]     elif initial_polarity == '4':      initial_polarity = [0,1] `  However when using the neural network, [1,0] is considered positive. However [1,0] corresponds to data originally labelled '0' which is 'negative'.  I mean, it had to be, I got:  Negative: pretty amazing, incredible, the best, awesome, very good Positive: horrible, the worst, so bad",True
@FirstNameLastName-fv4eu,2016-09-19T18:57:47Z,0,"Very nice. But it is not about the data [my guess]. We are just throwing the lines to NN, we need to make interesting feature vectors along with the comments. Challenge accepted !!! :)",True
@0xsuperman,2016-09-17T03:47:10Z,0,Can this tutorial series be followed using python 2.7 instead?,True
@RaoufGnda,2016-09-08T15:14:45Z,0,Could you implement RNN's or ConvNets for the same purpose plz..!,True
@RaoufGnda,2016-08-31T19:09:58Z,0,"Thank you for this amazing materials, shouldn't I get Certification for finishing all of the 52 tutorials  :) jk. Could you please make a video about using word2vec model for sentiment analysis on the same dataset 1.6m ?",True
@chuckschultz5437,2016-08-31T11:03:29Z,0,"This was super helpful! So thanks! I do have two questions on USING the neural network. You provided a script with two statements at the bottom (i.e. He's an idiot and a jerk). But what if I set up a data collector - let's say a bunch of statements in an MS Excel file or even a flat file hosted in the cloud. Is there a way to simply point the script to the file name/location? From there, the neural network would analyze the contents of that file. Second question, what if we wanted the script to print the output to file (i.e. Negative: He's an idiot and a jerk.). Then you could do an analysis on the output file to understand say 'net momentum' be it positive or negitive.",True
@varunmunagala840,2016-08-29T14:21:24Z,0,Can you make a video about using CNN for face recognition? Please,True
@johncusack3646,2016-08-26T17:47:36Z,0,Is this helpful for reading in data? https://www.tensorflow.org/versions/r0.10/how_tos/reading_data/index.html#reading-from-files,True
@robn9971,2016-08-26T05:14:38Z,5,He's an idiot!,True
@safaaal-wajidi4606,2016-08-25T16:56:50Z,0,"I think neural network also changed, by adding more hidden layers and more complex activation function, so not only the huge data.",True
@GuilhermePassero,2016-08-25T14:07:30Z,0,"What about a better pre processing with postagging, keeping only adjectives. I think that might increase accuracy significantly. Thanks for the videos! I'm still trying to understand the insides of neural networks...",True
