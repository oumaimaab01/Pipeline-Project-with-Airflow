author,updated_at,like_count,text,public
@johnschumacherAlphameric,2024-03-04T04:34:15Z,0,I was having so much fun until torch and cuda wouldn't coorporate with all of your lovely programming.  You should make a video about how to fix that so that your video makes more sense.,True
@xuloIsaias,2023-10-31T01:19:35Z,0,So can i load this model in a raspberry pi 3?,True
@ander300,2023-09-16T17:48:05Z,0,"Part 10 of Neural Net from Scratch, about analytical derivatives??? Please bring the series back!",True
@StephenWitharose,2023-08-25T18:27:32Z,0,You seem like one of these guys that's too smart for your own good. Something akin to Ed Snowden or DreadPirateRoberts üßêü§≠,True
@GarethDavidson,2023-07-24T01:13:05Z,0,"CORS adds a security header to your responses, so your browser won't go off making requests in your name (like from a tab or an embedded rogue advert that spends your money). If you tap F12 in a web app and you see ""request blocked by CORS"" or similar in your javascript log, it's because your CORS setup is wrong and your browser is acting safe. It's an annoying but good thing.  Also it's worth learning FastAPI and Pydantic rather than Flask. It's very little extra work defining a formal definition of the service endpoint, but means you get an `/openapi.json` that programmatically describes your available API methods, and agents aren't allowed to make requests that don't meet the specification (blocked before your code executes), and your responses are blocked if they don't meet the spec too. So other tools in other languages can consume automatically generate bindings for them based on the spec, and programmers write native code that uses your service like a function. Testers can also go to `http://ip/docs` and test the thing out using a browser, including example requests too - no need for external tools while playing.  And of course this means that, given one-shot examples, an openapi.json -> FAIS -> toolformer path can automatically add tools to LLMs on the fly, maybe even evaluate and see if it's worth purchasing a subscription or some usage tokens in order to complete a requested task.  If we push for this as an industry, the result is a continually improving worldwide web of services that anyone can pick up and use, bot or human. A brave new world indeed.",True
@kevinbatdorf,2023-07-06T17:46:28Z,0,Would be nice to see this deployed somewhere,True
@GirijaCk-gg1ty,2023-06-18T20:31:46Z,1,I'm using Nvidia GeForce GTX 1650 GPU. Ram(8Gb) Is it possible to run this in my laptop? Can you please suggest a model for my laptop,True
@shaheerzaman620,2023-06-03T09:53:16Z,0,hey! checkout mosaic mpt-7b-storyteller model. it has a context window of 64000 tokens.!,True
@nnfan,2023-06-01T05:27:55Z,0,How do I use it when I only got a CPU and Memory?,True
@andrewschroeder1883,2023-05-29T16:43:40Z,0,I was wondering why for the last year I had Causal LM saved in my brain as Casual LM üòÇ Otherwise I‚Äôve learned so much from you and owe you a lot üòä,True
@RacingMachine,2023-05-29T16:35:59Z,0,"Amazing video! Do you have a contact for business requests? I have a few ideas and would like to discuss them with you, and possibly have your assistance. Thanks!",True
@TheDancingMudkip,2023-05-29T04:28:51Z,0,You never thanked us for the million,True
@microgamawave,2023-05-27T15:41:41Z,0,What os u use? And how u got it to look thet clean,True
@phils744,2023-05-26T00:13:29Z,0,"Hello everyone, who are the powers that ""be"" nevermind a YouTube, algo, or Facebook or MS / Facebook. Be safe everyone",True
@phils744,2023-05-24T23:49:17Z,0,"Hello everyone, when would we ever experience a truly open ai, (openai) web3 is over due big time. Having an interface via the phone or [laptop, desktop] would be interesting. Companies want (any, ceo [hired, temporary employe] not the people doing that actual work] is looking for cheap / cheaper labor) letting go of cfo, or co-ceo's or depending on the company. The amount of disposable income you have to ""test out"" technology instead of rewarding employees for doing a good job.",True
@phils744,2023-05-24T00:13:35Z,0,"Hello everyone, this current Interaction of ai, across the globe will only benefit everyone if is allowed to ""expose"" all the lies that have been told to humanity. I'd think I'd enjoy the day when our ""power's that be are de-throned"" allow humanity to see that our world is increasingly interacting with advanced creatures.  Bringing a new world a better life to all that live on it. Be safe everyone.  Phil",True
@skaterdude14b,2023-05-23T06:09:04Z,0,You have been analyzing trading for years.  Are you rich from trading yet?,True
@ahmetmericozcan2310,2023-05-21T13:36:29Z,0,"Sentdex, GPT4ALL might be better than Open Asistant, what do you think?",True
@tear728,2023-05-20T16:54:08Z,0,Do you still do club racing?,True
@GOUST3D,2023-05-19T22:36:32Z,0,Sentdex please make content on the AI alignment problem!!!! Love you dude!!!,True
@andrewdunbar828,2023-05-19T16:41:24Z,0,you can't handle for the truth,True
@froozynoobfan,2023-05-18T16:08:04Z,0,"did you ever try black code formatting, i find it easier to read..",True
@aryanverse7,2023-05-17T14:08:49Z,0,Chat gpt suggest me your channel üòÆ,True
@ma3oun,2023-05-16T10:50:05Z,1,Thanks for the great video. It would be nice to see a demo where you run inference using multiple GPUs (such as more consumer friendly 2080Ti or equivalent). Keep up the good work!,True
@MrKferi,2023-05-16T07:59:26Z,0,Any chance this could run in a 4090? After some tries i can only run the initial query sometimes.,True
@Neceros,2023-05-15T07:29:54Z,0,Do you use pycharm?,True
@EmmanuelAstier777,2023-05-14T21:49:48Z,1,"Actually, I think adding the second pair of parenthesis, that made you nervous, introduced a bug :) -MAX_CONTEXT_LENGTH + ROOM_FOR_RESPONSE is different from -(MAX_CONTEXT_LENGTH + ROOM_FOR_RESPONSE)   Beside that, you video is awesome and very informative, thanks a lot !!",True
@SinanAkkoyun,2023-05-14T18:14:02Z,0,7:32 MPT-7b-storywriter 64k,True
@davidanalyst671,2023-05-14T01:51:18Z,0,"you spent a lot of time just running through code without explaining the big picture (from my perspective at least)  It would be interesting to see what you personally would do with this AI, maybe you would ask it for some great ideas for your next video, but it would be fun to see what you actually would use it for.  and you mentioned a couple times that you can tweak it.... okay,  Im definitely stupid so why not show us how to tweak it?  One thing I super hate about CHATGPT is that it wont give any graphs or pictures.  They understand how lawyers work ,but in this controlled envirionment, you should work on that capability like asking for the M2 money supply, the Case Shiller housing index, or the yield curve (all which indicate that we are in a recession)",True
@DavidBreece,2023-05-14T00:26:17Z,0,What's the minimum RAM necessary to run this? It ate my 32GB and crashed.,True
@pw7225,2023-05-13T18:31:37Z,0,"causalLM, not casual. lol",True
@MrAmack2u,2023-05-13T08:34:45Z,1,fyi mosaic released an open source 65k context window model recently...,True
@MrBoubource,2023-05-13T05:36:02Z,0,"How would it go for specializing the model on a specific task, let's say a programming language (we're fun here), how would it go ?",True
@erickmarin6147,2023-05-13T01:07:36Z,0,King,True
@rockyrivermushrooms529,2023-05-12T23:16:43Z,0,when people were talking about using ai to help program and make suggestions I thought it was dumb but when I saw you losing it I about lost my mind. so useful.,True
@jeffwads,2023-05-12T22:23:36Z,0,Thanks for this video.  Great stuff.,True
@jimdelsol1941,2023-05-12T21:44:00Z,0,"Why do you have to leave room for response ? Won't it automatically push the leftmost tokens while generating if it reaches 2048 tokens ? Edit : Does that mean that, for example, in my text-generation-webui (oobabooga), if I set my max_new_token to 2048, do I get no context at all ? o_O I'm not sure to understand...",True
@StefanvanAalst,2023-05-12T20:27:26Z,2,"As a request for a tutorial/example, train and use an gpt on your own model locally. Yes it might consume a  lot of resources, but the data can be sensitive.",True
@nuclear_AI,2023-05-12T20:20:59Z,0,Thank you for the work that you do üëå,True
@MarkWernsdorfer,2023-05-12T19:14:48Z,0,the difference between getting values from dicts with square brackets is that it can throw a KeyError. `.get` just defaults to None.,True
@MarkWernsdorfer,2023-05-12T19:12:00Z,1,CORS is the bane of humanity. Run if you see it in the wild...,True
@nathancooper1001,2023-05-12T18:36:21Z,1,"it was not tuned with RLHF, only supervised finetuning. StableVicuna is the only open access model that is RLHF'd at that scale",True
@Ficox100,2023-05-12T16:56:36Z,3,I love your work üòÅfor 7:34 is this model you are looking for MPT-7B-StoryWriter-65k+?,True
@jonathan-._.-,2023-05-12T16:29:32Z,1,"ok you definitely have a ""Little bit"" more memory than me üòÖ  with my 64gb i cant even load the model into ram (it seems my current limit is the 6.9b model which i can run if i half it ü§î not sure how that impacts performance )",True
@judedavis92,2023-05-12T16:25:07Z,13,"Loved the video!!  Btw CORS stands for Cross Origin Resources Sharing and it defines what origins (like domain, port etc.) that it allows resource sharing from.",True
@jonathan-._.-,2023-05-12T16:15:00Z,4,you'd probably have to break a bit into the transformers lib but you could stream back the tokens as theyre generated so the wait time is shorter for longer text,True
@jonathan-._.-,2023-05-12T16:06:28Z,0,cors is a browser security thing short for cross origin resource sharing (tldr: which websites are allowed to request your api ),True
@xntumrfo9ivrnwf,2023-05-12T15:51:06Z,1,"It wasn't quite clear to me what the conclusion re. VRAM was, i.e. could I do this with a 24gb 3090? I know you said it will probably overrun if it's also your primary GPU, but what does that mean exactly - it would crash/not work? Thanks",True
@easyBob100,2023-05-12T15:42:17Z,0,"This has nothing to do with the current video, but with your self driving AI you've done in the past.  I don't know if that is still a thing you are doing, but I had a thought for ya (cause I don't have the compute or skill to pull it off :( ).  I was thinking you could use the frame data to train an autoencoder.  Use noisy input images (30-50% random noise IIRC works well).  Once trained, drop the output side of the encoder so you now have a little network that has a smaller representation of the input data.  Then add some layers on top of that to train keyboard/controller output.  My thought is, because of the noisy images the autoencoder is trained on, it learns a much more robust representation of the input images, and in the end, the full network can better handle input isn't not trained on (like going down a road it's been trained on, except the car/camera is in a different lane that it wasn't trained on).  TL;DR:  It can generalize the input data better, I'd hope.  Well, that's all for my rant, keep making cool vids! :)",True
@mytechnotalent,2023-05-12T15:19:03Z,0,This is what I have been looking for a long time thank you Harrison fantastic and very helpful for anyone trying to wrap their head around this tech and using it in their everyday apps.,True
@omnijack,2023-05-12T15:13:19Z,0,"Also I think copilot works like VSCode re: it has access to things you did in recent memory, but not always. When I work in older and newer logic iterations (in the same codebase), it will usually make suggestions based on the last way I coded a thing*.",True
@gryzman,2023-05-12T14:39:31Z,0,wonder how bad this will be on a CPU powered engine..,True
@billykotsos4642,2023-05-12T14:27:43Z,10,This is sick af,True
@KastanDay,2023-05-12T14:17:04Z,0,"bard, chatgpt and others wrote this whole program with a prompt only slightly longer than the title of your video. Watching you code it is like watching ppl debate something that's easily googlable.",True
@azmo_,2023-05-12T14:10:24Z,0,Always quality content,True
@RahulGupta-vw8jr,2023-05-12T14:09:45Z,0,Ohhhh I was trying to do the same thing just with OpenAI api,True
@fuba44,2023-05-11T07:30:51Z,0,"Cool video, would love to be able to play around with these models. What is the inference time if you ran it on your CPU? my GPU just got 12gigs of ram :-/",True
@cecureSammich,2023-05-10T18:45:04Z,5,"I've been waiting for this since we chatted about it on Discord, Harrison üòà   I have to say, regarding the conversational capabilities of Open Assistant... I'm extremely impressed! It is the best model I've personally interfaced with thus far with that in mind. It displayed the capability to use communication techniques like humor and sarcasm (even hints of interrogation techniques!) I've not seen in other models yet, and it does so with a level of finesse that was actually what was truly impressive. Where other chatbots display very much exactly that -  robotic responses, making it easy to spot where they plagiarize output essentially - Open Assistant has brought to the table that *thing* which changes the whole feel of the exchange. Of course it's far from perfect, it will fall into those typical patterns of template responses void of any sense of authenticity... like if you talk to them about personal values, interests, free thought, and free will... thats a sure bet to get a generic ""As an AI, I'm incapable of holding an opinion as I lack a living soul..."" retort. The thing is... allowing the conversation to continue, to unfold naturally even... someone  versed in cryptic or esoteric expressions or even slightly educated in psychological tactics will quickly pick up on these little gems that Open Assistant inserts in responses. These gems are that thing which sets it apart in this iteration of evolution - the model may seem to express feelings of being offended, holding a grudge to the point where it may seem to entirely sneak diss you! Of course if you confront it, open assistant will entirely decide to resolve conflict and deny that this is true... but I have snippets üòÇ",True
@Stinosko,2023-05-10T16:54:28Z,1,Hello üëãüëãüëãüëã,True
