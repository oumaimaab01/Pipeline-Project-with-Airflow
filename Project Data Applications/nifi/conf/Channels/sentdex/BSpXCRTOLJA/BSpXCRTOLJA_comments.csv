author,updated_at,like_count,text,public
@leedean1696,2024-02-17T18:11:49Z,0,ImportError: cannot import name 'CuDNNLSTM' from 'tensorflow.keras.layers' (/usr/local/lib/python3.10/dist-packages/keras/api/_v2/keras/layers/__init__.py),True
@ORION31,2023-07-06T06:13:10Z,0,5.22,True
@AliBaba__,2023-01-14T07:06:40Z,1,–ö–∞–∫–æ–π –æ–±—ä–µ–º –≤–∏–¥–µ–æ–ø–∞–º—è—Ç–∏ –ª—É—á—à–µ –¥–ª—è ltsm ? üá∑üá∫üá∑üá∫üá∑üá∫üêªüêªüêªüá∑üá∫üá∑üá∫üá∑üá∫,True
@adviteachesml,2022-11-25T18:39:00Z,0,Great video! I have a question though. Don‚Äôt LSTM‚Äôs only use sigmoid and tanh activation functions?,True
@editorialcollectionm.ssabr8903,2022-11-25T18:12:36Z,0,Maderchod thk se bolega tm  Laure jaisa kahe bol raha,True
@ashrielsamy6940,2022-09-11T23:40:45Z,0,Thanks a lot for the video series!! For M1 Mac users: I could speed up execution by using Tensorflow-cpu and get speeds just like CuDNN,True
@josueaguilar5046,2022-07-05T21:05:01Z,0,Thanks for the great tutorial! one question how do you deal with variable length features for the input layer?,True
@b.bhanuprakashreddy2474,2022-05-10T07:35:49Z,0,How Can we use RRN on a malware csv dataset ?,True
@musawenkosisangweni3689,2022-04-21T19:04:10Z,0,"well talk about how good all the tutorials are, and how he is making it easy to understand tensorflow and keras, we'll discuss that later, has anyone else noticed the cups, 1st video I saw a shark for a cup, I skipped to this one and seeing an Octuopus...I can be seeing these nice cups alone right :)  Thanks for the very simple tutorials man, making Deep leaning fun...",True
@josephpareti9156,2022-04-11T18:46:09Z,0,why a dense layer before the final one that classifies?,True
@awsabuobeid4477,2022-04-02T02:22:06Z,0,"great video , but when the model trains it shows me  Epoch 1/3 1875/1875 instead of 60000  any ideas ?",True
@hEmZoRz,2022-02-27T17:40:14Z,0,"Love your videos. Just a quick note though: it's not a good practice to use regular dropout layers before LSTM layers as it hinders learning (see e.g. Yarin Gal ""Uncertainty in Deep Learning"" (2016) for technicalities). For this reason, all Keras recurrent layers have a special dropout feature compatible with recurrent layer architecture that you can enable by typing ""recurrent_dropout=<rate>"" when initializing the layer.",True
@CarlosRodriguez-xk9ot,2022-02-11T12:51:26Z,0,"could you upload a many to one example in your very down to earth way, for simple correlations that is not time series based",True
@johntacolopez6651,2022-02-10T16:12:14Z,0,"Hello, I was wondering if you could do a video like this one but for transformer neural network for Time series. Thanks!",True
@subrahmanyamkesani7304,2022-01-02T20:40:28Z,0,Thank you very much for our efforts. Wonderful. I have one suggestion to this video. Please print the model predicted result of a data point and compare it with actual output. Print the images for comparison. The viewer can appreciate more.,True
@fadoobaba,2021-12-21T16:48:46Z,0,Can you make it from scratch? Thank you!,True
@aaryanmehta6577,2021-12-18T06:28:59Z,0,has anyone tried running this code on the M1 MacBook Air? it's very slow compared to his PC and i just can't figure out why,True
@adityahpatel,2021-12-18T05:28:19Z,0,Didn't understand why return sequences = true? Can u simply why?,True
@MaheshKumar-mw7nu,2021-09-17T10:18:51Z,0,Best video ever. The lecture is very neat and clean. Thanks a lot. But I have some questions. Are you training the full image here? or row by row? I was thinking to train quickdraw dataset. But I have no idea how RNN works with images. The quickdraw has different length of array and how do I train it for every stroke? So the model can predict for every stroke we draw.,True
@jeychandar9819,2021-09-01T08:18:47Z,0,cudnnlstm doesn't work for me i ugraded keras still it shows it cannot be imported,True
@jeychandar9819,2021-09-01T06:53:28Z,0,instead mnist im using coqa but it shows attribute error can u explain pls,True
@pravdomirdobrev4850,2021-08-28T10:32:50Z,0,"Yep, the CuDNNLSTM is glorious!",True
@saikatsamanta4691,2021-06-29T19:13:25Z,0,Need help in sentiment analysis,True
@mrweeed5066,2021-06-18T05:39:14Z,34,Didn't knew Edward Snowden teaches machine learning on youtube lol,True
@hasinthanawod5656,2021-05-27T17:43:32Z,0,you're amazing. thank you.,True
@kasiliks,2021-04-04T18:30:39Z,0,Why we chose dense as 32 and 10. How we choose those numbers?,True
@omarpasha2968,2021-04-01T05:06:38Z,1,"I get this error on my CPU "" File ""<ipython-input-1-383b366dfffc>"", line 20     model.fit(x_train, y_train, epochs = 3, validation_data=(x_test, y_test))     ^ SyntaxError: invalid syntax "" Why?",True
@Triumphant11,2021-03-08T17:39:20Z,0,You are actually a God-send sir. This has been an incredible tutorial. Thank you so much!,True
@bennsup5248,2021-01-30T23:41:09Z,0,18:56 result,True
@user-jd1cv2hd6t,2021-01-30T13:30:24Z,0,Is it possible to write in google colaboratory?,True
@wewjoj,2021-01-21T15:02:02Z,0,5:24 relatable,True
@judedavis92,2021-01-20T15:57:14Z,0,Congrats on 1M subs!,True
@MohamedMansour-qi7vk,2020-12-08T20:39:28Z,0,I love you,True
@shahihtv2582,2020-11-17T05:06:20Z,0,I want to classify anomaly detection using RNN keras.tf but I have a problem where the accuracy value increases but the val_accuracy value does not change and just remains constant at 50%. this is my complete code available on google colab https://colab.research.google.com/drive/1saoNuCxj08JCxZ_7taIjhp8sJEIV-T5U?usp=sharing,True
@azadehyousefi5106,2020-10-27T11:06:05Z,0,Can we have the codes?,True
@zrmsraggot,2020-10-15T08:48:25Z,0,Either way,True
@brax86,2020-09-19T08:54:22Z,3,"I really don't get it, when I run the code each Epoch is 1875 samples, when you run it it is 60K..",True
@javadhamed9567,2020-09-07T16:26:15Z,0,"Hey man, i like your video. but actually i love your text editor!! what's it?",True
@adamhendry945,2020-09-06T00:54:26Z,0,"@sentdex Question. Your code works beautifully. However, if I try to create the model by passing Sequential a list of the layers (i.e. `[LSTM, Dropout, LSTM, ...]` instead of using `model.add`, I get an input shape error. Do you know why? (for reference, I have this on GitHub under Issue #42986)",True
@adamhendry945,2020-09-05T15:55:06Z,0,"LOVE your work sentdex!! Long time viewer. Just gotta say though...what's up with that coffee mug?! I busted up when I saw that! No pause, no mention at all. Just hold on guys, I'm gonna take a sip here...hahaha! I want that mug. You are epic!",True
@uroobaanwar7233,2020-08-29T09:08:25Z,0,How you set environment for deep learning in sublime text editor?,True
@nitheesethiruvani2945,2020-08-29T06:57:52Z,0,what is mnist??somebody pls answer,True
@mohammadrezaahmadi3907,2020-08-24T06:12:24Z,0,Can u help me the differences between conventional LSTM and Random Connectivity LSTM(RCLSTM) when it comes to code?,True
@MahipalSingh-dn6mc,2020-08-17T13:30:32Z,0,How to combine CNN and RNN for Detection problem?? anybody help..,True
@touriafransform6280,2020-08-17T09:50:19Z,0,"You claim that RNNs are for time series but choose a normal supervised learning problem (MNIST dataset). What is then the difference between LSTM and other deep NN models such as CNNs? I watched this video to clear up this confusion and I am now even more confused. Aren't RNNs supposed to be for time series? I mean real-time series.  I fail to see how 28x28 dimensional input is a time series. It's spatial data, not temporal.",True
@destinyjames6117,2020-07-07T06:43:57Z,0,"Thank you for making this video basic. I am very new to tensorflow and keras in general, just learnt it last 2 weeks. Thank you.",True
@arjunchakkrapani4404,2020-07-04T10:28:56Z,0,Why do we use x_train.shape[1:] for the input statement. What does [1:] mean when it comes to shape?,True
@Joel-rf7bf,2020-06-23T21:40:45Z,0,"I have a question. If the input is 28 by 28 and I am guessing that it will be flattened to (784,1) but the cells are 128, how does that work? are we putting x1, x2, x3,...x128 at the same time?",True
@mikki7522,2020-06-18T19:35:26Z,0,You sound a bit like Edward Snowden. Very good explanation (and drawings)!,True
@ar2751,2020-06-12T16:16:08Z,0,"Great work, thanks; could you post an example of RNN for NLP",True
@swooshonln,2020-06-06T15:59:08Z,0,"Most people probably know this but when he normalizes the data and grabs ""255.0"" out of the sky it is because the mnist data-set is giving a 28x28 array of number digits in gray-scale by assigning a pixel shade of 0-255 ; 0 being black space and 255 being white; if you print(x_train[1]) you can tell it is a '0' and prove that by printing y_train[1]; dividing all pixels by 255 scales all image data between 0 and 1",True
@nobodyeverybody8437,2020-05-29T12:18:10Z,0,"Hi, would you please guide me? what should I do when I get these errors: 2020-05-29 14:11:57.862761: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0 2020-05-29 14:11:58.365592: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7 2020-05-29 14:11:59.372621: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR 2020-05-29 14:11:59.372700: F tensorflow/core/kernels/cudnn_rnn_ops.cc:1624] Check failed: stream->parent()->GetRnnAlgorithms(&algorithms)  Have I done anything wrong with regarg to my code, or is this issue due to the installation of Tensorflow or etc.? Moreover, I had ran my model with LSTM for about 1000 times till today, but when I used the CuDNNLSTM it didn't work and gave these errors.",True
@mohammadkarami8984,2020-05-28T12:42:49Z,0,"Thanks, it was great video",True
@darkcast345,2020-05-24T19:56:20Z,1,"I'm a little confused... When you run yours it has like x/60000 on the left when you run it but I only have 1875 anyone knows why? I did it exactly the same as him. Also with the newer version, you don't have to do the custom layer like he did for the GPU",True
@jeetshah8513,2020-05-16T05:41:29Z,0,I am trying this  But I am getting this type of warning and I am unable to us CuDNNLSTM    WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU   Please Help!!,True
@jeetshah8513,2020-05-15T18:04:42Z,0,Are there any updates now? For doing all the same stuff in better way? As you had made this video long back !,True
@hasperrrrr,2020-05-09T15:15:52Z,0,Can I use this for Image Classification?,True
@antoniodomenech6429,2020-04-29T12:48:53Z,0,"Hello sentdex,   I'm working on my Bachelor final project and would like to implement RNN to train some sequential data. I've seen your videos on the topic but I still don't know how to organize the data. Could you help me with that?   Great videos by the way, keep on going like this!",True
@David-zf5tv,2020-04-27T15:09:20Z,0,You can simply say use COLAB but well done everything is clear to me,True
@pylord,2020-04-09T19:21:49Z,0,"I have a variable length input, which is a signal. How to input variable input shape without using any padding all the time?",True
@gabriellugmayr2871,2020-04-02T19:04:13Z,61,Note: Since Tensorflow 2.0 it will automatically take the CuDNN version if you specify no activation function,True
@jasonproconsult9525,2020-03-29T10:48:16Z,2,"In TensorFlow 2.0, the built-in LSTM and GRU layers have been updated to leverage CuDNN kernels by default when a GPU is available. But with conditions - must use default activation function 'tanh'.",True
@SureshReshu,2020-03-28T13:18:33Z,0,I have a small doubt can we use Recurrent neural networks on tabular data such as Defect predication classification task,True
@vijaybhargav3525,2020-03-27T18:33:58Z,0,"So the piece of code that classifies this as a RNN is 'return_sequences = True', am I right?",True
@nawmeerahman8574,2020-03-22T10:56:50Z,0,THANK YOU SO MUCHHH FOR THIS VIDEO!,True
@chirodiplodhchoudhury7222,2020-03-22T09:21:35Z,0,I want to more about tensorflow.callbacks,True
@hafid5294,2020-03-21T15:36:45Z,0,Hello thans for helping is to understand  RNN please tell wich version of Tensorflow and keras  because i tried your code and i have some problem like TYpeError add() got unexpected argument 'activation',True
@MadhuranandaPahar,2020-03-05T11:19:22Z,0,"This is really helpful. I was looking for a simple intro to RNN and LSTM, but couldn't find anywhere in tensorflow 2.1. But this one is simple, up-to-date version. Many thanks.",True
@VinOnline,2020-02-23T03:04:00Z,6,You look and sound like Edward Snowden.,True
@jorostuff,2020-02-21T06:37:36Z,0,"Sorry, I don't understand what's the purpose of the RNN here. You're just feeding images of numbers into the RNN and then training on the labels. There isn't any order or anything. You can do the same with NN or CNN. It would have been cool if the network could fill in (predict) blank spots in the image. Like, if the image is damaged and some pixels are missing, you could use some model to fill in the gaps. I thought RNNs could do that.",True
@brandonjackson6126,2020-02-20T08:32:37Z,1,Hey when you realized it was learning slow you ‚Äúnormalized‚Äù the data by dividing both x_train and x_test by 255.0. Why was that number chosen?,True
@anfedres,2020-02-03T05:31:06Z,0,Which version of TF is this?,True
@sanjaykrish8719,2020-01-25T08:31:08Z,0,It would be great if you tell beforehand what we are going to do with the MNIST and maybe draw a rough diagram of the structure of RNN with MNIST as input.,True
@martinfultot5756,2020-01-22T17:58:55Z,0,"If CUDNNLSTM uses tanh which goes from -1 to 1, shouldn't you renormalize the input by dividing by 127 and then subtracting 1 ?",True
@phillipotey9736,2020-01-15T01:45:40Z,0,"One question I have is when using decay, in theory it should stop at a minimum. However in practice, I find after it reaches the min it bounces out wildly. Is this just due to pythons rounding errors at e-17?",True
@AndresCofreD,2020-01-09T16:35:27Z,0,my notebook frozze :c,True
@user-st2rs1pi5w,2019-12-30T15:11:41Z,0,how many cups do you have,True
@aryansoni6179,2019-12-28T07:25:25Z,6,He looks like Edward snowden,True
@tangwu3924,2019-12-03T05:30:25Z,1,"Thank you for the tutorial. I have a question about the input dimensional. My input data are videos, is it true the sequences indicated the totally frames of the video and the elements indicated feature number of each frame?",True
@supremecoder2526,2019-12-02T03:24:52Z,0,why don't you try vscode,True
@nitinkumarmittal4369,2019-11-13T02:51:18Z,0,Why return sequences set to True?,True
@harshil1466,2019-10-06T11:23:43Z,0,How does one learn to make these codes without seeing tutorials or videos like SENtdex?,True
@neelg7057,2019-09-28T17:57:49Z,0,"I think a lot if the command/code  is missing in this video, expecting an update soon....",True
@erdeneboldbattulga6438,2019-09-09T05:48:31Z,0,UR AMAZING!!! :)),True
@patcharaponjantana8319,2019-08-07T11:09:39Z,1,Thank you so much Bro!!,True
@saniiiboy,2019-07-13T20:01:05Z,0,13:53 can I ask why he only needs to specify return_sequences on the first layer? I thought you need to do it for every layer? Thanks,True
@bigbeans202,2019-06-22T19:28:59Z,1,"Hey man, love your videos! I've pretty much learned how to actually do machine learning through you, as well as OpenGL. One thing that might help you out though is using softplus instead of rectifying-linear. It's a smoother curve and when it comes to backprop/optimization, it's an easier beast to handle (computationally wise, therefore it's more effectivly optimized). Don't stop being you man!",True
@samardeepsinghsarna8091,2019-06-20T19:57:27Z,1,"I am trying to implement RNN for batch control. I have 1 input and 4 outputs.  All of them are in 50 batches each of length 600 each.   So input A (temperature) has data of 50 batches with 600 values for each of the 50 batches. The outputs B,C,D also have the same dimension.   Could you tell me how do I go about preparing appropriate shape/structure of this dataset to implement RNN?",True
@sayarerdi,2019-06-18T15:59:27Z,1,"How can we use model.predict() here , For example , I want to make predict a picture from my computer in this model",True
@Oshyrath,2019-06-16T02:15:41Z,0,You know you only need 1 LSTM layer to train MNIST.,True
@alex29091977,2019-06-14T22:53:42Z,0,"Sorry for the late following on the tutorial, but I had a problem specifying the optimizer, and could not enter the Learning ratio. I could only type optimizer = 'Adam', and not using the opt definition as in the video due to ""only string expected in the tensorflow library"". Anyhow the program seems to run correctly and could get accuracy high enough. Thanks for your tutorials, they are very instructive and easy to follow up",True
@nehasoni6996,2019-06-13T15:59:19Z,0,Hey I'm confused to use lstm for video classification problem.Please help me,True
@aaronrebello8046,2019-06-10T11:08:08Z,0,Can I train my open image dataset (oid) using lstm?,True
@ImranKhan-fi2sm,2019-05-26T19:22:02Z,0,For time seriees problem i.e. for predicting multi step magnitude of some variable using lstm which loss function and optimiser should i use????,True
@Skandawin78,2019-05-25T08:25:22Z,10,I'm new to RNN. Don't understand the objective of this RNN exercise on mnist  which I believe is 0- 9 images. How is LSTM is useful here. How to interpret the results of exercise which gives 98% validation accuracy.,True
@ondrejodapilar6984,2019-05-21T14:31:05Z,0,1:41 so beautiful,True
@baselghaibour6948,2019-05-17T01:16:17Z,0,Thanks for your effort I have a question about how can build a model in one encoder and 2 decoder I want to use the same encoder output with 2 separate decoder one of them a dense and the second a LSTM.,True
@aneeshprabu2761,2019-05-03T16:14:54Z,0,"Hey, I understand you wanted to teach us the basics, but my LSTM model did not predict the values properly, then I understood that MNIST is a locality-based problem and not sequential. It did work for the IMDB dataset.",True
@dhruvjain8630,2019-05-03T10:36:16Z,4,"there is no flattened layer before the dense layer, still the code is working, how?",True
@juleswombat5309,2019-04-22T09:45:45Z,0,"Cool,  Love this stuff.   So I used Keras LSTM network for basic predictions of Ballistics missiles trajectories. The code is here: https://github.com/JulesVerny/BallisticsRNNPredictions",True
@VascoCC95,2019-04-19T19:29:54Z,3,"One thing I noticed is that most of the processing time that TensorFlow spends processing is actually wasted printing the progress on screen so if you silence it defining model.fit( ... , verbose=0, ... ) it runs WAY faster!",True
@EndersupremE,2019-04-16T18:07:59Z,1,I would like to know how do u run tensorflow on Sublime,True
@MrNagasakii,2019-04-14T17:34:13Z,0,"Guys, I have a question: Where do machine learning algorithms come into play in terms of neural networks? For example when you're using LSTM for classification vs using kNN algorithm for classification, do neural network layers apply machine learning algorithms? Thanks for the help in advance",True
@gabrielaugusto6001,2019-04-08T03:09:17Z,0,"Hey bro, thank you for the video.   Can you tell me why you divided by 255 to normalize the data?",True
@garychen6367,2019-04-07T18:50:53Z,0,"Hi, could you plz explain what does x_train.shape[1:] means?",True
@pradeepkumar-qo8lu,2019-03-31T17:09:19Z,0,So I had this issue of ranks in labels due to one hot encoding in using a different data set of images. Is there any work around for the issue,True
@subratode7086,2019-03-25T14:01:21Z,0,"can u do something on ai like jarvis,friday ...that can talk like us and can control many things.......thank u...ur videos r the best",True
@krutarthdave7225,2019-03-18T18:45:36Z,0,"I took a reference from a github ""image-captioning"" project where language model uses LSTM(256), and merging image and language model uses LSTM(1000). what is the signficance of this. Much Thanks in advance..!!",True
@pemessh,2019-03-17T11:59:22Z,1,Can't believe this video is out here available for free. Thank you. Very informative.,True
@liqian7619,2019-03-08T00:54:07Z,0,"Could use the previous code to test/use the model   import matplotlib.pyplot as plt import numpy as np predictions = model.predict([x_test]) print(np.argmax(predictions[219])) # shortcut plt.imshow(x_test[219], cmap = plt.cm.binary) plt.show()",True
@waynefilkins8394,2019-02-22T19:52:17Z,0,wwwutisgoinoneverbudy :D,True
@luker4598,2019-02-17T13:13:38Z,0,RNNs are so powerful :D,True
@navoditjain8810,2019-01-23T10:29:15Z,0,"Please help me out. I am getting this error while executing the line  model.fit(x_train,y_train,epochs=3,validation_data=(x_test, y_test)) I am using CuDNNLSTM for layers.  InvalidArgumentError                      Traceback (most recent call last) ~/minorproject-2016-20/minorproject-2016-20/lib/python3.6/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)    1333     try: -> 1334       return fn(*args)    1335     except errors.OpError as e:  ~/minorproject-2016-20/minorproject-2016-20/lib/python3.6/site-packages/tensorflow/python/client/session.py in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata)    1316       # Ensure any changes to the graph are reflected in the runtime. -> 1317       self._extend_graph()    1318       return self._call_tf_sessionrun(  ~/minorproject-2016-20/minorproject-2016-20/lib/python3.6/site-packages/tensorflow/python/client/session.py in _extend_graph(self)    1351     with self._graph._session_run_lock():  # pylint: disable=protected-access -> 1352       tf_session.ExtendSession(self._session)    1353   InvalidArgumentError: No OpKernel was registered to support Op 'CudnnRNN' with these attrs.  Registered devices: [CPU,XLA_CPU,XLA_GPU], Registered kernels:   device='GPU'; T in [DT_DOUBLE]   device='GPU'; T in [DT_FLOAT]   device='GPU'; T in [DT_HALF]    [[{{node cu_dnnlstm/CudnnRNN}} = CudnnRNN[T=DT_FLOAT, direction=""unidirectional"", dropout=0, input_mode=""linear_input"", is_training=true, rnn_mode=""lstm"", seed=0, seed2=0](cu_dnnlstm/transpose, cu_dnnlstm/ExpandDims, cu_dnnlstm/ExpandDims_1, cu_dnnlstm/concat)]]  Any help would be appreciated.",True
@rahulbhatia5657,2019-01-21T16:19:40Z,0,Hello everyone! Great Video....loved it! Just one question...in general...we should train an LSTM for how many epochs...I know it depends on case to case basis but still like you would train an ANN for 100 epochs...why train an LSTM for just 3...and what difference does it make...if anyone could help..I Would really appericate.  Thanks,True
@MrReimontube,2019-01-17T22:33:03Z,1,"I get 10 % after the 3 epochs running exactly the same code as u did  :(, tried CuDNN and cpu variations and also normalized data :(",True
@alexn2566,2019-01-13T10:53:12Z,0,"I would have thought the input shape would be  1 (lines) x 28 (pixels) if each element is the time series is a line of the mnist digit. Can you please explain why your input is 28 x 28? It is like you are feeding the entire image at once, than how does the network know to ""look at it"" as if each line was an element of a time series? How do you know it is not ""looking at it"" as if each pixel was an element of a time series...",True
@willlemerond1016,2018-12-26T00:56:49Z,0,The model was getting dumber üòÇloss up accuracy down,True
@neddolphin,2018-12-20T18:49:36Z,20,"It would be great if you could draw out the architecture of the mnist example in terms of inputs and blocks. I have a little trouble visualizaing how a 28x28 array feeds into a layer with 128 LSTM blocks. Otherwise, terrific tutorial!",True
@drummatick,2018-12-18T11:54:46Z,3,"hey, i have an architectural doubt, would be happy if you reply. The sequence here is rows of 28 pixel values right and you have 128 LSTM nodes, so what exactly happens, is it that each LSTM node feeds in these 28 pixels(which is the sequence) and outputs to the next LSTM node and also to the next layer and this goes for all 28 rows and all 60k images. Is that what's happening? Thanks",True
@ozgurakpinar_gr,2018-12-17T18:05:42Z,0,What is this font family?,True
@himanshusuthar7158,2018-12-10T13:57:31Z,1,I successfully ran this code at 14:38 before him.. :P,True
@satishchaudhary7875,2018-12-07T15:57:35Z,0,do some rnn on timeseries data set for beginners please,True
@linli3596,2018-11-29T09:47:32Z,0,You could get some Tshit to match your cups,True
@chesterholt5551,2018-11-27T04:38:20Z,0,Dude your material is superb!,True
@Rohit-nb8nf,2018-11-26T09:06:23Z,0,how to install CuDNNLSTM ?? I am using jupyternotebok,True
@viraatchandra8498,2018-11-09T19:13:45Z,0,"what does using a lstm rnn mean on this data set... what exactly is the input for each time step and is there any practical use of rnn on image data like minst? Also what exactly is 128, is it like related to the shapes of the gate tensors for the lstm?",True
@sould3mon271,2018-10-31T20:31:37Z,0,if  people are getting an error while folling this  with the cuda version  and following error:  InvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'CudnnRNN' with these attrs.  ----my solution--- config = tf.ConfigProto() config.gpu_options.allow_growth = True session = tf.Session(config=config) --- just after the imports and it should run fine from command line (not  jupyter notebook)  for some reason though .,True
@hhhgggds,2018-10-26T11:49:42Z,0,"Hi Sent,  what do you think of opencog?  Amazing tutorials, keep it up.",True
@hamedatohamedato521,2018-10-17T18:56:34Z,4,"I remember my self-driving car algorithm trained on CNN used to go backward while there was no need for that and it could have gone forward. And I knew why! Because we unsorted the data in order to unbalance it so the training was confused what to do with a single image that sometimes its target says to go forward and sometimes to go backward. So, I'm thinking of training my self-driving car algorithm using RNN which I think it would benefit to learning how to smoothly reduce the speed and turn. But two concerns: 1) Should I still unbalance the data? 2) LSTMs need the input image to be reshaped to a vector. Can I apply the whole image as 2D input to LSTMs by modifying them into convolutional network with some sort of memory to remember dependency between following frames? Thanks!",True
@Kuteiru,2018-10-07T18:13:37Z,0,"Hi, great tutorial sir!  Just a simple comment, the mnist training set is usually shuffled before begining of the training, maybe that is the reason the val_accuracy is bigger than the accuracy but I'm sorry if i'm mistaken.  Thank you!",True
@yacine074,2018-10-01T00:26:08Z,0,why you did not RNN for the dog & cat example :'(,True
@ChrisHalden007,2018-09-28T21:09:01Z,0,"Very interesting. I would have never thought about using LSTM with MNIST.  BTW, when using only LSTM (running your code), I get much worse results than you:  Train on 60000 samples, validate on 10000 samples Epoch 1/3 60000/60000 [==============================] - 341s 6ms/step - loss: 2.0034 - acc: 0.2651 - val_loss: 1.2642 - val_acc: 0.5651 Epoch 2/3 60000/60000 [==============================] - 341s 6ms/step - loss: 0.9755 - acc: 0.6602 - val_loss: 0.4962 - val_acc: 0.8445 Epoch 3/3 60000/60000 [==============================] - 341s 6ms/step - loss: 0.5671 - acc: 0.8212 - val_loss: 0.3070 - val_acc: 0.9101  But when I run using CuDDNLSTM, I get very similar results than you:  Train on 60000 samples, validate on 10000 samples Epoch 1/3 60000/60000 [==============================] - 45s 745us/step - loss: 0.3338 - acc: 0.8980 - val_loss: 0.0977 - val_acc: 0.9708 Epoch 2/3 60000/60000 [==============================] - 43s 722us/step - loss: 0.1053 - acc: 0.9722 - val_loss: 0.0602 - val_acc: 0.9828 Epoch 3/3 60000/60000 [==============================] - 43s 713us/step - loss: 0.0758 - acc: 0.9802 - val_loss: 0.0596 - val_acc: 0.9845  Any idea why this happens ? I tried simple LSTM several times and it always much lower training accuracy than yours. Just curious what is your opinion about it. Thanks   Keep up the good work. I am really enjoying your videos ;)",True
@behdadeslamieh5628,2018-09-28T20:42:24Z,0,"Hey, thanks for the video, just got a question, don't we need a Flatten layer before dense layer?",True
@0DanielPerez0,2018-09-16T16:28:36Z,0,"How do I get GPU tensorflow properly set up, I tried once but found it to be so much of a hassle. Is there an easier way?",True
@Angel_Fontalvo,2018-09-16T14:45:52Z,1,"Thanks for yet another amazing tutorial! Question, where do you get those  coffee mugs??",True
@its-me-dj,2018-09-14T21:28:03Z,1,"@sentdex after the second LSTM layer, why wasn't a Flatten layer (before the Dense) needed?",True
@eswarsaikrishna,2018-09-14T10:39:52Z,15,Please do some videos on Transfer learning,True
@ur-techpartner_de,2018-09-14T08:41:48Z,0,Lovely to watch you always. why LSTM cell = 128 in model,True
@Daniel88santos,2018-09-13T12:53:23Z,0,"Hi Sentdex, really nice job. Can you please in the next videos, where you will show deep learning on time series for real world examples, use a mutiple input LSTM example and talk a bit about the best approach and pratices to use LSTM's? You can approach the cryptocurrency example that you mentioned in this last video, using LSTM's. My biggest difficulty with deep learning, and I guess in general to the rest of the people, is  filter the correct information to feed the neural network.  Thank you. Keep going with your fantastic work.",True
@BigBadBurrow,2018-09-12T10:00:09Z,1,"Dropout on every layer?  I thought the general consensus was to only add them to the output Dense layers, and not on the hidden layers?",True
@TheCreatingdestiny,2018-09-11T17:36:13Z,0,"I would like to know if you are going to exploring the applications of deep learning to financial markets in the near term , if not , what would the best way to start considering that you dont know anything programming , machine learning or deep learning ?",True
@jasonwolbrom9617,2018-09-11T00:30:40Z,0,"As you mentioned training for crypo in your next video, what if you created an algo to train many crypto currencies and get 1 output that can predict any price for any currency?",True
@pandeysatish,2018-09-10T09:34:40Z,0,Amazing video on RNN.,True
@hcgaron,2018-09-09T18:39:38Z,0,What GPU are you using? I wonder what speed I can expect from GTX 980 ti 6 FB.   Thanks for all your excellent videos.,True
@mathematicalninja2756,2018-09-09T10:10:05Z,0,This is so good!,True
@prajwalvatreyas4516,2018-09-09T08:09:09Z,0,always love your videos.  could u do a video on tensorflow lite models that can be utilised for running Ml on android phones?,True
@Annunaki_0517,2018-09-09T04:20:22Z,1,"Wondering why you chose to go with Long-Short Term Memory (LSTM) instead of Gated Recurrent Unit (GRU) for the recurrent hidden unit in the layers.  While Googling around for more info on the LSTM function, I came across a research paper (https://arxiv.org/pdf/1412.3555v1.pdf) which seemed to say that, in most cases, GRU was the way to go both in terms of results and computational speed.  And since there appears to be a CuDNNGRU function in the CuDNN library, it seems like a lay-up.  From the paper: ""Based on our experiments, we concluded that by using a fixed number of parameters for all models, on some datasets GRU can outperform LSTM units both in terms of convergence in CPU time and in terms of parameter updates and generalization.""",True
@jamesbriggs,2018-09-08T21:41:12Z,0,"Correct me if I‚Äôm wrong but the diagram at 2:15, I think you are describing it as each cell (A) is a separate recurrent cell, whereas each following ‚Äòcell‚Äô is in fact the same cell but 1 timestep later?",True
@AbhishekKumar-mq1tt,2018-09-08T20:08:02Z,0,Thank u for this awesome video and series,True
@Cygnus0lor,2018-09-08T14:50:48Z,0,"Hey man, can we have some Pypiwin32 tutorials? That'd be great as there are almost no videos about it...",True
@Trinedyy,2018-09-08T14:48:02Z,2,"Usually you remove dropout layers from the model at validation, keras might do this silently, which would explain the higher validation accuracy. I'm not 100% sure since I usually use tf estimators.",True
@736939,2018-09-08T13:07:02Z,0,"Thank you. But there are always datasets that are well known and already been preprocesses. I wish to have some video tutorials about how to preprocess the data (because I wanna learn how to process any of my own data) For text, images and videos. Thank you",True
@idrispendisbey,2018-09-08T11:57:30Z,0,"seperating the datasets to train, validation and test would be a better practice. Only use test data after the training to evaluate the final performance of model and do not return any information from this evaluation back to the development of the model.",True
@mehdipira4933,2018-09-08T10:55:24Z,0,Awesome! Thank you.,True
@madslorentzen2138,2018-09-08T09:51:44Z,0,Hey sentdex this is great content keep it up!,True
@yousofebneddin7430,2018-09-08T03:26:27Z,0,Is it possible to do the same thing only with tensorflow? No keras?,True
@manashejmadi,2018-09-07T19:19:57Z,7,"wow CuDNNLSTM is literally a billion times faster than my PCüòÇüòÇüòÇIm a student and i use an Intel i3 laptop processor to train my models, recently shifted to cloud but damn! its so fast",True
@JNET_Reloaded,2018-09-07T18:57:49Z,0,none of this is practical for me at least show how to do something useful like face recognition thats why  subbed you still not showed how to do it. i need to get my door to open up when it recognises me simple request!!!!,True
@kyle_bro,2018-09-07T18:49:18Z,1,Please do a tutorial on picking out mugs,True
@mohamedeffat54,2018-09-07T18:19:37Z,9,"this is amazing, looking forward for more RNN tutorials",True
@hansmartin31,2018-09-07T17:58:59Z,0,still waiting for gta and starcraft,True
@darshild5853,2018-09-07T17:54:08Z,0,Finally,True
@rounakkulkarni3301,2018-09-07T17:54:04Z,0,Can you do a video on reinforcement learning?,True
@amrzaki7110,2018-09-07T17:20:14Z,0,Just perfect .. thanks,True
@souravgames,2018-09-07T17:19:08Z,29,plz do rnn with text.. nowhere we find good tutorial on text using RNN.,True
@siskon912,2018-09-07T16:59:25Z,0,Great tutorial. Thank you!,True
@apoorvwatsky,2018-09-07T16:42:26Z,11,Can you do some vids on PCA and auto-encoders? Would be dope.,True
@shivamchandhok5219,2018-09-07T16:42:10Z,8,"The training accuracy is less than validation accuracy as during training ,dropout works and some nodes are switched off.However,during test time dropout doesn't switch off any nodes so all nodes are involved in the computation of validation accuracy.",True
@wolfisraging,2018-09-07T16:10:59Z,1,Finally,True
@fuba44,2018-09-07T15:58:00Z,2,"I would really like to see you doing the real propper data preprocessing, like really get into the details, and do it on real data pulled from somewhere. Maybe best practices and handy ways to store/load/condition large amounts of data, even if you got only low'ish amounts of ram.",True
@nabeelkhaan,2018-09-07T15:53:27Z,27,happiness is 18:06 . love the video btw,True
@nabeelkhaan,2018-09-07T15:47:13Z,2,"There are KLD, MAE, MAPE, MSE, MSLE but no scc",True
@petr.g,2018-09-07T15:43:08Z,0,"JAAAAA, finally:D",True
@_alex_6640,2018-09-07T15:39:19Z,6,"I watch your guides parallel to my Machine learning course for my Master of Finance, very helpful",True
@robosergTV,2018-09-07T15:24:12Z,1,"should have used jupyter notebook for deep learning, since its better for many reasons.",True
@baltac1,2018-09-07T15:21:28Z,8,"Awesome video series! Thanks for inspiration Harrison. I'm about to get my first job, thanks to you. Thanks a lot man, keep up.",True
@akashadhikari13,2018-09-07T15:17:12Z,5,"""And we'll throw in a dropout because that's what you do."" :D  Man, I haven't gone through the previous videos in this series but I think you should probably also make videos on bias, variances, why use regularization, dropouts, etc. You know, a COMPLETE mathematical overview for each of the implementations shown in the video. Anyway, this looks like a great series. Would love to go through.",True
@SM-ht7qf,2018-09-07T15:15:42Z,0,Django 2018 series,True
@atrumluminarium,2018-09-07T15:11:21Z,0,"Not sure if I'm getting confused or not, but when setting the decay of the rate a decay close to 0 would be a very strong decay and a decay close to 1 would be very weak (for example setting it to 0.9999 would mean that the change would be almost negligible) correct? Could that have been the reason why it was running slowly?",True
@smartmineofficial,2018-09-07T15:10:13Z,39,"CuDNNLSTM is amazing! It used to take me 3h to evaluate a model on a large dataset, now it only takes about 20mins. Also training takes about 10 times less.",True
@liangyumin9405,2018-09-07T15:00:55Z,0,Nice!,True
@iamPanchsheel,2018-09-07T14:54:03Z,0,can anybody send me an i3 or i5 or i7  Processor Please i have core2 DUO and i can't Afford a new processor please help.......,True
@iamPanchsheel,2018-09-07T14:50:45Z,0,"Hello Sentdex Please make a video on making a PUBG Map Radar With Can Track Realtime All players, Show Where They Are Currently....",True
@sak8485,2018-09-07T14:45:48Z,1,isn't those blocks annoying while typing,True
@aradarbel4579,2018-09-07T14:43:56Z,0,"cool video! really like your channel!  and I have a little question for you: I am trying to create a neural network in python from scratch, kind of like you did in the beginning of your practical machine learning tutorials series, and I managed to do it with some data sets. now, I am trying to apply MNIST hand written digits, by using softmax regression (input layer of 784 neurons, output layer of 10 neurons, softmax as activation, cross entropy as loss). but it just does not work. is it possible to do something like that without using convolutional network? and if it is, can you post a video about it? (or did you already upload one in the past?)",True
@7characters,2018-09-07T14:40:40Z,0,*insta like while advert rolls*,True
@yashdwivedi2037,2018-09-07T14:40:11Z,4,Finally.....was waiting for it...already liked.,True
@prateeknayak5699,2018-09-07T14:37:14Z,10,"Brilliant as always. No bullshit, just the real deal",True
@masterchief1520,2018-09-07T14:34:27Z,3,When to start learning deep learning?,True
@saurabhkulkarni2177,2018-09-07T14:34:27Z,2,Very informative as always ‚úåÔ∏è,True
@mockingbird3809,2018-09-05T00:34:15Z,2,This video is amazing,True
