author,updated_at,like_count,text,public
@GrantGamez365,2023-01-21T16:35:41Z,1,"Just putting this out there for the people who want to learn about this stuff years later.  You might be getting some error with classifier = nltk.NaiveBayesClassifier.train(training_set)  Remember to put parentheses instead of brackets. For me I had to change 'features[w] = {w in words}' to 'features[w] = (w in words)'. This sets up your tuple correctly.",True
@ahmedifhaam7266,2022-03-17T07:55:43Z,0,"btw here, feature set is only 2000 total right, so train->test 19:1 ?",True
@jeremyheng8573,2022-02-10T07:37:21Z,0,Thank you for the tutorial. Hope that if you can show us its use case,True
@Dogewow,2021-08-11T20:16:13Z,1,"How do you print out the precision, recall and F score of your classifier ?",True
@ygbr2997,2021-04-12T05:17:59Z,0,"Could that 3000 be for Avengers 4, ""I love you 3000""",True
@peschebichsu,2021-03-19T14:37:19Z,0,"Thanks for all your videos, you are amazing! One question to the Naive Bayes algorithm: What are the ""more elegant"" alternatives and could you do a video about using them?  And btw: I constantly get an accuracy of 75 - 80 % when testing :O. Maybe Naive Bayes got improved over the years?",True
@AnAN-bn1ol,2020-12-15T12:00:07Z,0,how to predict new sentences with model,True
@elementsofarah7918,2020-09-09T21:36:57Z,0,"does this also work for categories such as ""positive, neutral, negative"" ?",True
@crush_king0792,2020-03-10T05:49:56Z,3,"Why everytime it show different percentage and diff. 15 informative feature, without even changing a single word in program. Same input diff. Output why?",True
@baburaj941,2020-01-26T10:50:22Z,0,but u r just taking th file inside he library what about our own files ..txt files i meant,True
@adhamfakhri2500,2019-04-26T14:55:04Z,0,"hello im from indonesia, i wanna ask, is it possible to do natural language processing with python using indonesian language?",True
@GelsYT,2019-04-10T15:52:26Z,0,mine hit 83.0 2x,True
@GelsYT,2019-04-10T15:29:18Z,0,can someone explain to me why we train? difference between training_set and testing_set. Like what do you get from training? THANK YOUU,True
@navneetarya4398,2019-04-08T11:06:30Z,0,Where do I practice NLP problem  ?,True
@suwarnachoudhary8591,2019-04-06T11:40:41Z,0,"The Naive Bayes classifier was not imported initially, then how did it worked?",True
@luis96xd,2019-02-10T01:46:35Z,0,This is an excellent video! Thanks,True
@markytwain6026,2018-11-22T08:49:15Z,0,I get an 'invalid syntax' in the line:  classifier.show_most_informative_features(15)  My code is the same as in the video. Maybe something is not imported as it should? I am using python 3.6 on Anaconda. Anybody that can help with that issue?,True
@ziauddinmohammed7759,2018-09-01T16:34:26Z,0,"Bro I m getting an error called"" ELE  Probablity distribution must have at least one bin"" Will u please help me out of this",True
@akshaymilmile,2018-08-16T18:46:47Z,1,"list(all_words.keys())[:3000] ---> why did you use first 3000 values, because I just printed it and checked,  most observed words are not in first 3000, list is totally random. So can I assume and say that it is just random? If it is random, it would have made sense to first collect most observed words and then use it as feature set.",True
@ep-spdchess52,2018-08-16T11:29:08Z,1,"why would there be a 3000? haha - that is when you do not know ""Mystery Science Theater 3000"" btw I recommend the series - even for a german the mockery of the bad movies is amazing.",True
@kdvilla1148,2018-03-22T17:22:31Z,1,"Question not related to this video, but is related to NLTK library. I want to verify a specific word is a specific part speech (ex. verify a word entered by a user is a noun). What would the command look like and what would the import nltk look like?",True
@VG-kn9de,2018-03-21T13:17:17Z,0,pls post your code github <3,True
@akanshashah9631,2018-03-16T12:23:10Z,0,"HI, Would you mind giving tutorial on visual recommended systems",True
@hardikajmani5088,2018-03-06T06:32:16Z,0,"Hey there, can someone help me out with the following error?  "" classifier = nltk.NaiveBayesClassifier.train(training_set)   File ""C:\Python36\lib\site-packages\nltk\classify\naivebayes.py"", line 198, in train     feature_freqdist[label, fname][fval] += 1 TypeError: unhashable type: 'set' "" Even after consistently tallying the code with the video I am getting the same error.",True
@dzerodhero2780,2018-02-14T07:28:30Z,0,How only print if a comment pos or neg .Nothing else,True
@thisisshakkhor9618,2018-02-13T06:48:08Z,0,what if I had to use a tagged csv file for my dataset. like column 'A' is a comment and column 'B' the level either 0(for negative) and 1(for positive) and the language is bangla.  Now how do I feed these into a classifier?,True
@pujithavemulapati3207,2018-02-03T18:21:45Z,0,how to collect those 3000 reviews??,True
@MuhammadShoaib-sp4em,2018-02-02T22:07:06Z,0,in featureset documents can acess it show named error,True
@chasonfu4125,2018-01-24T08:50:20Z,0,Can anyone tell me why the length of featuresets is equal to 2000.,True
@anilkumarpn7202,2017-12-20T05:22:17Z,0,"When i classify  ""It is not a bad thing"" it gives  the result  of negative. Why? Its a positive sentence no ?",True
@amitbardhan5312,2017-11-27T08:16:58Z,1,"Hey you videos are really intresting. Can you help me in if there is a change in this algorithm, thats is instead of Naive Bayes , i want to use Support Vector Machine, then what will be change in the given scenario?",True
@gottakeepup,2017-10-30T05:52:02Z,0,"Dude thank you so much made used some custom data, (that was pretty shitty) and it works literally You saved me so much time you brilliant mind ^_^",True
@Himanshukumar-pu3bh,2017-10-12T07:21:38Z,0,"please help i have this error C:\Users\Himanshu\Desktop\NLTK>python TextClass.py Traceback (most recent call last):   File ""TextClass.py"", line 41, in <module>     classifier = nltk.NaiveBayesClassifier.train(training_set)   File ""C:\Users\Himanshu\AppData\Local\Programs\Python\Python35-32\lib\site-packages\nltk\classify\naivebayes.py"", line 220, in train     label_probdist = estimator(label_freqdist)   File ""C:\Users\Himanshu\AppData\Local\Programs\Python\Python35-32\lib\site-packages\nltk\probability.py"", line 891, in __init__     LidstoneProbDist.__init__(self, freqdist, 0.5, bins)   File ""C:\Users\Himanshu\AppData\Local\Programs\Python\Python35-32\lib\site-packages\nltk\probability.py"", line 771, in __init__     'must have at least one bin.') ValueError: A ELE probability distribution must have at least one bin.",True
@zimttrolle6196,2017-09-08T19:19:22Z,1,I am getting only an accuracy of  28 - 31% I don't understand how you are getting 60- 80 % accuracy.  native bayers accuracy percentage  31.35 MNB_classifier accuracy percentage  28.999999999999996 BernoulliNB_classifier accuracy percentage  31.4 LogisticRegression_classifier accuracy percentage  25.25 SGDClassifier_classifier accuracy percentage  28.9 SVC_classifier accuracy percentage  49.25 LinearSVC_classifier accuracy percentage  25.25 NuSVC_classifier accuracy percentage  25.85,True
@moazim1993,2017-08-27T21:05:32Z,0,"I'm not really understanding how you can have 3000 features and  1900 rows. How is this being handled? If it's not, this wouldn't work due to the curse of dimensionality, right?",True
@simonchan2394,2017-08-09T15:50:04Z,0,"I think grammar not being featured in your ""Most Informative Features"" is because grammar (apostrophes, commas, fullstops etc.) are excluded as you are taking the first 3000 words from the word distribution. Those grammar items appears far more frequently so they would be more than 3000 in our case, so they are automatically excluded.",True
@revanttiwari4669,2017-08-08T02:33:10Z,0,I am getting a constant accuracy of 0% please help,True
@yvsvf8423,2017-07-27T15:45:08Z,16,"mystery science theater 3000, a show where they showcase bad movies.",True
@gnoahs1994,2017-07-19T20:30:24Z,0,"Hi, thanks for the video! I am trying to build a classifier with my own data and was wondering what format my training and testing sets. When using the package textblob I made a list of tuples containing two elements each -- the first element was the text as a string and the second element was the ex-ante classification, i.e. [('test string one', 'positive'), ('test string two', 'negative')]. Any guidance would be appreciated. Thanks!",True
@16avnisharma,2017-06-09T09:53:14Z,0,How to tune naive Bayes classifier. The accuracy is less..,True
@lukaskris3484,2017-05-21T03:20:28Z,0,"need tutorial using dataset ISEAR, :( my percentage using function extract features under 40% can you help me",True
@DineshPatil-lo1vq,2017-04-08T02:26:34Z,2,"Is it necessary that we provide training sets (featuresets) in the particular format that we gave (tuples of (features, category)), for naiveBayes classifier to work. If not, how does nltk adapt and train according to the format of training featureSets which we provided?",True
@rhettscronfinkle3106,2017-03-26T12:33:57Z,0,"+sentdex. I am getting an accuracy of 100percent and  the most_informative features() function isn't printing out anything.Please have a look   import nltk import random from nltk.corpus import movie_reviews documents=[]   for category in movie_reviews.categories():   for fileid in movie_reviews.fileids(category):    documents.append((list(movie_reviews.words(fileid)),category))  random.shuffle(documents) allwords = []  for w in movie_reviews.words():  allwords.append(w.lower())   all_words = nltk.FreqDist(allwords)   word_features = list(all_words.keys())[:3000]   def findfeatures(document):  words=set(document)  features={}  for w in word_features:   features[w]=(w in words)  return features  featuresets = [(findfeatures(rev),category) for (rev, catgory) in documents]   trainingset = featuresets[:1900] testingset = featuresets[1900:] # print (type(featuresets))  classifier = nltk.NaiveBayesClassifier.train(trainingset)  print (""Accuracy -> "",nltk.classify.accuracy(classifier, testingset))  classifier.show_most_informative_features(15)  Output: Accuracy ->  1.0 Most Informative Features",True
@keshavvp6767,2017-03-25T09:08:28Z,0,"hey hi how to use naive bayes classifier to classifty the affiliation string text of author and identify name of author,name of institution,research department and location in the text please can you show how to achhieve this ? i have urgrncy and need of this code",True
@sukumarh3646,2017-03-09T00:16:53Z,0,"i always make a mistake with the spelling of occurrences and hence, I copied yours. Turns out you too have the same problem :P",True
@AstakhovLL,2017-02-17T07:39:21Z,0,"Please, help me! Traceback (most recent call last):   File ""nlt.py"", line 37, in <module>     classifier = nltk.NaiveBayesClassifier.train(training_set)   File ""/usr/local/lib/python3.5/dist-packages/nltk/classify/naivebayes.py"", line 198, in train     feature_freqdist[label, fname][fval] += 1 TypeError: unhashable type: 'set'",True
@OnlyHouseMuzic,2017-02-01T10:59:46Z,1,"I didn't understand a passage: in the line ""featuresets = ............"" where do the ""rev"" and ""category"" come from?",True
@manankalra7978,2017-01-14T06:57:16Z,0,"# #  Naive-Bayes (posterior = (prior occurrences * likelihood) / evidence) classifier = nltk.NaiveBayesClassifier.train(training_set) accuracy = nltk.classify.accuracy(classifier, testing_set) * 100 print(""Accuracy: "", accuracy)  Here training set is a list of tuples, where each tuple has a dictionary{word:Boolean} and a category(pos/neg). So  how does the train() method of the NaiveBayesClassifier know that it has to mark the review as positive or negative(i.e. mark it to the second entry of the tuple) by iterating through the first entry of the tuple, i.e. the dictionary.",True
@adarshatluri,2017-01-10T11:12:41Z,2,"Great videos :)   . How come the accuracy changes each time i rerun the same program on the same data set. If the training and testing set being used is the same , shouldn't the accuracy also be the same?",True
@darinam6013,2016-12-11T21:47:08Z,2,"Thanks a lot for your videos! I have a question according to precision, recall and f-measure. How could I find it?",True
@amrinfathima4958,2016-10-31T12:30:30Z,0,Thanks a lott!! The videos are very useful for my project. I have problem in applying naive bayes algorithm in heart disease diagnosis. Can you tell the way i could use my own data and apply the algorithm.,True
@g00dvibes47,2016-10-21T21:08:20Z,1,how would I use a scikitlearn model wrapper instead of the nltk naivebayes?   the reason being:  it's far too slow and with a huge dataset like 1 million tweets how the heck could I do that in a reasonable amount of time?   thanks,True
@keregnew,2016-10-10T22:08:12Z,1,"Useful and inspring tutorials - thanks alot! i am trying to do sentiment analysis for german tweets and for the lack of labeled rewies or documents in german i am using SentiWS which is basically two labeled word lists - one positive and one negative. question is: how to get the features and how to split training data from testing data? my strategy so far (and it seems to be working): Every word from the collected Tweets get it's feature with True or False value, depending on, if it is in the Tweet or not so by iterating over every Tweet, every word in the sample set (FreqDist of the words in the Tweet collection) should at least one time get the feature True. when i use as training set the wordlists with known sentiment values, these true or false will get positive or negative values as features later. If a word from the SentiWS training set is in the samples list of the words we have in all the Tweets, we also have a sentiment (positive or negative) to classify it (Naive Bayes, logistic regression or another classifier).  I tried it this way and it seems to work but how to test and against what? How to test different classifiers or vote between them and so on? It would be very nice if you could give me some hint. Thanks and keep up your great work!",True
@RaoufGnda,2016-08-22T22:03:44Z,2,Thank you for this awesome tutorial.,True
@navyatreddy2647,2016-05-22T05:51:26Z,0,an error while running code: at nltk.NaiveBayesClassifier(training_set):  __init__() takes exactly 3 arguments (2 given) how to resolve it?,True
@warsaw11000,2016-03-19T19:32:06Z,0,I love that the word cronenberg (for the great David Cronenberg) was a 6.9:1 positive.,True
@roegger,2016-03-02T21:14:52Z,1,"Everything works fine with the movie_review files - but if I want to use my hotel review files it doesn´t calculate any accuracy. (see: https://www.dropbox.com/s/gm0skzb6ykia27i/Screenshot%202016-03-01%2008.33.20.png?dl=0) - I copied everything in the movie_review folder to test, so I don´t need to change things in the code...  And I get some errors later on..... x...empty... - these are the files I use as my corpora (in nltk-data) and short_reviews (where my script is in) https://www.dropbox.com/sh/zpxf5lvtg9bbei8/AADUf3Ab02nDmOCtgKjDEFmWa?dl=0",True
@torrtuganooh2484,2016-02-09T14:33:12Z,0,You are such a help . Wonderful tutorials. I just have one problem. I am using a different training set and data set from here : http://ai.stanford.edu/~amaas/data/sentiment/ The data set is in the same format as the movie_review folder. But we are importing the movie review folder as its already there but how to do for my external data set. Please help me as I am really stuck.,True
@mohammedabujayyab6146,2016-01-02T20:56:38Z,0,"Thank you, Great explanation ! but you did not mention TF-IDF ? how the data were weighted ? any idea?",True
@finnli3835,2015-11-11T02:59:49Z,0,Thanks a lot! Just one question that how's the accuracy calculated?,True
@mainulquraishi6922,2015-11-08T17:32:39Z,0,"Hi, I am new to python. Actually I am learning python to work with NLTK. It may be a silly question but i can not understand,  the total featuresets is 2000(as the number of rev is 2000), why u wrote first 1900 for training set and last 1900 for testing set? Then in testing_set there are only 100 document. So you could write 100  for testing_set. Am i understanding anything  wrong? Thanks for your effort for making this very helpful tutorial series.",True
@aerinkim88,2015-10-06T05:01:08Z,3,"Hi, thanks for the video. When you ran the code 2nd time, did you change the training /testing set? Is it choosing testing set randomly every time that you run the code?",True
@0xsuperman,2015-09-23T02:57:21Z,0,"Also Sentdex, this person FXlive is using your exact video on its channel. Just so you know.",True
@0xsuperman,2015-09-23T02:41:23Z,0,"sklearn's NB classifier seems to not deal with text features well without pipeline, does nltk's NB classifier deals with textual feature (like words, and letters) well by default?",True
@anuragsrivastava1282,2015-08-11T18:23:55Z,0,"At the step: >>> classifier = nltk.NaiveBayesClassifier.train(training_set)  the error shown is: Traceback (most recent call last):   File ""<stdin>"", line 1, in <module>   File ""C:\Python27\lib\site-packages\nltk\classify\naivebayes.py"", line 196, in train AttributeError: 'list' object has no attribute 'items'  somehow the list ""featureset"" being generated in ""naivebayes.py"" does not have an attribute item()  any suggestions?",True
@JordanStarkey,2015-07-29T23:19:10Z,1,"I am reading data from a json(specifically the yelp api academic dataset). I split the data into either a positive or negative list based on the start rating from 1-5, 3.7 being the average of the dataset and my threshold. I get the error ""ValueError: too many values to unpack"" on classifier = nltk.NaiveBayesClassifier.train(all_words) and also featuresets = [(find_features(rev), category) for (rev,category) in documents].  I am also unsure of what my training set would consist of since I only have two lists (positive and negative based on star rating). Any insight would be greatly appreciated. Thank you and please keep up the great work, your tutorials are by far the best",True
@TeddyJohnson,2015-05-14T16:13:35Z,0,This video will be a nice lead into Cross Validation.,True
@aikimark1955,2015-05-14T16:05:00Z,5,Why did you get different results using the same data and code?,True
