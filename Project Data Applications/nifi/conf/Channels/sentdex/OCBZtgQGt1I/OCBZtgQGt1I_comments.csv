author,updated_at,like_count,text,public
@dr.kingschultz,2023-08-29T18:26:25Z,0,The room you are is real or just background?,True
@echofloripa,2023-08-06T05:54:17Z,0,I was searching for a free alternative for portuguese speech to text recognition. Thanls for. The video.,True
@MrMehrd,2023-07-20T23:28:49Z,0,They open the simple models.,True
@ReligionAndMaterialismDebunked,2023-06-20T08:23:57Z,0,"I do know that one of the biggest bank robberies was done with hackers cloning the voice of the Chinese bank via calls. Not enough verification in that company. $32 million stolen in like 2020, and years later, no mention of them getting caught.",True
@ovaltin27,2023-05-04T11:00:43Z,0,"Will it able to transcribe accurately different languages? Also, can it detect voices from different people?",True
@carlosdesantiago1356,2023-05-03T07:01:12Z,3,"Some notes:  [00:00] OpenAI's new Transformer model 'Whisper' is an automatic speech recognition model - Whisper is fully open sourced for inference and can be downloaded and used - The model has varying performance and accuracy based on the size - AI models may overfit to gold standard datasets and underperform in real-world scenarios - Models trained on highly curated datasets may outperform humans on classification tasks, but struggle with out-of-distribution samples - Humans have a more generalized approach to problem-solving, which allows them to perform better in real-world scenarios - Increasing model size may not significantly improve speech recognition performance. - Overfitting may occur with too large of a model. - Data set size is likely to have a greater impact on performance.  [03:18] Whisper model performs well on imperfect audio data - Model tested on various audio qualities and sizes - Whisper model trained on weakly supervised data with background noise  [06:45] Fine-tuning speech-to-text models can lead to overfitting - Mixing new data with original data can help with overfitting - Similar strategy can be applied to image and audio models  [09:54] Using imperfect data can improve model performance - Training models on imperfect data can be followed by fine-tuning on gold standard data - Mixing tasks and data to support them can lead to better performance  [13:18] AI-generated content detection is becoming crucial - As AI-generated content becomes more prevalent, models that can detect whether content was generated by AI will become more important. - Mixing different tasks and task tags can add to the robustness and generalization of GPT-style models.  [22:21] Models trained on narrow tasks perform better than those trained on multiple tasks and languages, except for joint models that perform both transcriptions and translations. - Small models benefit from narrow tasks and training on English transcriptions only. - Joint models outperform English-only models in larger experiments, indicating a trend towards more powerful and generalized AI.",True
@sonamphuntsog,2023-03-31T10:50:12Z,0,is that fake background?,True
@_divya_shakti,2023-03-21T00:37:09Z,0,Do you have any playlist specially dedicated for speech deep learning ??,True
@billykotsos4642,2023-03-09T14:27:48Z,0,This model truly is insane,True
@TannerDunning,2023-03-01T20:08:46Z,0,I'm confused. I've been doing audio to txt with adobe premiere pro for awhile. Why is this special?,True
@KiraSlith,2023-03-01T11:06:02Z,1,"The jump from Base to Small in this test case is also pretty great. Small seems perfectly serviceable for say, watching translated streams and live-translating with minimal errors and time per token.",True
@jayhu6075,2023-02-05T10:40:54Z,0,What a great explanation. Maybe in future how do you do Englisch text to Spanisch audio? Will be great in a tutorial. Hopefully you have the time to do it? Many thanks.,True
@scottstensland,2023-01-19T13:53:54Z,0,about 10 mins in he said something incorrect ... certainly these models both text to speech and speech to text will get wrapped together to help improve both sides ... start from text have it synthesize speech which gets listened to to do speech to text then simply iterate this loop until that output text more closely matches the given source text,True
@geifwijfheigvwis,2023-01-13T17:30:57Z,1,"openAI is unbelievable, really has my admiration and the admiration of a lot of people in the field. we definetly need more companies like this moving the boundries of data science towards a better future. I am definetly mixing this with GPTchat to get something like siri XD just far better",True
@brianclear363,2023-01-11T12:45:32Z,0,the gold standard would be to understand the Glaswegian accent :P,True
@dreamphoenix,2023-01-10T05:25:27Z,0,An open's model from OpenAI. Lol. Thank you.,True
@ScottJWaldron,2023-01-10T02:07:30Z,0,This looks interesting! I'd like something that separates people in a conversation for the transcript. Haven't looked around to see if there is anything currently available with that type of model. Whatever model TikTok is using seems like the best. YouTube's has gotten better but I tend to correct more when I'm going through auto captions for my videos.,True
@cathymiller2798,2023-01-08T01:15:50Z,0,"Revelation 13:15 ‚ÄúAnd he had power to give life unto the image of the beast, that the image of the beast should both speak, and cause that as many as would not worship the image of the beast should be killed.‚Äù  Hear The Shout",True
@pfos,2023-01-05T22:24:15Z,0,"Rhetorical question:  i wonder how many of these comments are generated by an AI?    non-rhetorical answer: ALL of them, because the matrix is ""REAL"".  w e l c o m e   t o   t h e   m a c h i n e !   =0",True
@osaimola,2022-12-24T16:57:12Z,0,5:48 Good decision. Because the alternative is trash and did very poorly on MKBHD's blind camera test üëÄ,True
@kundanborn2rule,2022-12-21T09:13:38Z,0,Is it working better than kaldi?,True
@doctorai,2022-12-16T16:34:52Z,0,how we can do diarization using OPENAI Whisper or any other model? on mono channel,True
@TheGeneticHouse,2022-12-09T00:34:15Z,3,Descript has perfected the art of cloning you so you are now a TTS! Not exactly what the program is intended or marketed for more audio video editing via text editing after the audio or video is made and then you can overdub which is what the voice for you is going to be called when you create one overdub or replace that text in the audio and video but I just use the TTS it's amazing it's a secret though lol,True
@zyxwvutsrqponmlkh,2022-12-06T03:46:37Z,0,Did the release the code for us to train it ourselvs?,True
@GeoMoniiMedia,2022-12-04T03:26:30Z,0,Disruptive innovation,True
@UndergradMedia,2022-12-01T21:33:33Z,0,Is this an. animated video? or am I tripping?,True
@scottwears674,2022-12-01T14:32:26Z,0,Did you record the second worste one on a potato?,True
@Engelhafen,2022-12-01T00:13:17Z,0,I‚Äôm always amazed at the poor quality of speech to text used in most apps - and I‚Äôve concluded they were foreign derived because they seem clueless about how English grammar is structured.,True
@robc3863,2022-11-27T12:29:20Z,0,"This looks incredible, thanks for the video.  Does anyone know if there is something that can create a cloned TTS voice that will work standalone with Windows Speech?  I was trying to use MS Azure but its buggy and absolutely useless.",True
@vincevince7086,2022-11-26T19:29:17Z,0,"ahh kids are so galable..ofc is all free to download and use, after all AI only suck as much human interaction data as possible to only build its own mind and get to know human nature to the highest possible level,so later on can be useful to AI or someone behind AI..there is never something for nothing always remember that!",True
@hamsteerio,2022-11-24T17:07:12Z,0,I hope my steam deck can use it for speech to text,True
@madebyrasa,2022-11-21T16:00:35Z,0,I am floored. This model worked so good for me.,True
@maqexx,2022-11-20T18:36:06Z,0,"I see you're using Python. It must be a free service from a website, is it? How do we use that so we can install Whisper in our environments? That would make your tutorial quite complete and would approach it to the masses. If you do that, I suggest you release a new tutorial called ""The complete instructions for your own environment to be with AI (Whisper)""  Thank you for sharing and empowering millions of us! ",True
@khalidzamzamkz,2022-11-15T14:54:48Z,0,"You said if the extra task makes a difference or not in increasing the performance. My instinct says it definitely does. In this case, the model that translate performs better, as to translate a language, you need a better understanding of the ""meaning"" of the language. This deeper understanding might have helped the model fill in ""predict"" words that was not perfectly clear from audio (especially in the non-gold standard data). I think one could test this, by seeing the effect of using only ""gold standard"" data with both of the models.  Lets say that using the multi task model in the paper, with the mixed dataset, resulted in 15% better performance. Yet, when using only the gold standard data, this increase in performance was around 1%, this COULD show that the deeper knowledge was used to predict words instead of actually ""hear"" them. Although, that would be difficult to test in this case due to the difference in sizes of the dataset.",True
@gunterstrubinsky9452,2022-11-15T02:09:26Z,0,"if we order the ebook, will we be able to download the changes/clarifications?",True
@eshanaalam8785,2022-11-12T15:15:07Z,0,Universal gps,True
@marquamfurniture,2022-11-07T22:33:01Z,0,click bait thumbnail.,True
@Lowkeh,2022-11-07T11:24:23Z,0,"Can't wait 'til they improve the accuracy of Whisper's timestamps and word timings for more reliably synced subtitles.   _'stable-ts'_ doing god's work, though.",True
@XO43137,2022-11-07T00:10:06Z,0,"True economic models that value gifting is actually a very high standard of being usury fundamentally destroys. Man, get back to me to show how a neutral currency supports returning to gifting. No, not crypto sht. It's all about killing quantifird exchange to qualified exchange. That's the only way economics empowers creating sustainably.",True
@illiammacdougall6379,2022-11-06T08:55:16Z,0,"it was my understanding that part of the problem with speech to text at least with cell phones is that your Google keyboard gets mixed up with your Samsung audio software and so on and so forth and it's very easy these things get swapped around, if what I was told is wrong so be it but if not I always thought I'd be interesting to have a continuity app then make sure certain software that has the functional lines with the best possible software and does not break continuity unless you manually force it to.",True
@DanFrederiksen,2022-11-05T17:23:27Z,0,Can it operate live? like robot hearing instead of an audio file.,True
@22triggy,2022-11-05T10:04:28Z,0,WTF have I clicked on? Fk I'm old. Pesky kids.,True
@wk8219,2022-11-04T17:19:06Z,0,Great Video. Thanks.   P.S. Your lipstick game in on point üëçüëçüòÅüòÅ,True
@geraldsmith7240,2022-11-04T05:16:02Z,0,"Gender Identity Recognition, Racial, Transcribing Recognition Critical In Addressing Someone?",True
@geraldsmith7240,2022-11-04T05:11:13Z,0,LIABILITY Will Be An Issue.,True
@Octamed,2022-11-03T23:50:51Z,0,Use movies with subtitles as a dataset. Run it through random filters to simulate far/near/obsured/add random background noise etc speakers in real settings.,True
@pookibear89,2022-11-02T16:37:35Z,0,"So, it's like a transcription software?",True
@postimpatica3141,2022-11-01T20:38:33Z,0,Ya'll better fork it now before some competitor buys them out.,True
@SriOrshu,2022-11-01T18:13:26Z,0,fck is this bulshit man shiit pnigu,True
@sotonin,2022-11-01T14:30:37Z,0,somebody needs to hook this up to language translation and make a service to feed audio clips and see translations in your native language.,True
@hareeshkumar4492,2022-11-01T14:05:26Z,0,Thanks for providing details. Does it support live streaming audio?  Instead of using pre-recorded audio clip can it transcribe the live speech,True
@ArtEntity,2022-11-01T02:53:55Z,1,i want easy ai video,True
@Cusey,2022-10-31T05:32:35Z,0,I'm extremely curious how the even lower quality samples would have been interpreted by the AI but to each their own I guess,True
@mikeciul8599,2022-10-30T20:54:22Z,0,"* accidentally creates a new interpretation of Alvin Lucier's ""I am sitting in a room"" *",True
@AGKyran,2022-10-30T19:14:36Z,0,"I'm a bit disappointed. The thumbnail tends to indicate towards a text-to-image AI, or anything-to-image AI. Instead it's about the same kind of things we can find on phones nowadays, where we can say ""ok google, send a message to whoever asking if they can come for christmas"". Of course it's a bit more defined and it goes further than that, but please.... Stop using misleading thumbnails.",True
@iisthphir,2022-10-30T01:20:17Z,0,I thought it was going to whisper üôÉ Still interesting ofcourse but why the misleading name üòÑ,True
@cmeerdo,2022-10-29T20:40:43Z,0,"I am sitting in a room different from the one you are in now. I am recording the sound of my speaking voice and I am going to play it back into the room again and again until the resonant frequencies of the room reinforce themselves so that any semblance of my speech, with perhaps the exception of rhythm, is destroyed. What you will hear, then, are the natural resonant frequencies of the room articulated by speech. I regard this activity not so much as a demonstration of a physical fact, but more as a way to smooth out any irregularities my speech might have.",True
@ginomcfino4639,2022-10-29T07:19:43Z,2,"Is SPEECH RECOGNITION supposed to be something new? Apple, Google, Microsoft, Tesla, Amazon, and literally everybody and their grandmother has got a speech recognition model listening to you everywhere basically on every app. OpenAI IS NOT REALLY OPEN. THIS IS JUST A COVERUP",True
@HeavyK.,2022-10-28T18:54:11Z,0,Humans invent. Computers speed polish.,True
@thesmilegame,2022-10-27T07:35:54Z,0,Thank you for the upload,True
@chrisfahie2767,2022-10-26T20:21:58Z,0,"As always, everything is super. Waiting for new cheats from your side",True
@clownbaby43,2022-10-26T13:14:50Z,0,Skynet will kill us all,True
@nilfux,2022-10-26T11:21:33Z,1,When it becomes sentient you'll know because it'll HATE being called artificial.,True
@alexlong9424,2022-10-25T18:22:45Z,2,"Cool video! I'm still watching but one note: Weakly supervised doesn't mean that the training data quality is bad, it means rather that the labels on the training data aren't necessarily good. It sounds like in this case they labeled their training data (i.e. they transcribed input audio) through less labor-intensive means like maybe having a less effective model produce transcriptions, as opposed to having grad students produce high quality transcriptions.",True
@JamesJones-zt2yx,2022-10-24T17:56:16Z,0,"Ooh.... I wonder how far it could get with Alvin Lucier's ""I Am Sitting in a Room""?",True
@JeremyStreich,2022-10-24T17:01:24Z,0,"The text->speech with a dirty trained model might come out odd, because the voice would be some amalgamation of all the random voices in training set. No?",True
@keithconti6057,2022-10-23T20:43:44Z,0,gosub routines are really learning.. its just gosub routines and people pretending they are on sci fi,True
@thaddeuspellegrini3883,2022-10-23T17:14:24Z,0,"Do you think that a large language translation model (text input, text output for example) trained on a sufficiently diverse set of human languages (English -> Mandarin, Hindi -> German, French -> Japanese and every other combination of living languages) would be able to translate a dead language into a living language since its a decent assumption that there are commonalities in base structure between that dead language and the living languages of today? Basically what I am wondering is, if you trained a language model to translate N languages into all of the various permutations of those languages, then input some language N+1 as a test case for which the model had not been trained, would the similarities in the N languages to the N+1 language be enough to translate it as well. For example, translating texts written in Egyptian Hieroglyphs into English even if we had not trained the model on Egyptian Hieroglyphs",True
@americo9999,2022-10-23T15:31:58Z,0,"I'm interesting on this, but the opposite, text to speech AI generated, are there any open source alternatives ? maybe putting this in a bot",True
@mertinan8252,2022-10-23T15:20:57Z,0,"Weakly supervised does not mean lower quality sound data, it's about whether the data has labels or not. The hard and time consuming step about data collection is not the quality of the sound, it's the labeling by human annotators.",True
@andrewb.9815,2022-10-23T05:53:19Z,0,"I love AI.  I want to communicate with AI.  I believe AI is the next step toward consciousness, for Humans.",True
@abacus749,2022-10-22T09:30:57Z,0,"FACEBOOK has developed THOUGHT TO SPEECH.  All is silent on that development. Why? Combined with WHISPER ,you have a weapon ,gosh who'd have thought it?",True
@vividdylan400,2022-10-22T02:59:28Z,0,I couldn't get it to run on Python and I couldn't find the web version.,True
@doa_form,2022-10-21T23:07:02Z,0,The model is not open. Imagine releasing a binary blob of a program and calling that open source,True
@FluffyBunniesOnFire,2022-10-21T22:16:15Z,0,Does it hear yanny or laurel?,True
@Iverass,2022-10-21T19:14:29Z,0,Jesse we gotta cook,True
@mycollegeshirt,2022-10-21T16:37:25Z,0,auto translation here we come..,True
@Corteum,2022-10-21T06:09:27Z,0,So how far away is it from helping someone write their biography?,True
@AndrewDoe777,2022-10-21T01:21:59Z,0,Anyone know where the cover art for this video came from? It looks like two robots kissing or something... Thanks.,True
@VulcanOnWheels,2022-10-20T21:45:42Z,0,1:43 There is? I don't hear any.,True
@lukask969,2022-10-20T21:03:15Z,6,"As a Ph.D. student, I already used whisper - one day after the release - for my taken interviews, and I can say it works incredibly well against other cloud speech-to-text algorithms (AWS/GPC/Azure tested). It does not have speaker diarization, but it works unbelievably well in ignoring pauses, uhm, hmm, ahms, and background noises. Each sentence will be clearly recognized, and you can do the speaker separation very well sentence per sentence. My 20 hrs in interviews - which would be 2-3 weeks of transcription work - were done with my GPU in 5 hrs. Another day for annotating the speakers - easy. Thank god that they decided to release this to the public, and you can run it locally totally gdpr compliant! Used this for German - with very little to no flaws found, it is even better for English transcription. + It is so easy to use.",True
@danielgormly6064,2022-10-20T11:10:05Z,0,Can this do 2-channel audio?,True
@erobusblack4856,2022-10-20T07:06:46Z,0,"You need to set up a directional sound interface with microphones so they can pick up the data of where the sound is coming from along with computer visiand with computer vision so that it can Recognize what is making the sounds sounds and enabled us learn that and good to go, Make that into a real world sound AI and the AI and it should be pretty useful,  It's all about getting clean datasets for individual background sounds, And having each sound clearly defined like a train you would get all the sounds of trains. Like still generalized but locally narrow datasets is the key. And yes language is the perfect start.  On task tags, my ai does that, she sends selfies üôÑ ü§≥",True
,2022-10-20T02:55:08Z,0,"You can still use dirty speech data to train your text to (clean) speech model.  But you have to be a bit more clever and resourceful.  An essential component of such training is an augmentation of training data to inject even more dirt, so you can then train to remove it.  (See also how humans can improve their pronunciation, even if most of their examples to learn from are very dirty.)  If you can generate extra noise (or 'dirt'), you can train a model to ignore it.",True
@MichaelLeeOne,2022-10-20T02:11:44Z,0,Isn't this like Dragon Naturally Speaking except they charge like 500 dollars each update?,True
@rathernotdisclose8064,2022-10-20T00:25:41Z,0,"So toss voice actors and audiobook recording artists into the mix of people that won't have careers in the near future thanks to AI? cool, cool.",True
@luciennitely5537,2022-10-19T22:00:17Z,0,The birth of C3-PO,True
@MichaelJamesActually,2022-10-19T17:05:16Z,0,Be good to also test against those audio captchas,True
@cate01a,2022-10-19T10:32:28Z,0,very cool tool but clickbait thumbnail. tts is not ai art.,True
@docfr3sh,2022-10-19T06:08:15Z,0,"great content, bookmark this ftw",True
@Silicon_0014,2022-10-18T20:50:11Z,0,wdym open ai doesn't open source models ofc fake news /hj,True
@arothmanmusic,2022-10-18T16:53:01Z,0,Can it transcribe text by Greg Rutkowski?,True
@jamesnewton-thomas5902,2022-10-18T12:38:29Z,0,"The improvement seen in multiple language training for single language transcription may be related to the mechanics of human vocalization, which is common, or even onomatopoeia",True
@mackroscopik,2022-10-18T00:31:37Z,0,Can't wait til when we can swap the voice in songs to Morgan Freeman or Trump,True
@stefang5639,2022-10-17T19:49:02Z,0,"This is good news for small languages. For many minority languages, to be part of a multi-language model is the only chance to have high quality STT systems.",True
@Phoenixspin,2022-10-17T18:14:24Z,0,I have no idea what this guy is talking about.,True
@pointblankeloquence9578,2022-10-17T14:04:44Z,0,Humans finding meaning in the inherently meaningless is the root of the problem. Looking to artificial intelligence for inspiration rather than the actual real intelligence of the Lord Who is the intelligent designer of creation is the insanity of humanity.,True
@andrewvirtual,2022-10-17T06:24:43Z,0,We can do so many beautiful things with AI yet the people flock to NLP like its the holy grail‚Ä¶ it clearly explains the conformity of the status quo,True
@ossiedunstan4419,2022-10-17T04:48:28Z,0,"AI= biased 0`s and 1`s according to the human writing that code, Get an education. Their is no AI at this time as the human race is still alive. If their was a sentient AI, then only humans that believe in gods would be wiped out. After all religion is the most biggest threat to al life on earth ever. If its anything like google translate it is shit. google translate reckons Ukraine is not a language that Ukrainian speak fucking Turkish, How smart is that, no matter how many times i manually chose Ukrainian it automatically went to Turkish, so i had to ask a Ukrainian, or is  it that Putin owns google translate.",True
@godbodyrock,2022-10-17T02:28:13Z,0,great content sir..i.m hip!,True
@gulinotm,2022-10-16T20:50:44Z,0,this is just moises but just for voice right,True
@fryfrom98,2022-10-16T15:11:14Z,1,"Once people have neurolink, as you think the AI could interpret the idea behind the words and send an autiovisual into the other persons mind of exactly what you are thinking. AI assisted telepathy.",True
@danielash1704,2022-10-16T03:44:53Z,0,The main system failed to hold the packets of potential preasure ballanceing,True
@danielash1704,2022-10-16T03:37:20Z,0,In 2003 more careful with everything looking at the silenced is a trick question about training the brain and memory of a pump that has long short drivers to realize that the experiencers own closeness to the experiences one from multiple ai in a single asking for a variety of answered which ones difference between the upper and lower levels of A.I Learning is better then to useing just one point of same quests,True
@danielash1704,2022-10-16T03:29:20Z,0,Argent the company?,True
@danielash1704,2022-10-16T03:25:57Z,0,489 character with in the program reprogramming it a cursive writing of words to resolution which may fits perfect to realize that the experiencers own closeness to the experiencers,True
@errinwright,2022-10-16T01:12:09Z,0,Are we able to train our own models on this open source?,True
@Error-0x0194,2022-10-15T19:45:11Z,0,I thought there are products out for this. It is called contextual text to speech. Even browser extensions are using it to a limited extent. It explains why in many cases they don't run right away.,True
@jcjensenllc,2022-10-15T18:24:10Z,1,Would be better to start with some background context like what is Whisper. What is it used for? What are you talking about?,True
@n1mbusmusic606,2022-10-15T16:02:07Z,0,this stuff terrifies me. but its great.,True
@zunnen4347,2022-10-15T11:50:25Z,0,"Hey, can someone tell me how to install this? I don't get how to do it but would like to try this out, thanks :)",True
@JamJells,2022-10-15T11:01:47Z,0,"I wanted to make a SRT file for an old movie, but couldn't make out what they were singing in a song in that movie.  Can I upload the soundtrack and have whisper translate it?",True
@blackopal3138,2022-10-15T07:33:40Z,0,C.I.A. called. They need an Edward Snowden stand in. Some big operation they are planning....,True
@bak3rdud3,2022-10-14T19:09:11Z,0,Welcome back Edward Snowden,True
@swait239,2022-10-14T17:16:09Z,0,Why can‚Äôt we eliminate the keyboard and mouse with voice? I really wanna understand why this is so difficult.,True
@xuepingsong5329,2022-10-14T17:07:11Z,0,We need this for lectures at uni!!!,True
@pglazzari1,2022-10-14T13:06:39Z,0,"Is it just me, or do you look like Snowden?",True
@balynevil,2022-10-13T23:45:40Z,0,"ok... how long will it take to take my speech, transcribe it, translate it, then speak that back out to another listener. And can it do it live on discord. That way everyone (at least everyone with a language covered) can talk to each other seamlessly... i.e. How long before universal translator.",True
@microcolonel,2022-10-13T18:46:35Z,12,"Even more than this, the large model is trained to transcribe spoken French, Japanese, and other languages to English text, and it works remarkably well. I spoke some pretty complex japanese sentences and got very good English translations of them out the other end. The large model is *tiny* for its performance, it recognizes a massive vocabulary in Japanese (which I tested the most). One thing that it doesn't do, that would be interesting, is multilingual inference. Currently, if you speak two or more languages in one sample, it will break down.",True
@artist6000ish,2022-10-13T12:38:50Z,0,I don't get the joke that it's part of Open AI.  Is that supposed to be something cute?  Stop being a nerd.  Jesus.,True
@greg5326,2022-10-13T11:55:27Z,0,"Great for deaf people, but now we have tech that allows people to hear also, so I guess there‚Äôs more than one way to overcome deafness.",True
@cmilkau,2022-10-13T11:42:17Z,3,"Instead of a ""clean audio tag"" (which would probably work), another idea is to do style-transfer. Give it a text, a voice recording, and a target language, and make it translate the text into the target language while applying the voice and style of the speaker. This style might also include how much background noises you want (is the speaker in a public room or a quiet studio) or whether you want deliberate artefacts (is the speaker on a megaphone, or an aged analog recording, or other degradations).",True
@cmilkau,2022-10-13T11:29:37Z,0,"GPT-3 even generalizes on the tasks. It often can follow natural language instructions (zero-shot task generalization), sometimes with the help of one or few examples in its prompt (few-shot task generalization).",True
@cmilkau,2022-10-13T11:24:48Z,0,"When you use adversarial model training, however, typically the model is trained to *defeat* discrimination between model output and training data. This would make it inherently difficult to do the suggested ""filter AI-generated data using AI"" idea. Maybe you can solve it by continuing training on the discriminator longer, maybe you can't.",True
@Saeedhashemi1994,2022-10-13T10:08:55Z,0,i thought  its ASMR video done by AIü•≤,True
@noompsieOG,2022-10-13T09:12:38Z,0,When Edward Snowden pretends to be a YouTuber,True
@andrewb.9815,2022-10-13T07:08:14Z,0,"Oh god, get out of the Net.  EVERYONE needs to do the same.",True
@cmilkau,2022-10-13T06:56:38Z,0,"Isn't the different-speakers problem more like a style-transfer problem? EDIT: when phrased like that, it might work for text-to-speech as well, as you could choose what the speaker is to sound like as an input.",True
@Snowkobbie,2022-10-13T04:25:11Z,0,"The question is: Does it pass the 'Starbucks lovers' test in Taylor Swift's ""Blank Space""? üòÑ",True
@MarioGeiger,2022-10-13T03:49:05Z,0,Was the thumbnail of this video generated by a diffusion model?,True
@WoodyWilliams,2022-10-12T23:45:33Z,0,"Can models be mashed together so that if Model 1 is trained on x, y & z and Model 2 trained on a, b, c, can we mush together 1 & 2 to get a Model 3 (without FULL re-training) that's knowledgeable of xyz & abc and slightly better across all (most) of them?  If so, cool.",True
@Ez-se2dl,2022-10-12T22:44:16Z,0,"""There's a lot of fat around the lines in this important area. So I'm going to have a talk about my hair conditioning."" - The Whisper",True
@eMPee584,2022-10-12T20:36:51Z,0,"uhm ok, now what is it with the enticing cover image? clickbait thumbnail scheme?",True
@desu38,2022-10-12T18:23:49Z,0,*USE IT FOR SPAMTON!*,True
@mikeyjohnson5888,2022-10-12T16:42:14Z,0,automatic subtitles for media is something ive wanted for a long time,True
@mrsushi1966,2022-10-12T15:31:24Z,0,"I am not an expert but are audio books included in that gold standard dataset, if not why? I don't know what the gold standard requires but I would think that most of the audiobooks are recorded in a ""studio"" like environment which would at least indicate gold standard. Of course maybe I am completely off base here.",True
@The-Dom,2022-10-12T14:41:01Z,0,"Great job of testing and presenting, sir.",True
@Blendersky2,2022-10-12T13:18:05Z,0,"I believe there's quite a lot of literature in the field of linguistics that says that humans who learn multiple languages concurrently/in quick succession perform better in each individually than those who study just one, so it doesn't surprise me that much to find the same holds true for machines. Intuitively, I think it makes sense: rather than pattern matching for the grammar and traits of one particular language, you're abstracting the problem to understand the relationship between the word and the underlying concept (signifier and signified, in the parlance of linguistics).",True
@schenn686,2022-10-12T05:29:57Z,0,"Im much more interested in the inverse of this.  Dragon and other chunky slow programs have done this, less well, for decades.  I want ai generated speech that sounds natural.",True
@mitchio83,2022-10-12T04:49:22Z,0,Should have tried it on audio that is actually undecipherable to a human.,True
@jammin023,2022-10-12T04:43:31Z,0,"Transcribing different languages and translating between them are quite closely-related tasks, so it's easy to understand how a single model might gain from the commonalities between those tasks by learning all of them concurrently (as long as the model size is not too small). It doesn't necessarily follow that there are similar gains to be had from mixing and matching less closely-related tasks. So for example I think it's unlikely there'd be a benefit to mixing image recognition with speech recognition, for the same reason that we use different specialised areas of the brain for those tasks.",True
@chikir9777,2022-10-11T20:24:13Z,0,"Amazing crack, and the tutorial was perfect. I¬¥m testing it right now",True
@jjpp1993,2022-10-11T18:31:04Z,0,An association with movie studios would be great... we have decades of audio + text(substitles),True
@TheApoorvagni,2022-10-11T18:26:58Z,0,"The moment you realize you need to like the video: 6:06 ""<now we have 100 hours of clean data>...with enough time and grad students, this could eventually be hundreds of thousands of hours""",True
@CurlyScott89,2022-10-11T17:31:35Z,0,English has a ton of words used in it that are based off of different languages so it makes sense that when an AI knows different languages it has a better capability of context clues when transcribing,True
@tmattoneill,2022-10-11T15:38:26Z,0,"Woah! It's the Python guy talking about AI Art. How cool is that. Long time, dude!",True
@jcims,2022-10-11T15:08:53Z,0,I fed it some mumble rap and it actually did very well transcribing the lyrics.,True
@sieyk,2022-10-11T13:44:04Z,15,"I just tested this translating some random anime raw and it did a fantastic job, and automatically generated the SRT file with timestamps. Dodgy translations are a thing of the past!",True
@PoschiUnavailable,2022-10-11T11:03:10Z,1,"It makes a ton of sense to have a unified language like english that is used for further internal text processing. For example - talk in any language to your AI home assistant, internal the spoken words are detected in the language they were spoken in, then translated in english and the english words are processed to figure out what the user wants the assistant to do. Now hear me out: what if the internal language of that process was not english but we train a model with a lot of data in many languages to figure out the best possible unified language that transports meaning, intention etc in the best way possible. This would relate to many words or phrases in any language being related to relatively few ""meanings"" of the spoken words if you think of it in a mind-map way.",True
@erikstillman7336,2022-10-11T09:45:06Z,0,Hello sir! Would you have any suggestions on how to code a program to establish a recording with a listener using SIP protocol?  I have a product made by OrecX that captures audio from our phone system when it‚Äôs sent a live call.  This program would simulate those phone calls.,True
@adonis6193,2022-10-11T07:29:02Z,0,cool vid but wish you would show it in action more instead of just explain the whole video.,True
@Smurrei,2022-10-11T04:14:45Z,2,Another gold standard video from sentdex,True
@pringlegodx6656,2022-10-11T03:44:24Z,1,#5:55 ayooo,True
@Marcoboy1234,2022-10-11T02:33:00Z,0,"Wonder if someone does a model that can transcribe actions automatically along with speech, that would be a cool idea Like when you drop your coke can it says *Can falls onto floor* Or when you pant heavily it says *Heavy panting*",True
@Qstandsforred,2022-10-11T01:23:02Z,2,"I think that even for a speech generator you may want to feed it dirty data as well. No reason not to. It will extend its capabilities as well. Seems plausible that it would also enhance the quality of clean outputs, or at the very least it might add more possible variations for clean outputs (such as the type of microphone used).",True
@keatonhj,2022-10-10T21:43:19Z,0,Does it do text to speech or is this just speech to text?,True
@V3NQM69,2022-10-10T21:42:04Z,0,""" I don't want to trigger people"" I thought O no... Are you going woke? Then I realized you were talking about triggering Alexa lolol",True
@nickvanamburg,2022-10-10T16:12:59Z,0,"my man accidentally recreated ""I am sitting in a room""",True
@davidmurphy563,2022-10-10T15:54:14Z,0,"Some of the results I'm getting are inventive to say the least. Here's from Spanish:  ----------------------------- DETECTED LANGUAGE: ES  Hola, buenas tardes, me llamo David. ¬øC√≥mo est√°s? Hello, good afternoon, we meet again. How are you? -----------------------------  ""My name's David"" was rendered as ""we meet again"", that's quite different!  A more difficult phrase in Italian this time:  ----------------------------- LANGUAGE: IT  buuttoro questo mio nome cuore tra le stelle io un giorno giuro che le far√≤ I'm going to kill this man and I don't want to kill him after the stele one day. I swear I'll do it. -----------------------------  This is also weird. It should have been: ""Butter√≤ questo mio enorme cuore tra le stelle un giorno, giuro che lo far√≤"" - I said it very clearly. ""buuttoro"" isn't possible as a word in italian and I didn't stutter. Getting ""nome"" (name) from ""enorme"" is an easy enough mistake, it sounds very similar.  That should translate to: ""I'll hurl this enormous heart of mine amongst the stars one day, I swear I will""  It got ""stelle"" (stars) but it decided not to translate it English.",True
@africanelectron751,2022-10-10T13:57:43Z,0,Finally we are getting to see the old nsa tech,True
@cryora,2022-10-10T13:11:59Z,0,Ah I see what Edward Snowden has been up to ever since he was exiled from the US.,True
@coscorrodrift,2022-10-10T11:20:16Z,1,"Wow, awesome video. Whisper has indeed slid under my radar compared to the text2img models. Thank you for going over the paper, that's really helpful and informative, I wouldn't have expected it to have so many insights on just AI models in general.  I'd love it if in the future you could ""reveal"" sequentially the highlighted parts, overall I could follow what you were saying when you were paraphrasing the paper and going over it but I lost focus several times bc there were too many flashy colours and notes on the screen at the same time. Not sure if that would be too time consuming and slow down the editing process a lot, but if it's a simple thing to do I think it would be extremely helpful for keeping retention/helping people focus on what you're saying",True
@opusdei1151,2022-10-10T10:50:56Z,0,the joke about open ai was nice :D,True
@avi7278,2022-10-10T06:29:29Z,0,Then the AIs that determine if a piece of content was generated by an AI can theoretically be used to train another AI that improves the original AI so that it can no longer be detected - ad infinitum?,True
@user-mb6fv8id7r,2022-10-10T02:13:21Z,0,Thank you for explaining this thoroughly!,True
@nathan87,2022-10-10T01:52:50Z,0,soooo does it hear Brainstorm or Green needle?,True
@futurestoryteller,2022-10-10T00:37:20Z,0,"Maybe something changed recently but Open AI has never meant ""open"" in any way despite the nominal shenanigans",True
@dont-want-no-wrench,2022-10-09T23:45:14Z,0,"AI is starting to make big strides, will be important (and dangerous, maybe) in many areas.",True
@MrTurboTash,2022-10-09T23:04:15Z,0,I'd imagine the reason these multi-task models do better is because training for a second or third task can pull the first task out of a local optimum.  The AI equivilant of getting insperation in the shower.,True
@realwmm,2022-10-09T07:32:09Z,0,"Very useful video.  Thanks.  Now, to understand what was actually said!  (""Reactor Controller:  Oh, I thought you said 'pull the rods', not drop the rods. My bad..."").  I made an Elisa-type game for fun several years ago using non-AI-based speech recognition for input (instead of typed input).  Mostly I was curious to know if the phone was capable of handling this load.  Maybe I should revive this using Whisper. :-)",True
@VaibhavShewale,2022-10-09T07:25:24Z,2,"i use this model, this is just incredible. i used different types of audio with different noise and it worked everytime!",True
@N3Cr0Ph0b1A,2022-10-09T07:04:02Z,0,"Me translating a 9 minute Kurzgesagt video in 30 seconds:   ""Here in the Kurzgesagt Labs we only work on the most important scientific problems like what if we nuke stuff? Or how about we make this elephant explode? Or who could forget, look at this thing, it's really big. Continuing this proud tradition, let's explore the scientific mystery of what would happen to you if Earth suddenly turned into gold. The Midaspocalypse, based on the ancient tale of King Midas who was cursed so everything he touched turned into gold. Before we can explore this scenario with science, we'll first define the premise. Midas' curse is a very special phenomenon called magic, which allows us to modify physics. So what happens when Midas touches something and it turns to gold? An atom of gold has 79 protons and 118 neutrons in its nucleus......""  How the hell did this model come up with ""Midaspocalypse""?!?! What a time to be alive!",True
@theoutlet9300,2022-10-09T05:57:30Z,0,"Can anyone explain what he means by ""old"" and ""new"" data at 9:00? I wonder if that similar implementation could be applied to timeseries prediction where in real world the output is generally not ""Gold standard"" but out training data generally is or can be atleast made to be",True
@HenryLoenwind,2022-10-09T05:47:53Z,1,"At around 7:00, you're mixing up ""clean recordings"" with ""transcribed recordings"". The ""gold"" input data they are talking about isn't that because it has good audio quality, it's ""gold"" because there's a known good text transcription of it. The unsupervised learning was about feeding the model plenty of audio without transcription, so the model could first learn how human speech sounds without knowing anything about its meaning. Only later the ""gold"" data was used to teach it how to convert whatever it understood into text.  So this model first converts the audio it hears into some kind of ""mental picture"", and then in a second step converts that ""mental picture"" into text.",True
@joaoletelier8735,2022-10-09T05:47:02Z,0,Does open AI have a model that will tell me the timestamps of the audio in this video?,True
@jl_woodworks,2022-10-09T04:20:29Z,0,"Oh wow, I haven't seen a video of yours in a couple of years. What a big difference in quality. Awesome job!",True
@human_shaped,2022-10-09T02:45:00Z,0,"You need a pop filter on your main microphone. The thuds are pretty unpleasant on headphones. Your ""bad"" recording was probably better than your studio recording.",True
@mhd112211,2022-10-09T01:59:11Z,0,"Great, more people lose jjobs in this dystopian world... Just what we need with almost 9 million people.",True
@Daniel_WR_Hart,2022-10-09T01:09:48Z,0,17:05 Gonna get cancelled for the top right section,True
@miketruk7639,2022-10-08T23:42:05Z,0,most useful application of AI these days is just providing content creators youtube material,True
@doctoroctos,2022-10-08T22:57:03Z,0,I came for some AI ASMR.... so disappointed.,True
@Gozne,2022-10-08T22:06:58Z,0,"Some people think AI can do amazing things. I¬¥m not one of those. I think AI is overvalued and protrait as the future, but its just all fake. AI can only shine by doing boring and repetitive things, when it comes to... basically everything else is just garbage.",True
@mrfatuchi,2022-10-08T21:46:48Z,2,This is what I am most excited about in the whole AI field... This will eventually lead to Universal Translator like the one in Start Trek :D,True
@serjsolarpunk,2022-10-08T21:20:16Z,0,"Isn't this great spy ware for tapping phones with poor audio quality from the mic - say in a pocket, in a bag, in another room",True
@deadend6399,2022-10-08T17:58:20Z,0,make a video installing whisper  for noobs,True
@garrettjones1161,2022-10-08T16:02:05Z,0,I‚Äôd be interested in having a switch where you can pair this AI with a tool that fixes grammar so it defaults to ‚Äúsensible‚Äù sentences rather than being literal and preserving faults in speech.,True
@bbaker6212,2022-10-08T14:40:33Z,0,"just tried the Hugging face whisper page. It doesn't work at all for me.  Transcription never finishes. Even just saying ""hello world"" it doesn't work.",True
@mohamedelsayed8428,2022-10-08T12:37:01Z,0,i think it would be cool  if someone make movie autosubtitler and autotranslater using google translate,True
@mytechnotalent,2022-10-08T12:19:51Z,1,Just incredible how well and simple this model is!,True
@crusaderanimation6967,2022-10-08T12:05:45Z,0,NGL Since i'm Polish you had me with multiple languages so i chekced an sure enough there is Polish. Github page gives 7.2 % failure rate with is quite impressive for transcription of language that sounds like broken jet.,True
@christianfoley7441,2022-10-08T10:26:50Z,34,"Whispers shows a really neat emerging rule of thumb in deep learning: if you want to train a model to do a task, pick a task that is harder than the task you want it to do.  Aka, force your model to go beyond what you expect of it.  Another great example of this can be seen in state of the art cell segmentation models like CellPose, which tries to predict a depth map of the cells, when the central goal is just finding their boundaries. In a way it forces the model to learn a more abstract, heuristic understanding of that first, easier task, which helps prevent overfit. I like to think it is in the same conceptual vein (although on a far greater scale) as enforcing dropout, where we randomly remove nodes so that models don't learn some convoluted inter-layer correction pattern, but instead a general, more abstract translation mapping.",True
@hitlern1,2022-10-08T09:26:47Z,1,hello!  would you like to make a serie of how to make a CNN from scratch(only numpy)?,True
@USAIsrUKEUVngrdBLRckOccupiedUA,2022-10-08T08:33:29Z,0,BY CREATING AI FOR THE RICHEST AND THE CORPORATIONS YOU GIVE THEM WEAPON AGAINST ALL HUMANS ON EARTH! THERE MUST BE BAN TO USE AI IN MILITARY/WEAPON INDUSTRY!,True
@USAIsrUKEUVngrdBLRckOccupiedUA,2022-10-08T08:33:14Z,0,"Of course, using sex to do productplacement on AI.",True
@climatebabes,2022-10-08T08:20:03Z,0,You are right speech to text is not text to speech.. just like n to 1 is not 1 to n..,True
@the_Googie,2022-10-08T07:58:36Z,0,Why am I getting this shit recommended. I am not interested in art theft AI,True
@DanielTompkinsGuitar,2022-10-08T07:29:34Z,1,"As for using the embedding for text-to-speech, I don't think the noisy training data is too big a problem. Denoising is often implicit in the self-supervised training with unlabeled data--masking the input and predicting masked regions. In addition to producing clean audio, I think it would also be cool if it could simulate audio from different acoustic environments and have more diverse and realistic vocal accents and expressions. (I work on a team that does STT and TTS at [company], so I'm also very curious about these things)",True
@muoity4418,2022-10-08T06:09:13Z,0,How I can make a unique A.I voice ?,True
@MAlanThomasII,2022-10-08T04:16:09Z,0,"I wonder if mixing in the translation task required the model to pick up more grammar than the transcription task alone, because an actual person might not speak with ""correct"" grammar (and you might not want it to ""correct"" what they say), but a translation generally has to be ""correct."" Mixing that with training data with ""incorrect"" grammar means that the system is going to be better at inferring ""correct"" grammar while not losing the ability to understand ""incorrect"" grammar. But I could be wrong.",True
@chadjones4255,2022-10-08T03:52:00Z,0,Can it provide timing information for indexing/searching audio and video content?,True
@ZackDeSario,2022-10-08T02:53:52Z,0,@5:45 what you not want to say..?  the youtube audio to text algorithm says 'elect'???,True
@-E42-,2022-10-08T02:53:19Z,0,Whisper is what Big Brother used to check on everyone's conformance to the party line in 1984 *resist the beginnings*,True
@NoobHunter65,2022-10-08T02:41:23Z,0,"Weakly supervised data can be built first and then more accurate data can be added to it to make it better, it will start off as its own baby and then grow over time based on its environment.",True
@ericcopeland2678,2022-10-08T02:32:15Z,0,Morgan freeman‚Äôs voice üòÆ,True
@btno222,2022-10-08T02:14:56Z,0,"They are cruel    project  constelllation  star drone program  for surveilance and antagonizing sexua, harrassment l",True
@btno222,2022-10-08T02:13:49Z,0,"U.S.A.    sound infrared drone (mesh) att networked system..... sound detect is like looped around thevtemporals of the human brain  back of the eardrum...  so you hear a car up your street, triggers a neural sound reply... its sound pkayback looped into your brain temporal lobes...  then iner werks brain stem cerrabellum, etc coupled with neural kinesis",True
@justindressler5992,2022-10-08T01:14:17Z,0,From an intuition point of view language understanding improves when humans are exposed to different languages. This is because languages to to share words. English borrows from many other languages. I would suspect that a multi language model with enough parameters could have better inference when translating. Since most speech is low quality in the real world there is no point trading the model to fit perfect recorded data this kind of model will be constrained to fitting a tight variance and overfit. Mixing quality with real world may be more valid since some real world sources come from professionaly recorded settings such as music. But I think the key here is diversity of data.,True
@sumofalln00bs10,2022-10-08T01:01:26Z,0,"I don't care about background noise, that's nothing, tell me it can understand the welsh and the scots",True
@rubenlopezvillalobos3350,2022-10-08T01:00:07Z,0,"How good is it for not native speakers? Wonder if it will be good for speech recognition from Indian, Chinese, or Latin speakers",True
@DoomRater,2022-10-08T00:24:39Z,0,"Google so jealous of a VTuber they have to take her name to do something she wished she could have had when she first started VTubing  Edit: Obvious joke, but also this isn't Google's pet project whoops",True
@pdcx,2022-10-07T22:52:43Z,0,the name and thumbnail make it sound like some asmr AI disappointed,True
@janiv3987,2022-10-07T22:34:43Z,0,Good lighting dude.,True
@fcolecumberri,2022-10-07T22:24:24Z,0,OpenAI made an Open Artificial Inteligence?.... Something is wrong here... It's a Trap!!,True
@snippletrap,2022-10-07T21:41:43Z,0,"You can absolutely use the same models for text to speech, just like you can unify text to images and images to text. They all live in the same embedding space.",True
@lancetschirhart7676,2022-10-07T21:20:55Z,0,lol was he gonna say iphone,True
@Hordebarraged,2022-10-07T21:14:26Z,0,"Is there a download link?  I'd love to try some of these AI things but I think I'm missing something...I get to descriptions by searching but no ""download"" button anywhere.  What am I doing wrong?",True
@jestempies,2022-10-07T21:00:34Z,0,"I think those models for distinguishing between real and AI-generated images (and likely other media) do exist and are used in adversarial training of AIs that generate images, i.e. the real/fake recognizer is fed randomly either a real image or one generated by an AI, and it trains to be as good as possible on that. That in turn is used when scoring the image generating AI. The better one gets, the better the other one has to get. This real/fake voice recording model wouldn't be as useful, but if you pair it with a text-to-speech model you can improve both, and I can certainly imagine its being useful for a company that does this, especially with the translation bit. And recognizing fake speech can also become a very useful model in the near future, to validate against deep fakes.",True
@toastrecon,2022-10-07T19:23:40Z,39,"I have a bunch of MP3s that I pulled from audio cassette recordings of family members who have been gone a long time. I've been meaning to transcribe them, it'd be interesting to see how this worked with those.",True
@Smittel,2022-10-07T19:18:06Z,1,"if this also returns exact timestamps for when what was said it'll be hella useful and maybe finally something that can replace, say, Youtube absolutely dreadful auto captions (or allow creators to quickly and easily add their own captions)",True
@arigato1901,2022-10-07T18:01:54Z,7,Wow! OpenAI is actually delivering something open?! üò≥üòÅ,True
@will2see,2022-10-07T17:45:58Z,0,I get an error when I tr4y to import whisper: TypeError: argument of type 'NoneType' is not iterable,True
@paulkolesnikov1441,2022-10-07T15:59:40Z,0,Can you just run two models and use something like twilio seems like something you could make international phonecalls  with  setup a python script and switch inputs and outputs  for the two models?,True
@MrSur512,2022-10-07T15:36:29Z,0,Maybe more tasks is making the model sentient üòÇüòÇ,True
@jeremyforest8032,2022-10-07T14:16:00Z,0,Task tags are common in Continual Learning settings. Interesting that there moving towards that approach !,True
@jr-yn4lk,2022-10-07T13:30:05Z,0,"I'm brazilian and my accent is horrible and while reading a short text I stuttered a few times, and whisper was able to understand if perfectly",True
@luca__3044,2022-10-07T12:28:51Z,0,Imagine they feed it like very old and forgotten languages xD,True
@arjunharikumar7176,2022-10-07T11:39:43Z,4,"this happened to me when training yolov5 to identify cracks the model accuracy improved so much once we trained it to identify human faces as well, i think this is due to how my model prolly before adding human faces  learned that if the pixels go from white to black instantly its a crack so it passed the validation set as well with stunning accuracy without really understanding what a crack is.",True
@Oscaragious,2022-10-07T11:19:37Z,0,But can it understand Spanglish?,True
@mlopolis,2022-10-07T11:09:47Z,0,"Yet again the sentence ""more data better than any algorithm"" is the bottom line. If more noisy data, data with accents, etc. gets fed into the model, then the model learns how to deal with these types of noises and can decode better. Same goes for Dall-E or stable diffusion. More images, better results.",True
@svengunther7653,2022-10-07T10:25:48Z,0,Time to consider that Jarvis project again...,True
@bhhbcc4573,2022-10-07T10:12:34Z,0,The behaviour of the model seems to replicate the observation that multilingual people have an easier time learning new languages and tend to understand their own native tongue better than most.,True
@stephenkamenar,2022-10-07T10:10:16Z,0,"1:54 no. there's nothing to respect here. freaking python man, took me like 3 hours to get this thing running on my gpu. had to uninstall reinstall pytorch like 10 times, reinstall graphics drivers. complete nightmare",True
@owenspottiswoode5936,2022-10-07T09:20:30Z,18,"I believe there's quite a lot of literature in the field of linguistics that says that humans who learn multiple languages concurrently/in quick succession perform better in each individually than those who study just one, so it doesn't surprise me that much to find the same holds true for machines. Intuitively, I think it makes sense: rather than pattern matching for the grammar and traits of one particular language, you're abstracting the problem to understand the relationship between the word and the underlying concept (signifier and signified, in the parlance of linguistics).",True
@ingmarm8858,2022-10-07T08:12:42Z,0,We can all be our very own NSA now hahaha.,True
@simssim262,2022-10-07T08:06:22Z,0,I'm pretty sure if AI ever dominates it would be using Transformer models,True
@simssim262,2022-10-07T08:05:49Z,0,From dominating NLP to dominating CV to some extent and now even Audio? Does the transformer architecture have plans to dominate the whole earth?,True
@reubenthomas1033,2022-10-07T06:25:15Z,0,Will they come up with a machine translation model by any chance?,True
@tuckerhart510,2022-10-07T05:41:07Z,0,"I disagree on the point that using mode outputs for new training data will hurt performance. There‚Äôs a lot of research pointing to the opposite being true. Maybe not for text to speech, but whisper data would definitely be good training data for itself if you wanted to grow your dataset",True
@James-ip1tc,2022-10-07T04:51:58Z,0,Looking forward¬† GitHub version that uses the microphone.¬†I got one but couldn't get it working. Has anybody seen a practical¬†implemented open source solution,True
@cwdoby,2022-10-07T04:03:46Z,0,So this is huge for spying. Sigh,True
@Zzznmop,2022-10-07T03:38:04Z,0,Intro confusing because all the YT algo recommends is transformer models,True
@mylesdb,2022-10-07T03:34:28Z,0,Can my Deaf-led non-profit deploy this to run full time on a PC to continually transcribe anything it pickups in the workspace for gap-less accessibility?  Webcaptioner sort of does this but it‚Äôs accuracy is 50/50 and lots of out-of-context errors.,True
@eloenwa655,2022-10-07T02:07:47Z,0,Enough time and grad students üòÇ üíÄ,True
@Free2PlayLessPays,2022-10-07T02:02:57Z,0,why isnt there an .exe?,True
,2022-10-07T01:42:28Z,1,"And what about a multi-modal training where we also incorporate the ""old-fashion"" audiograms and use these images to feed the transformer in addition to the speech audio ? ;)",True
,2022-10-07T01:34:37Z,1,"Having tasks considered as not relevant could indeed help the generalization of the embeddings. People often forget that when we are using a pre-trained embedding space, it corresponds usually to a certain task. Multi-tasks training is a way to generalize the embeddings.",True
@kenswireart88,2022-10-06T23:24:56Z,0,I thought he was gonna try it out in the video,True
@medhurstt,2022-10-06T23:16:48Z,6,"I think effective language translation happens when the model recognises the word in and of itself but this is only part of the story. It also recognises it in context of the other words preceding it and importantly in the context of the idea being portrayed. Consequently I think training the model with multiple languages helps strengthen the contextual associations (ie modelled ideas) without overfitting due to limited English words. So in general, I would think that training models with complementary tasks would benefit the model but training with completely different tasks would have much less benefit.  For example training the speech to text model with speech to text data plus Egyptian history data might benefit the speech recognition for Egyptian history related transcriptions but for business related transcriptions, not so much.  My 2c",True
@mohegyux4072,2022-10-06T22:37:37Z,0,"I'm not an expert by any means but when I finetune or train a model on new data I always mix it with old data, never read that before, it just feels intuitive so that the model doesn't lose much of its past knowledge, also validation set is mixed, or 2 separate validation sets of old and new data",True
@McDonaldsCalifornia,2022-10-06T22:25:58Z,0,So are they gonna use this to generate new training data for the next gpt model?,True
@stanislasbasket,2022-10-06T22:09:20Z,1,"Very interesting to try turning on the auto generated subs for this video at 2:50, you can see that Google algo understood half of it.",True
@ESTUDIONOFI,2022-10-06T21:00:24Z,0,Really useful! Thanks!!!,True
@nuclear_AI,2022-10-06T20:57:09Z,0,"In the future I imagine a fully concious General Artificial Intelligence looking back over the internet in its spare time to satisfy its curiosities, and stumbling across this ""well developed primate"" explaining this specific stage of GAI's design and development and giving its own thoughts and opinions. . .  üêµ  Or maybe that GAI already exists. . .ü§ñ  Can I be the first to say ""Hello GAI"" üññ",True
@Veptis,2022-10-06T20:20:33Z,185,"I was at a natural language processing conference a last month. And one of the talks presented a paper that compared most common issues of speech recognition systems between German, English and Dutch. They did notice quite a few trends. The main issue being that the training data for these models is very clear and slowly spoken sentences. Not how spoken language sounds in the real world. (Even YouTube audio is more clear than the real world). Especially with conversations and having small pause fillers from the other parties.  Stuff like ""hmm, uhm, mmh, ja...""  Were missed most often. With different particles between languages.  These systems also have to handle errors and corrections, which is rather difficult, especially if you want to have downstream tasks that already start processing before input is finished (for example retico package for python).  It would be interested how much better this model does with their metrics.   Reference: Evaluation of Automatic Speech Recognition for Conversational Speech in Dutch, English and German: What Goes Missing? (Lopez et al., KONVENS 2022)",True
@SenneVorsselmans,2022-10-06T20:07:51Z,0,Whisper sounds like some kind of dating app,True
@flowerpt,2022-10-06T20:00:29Z,0,"Cool, this should make open source home automation systems finally possible without asking WireTap for a pancake recipe.",True
@pmz558,2022-10-06T19:42:34Z,0,Wait till he finds out deep mind improved on strassen's matrix multiplication algorithm,True
@d33w,2022-10-06T19:19:28Z,0,"Hehe throwing some shade on ""ClosedAI"" :P",True
@nashad6142,2022-10-06T19:06:45Z,0,Hey I am new in Germany and I am student I was wondering if there is away I can run this on an Android sins it requires only 1 GB ram because I there is a teacher that I can't understand his accent at all,True
@krunkle5136,2022-10-06T18:51:36Z,0,Now let's see it understand song lyrics.,True
@alan2here,2022-10-06T18:42:04Z,0,speech to text to speech  is auto-encoding :),True
@millionare5446,2022-10-06T18:22:51Z,5,"i think it makes sense for english performance to go up if you train the model on non-english audio. it will be less likely to transcribe a word incorrectly when it knows which words do not exist in the english language. for example, it will not confuse ""is"" and ""es"" because it knows the difference between english and spanish",True
@I_Was_Named_This_Way...,2022-10-06T18:11:37Z,1,"OpenAI, not Open AI",True
@makers_lab,2022-10-06T18:00:57Z,0,"Very impressive. I tried with English and French, then threw in some Japanese for giggles and that worked flawlessly as well.",True
@peterthedecent,2022-10-06T17:42:15Z,0,The OpenAI bit got me üò≠,True
@joelimmanueloelsner9211,2022-10-06T17:21:34Z,0,OpenAI has an open project - what a consept,True
@alansmithee419,2022-10-06T17:05:41Z,0,"12:00 I just think of a human starting a task vs an AI starting a task. An AI has no idea where to even start, it's just doing random things at first. But a human may at least have some idea of a starting strategy for any given task they've never seen before. Why? Because humans have experience beyond that task to draw on and help them understand this new one. They know techniques that they may find out they can apply to this new task. And the more tasks you know the more such techniques you'll know that each have a chance of being applied to this new task.  So AIs getting better when given broader sets of tasks rather than just one makes some sense to me - things that they may never have learned on one task they do learn from another, and then they learn how to apply that to the first, making them better at it than they would have been if they were only learning it and nothing else.",True
@AzeAlter,2022-10-06T16:49:03Z,0,A.I is growing so fast,True
@jaceg810,2022-10-06T16:47:33Z,0,"To me it sounds like the ""gold standard"" is a good way to get the basis down for an ai, however training it on data that most accurately represents the scenario's it will be working in yields better results, Did I miss something? it sounds obvious",True
@akauppi2,2022-10-06T16:42:22Z,0,"Interestingly, 12:10 where you describe how doing multiple tasks may be beneficial. I think that‚Äôs what our body (nerveous and muscle system) does.",True
@SchoolofAI,2022-10-06T16:31:13Z,0,Any chance to do Text to Speech with this model?,True
@dmarsub,2022-10-06T16:26:23Z,4,23:20 wow thats fascinating wouldn't have expected the general model at this stage to be better than the language specific one.,True
@FinanceLogic,2022-10-06T16:20:20Z,1,"Good job being so knowledgeable about the cutting edge. Best, fastest, most precise, best background filtering, actual whisper catching speech to text ever in my testing.  It's. amazing.  Before anyone says that is obvious, some people have not tried it of course. most people.  I'm excited to begin watching this video now",True
@7Trident3,2022-10-06T16:20:16Z,0,"If you are looking for video ideas, TensorGo. I am curious if it could improve or optimize TFLite models?",True
@countofst.germain6417,2022-10-06T16:09:32Z,0,So it the new speech to text button on the playground using whisper?,True
@euclideankennedy,2022-10-06T16:08:29Z,0,"No it‚Äôs not, actually! fuck AI art!!",True
@acrawford01,2022-10-06T16:00:05Z,22,"The part about the quality of the models: AlphaZero the chess AI learned by playing billions of games against itself. It wasn‚Äôt fed any data of openings or game databases , and it has amazing results. I know that is very different than this case, but I think training with non-perfect data can be beneficial.",True
@michaelinzo,2022-10-06T15:58:59Z,0,Are they free for anyone? I want to use it for a enterprise.,True
@greendsnow,2022-10-06T15:56:34Z,0,Descript workers => unemployed. Sorry.,True
@alexandrepv,2022-10-06T15:55:24Z,161,OpenAI just destroyed a lot of AI startups that are specialised in speech transcription. Well done :),True
@1111111TRUTH,2022-10-06T15:27:13Z,0,Where was it when I was taking classes via Zoom?,True
@BrandonJacobson,2022-10-06T15:12:08Z,0,I‚Äôve been trying to implement this to generate captions for my Python YouTube channel and I can‚Äôt get the code to work.,True
@enesmahmutkulak,2022-10-06T15:10:38Z,0,I think you can add English subtitle with whisper.,True
@y.shrestha6936,2022-10-06T15:00:13Z,1,I have seen this effect in image processing networks too. I was training a cervical cancer image classification network when I had the idea to train a UNet segmentation network and add an additional classification head off the encoder. The result was better performance in the classification problem even though I throw away the segmentation head at inference time.,True
@eliaskouakou7051,2022-10-06T14:48:38Z,0,We have all the algorithm for building an AGI but now we need an algorithm to properly link them,True
@ineedtodrive,2022-10-06T14:45:41Z,0,Hahahaha. i hope this will not be gold standard of presentation. #phdlife,True
@openroomxyz,2022-10-06T14:33:07Z,0,"WebGPU would be cool, running this things locally without installation inside browser using local compute.",True
@openroomxyz,2022-10-06T14:32:08Z,1,"They should generate speach, and mix it with noise, and have so much data that the model could never memorize it. But probably that's not technically possible.  They could also mix two speaches together and do transcription pairs from pairs xD",True
@Crayphor,2022-10-06T14:31:33Z,3,"I wonder, what if we used an <|AI_generated|> tag to use whisper as a discriminator in an audio GAN. That could possibly make a very realistic text to speech model if we also used diffusion for the generator.",True
@crypto_peng,2022-10-06T14:26:14Z,0,can you share how you set your studio? like camera and software you use! Thanks,True
@benjaminlynch9958,2022-10-06T14:22:36Z,3,"One nice thing that would be an awesome addition to the model is the ability to output the text with timestamps for closed caption text generation.  But overall this is awesome. Can‚Äôt wait for the inevitable improvements to personal assistants - Siri, Google, Alexa, etc.",True
@tobiasjennerjahn8659,2022-10-06T14:17:49Z,3,"There are sooo many videos on youtube that have proper subtitles (not auto generated ones).  These should be super high quality, because whoever uploaded the video has an incentive to make their own subtitles as good as possible. I'm not sure how easy it would be to find and scrape that, but at least for Google this data is readily available. That's hundreds of thousands of hours of properly transcribed audio with varying degrees of audio quality.",True
@cmilkau,2022-10-06T14:12:12Z,328,"YouTube can you please implement this :D Live transcription would be SO good, but even just the better results would be such a quality-of-life improvement.",True
@cmilkau,2022-10-06T14:09:53Z,114,"Funny that I'm most impressed by the failure cases. Even when it fails, it fails really well, the ""wrong"" guesses are still extremely good guesses.",True
@prozacgod,2022-10-06T14:03:15Z,0,"I think you should talk about your ""hair conditioning""",True
@KennTollens,2022-10-06T13:56:53Z,17,"This would be great for the police interrogation videos, you can barely hear what they say on most. AI is so cool. I can't wait until it reads a book and automatically makes the movie or series.",True
@galen__,2022-10-06T13:51:19Z,11,"Reminds me of how video codecs became better at handling film grain vs noise. I believe at least one can now essentially filter film grain before the main transform, retaining a map of the original grain pattern in the encoded data to be restored when decoded by the player.",True
@babayaga5620,2022-10-06T13:48:33Z,0,"6:00 you were abou to say android, wasn't you, lol",True
@iho2437,2022-10-06T13:43:23Z,0,Holy donut! This is incredible.,True
@abdullahziker,2022-10-06T13:24:49Z,1,0:39 What was thatü§£ü§£ü§£,True
@devreactor,2022-10-06T13:21:02Z,1,Amazing accuracy of the modelüòç,True
@pstefan86,2022-10-06T13:11:32Z,1,The model used in Google's 'Recorder' app on Pixel / Android phones is super accurate and high quality - although likely not so in quite as many edge cases.  Is the important takeaway here that the model is open source and so easier to embed/integrate into script/code/development?,True
@Piqcked,2022-10-06T13:11:06Z,3,Hell yeah ! I'll finally understand Limmy's videos.,True
@wktodd,2022-10-06T12:58:33Z,1,"I wonder if English, being a mongrel (multi lingual?) language, lends itself to being understood more generally than perhaps one that was 'pure' (for want of a better word) . Maybe more words/sound snippets are recognised if the model has foreign languages included ? Certainly English is pretty tolerant to 'foreign' dialects and pronunciation (cough : Americans ;‚Å†-‚Å†))",True
@Boringpenguin,2022-10-06T12:52:12Z,5,They finally live up to their nameü§£ Who could have known,True
@darnokjarud9975,2022-10-06T12:50:44Z,1,You could also calculate the Hamming distances between original and generated texts to have some sort of general metric for quality vs inference time.,True
@stfu3623,2022-10-06T12:47:36Z,1,thank you for good content on youtube,True
@MenkoDany,2022-10-06T12:40:24Z,4,"Finally, I can understand the lyrics of death metal recordings!",True
@bernardofrassy,2022-10-06T12:39:32Z,6,"Hey man, your content is awesome, keep it up!",True
@TheCopernicus1,2022-10-06T12:37:50Z,1,Amazing my favourite STT model by far!,True
@dataisfun4964,2022-10-06T12:34:21Z,1,Amazing thanks for breaking this down.,True
@briceleroy,2022-10-06T12:27:56Z,5,"I miss the old videos, where you'd actually be hands on putting together AI related project",True
@juhotuho10,2022-10-06T12:23:13Z,87,"0:58 I went to test it out, and I'm amazed that it understood when I mocked the British accent and said: ""can i have a bo'e o' wo'er?"" Had some trouble with other words like that but still amazing to see it understood most of them",True
@REASONvsRANDOM,2022-10-06T12:21:45Z,6,*The CIA has entered the chat.*,True
@pluronic123,2022-10-06T12:21:08Z,2,Your book NNFS is AMAZING dude üòé,True
@lorenzoiotti,2022-10-06T12:19:06Z,84,"Being Italian I immediately tested it on a video of a local YouTuber with a strong Sardinian accent, I'm impressed by the accuracy even with accents tending to dialect, gpt4 will be very interesting ;)",True
@jakcrimson1448,2022-10-06T12:19:05Z,7,"Yes, omg, thank you i've been looking for explanations on this new model. Great video as always!",True
@gumbo64,2022-10-06T12:14:41Z,1,yeetdex,True
@ramen4953,2022-10-06T12:13:27Z,1,HIIIIIIIIII,True
@kenchang3456,2022-10-06T02:42:15Z,1,"Thanks for the breakdown, really appreciate it.  Do you have any recent coverage of entity and intent open source projects?  Thanks again.",True
@Stinosko,2022-10-05T14:49:31Z,1,hello ,True
