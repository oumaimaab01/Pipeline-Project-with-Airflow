author,updated_at,like_count,text,public
@sentdex,2017-02-10T14:05:42Z,1,Associated Kernel for these tutorials: https://www.kaggle.com/sentdex/data-science-bowl-2017/first-pass-through-data-w-3d-convnet,True
@will_s_citylights,2021-11-04T00:14:07Z,0,the HM_SLICES isn't a defined variable in your code. Unless I'm missing something?,True
@adigoedutech279,2021-03-07T03:52:15Z,0,"Sir I am not able to install cv2, I am working on Jupiter notebook",True
@CagnPolat,2021-01-08T07:25:32Z,2,Scipy has a function for resizing n dimensional arrays. The function also uses interpolation for the up/down-sampling processes. https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.zoom.html#scipy.ndimage.zoom,True
@lesliewubbel9157,2020-03-11T07:29:49Z,0,"Could someone fix this code, honestly use a resampling function from the preprocessing",True
@abcdxx1059,2018-10-30T18:36:51Z,0,Looks like nothing to me,True
@nikithajv6460,2018-05-07T03:01:13Z,0,"Hi, thanks for the great tutorial. Could you let us know about the detailed architecture of CNN and op size after each layer?",True
@karansawlani5959,2018-01-12T22:32:04Z,0,"for num,each_slice in enumerate(new_slices):         y = fig.add_subplot(4,5,num+1)         y.imshow(each_slice, cmap='gray')     plt.show()  Sir , this part of code throws a (TypeError: Image data cannot be converted to float) what else can be done??",True
@benjaminborie3525,2018-01-03T10:18:22Z,0,"I am not an expert in python but imagine you could do something like that: nb_of_desired_slices = 32  chunk_size = int(len(slices)/nb_of_desired_slices)  r = len(slices)%nb_of_desired_slices  print('The length of the list:', len(slices))  print('The chunk size is:', chunk_size)  print('Remainder:', len(slices)%nb_of_desired_slices)   for slice_chunk in chunks(slices[:-(r*chunk_size+r)], chunk_size):   print(len(slice_chunk))   slice_chunk = list(map(mean, zip(*slice_chunk)))   new_slices.append(slice_chunk)  for slice_chunk in chunks(slices[-(r*chunk_size+r):], chunk_size+1):   print(len(slice_chunk))   slice_chunk = list(map(mean, zip(*slice_chunk)))   new_slices.append(slice_chunk)  print(len(new_slices))",True
@LucasRamosNL,2017-08-17T08:56:19Z,3,"Very interesting solution, I'm really enjoying your videos. For resizing medical images I recommend the 3DConvert tool from ITK snap.  With this you can get all your scans in the same 3D dimension using different interpolation functions.",True
@thomas01pd2016,2017-07-10T08:06:01Z,4,Props to the remaining 5000 viewers who persevered up till now!,True
@herp_derpingson,2017-07-08T11:04:22Z,4,"1. You have a big non cubic volume of images, make sure it is np.array 2. `cv2.resize` would resize the x and y axes. 3. use `np.transpose(x,[1,2,0])` to rotate 4. Again resize the x,y axes 5. Rotate back if you want",True
@11skorek,2017-07-05T17:54:07Z,1,"You could use chunks method like this: def chunks(l, nr_of_chunks=HM_SLICES):     i = 0     chunk_size = len(l) / nr_of_chunks     while chunk_size * i < len(l):         yield l[math.floor(chunk_size * i):math.floor(chunk_size * (i + 1))]         i += 1 It guarantees that ""l"" will be divided into ""nr_of_chunks"" chunks",True
@anmolnaugaria6965,2017-06-07T10:41:57Z,1,"what does 'slice_chunk = list(map(mean, zip(*slice_chunk)))' do? Can someone please help me out.",True
@user-cc9yv2cc7t,2017-02-20T03:23:21Z,0,"Hi,why len(new_slices) == HM_SLICES+2,len(new_slices) == HM_SLICES+1 have the same code? len(new_slices) == HM_SLICES+2 has two more elements,right?but you just delete one? It runs right because you use ceil so it only could be 18,19,20, the two cases 21,22 doesn't really happen ,but it is a bugï¼Ÿ",True
@superfreestyleer,2017-02-17T23:55:27Z,0,"Also, it looks like you might have a typo in your description. I believe it should not be lulng",True
@superfreestyleer,2017-02-17T23:54:58Z,0,"Maybe I am not fully comprehending your solution, but wouldnt it be better to make all of the pictures the same size by filling the smaller ones with blank pixels to make the smaller the same size as the larger? I think the neural net should be able to distinguish that those pixels are useless data. This would make it so you dont need to lose any resolution or do any averaging. This would make each individual picture the same size as the largest one and will take more data, but based on what I saw of the data it looks like only + or - like 30 pixels on any dimension",True
@antopolskiy,2017-02-10T17:43:52Z,1,Shortcut for block comment/uncomment in Jupyter notebooks: Control + ' / ',True
@hugohugod21,2017-02-10T14:58:46Z,0,"Also, do you know where the dicom colour data is coming from? Does that relate to tissue density in the scan? Thanks and great videos!",True
@hugohugod21,2017-02-10T14:52:04Z,0,Why not use np.reshape to transform your data into list of lists then apply your mean function?,True
@tawsifjawad6625,2017-02-10T14:29:56Z,0,Thank you  very much for your  kindness.,True
