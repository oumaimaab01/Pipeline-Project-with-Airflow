author,updated_at,like_count,text,public
@orcunalp4541,2020-08-20T14:38:14Z,0,Still watching :)),True
@aaronge5195,2020-03-27T18:27:03Z,1,"In case you are looking for the working code because the unemployment data and yahoo sp500 data are unavailable, here it is. I used alternative data sources.     import pandas as pd import quandl import matplotlib.pyplot as plt from matplotlib import style  style.use('fivethirtyeight')  api_key = 'Your key'  # Code to get Housing Price Index of all fifty states def getInitialData():     fifty_states = pd.read_html('https://en.wikipedia.org/wiki/List_of_states_and_territories_of_the_United_States')     fifty_states = fifty_states[0]      fifty_states = fifty_states['Name &postal abbreviation[12]', 'Name &postal abbreviation[12].1']     fifty_states = fifty_states[0:50]     URLs = []     for abbrv in fifty_states:         URLs.append('FMAC/HPI_' + abbrv)      fifty_states_housing_data = []     i = 0     for url in URLs:         df = quandl.get(url, authtoken=api_key)          df.drop(columns='NSA Value', inplace=True)         df.rename(columns={""SA Value"": fifty_states[i]}, inplace=True)          df[fifty_states[i]] = ((df[fifty_states[i]] - df[fifty_states[i]][0]) / df[fifty_states[i]][0]) * 100          fifty_states_housing_data.append((df))         i += 1     joined = pd.concat(fifty_states_housing_data, axis=1)     joined.to_csv('Fifty_States_HousingPriceIndex.csv')   def HPI_Benchmark():     benchmark = quandl.get(""FMAC/HPI_USA"", authtoken=api_key)     benchmark['SA Value'] = ((benchmark['SA Value'] - benchmark['SA Value'][0]) / benchmark['SA Value'][0]) * 100     benchmark.drop(columns='NSA Value', inplace=True)     benchmark.rename(columns={""SA Value"": ""US_HPI""}, inplace=True)     benchmark.to_csv('UnitedStatesHousingPriceIndex.csv')     return benchmark  def mortgage_30y():     df = quandl.get(""FMAC/MORTG"", trim_start = ""1975-01-01"", authtoken=api_key)     df[""Value""] = (df[""Value""] - df[""Value""][0]) / df[""Value""][0] * 100     df = df.resample('M').mean()     df.columns = ['M30']     return df  def sp500_data():     df = pd.read_csv('^GSPC.csv')     df.set_index('Date', inplace=True)     df.index = pd.to_datetime(df.index)     df[""Adj Close""] = (df[""Adj Close""]-df[""Adj Close""][0]) / df[""Adj Close""][0] * 100.0     df=df.resample('M').mean()     df.rename(columns={'Adj Close':'sp500'}, inplace=True)     df = df['sp500']     return df  def gdp_data():     df = quandl.get(""BCB/4385"", trim_start=""1975-01-01"", authtoken=api_key)     df[""Value""] = (df[""Value""]-df[""Value""][0]) / df[""Value""][0] * 100.0     df=df.resample('M').mean()     df.rename(columns={'Value':'GDP'}, inplace=True)     df = df['GDP']     return df  def us_unemployment():     df = quandl.get(""FRED/UNRATE"", trim_start=""1975-01-01"", authtoken=api_key)     df[""Value""] = (df[""Value""]-df[""Value""][0]) / df[""Value""][0] * 100.0     df.rename(columns={'Value':'Unemployment Rate'}, inplace=True)     df=df.resample('1D').mean()     df=df.resample('M').mean()     return df  HPI_data = pd.read_csv('Path to your fifty states data') HPI_data.set_index('Date', inplace=True) HPI_data.index = pd.to_datetime(HPI_data.index) m30 = mortgage_30y() sp500 = sp500_data() gdp = gdp_data() HPI_Bench = HPI_Benchmark() unemployment = us_unemployment() m30.columns=['M30'] HPI = HPI_Bench.join([m30,sp500, gdp, unemployment]) HPI.dropna(inplace=True) print(HPI.corr())",True
@MrIrishMoore1,2019-11-24T22:04:56Z,2,"For anyone trying to follow this, YAHOO/INDEX_GSPC is no longer available. I ended up using pandas_datareader module to get the data from yahoo. Yahoo also includes adjusted close.  Here's the code I used:   # use pip install pandas-datareader if you don't have it already from pandas_datareader import data as wb  def sp500_data():     ticker = ""^GSPC""     df = wb.DataReader(ticker, start='1975-01-01', data_source='yahoo')     df[""Adj Close""] = (df[""Adj Close""] - df[""Adj Close""][0]) / df[""Adj Close""][0] * 100.0     df.resample('M')     df.rename(columns={'Adj Close':'sp500'}, inplace=True)     return df['sp500']  The ticker label can be found on yahoo's finance page: https://finance.yahoo.com/  For unemployment rate, I found EIA/STEO_XRUNR_M, which is civil unemployment rate. Not the same, but it provides monthly data for the sake of this tutorial.",True
@eastwoodsamuel4,2019-09-06T18:38:47Z,0,YAHOO/INDEX_GSPC is defunct..What to do?,True
@matthewchisambi5898,2019-01-20T19:18:12Z,0,"Hello for those unsure about how to replace the old quandl requests.   Here are the ones I used, which match the 1990 start date at 12:01 in the video:  SP500 -> df = quandl.get(""MULTPL/SP500_REAL_PRICE_MONTH"", trim_start=""1975-01-01"", authtoken=api_key)  USGDP -> df = quandl.get(""FRED/GDPSOPQ027S"", trim_start=""1975-01-01"", authtoken=api_key)  US_UNEMPLOYMENT -> df = quandl.get(""EIA/STEO_XRUNR_M"", trim_start=""1975-01-01"", authtoken=api_key)  NB. you will have to change the percentage change calculation based on the titles of the columns in each file. All 3 have title columns of value and not the 'Adjusted Close' for S&P.",True
@finnroblin4212,2019-01-20T05:42:55Z,0,"Just in case anyone wants GDP data from 1975 onwards you can download the data from https://fred.stlouisfed.org/series/GDP as a csv and rewrite the gdp_data() function as:  def gdp_data():     df = pd.read_csv(""GDP.csv"")     df[""DATE""] = pd.to_datetime(df[""DATE""])     df.rename(columns = {""DATE"":""Date""},inplace=True)     df.set_index(""Date"",inplace=True)     df[""GDP""] = (df[""GDP""]-df[""GDP""][0]) / df[""GDP""][0] * 100.0     df=df.resample('M').mean()     df = df.truncate(before=""1975-01-01"")     df = df['GDP']     return df  This allows the entire HPI dataframe to start at 1975 instead of 1990.",True
@markd964,2018-08-07T10:36:19Z,1,"Difficult tutorial here, because a lot of the data sources are defunct, so a bit tangled in the middle. Kept going (Persevere!) and eventually got to the HPI.pickle at the end... Excellent series Harrison - Thx.",True
@kylelaramee5848,2018-05-22T21:50:51Z,0,"I am really struggling to find what's wrong with my code.  I keep getting AttributeError: 'NoneType' object has no attribute 'index'  Please help!  import quandl import pandas as pd import pickle import matplotlib.pyplot as plt from matplotlib import style style.use('fivethirtyeight')   api_key = open('quandlapikey.txt','r').read()  def state_list():     fiddy_states = pd.read_html('https://simple.wikipedia.org/wiki/List_of_U.S._states')     return fiddy_states[0][1][1:]       def grab_initial_state_data():     states = state_list()      main_df = pd.DataFrame()      for abbv in states:         query = ""FMAC/HPI_""+str(abbv)         df = quandl.get(query, authtoken=api_key)         df.rename(columns={'Value': abbv}, inplace=True)         df[abbv] = (df[abbv]-df[abbv][0]) / df[abbv][0] * 100.0         print(df.head())         if main_df.empty:             main_df = df         else:             main_df = main_df.join(df)                  pickle_out = open('fiddy_states3.pickle','wb')     pickle.dump(main_df, pickle_out)     pickle_out.close()  def HPI_Benchmark():     df = quandl.get(""FMAC/HPI_USA"", authtoken=api_key)     df[""United States""] = (df[""Value""]-df[""Value""][0]) / df[""Value""][0] * 100.0     df.rename(columns={'United States':'US_HPI'}, inplace=True)     return df  def mortgage_30y():     df = quandl.get(""FMAC/MORTG"", trim_start=""1975-01-01"", authtoken=api_key)     df[""Value""] = (df[""Value""]-df[""Value""][0]) / df[""Value""][0] * 100.0     df=df.resample('1D').mean()     df=df.resample('M').mean()     return df  def sp500_data():     df = pd.read_csv('sp500.csv')      df['Date']=pd.to_datetime(df['Date'])      df.set_index('Date', inplace=True)      df[""Adj Close""] = (df[""Adj Close""]-df[""Adj Close""][0]) / df[""Adj Close""][0] * 100.0     df=df.resample('M').mean()     df.rename(columns={'Adjusted Close':'sp500'}, inplace=True)  def salaries_data():     df = quandl.get(""BEA/T20600_M"", trim_start=""1975-01-01"", authtoken=api_key)     df[""::Wages and salaries""] = (df[""::Wages and salaries""]-df[""::Wages and salaries""][0]) / df[""::Wages and salaries""][0] * 100.0     df=df.resample('M').mean()     df.rename(columns={'::Wages and salaries':'Salaries'}, inplace=True)     df = df['Salaries']     return df  def us_unemployment():     df = quandl.get(""BLSE/CEU0500000001"", trim_start=""1975-01-01"", authtoken=api_key)     df[""Value""] = (df[""Value""]-df[""Value""][0]) / df[""Value""][0] * 100.0     df=df.resample('1D').mean()     df=df.resample('M').mean()     return df    grab_initial_state_data()  HPI_data = pd.read_pickle('fiddy_states3.pickle') m30 = mortgage_30y() sp500 = sp500_data() salaries = salaries_data() HPI_Bench = HPI_Benchmark() unemployment = us_unemployment() m30.columns=['M30'] HPI = HPI_Bench.join([m30,sp500,salaries,unemployment]) HPI.dropna(inplace=True) print(HPI.corr())  #HPI.to_pickle('HPI.pickle')",True
@vladsirbu9538,2017-12-17T11:34:57Z,0,Those datasets are no longer available since quandl dropped the YAHOO and GOOG code based ones. Do you have any idea how they've been renamed or something? Thanks in advance!,True
@TheZykloned,2017-12-02T12:22:28Z,3,"working code for 3 new functions:    def sp500_data():     df = quandl.get(""YALE/SPCOMP"", trim_start=""1975-01-01"", authtoken=api_key)     df.columns = ['Adjusted Close',""1"",""1"",""1"",""1"",""1"",""1"",""1"",""1""]     df[""Adjusted Close""] = (df[""Adjusted Close""]-df[""Adjusted Close""][0]) / df[""Adjusted Close""][0] * 100.0     df=df.resample('M').mean()     df.rename(columns={'Adjusted Close':'sp500'}, inplace=True)     df = df['sp500']     return df  def gdp_data():     df = quandl.get(""FRED/GDP"", trim_start=""1975-01-01"", authtoken=api_key)     df[""Value""] = (df[""Value""]-df[""Value""][0]) / df[""Value""][0] * 100.0     df=df.resample('M').mean()     df.rename(columns={'Value':'GDP'}, inplace=True)     df = df['GDP']     return df  def us_unemployment():     df = quandl.get(""FRED/UNRATE"", trim_start=""1975-01-01"", authtoken=api_key)     df.columns = [""Unemployment Rate""]     df[""Unemployment Rate""] = (df[""Unemployment Rate""]-df[""Unemployment Rate""][0]) / df[""Unemployment Rate""][0] * 100.0     df=df.resample('1D').mean()     df=df.resample('M').mean()     return df",True
@FixABike,2017-11-15T14:00:08Z,0,"Instead of yahoo for sp500, you can use Yale Economic data at https://www.quandl.com/data/YALE/SPCOMP-S-P-Composite  or  quandl.get('YALE/SPCOMP')",True
@rubenvicente4677,2017-10-07T23:13:33Z,0,"you write pikcle and worked!!!! if its is pickle XD, I'm flipping out!  https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_pickle.html",True
@MarcelJanKr,2017-08-01T20:51:38Z,4,"I'm getting ""quandl.errors.quandl_error.NotFoundError: (Status 404) (Quandl Error QECx02) You have submitted an incorrect Quandl code. Please check your Quandl codes and try again."" on the YAHOO/INDEX_GSPC. I know very little about stock indexes. Any idea for a good replacement?",True
@jaredconnor7156,2017-05-22T16:52:36Z,0,"For the GDP series, BCB/4385 seems to be Brazil's monthly GDP: https://www.quandl.com/data/BCB/4385-GDP-monthly-in-US-million  Just a heads up.",True
@amrutshintre227,2017-02-13T04:34:15Z,0,"Hi sentdex, Thank you for the videos! they are awesome. Just a quick question. I have problems with SP500 data frame. Code is almost similar to the code you used and here it is  ""def sp500_data():     df1= quandl.get(""YAHOO/INDEX_GSPC"",trim_start=""1975-01-01"",authtoken=api_key)     df1[""ADJUSTED CLOSE""]= ((df1[""ADJUSTED CLOSE""]-df1[""ADJUSTED CLOSE""][0])/df1[""ADJUSTED CLOSE""][0])*100     df1=df1.resample('M').mean()     df1.rename(columns={'ADJUSTED CLOSE':'sp500'},inplace=True)     df1=df1['sp500']     return df1 "" and the error is  ""Traceback (most recent call last):   File ""C:\Users\amrut\AppData\Local\Programs\Python\Python36-32\psp.py"", line 97, in <module>     sp500=sp500_data()   File ""C:\Users\amrut\AppData\Local\Programs\Python\Python36-32\psp.py"", line 69, in sp500_data     df1[""ADJUSTED CLOSE""]= ((df1[""ADJUSTED CLOSE""]-df1[""ADJUSTED CLOSE""][0])/df1[""ADJUSTED CLOSE""][0])*100   File ""C:\Users\amrut\AppData\Local\Programs\Python\Python36-32\lib\site-packages\pandas\core\frame.py"", line 2059, in __getitem__     return self._getitem_column(key)   File ""C:\Users\amrut\AppData\Local\Programs\Python\Python36-32\lib\site-packages\pandas\core\frame.py"", line 2066, in _getitem_column     return self._get_item_cache(key)   File ""C:\Users\amrut\AppData\Local\Programs\Python\Python36-32\lib\site-packages\pandas\core\generic.py"", line 1386, in _get_item_cache     values = self._data.get(item)   File ""C:\Users\amrut\AppData\Local\Programs\Python\Python36-32\lib\site-packages\pandas\core\internals.py"", line 3543, in get     loc = self.items.get_loc(item)   File ""C:\Users\amrut\AppData\Local\Programs\Python\Python36-32\lib\site-packages\pandas\indexes\base.py"", line 2136, in get_loc     return self._engine.get_loc(self._maybe_cast_indexer(key))   File ""pandas\index.pyx"", line 132, in pandas.index.IndexEngine.get_loc (pandas\index.c:4433)   File ""pandas\index.pyx"", line 154, in pandas.index.IndexEngine.get_loc (pandas\index.c:4279)   File ""pandas\src\hashtable_class_helper.pxi"", line 732, in pandas.hashtable.PyObjectHashTable.get_item (pandas\hashtable.c:13742)   File ""pandas\src\hashtable_class_helper.pxi"", line 740, in pandas.hashtable.PyObjectHashTable.get_item (pandas\hashtable.c:13696) KeyError: 'ADJUSTED CLOSE' "" Please let me know where I am going wrong. Thanks in advance.",True
@adrianf3713,2017-01-25T12:21:28Z,3,BCB/4385 is Brazil GDP?,True
@patrickwong2867,2016-12-27T06:09:47Z,0,You spelled it as pikcle!,True
@rshrott,2016-11-15T00:08:50Z,1,"Loving your vids, moving through them quick!",True
@davez5544,2016-11-12T02:37:52Z,1,"Hey Harrison, thanks so much for the tutorials. I got an error as follows,     File ""C:\Python27\lib\site-packages\pandas\tseries\resample.py"", line 102, in resample     raise TypeError('Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex') TypeError: Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex  you have any idea why? Thanks!",True
@theworstbird,2016-06-07T03:31:46Z,4,"In case anyone using latest releases of various modules in 2016 is getting KeyError: 'Column not found: sp500' or just having issues with running the copy-pasted code, you might need to update your resampling lines. Even though IDLE is only really giving me future warning errors, it's still causing issues elsewhere for some reason. All you really have to do is add .mean() to the end of df=df.resample('M'), etc.  Additionally, if you like, I believe you can replace the two lines of resampling in the Unemployment function with a single line, df=df.resample('M').sum() and obtain the same results",True
@RealMcDudu,2016-05-11T13:01:02Z,0,"For some reason I have problems with the SP500 dataframe - it's acting weird  - as if it's not being recognized as a dataframe anymore. Printing the head() doesn't give any label but does give an extra line: Freq: M, Name: Adjusted Close, dtype: float64  UPDATE: managed to solve that. I had to redefine everything as a dataframe for some reason. df2 = pd.DataFrame(df[""Adjusted Close""])  Also - notice that the GDP data is also monthly, so you would need to resample it with df = df.resample('M', how='sum')",True
@seanturner7400,2016-04-27T21:38:24Z,0,"Hi Sentdex, I'm having an issue with running the sample code from the link in the description. Basically, everytime I run the program, HPI_Bench = HPI_Benchmark() encounters a key error in 'United States' I'm on Python 3.   Do you know why this would be happening?",True
@MattCamp,2016-03-25T23:42:24Z,0,is there an updated syntax for renaming the fields? cause I keep getting errors with the code. It seems to be due to it not finding the fields like sp500. I go to the sp500 function and just print the dataframe and sure enough the field names aren't changing.. I've been fooling around with this for the past 20 mins and no luck.. If I figure it out before a response I'll post my solution.,True
@joeg6588,2016-01-28T00:40:44Z,0,"Check out https://www.quandl.com/data/YAHOO/INDEX_GSPC-S-P-500-Index for updated ""Adjusted Close"" column name. It's different than video.",True
@luguk9676,2015-10-31T14:04:07Z,5,"Hi Sentdex, why do you use Python IDLE instead of some better Python IDEs?",True
@gaslight0513,2015-10-30T18:37:53Z,0,another good video harrison!   you probably already know this but sklearn provides a good way to both split the data set for training and testing along with optimizing classifier parameters. it also gives several different accuracy measures. simple to set up! http://scikit-learn.org/stable/auto_examples/grid_search_digits.html .,True
@SungHaJunTMT,2015-10-30T04:28:10Z,1,"hello, you can explain more about the module HTMLParser :D",True
