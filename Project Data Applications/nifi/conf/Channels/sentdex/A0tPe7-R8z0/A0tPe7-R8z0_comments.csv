author,updated_at,like_count,text,public
@Build_the_Future,2024-03-20T00:08:18Z,0,How are you able to update the joint positions?  I saw in part 1 that you had to constantly rewrite the file did you find a better way?,True
@ashutoshmishra5901,2024-02-08T16:46:54Z,0,Where is other 2 parts ?,True
@codetestdummy,2023-11-12T07:56:39Z,0,"Is it best (not sure if unavoidable) to consider each servo independently? Looking at the ""tippy-toe"" solution which the model arrived at, we can imagine that it would be very difficult for an actual dog to achieve or maintain that kind of posture (completely understand how local reward valley caused this). We know that in real life both joints on each leg would necessarily move in some kind of biomechanical proportion. I also image that what a real dog's brain is trying to do is imagine ""where"" it wants to put its paw (for balance or some impulse), and the motor cortex figures out the IK subconsciously, rather than thinking of ""how much"" to move it's leg muscles. But since the goal is just a forward gait, is it possible to have a reward function or constraint on the servo solution that follows the ""natural"" movement of the leg? I.e. (edit:) the next movement is a feasible IK solution based on current posture of the leg?",True
@petriseppanen4975,2023-08-17T20:18:47Z,0,"After a couple of days of swearing and testing dobot robot model on Omniverse RL. My model has two servos (exactly three, but the third is not used in this case) that are working together at the same time. Now I started to understand why, I like the discrete delta explanation. Huge thanks to you",True
@bytblaster,2023-05-02T11:09:39Z,0,Can we find the code somewhere?,True
@cvspvr,2023-01-09T17:47:52Z,0,"you could probably get the torque and speed from isaac to calculate to the true motor output power. also, look into shac. it's supposed to be even more godly than ppo. also also, maybe you should kill the bittle as soon as it flips over or its knees touch the ground",True
@BenjaminScottfromFrance,2022-12-14T18:00:42Z,0,"I'm loving these videos! A few months ago I had an idea of doing exactly what you are doing: running a simulation of an existing robots to try and teach it to walk through reinforcement learning rather than doing it with a real robot.  It's impressive to see how far you're getting. My knowledge about AI, machine learning and, frankly, programming are not even close to yours!  When I thought of the idea I thought of doing it in different steps, for example: - Use IMU and the first task is for the robot to stand up and stay horizontal; - Walk and, still using the IMU, staying as horizontal as possible;  Is is possible to start training a model to do something specific to start with, and then train it to evolve more complex behaviours, like the examples I gave above?  Thanks, and keep up the good work!",True
@sdfgeoff,2022-11-05T12:58:02Z,0,"I've been playing with a similar problem - getting a (sprawling rather than mammalian) type quadrupedal robot to walk using RL. Your videos gave me some great ideas, so big thanks for uploading. One very simple change that gave a big gain was to use the centroid of feet position as the ""robot position"" rather than the center of mass or body coordinates. This avoids the problem of the robot making big initial gains simply by ""leaning"" forwards - and avoids the tendency to end up with hunched forward poses such as the one seen at 16:29 18:17 etc.",True
@keldfrslev3935,2022-09-17T11:10:57Z,0,I understand that it's cool teaching the robot to walk from scratch. Wouldn't it be much better to start with the hand coded walk and have it improve that?,True
@trongnguyenphanminh5615,2022-08-11T04:42:55Z,0,what software you used in this video,True
@josgraha,2022-08-03T09:11:53Z,0,seems like there should be punishment for power consumption if that could be thrown in somehow (total movements of servos and kg/cm applied),True
@Skyentific,2022-07-27T12:24:15Z,20,"I really hope to see part 4 of these series. Maybe with minimum power/energy usage, instead of minimum changes in direction. I think this will solve everything! :)",True
@mr.witter4543,2022-04-27T00:41:26Z,1,"This is awesome! I also have a Petoi Bittle and I'm planning to start practice reinforcement learning on it as well so these videos are a life-saver. Right now I'm using ROS with a raspi mounted on mine for teleoperation and other cool features but I'd like to train it to make sense of it's surroundings and eventually just act on it's own (for now walking and flipping would be a start).   I see a couple of comments about calculating energy usage and how you could do it on Bittle. One thing that comes to mind is to simulate the current draw from the battery to each of the motors-basically simulate the battery on the robot as well. So for example, if motor 8 moves by 0.2, the battery discharges 0.5%. These are made up numbers as I didn't look into the exact draw of the servo motors.  The second change you could make which would benefit the simulated battery is to have a delayed reward, so instead of getting a reward after each action, you get a reward after either making it a certain distance or fully depleting the battery, and this would reset the simulation. This would encourage Bittle to not only move in a certain direction, but to also conserve energy with movements. This also alleviates your worry of over constraining the robot, and since you have the resources for training it should work just as well with the Proximal Policy.",True
@giusepperandazzo5357,2022-04-17T11:08:33Z,0,"Hi there, I'm here after 2 months after I collected a lot of experience with RL. Rewatching the video, a cool thing that actually you could try:  1) Program your robot to walk normally without using any AI algo. Hand coding as well... 2) Use the RL algos to IMITATE your previously programmed controller.  I mean, instead of starting from 0...put into the system something that already properly works.  Hi there, I'm here after 2 months after I collected a lot of experience with RL. Rewatching the video, a cool thing that actually you could try:  1) Program your robot to walk normally without using any AI algo. Hand coding as well... 2) Use the RL algos to IMITATE your previously programmed controller.  I mean, instead of starting from 0...put into the system something that already properly works.",True
@daniellaucht5560,2022-04-14T21:05:31Z,0,Would it be possible for you to provide a newer branch of your great Bittle solution. At the moment I get this error with isaac sim 1.2: [carb.python] Failed to reload python module pxr.Tf. Error: module pxr.Tf._tf not in sys.modules.This heapens when I run TD3-Bittle-16-1.py via ./python.sh Maybe this module is nor longer supported.,True
@Veptis,2022-04-11T08:35:36Z,0,"If reinforcement learning models biological evolution - it's crazy to believe we developed walking, running or stuff like the human ear",True
@RoseMaster3000,2022-04-06T02:38:55Z,0,"The reason it jumps is because that is the ideal adaptation given the environment it is being trained in (a perfectly smooth plane) If you want the model to evolve to have a ""realistic gait"" you will need to train it in an environment where the ground plane is bumpy or something. Just my take on it, love your vids!",True
@usercurious,2022-03-16T16:20:41Z,0,Cool that robot learned to fly instead of walking üòÉ,True
@PatrickHoodDaniel,2022-03-12T17:00:31Z,0,"Could you treat each leg as a planar 2D mechanism instead of using the rotation of the individual servo and use inverse kinematics (planar 2D version of that) as the input? This way, it's like inputting a 2D image into the model rather than the positions of each servo and the problem is just the position of the foot in that plane. Just a thought.",True
@jacobdavidcunningham1440,2022-02-08T05:52:22Z,0,16:54 lol 20:15 aerodynamic boi,True
@simonrichter3950,2022-02-07T16:32:21Z,1,It looks like it freezes the upper leg joint once you activate the movement punishment :/ Maybe punishment should not be the same for every joint .,True
@giusepperandazzo5357,2022-02-04T20:31:02Z,0,"Hi there, thanks for your videos. I'm specialized in industrial robotics and I love them.  Currently, I'm trying to apply rl to the stock market with discrete success...(I'm at the beginning).... What disturbs my personality is not to not understanding in depth what really happens inside these neural networks...so actually your videos, helped me with the deep neural networks....but I should understand better math beyond lstm and reinforcement learning algos. In your book, you provide those explanations ? Thanks in advance,  Giuseppe",True
@zbigniewloboda3393,2022-01-31T17:34:53Z,0,"2:35  Forgive me my open response. It looks like, you have no methodology of operate of your creation. I don't have it also but I hope that stop, where you are and star develop methodology. Than you.",True
@judedavis92,2022-01-31T11:26:18Z,0,Loved to video. Any news on the nnfs video series?,True
@xakslim,2022-01-29T18:31:41Z,0,"Oh, my God. You create a half-life monster üòÄ",True
@EtherealIntellect,2022-01-25T20:27:09Z,0,"Might be early for it, but adding in a latency/delay to the sensors can apparently sometimes help produce a more natural gait when the ai has to predict and adapt. Ofc humans have at least 100ish/200ish ms we gotta predict for constantly",True
@aadarshkumar2257,2022-01-20T21:28:32Z,0,Will the Neural Networls from scratch in python series continue ? When the next video in that series will come. Please clarify this matter !,True
@aadarshkumar2257,2022-01-19T19:44:25Z,0,I am here from your Neural Networks from scratch course.  My only question for you is just tell me how you taught yourself Machne Learing and Deep Learning ? and moreover i think many people must be wondering about this. And a very deep request from the bootom of my heart please do a video on your journey from how you got interested in programming to growing this channel and teaching peoplpe in the most simple and easy to understand way. Your NN from scratch course is insane and one of the most valueable content i found in the deep learning material available.,True
@KennTollens,2022-01-19T02:42:12Z,0,What would happen if you punished for crouching?,True
@iliya-malecki,2022-01-19T00:29:32Z,0,"well, if a robot moves ""fluently"", its ICU is mainly gonna output sinusoidal and half-sinusoidal 2d shapes, so I think you should try punishing for deviations from those shapes. I would define that additional cost as SS from a curve you can precompute, leaving delta of the distance travelled to plug in the formula as the simulation runs. Obviously, distance should be a little smarter than just an L2 norm, but you get the point",True
@tsunamio7750,2022-01-18T06:32:33Z,1,"Your poor things are scared of using their god damned thighs. They are only using the front part of their legs! That just can't be smooth!  Somewhere in your restriction, you should let the hip joints be free of movement, because here it's not jittery, it's stiff as steel.",True
@fctrend6170,2022-01-17T10:09:04Z,0,"nice, i can supply  robot dog hardware",True
@iwoaugustynski9265,2022-01-16T17:41:32Z,0,What about reward for similar movement of pair of legs? Or directly link legs in pairs?,True
@jameshodds8800,2022-01-13T13:18:00Z,0,Sentdex I'm looking at starting opencv on Raspberry pi 4b I have no computer knowledge I would like to know which of your video it would be best to start from. What I would like to do with opencv is body detection and grab a image from pi camera and email it to myself sorry for this comment on your youtube page but I don't know how to find your email address from youtube James please delete if required,True
@HungrySoutherner,2022-01-11T18:09:24Z,0,"Have you considered instead of trying to learn the gate, instead learning the optimization functions for the prime kinematics for the legs with respect to the body. It seems approaching it this is always going to be approaching odd walking behaviors. Since the kinematics for the joints per leg is a known, learning how to optimize those and using those learn kinematics functions would make this thing walk smoother.",True
@rumdabbadoh,2022-01-10T19:48:05Z,4,"Just an idea, since you punish any movement of the joints to counteract the jitter, that would also punish using all the joints on each leg, right? I saw a lot of your walkers were using only one of lower joint in the leg. What do you think?  Anyways thanks for creating all your content, your videos are a big part of my career choices and development the last couple of years! Cheers!",True
@lennartlut,2022-01-10T13:19:25Z,0,Thank you for this great video. Well done!,True
@ethanblackthorn3533,2022-01-07T23:37:21Z,0,thank you for amazing videos! They're very motivational,True
@phillipotey9736,2022-01-07T03:31:36Z,0,"give  a punishment for low height, or if you want a specific height maybe. you're awesome",True
@Voloskaya,2022-01-05T16:58:31Z,3,"I think you should really consider giving IsaacGym another try. You get 2 or 3 orders of magnitude speedup for training which allows you to have a much faster feedback loop and add things like randomization to prevent your model from being stock in a local minima. I was doing the same thing as you: training bittle with RL, and that's how I found your videos, and I am able to train a reasonably good gait in about 10 minutes on a single 1070 GPU with IsaacGym (about a million steps). Not sure how IsaacGym handles camera however, or if it can at all.",True
@tcgvsocg1458,2022-01-05T10:13:09Z,0,Can you do a python tutorial?,True
@tj_1260,2022-01-05T09:09:16Z,0,Lopfs,True
@monisprabu1174,2022-01-04T22:56:02Z,0,"I don't have a clue how to use nvidia Omniverse or what that thing is it would be great if you upload a tutorial on it , BTW greater video!!! very interesting!",True
@greatsea,2022-01-04T00:19:19Z,0,"Sentdex a few years ago I left comment regarding my not liking Anaconda b/c broke some things in my Win 10 config, somehow clashing with way I had something else set up on my sys.   You agreed and expressed aversion to using Anaconda for your own Python setups.    SO anyway it's few years later & Anaconda has presumably made improvements compatibility wise. But still feels bloaty & what-not.  My boss just messaged me & asked me to do research on an ideal Python setup for him as he has begun prepping to get into PhD physics program & wanted me to research around for pros/cons of Anaconda for his needs.   Just curious if you are still averted to Anaconda or if have any thoughts on it.  Right now I am leaning against advising my boss to install it.",True
@Tolstoievsky,2022-01-03T20:05:15Z,4,"i think the coolest part was when it stumbled into hopping...esp since that exists in nature anyway (frogs, pigeons, etc), no other movement looked even remotely natural",True
@ienesree6808,2022-01-03T18:41:56Z,1,"Hello Sentdex, I want to start programming AI, but I don't know how to start. I tried several times to start with pytorch but always stopped because I didn't understand. I have basic knowledge of Python, but I still only understand a small part. Do you have any tips for me?",True
@cryptojanne1134,2022-01-03T09:40:25Z,0,Amazing. Fun project!,True
@baserockbathead,2022-01-03T08:21:22Z,2,"Wouldn't it be better to punish for 'per servo' change of direction instead of total? That's probably why your upper legs aren't working, right? As it would seek to prevent as much servo movement as possible?",True
@t3chm0nkey,2022-01-02T20:03:31Z,0,"You could try something like this: hipCost = (1 - Abs( Dot( thighDir, gravityDir))) * hipToFootDis * costDelta; kneeCost = (1 - Abs(Dot( calfDir,  gravityDir))) * kneeToFootDis * costDelta;  sumCost = glueCost + kneeCost;  This should into account moving against gravity and leverage (the hipToFootDis is the euclidean distance. not the length of the appendage)  You could also mess around per joint cost i.e. the knee costs more then the hip to move",True
@1UniverseGames,2022-01-02T17:59:28Z,0,"Happy new year sir. I have a a question, how can I plug or Integrate a Pytorch based GNN models into Pyspark or Spark cluster?",True
@UNTBC,2022-01-02T16:13:12Z,0,"Punish for efficiency, faster legs use more power with less effective work.",True
@22vortex22,2022-01-02T05:27:38Z,1,Would making it navigate non flat terrain promote more standard gaits,True
@rlew12,2022-01-01T23:38:28Z,2,"Have you considered creating an energy usage model for the biddle that calculates the center-of-mass and moment-of-inertia of the body and each joint. You could get a rough calculation of the energy usage by looking at the acceleration of the joints and even have a more natural penalty for jumpy movements since there'd be a higher energy usage for moving in the upwards Z direction which you wouldn't get back in the downwards motion.  This would also punish jittery movements since it would punish rapid back and forth acceleration. I know this would be pretty involved to make but might give you more realistic constraints than ""no side to side sway"", ""no roll"", ""no bobbing up and down"" etc. It might even translate into a more natural running gait where you might want something more like a leap in between steps.   Great video and looking forward to the next! Happy new year!",True
@Kram1032,2022-01-01T21:14:51Z,26,"One thing that's probably a good idea is to go for efficiency. Generally speaking, that means punishing energy usage. Lower-energy gaits tend to also be more robust afaik",True
@pedroalvarado2515,2022-01-01T19:56:19Z,0,"Sentdex, do you think it is possible to make ai gym environment of planet surfaces for robots to explore? This robot reminds me of prototype idea of martian walking probes",True
@Ihsees91,2022-01-01T19:41:29Z,3,"Cool video! Good mix between information and showcasing your models.  Didn't know about discrete delta PPO yet, this alone was worth subscribing to you in the past.  Regarding the stiff upper legs: maybe that has something to do with move_punish_div? Having no movement in those joints will punish the agents less after all.  When I had to deal with jittering I tried limiting the overall ""joint-movement sum"" per step. If an agent requested more than the allowed value, I scaled the movement of every joint linearly. This works because jittering takes a longer ""path"" to get to the same target position, thus forcing the agent to reduce jitter. I've had decent results with this method (albeit on a different continuous-control problem - and not a walker)  Of course this will give you another hyper-parameter to tune. Maybe do the same calculations on an already working model, and see what kind of value is needed for a stable gait?",True
@hendazzler,2022-01-01T19:15:30Z,0,"more like _brittle_ reinforcement learning, amirite",True
@jeffmofo5013,2022-01-01T18:12:48Z,1,Look up two minute papers.  They have showcased many papers that capture walking gates with neural networks.,True
@swannschilling474,2022-01-01T18:09:15Z,1,I am so happy about this series!! Its just great!! üòä,True
@serta5727,2022-01-01T17:45:47Z,1,I also looked a little into the NEAT python library. It is really cool.,True
@Nerdy135,2022-01-01T17:12:11Z,6,My NNFS book came in a few days ago and I gotta say I love it. Thank you for all you do here on this channel.,True
@amangautam1779,2022-01-01T17:11:30Z,0,How did you learn all this stuff???!!!!,True
@wktodd,2022-01-01T17:05:35Z,3,"Happy New year.  The robot is only moving part of each limb. Is that something you've restricted the model to, or is it simply not learning to use the shoulder/hip joints?",True
@danielniels22,2022-01-01T16:56:51Z,0,have you ever made a video where you talk about yourself? I still wonder how you went from law major and to do these without computer science background,True
@54peace,2022-01-01T16:50:12Z,0,my very first comment on yotube. i'll check again next year & let's see how much i will develop.,True
@Los__Merengues,2022-01-01T16:45:47Z,2,Happy new year,True
@unknowinglyanonymous9215,2022-01-01T16:41:14Z,0,yo! happy new year tanks for the nice content,True
@Stinosko,2022-01-01T11:18:59Z,3,"I do wonder if it would be possible to predict the position of the main body.   For a position of a object in 3d you need 3 parameters: a center point position of the center of the main body, and two vectors with force 1 that can make a 3D plane that the main body is currently at. (A vector from the center to the front like 1,0,0 and a vector 90¬∞ from the center for example the vector up 0,0,1) Those result in 9 values the robot has to keep track off  in order to know it's his 3d position of the main body, and only 6 values for stabality.   Than you can make observations with the current model where you try to predict the position of the main body based on the movement the dog is gonna make. So he learns and predict his behaviour in 3D and maybe can use those prediction in future model?   Than you can try to make a model that minimise the wobbling in 3D plane of the main body, and keeping the walking direction forward.   In a project of the university where i had to calculate a 3d plane from point I used sympy library. Maybe you can use it as well although if i remember correctly it was fairly slow üòä",True
@MrJosephtrapani,2022-01-01T01:11:22Z,1,üññAmazing work! Happy new year.   Would it be practical to set a bounding box moving in the y at a speed and height you would like and punish if the body doesn't stay within it? Not sure how it would generalise once this crutch is removed but may help pass design intent to the model more quickly.   Thank you for the constant inspiration. ,True
@Stinosko,2021-12-31T21:24:49Z,2,What a nice New Year gift! üéÅ ,True
