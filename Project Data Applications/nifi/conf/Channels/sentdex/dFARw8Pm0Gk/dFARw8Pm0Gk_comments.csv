author,updated_at,like_count,text,public
@thread_pool,2017-10-29T06:31:34Z,29,"For folks using the newer version of TensorFlow, change this code:  from tensorflow.contrib import rnn   lstm_cell = rnn.BasicLSTMCell(rnn_size)  outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)  to this code:  from tensorflow.python.ops import rnn, rnn_cell   lstm_cell = rnn_cell.BasicLSTMCell(rnn_size,state_is_tuple=True)  outputs, states = rnn.rnn(lstm_cell, x, dtype=tf.float32)",True
@Faisal-jo5vk,2022-07-24T12:16:29Z,0,THIS SHIT DOENST WORK,True
@ddas8554,2020-08-28T02:12:51Z,0,does rnn_size mean the number of hidden layers?,True
@klahsiv,2020-06-26T18:24:42Z,1,"Anyone one with tensorflow 2.2.0  Use : Import tensorflow.compat.v1 as tf tf.disable_v2_behaviour() lstm_cell =   tf.nn.rnn_cell.BasicLSTMCell(rnn_size) outputs, states = tf.nn.static_rnn",True
@maxusldragold5641,2020-05-23T05:49:15Z,0,"For those using TensorFLow 1.15 or greater use this:       lstm_cell = tf.nn.rnn_cell.LSTMCell(rnn_size,state_is_tuple=True)      outputs, states = tf.compat.v1.nn.static_rnn(lstm_cell, x, dtype=tf.float32)  instead of :     lstm_cell = rnn_cell.BasicLSTMCell(rnn_size,state_is_tuple=True)      outputs, states = rnn.rnn(lstm_cell, x, dtype=tf.float32)",True
@tsnimsiddig3259,2020-05-12T11:25:53Z,0,I got error no module name from import. Tutorial,True
@tsnimsiddig3259,2020-05-06T12:06:58Z,0,I got indentation error :unexpected indent  In line  Output=tf.matmul(outputs[-1]..... Please help,True
@tsnimsiddig3259,2020-03-12T12:40:01Z,0,how I can insert my dataset to this code,True
@JCSMOOTH345,2019-10-08T19:00:07Z,0,can you show us how to code a Q learning algorithm?,True
@arun3151997,2019-07-22T08:31:56Z,0,can someone tell me why he uses output[-1] at 8:51?,True
@brojoegan5012,2019-06-27T08:59:22Z,0,"for all the people that are getting something like this -  Variable rnn/basic_lstm_cell/kernel already exists, disallowed.   add this at the start of your code - tf.reset_default_graph()   the computational graph is not cleared",True
@anshdesai6804,2019-06-18T13:25:22Z,1,How do I make predictions using the RNN model,True
@user-jc4oi1xg1z,2019-03-30T01:34:25Z,0,"ValueError: Only call `softmax_cross_entropy_with_logits` with named arguments (labels=..., logits=..., ...)",True
@shivampande7592,2019-03-13T10:22:15Z,0,Can somebody clarify what does rnn_size mean? Is it the number of hidden nodes (cells) in rnn or something else?,True
@redyandrimof7565,2019-01-22T00:18:11Z,0,Awesome. Very helpful for beginner like me,True
@nithishsomesetty,2018-12-09T10:53:16Z,0,does the wiscosin breast cancer dataset can be classified using rnn,True
@SaretMagnoslove,2018-10-03T19:25:02Z,1,"Full code for Tensorflow version 1.10 :)   import tensorflow as tf from tensorflow.examples.tutorials.mnist import input_data from tensorflow.nn import rnn_cell from tensorflow.contrib import rnn mnist = input_data.read_data_sets(""/tmp/data/"", one_hot = True)  hm_epochs = 10 n_classes = 10 batch_size = 128 chunk_size = 28 n_chunks = 28 rnn_size = 128  x = tf.placeholder('float', [None, n_chunks,chunk_size]) y = tf.placeholder('float')  def reccurent_neural_network(x):     layer = {'weights':tf.Variable(tf.random_normal([rnn_size, n_classes])),              'biases':tf.Variable(tf.random_normal([n_classes]))}      x = tf.transpose(x, [1,0,2])     x = tf.reshape(x, [-1, chunk_size])     x = tf.split(x, n_chunks, 0)      lstm_cell = rnn_cell.BasicLSTMCell(rnn_size)     outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)          output = tf.matmul(outputs[-1], layer['weights']) + layer['biases']      return output  def train_neural_network(x):     prediction = reccurent_neural_network(x)      cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y) )     optimizer = tf.train.AdamOptimizer().minimize(cost)          with tf.Session() as sess:         sess.run(tf.global_variables_initializer())          for epoch in range(hm_epochs):             epoch_loss = 0             for _ in range(int(mnist.train.num_examples/batch_size)):                 epoch_x, epoch_y = mnist.train.next_batch(batch_size)                 epoch_x = epoch_x.reshape(batch_size, n_chunks, chunk_size)                  _, c = sess.run([optimizer, cost], feed_dict={x: epoch_x, y: epoch_y})                 epoch_loss += c              print('Epoch', epoch, 'completed out of',hm_epochs,'loss:',epoch_loss)          correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))          accuracy = tf.reduce_mean(tf.cast(correct, 'float'))         print('Accuracy:',accuracy.eval({x:mnist.test.images.reshape((-1, n_chunks, chunk_size)), y:mnist.test.labels}))  train_neural_network(x)",True
@markisaac7970,2018-10-02T18:50:27Z,0,"I'm getting: ValueError: Variable rnn/basic_lstm_cell/kernel already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope?",True
@zahidulislam9812,2018-09-24T13:17:47Z,0,"can any one help me where we get it mnist = input_data.read_data_sets(""/tmp/data/"", one_hot = True)..  because my windows program doesn't support it .i use pyChamp",True
@MrAbhishekverma7,2018-09-20T13:36:47Z,0,Hi. Please make a video for gated recurrent units too! Thnx,True
@chuanjiang6931,2018-09-19T02:58:04Z,0,"Can anyone have a good idea why we need use chunks?  I set chunk_size = 784, n_chunks = 1 and chunk_size = 49, n_chunks = 16, they both gave me 97%-ish result",True
@stevepisano5566,2018-08-18T20:42:36Z,0,"What exactly does ""rnn_size"" refer to?",True
@amoghdevanagavi3577,2018-08-08T09:31:39Z,0,Hey I need to know how to get output not in accuracy but in form of letter it recognized,True
@demonlord4712,2018-08-04T17:27:33Z,0,sound is low in this video,True
@weiloon0,2018-08-02T06:32:58Z,1,Thanks for the great and intuitive tutorial. Can we apply this model in audio recognition? I tried to feed audio mfcc but the accuracy is very low.,True
@junhyeonglee5397,2018-07-07T04:01:54Z,0,"from tensorflow.contrib.rnn.python.ops import rnn, rnn_cell from tensorflow.contrib.rnn import BasicLSTMCell, static_rnn  new path for BasicLASTMCell and static_rnn here",True
@techynerdz9566,2018-06-27T16:44:56Z,0,"I keep getting a ValueError saying ""Attempt to have a second RNNCell use the weights of a variable scope that already has weights: 'rnn/basic_lstm_cell'; and the cell was not constructed as BasicLSTMCell(..., reuse=True)"" What have I done wrong?",True
@nachovillaluenga,2018-06-05T22:57:49Z,0,"Hi sentdex, great video, but this is actually single layer LSTM neural net? how can I add more layers?",True
@alakazam2451,2018-06-04T09:56:10Z,0,"Is there a reason to reshape x into [-1, chunk_size] and not [n_chunks, chunk_size] ?  I'm trying to understand",True
@MisterDidactic,2018-05-10T09:22:56Z,0,"Hey Harrison. I can't seem to find anything about this in the documentation and I'm a bit confused but: When you assign lstm_cell = BasicLSTMCell(num_units) where num_units is some integer, is that how many LSTM cells you're creating as part of a layer or is that something like the length of that cell's memory? Sorry if it's a silly question but I was looking at the RNN I made in tensorboard's graph view and it only shows one LSTM node. Thanks in advance!",True
@CoolDude911,2018-04-21T10:28:25Z,0,"Does the LSTM cell have any parameters to train, apart from the forget bias?",True
@viraatchandra8498,2018-04-18T15:16:02Z,0,"Sir, does using a LSTM network even make sense with MNIST problem? There is no time series data and no prediction about future being made? Also if this is true, why is this giving almost equal accuracy to a convolutional neural network?",True
@prashanttarey9902,2018-04-18T06:20:43Z,0,"With Tensor Flow v1.5.1, I was getting an error. Looking at the error message, I just changed line #34 from: cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(prediction, y)) to: cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=prediction, labels=y)) ==================================================================================== With these changes I am getting similar output: Epoch 0 completed out of 3 loss: 193.44008703529835 Epoch 1 completed out of 3 loss: 55.611899895593524 Epoch 2 completed out of 3 loss: 37.679315445013344 Accuracy: 0.9754 ==================================================================================== ""y"" for sure is label array  ""prediction"" is storing the output from ""recurrent_neural_network(x)"", so it must be some kind of probability ==================================================================================== Please correct me if I am wrong. Thanks!",True
@Claudia-hy3ml,2018-04-15T08:56:00Z,0,"Hi! Thanks for the video, it was very useful! Do you know any simple way to make the confusion matrix on your code? To later calculate precision and recall.",True
@rksahu17,2018-03-21T07:47:22Z,0,how to use a rnn output(from a sequence classification) fed into a feed forward nn with other attributes to get a joint classifier??,True
@Steev1995,2018-03-16T20:19:28Z,0,"Hi sentdex, this code is not working anymore, due to different changes. Maybe you could update it on your website? Additionally, I just wonder where you use the hidden state in this code. It is retrieved in line 26, but I cannot see where it is processed any further.  Thank you for your great videos!",True
@neelm4037,2018-03-05T19:44:37Z,0,"Could anyone help me with a problem I'm facing while trying to run the code? Its giving me this error  ValueError: Input graph and Layer graph are not the same: Tensor(""split_2:0"", shape=(?, 28), dtype=float32) is not from the passed-in graph.  Pointing to this line outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)",True
@gmaedzl,2018-02-20T15:45:54Z,1,"After reading:  https://www.tensorflow.org/api_docs/python/tf/split  I changed  x = tf.split(0, n_chunks, x)  to  x = tf.split(x, n_chunks, 0)  previous I got the error:  ValueError: Tensor conversion requested dtype int32 for Tensor with dtype float32: 'Tensor(""Reshape:0"", shape=(?, 28), dtype=float32)'  TypeError: Input 'split_dim' of 'Split' Op has type float32 that does not match expected type of int32.",True
@aiysiri,2018-02-09T09:48:34Z,0,"Tensorflow 1.4 should be  from tensorflow.contrib import rnn    lstm = rnn.BasicLSTMCell(rnn_size, state_is_tuple=True)   (outputs, states) = rnn.static_rnn(lstm, x, dtype=tf.float32)",True
@LC-lj5kd,2018-01-29T20:03:45Z,0,what does output[-1] mean?,True
@jesper5443,2018-01-16T12:34:32Z,0,"Will you make another tutorial on LSTM RRN neural nets, but with this example it's made for pattern recognision i.e. you givie it: 1,3,2,4,3,5,4,6,5 and it will output 7,6,8,7,9,8 and so on. I want to design a neurl network like that but I found that it was rather difficult because almost all tutorials are made of image/speech recognision or translation. And I find it to be really confusing.",True
@mokshnigamsatsangi1780,2017-12-30T05:17:04Z,0,"the video helped a lot! but I'm having trouble about loading datasets. the library you imported to load mnist dataset was fine but how can I load an already downloaded dataset, like I have a dataset already which I downloaded. How can I load it?",True
@rajdamani6923,2017-12-18T05:20:55Z,0,https://github.com/raj-damani/rnn Error : TypeError: inputs must be a sequence Please help me.,True
@sebastiaan724,2017-09-17T20:06:47Z,0,"If you guys got some errors try it like this:  import tensorflow as tf from tensorflow.examples.tutorials.mnist import input_data from tensorflow.contrib import rnn mnist = input_data.read_data_sets(""/tmp/data/"", one_hot = True)  hm_epochs = 3 n_classes = 10 batch_size = 128 chunk_size = 28 n_chunks = 28 rnn_size = 128   x = tf.placeholder('float', [None, n_chunks,chunk_size]) y = tf.placeholder('float')   def recurrent_neural_network(x):     layer = {'weights':tf.Variable(tf.random_normal([rnn_size,n_classes])),              'biases':tf.Variable(tf.random_normal([n_classes]))}      x = tf.transpose(x, [1,0,2])     x = tf.reshape(x, [-1, chunk_size])     x = tf.split(x, n_chunks, 0)      lstm_cell = rnn.BasicLSTMCell(rnn_size)     outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)      output = tf.matmul(outputs[-1],layer['weights']) + layer['biases']      return output   def train_neural_network(x):     prediction = recurrent_neural_network(x)     # OLD cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(prediction, y))     cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y))     optimizer = tf.train.AdamOptimizer().minimize(cost)      with tf.Session() as sess:         sess.run(tf.initialize_all_variables())          for epoch in range(hm_epochs):             epoch_loss = 0             for _ in range(int(mnist.train.num_examples / batch_size)):                 epoch_x, epoch_y = mnist.train.next_batch(batch_size)                 epoch_x = epoch_x.reshape((batch_size, n_chunks, chunk_size))                  _, c = sess.run([optimizer, cost], feed_dict={x: epoch_x, y: epoch_y})                 epoch_loss += c              print('Epoch', epoch, 'completed out of', hm_epochs, 'loss:', epoch_loss)          correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))          accuracy = tf.reduce_mean(tf.cast(correct, 'float'))         print('Accuracy:',               accuracy.eval({x: mnist.test.images.reshape((-1, n_chunks, chunk_size)), y: mnist.test.labels}))   train_neural_network(x)",True
@ShlomoOrna,2017-09-05T13:54:47Z,0,"Hi, thanks for the tutorial. I wonder, is RNN capable of handling video or images from video size 224 X 224 ? especially if I want to do semantic segmentation ? So the output for each image is an image size pixel classification. thanks.",True
@arjunkrishna8873,2017-09-04T18:05:43Z,0,"some helpful insights http://colah.github.io/posts/2015-08-Understanding-LSTMs/  following modifications has to be made in above code: x = tf.split( x, n_chunks,0) lstm_cell = rnn.BasicLSTMCell(rnn_size)     outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)  now talking about why we reshape x we know our RNN tries to find out patterns in a horizontal line of each image for our classification problem hence after all 128 timesteps we predict our output y based on sequential information we have regarding all n_chunks*horizontal line (where n_chunks how many horizontal lines are there in an image)",True
@fuba44,2017-08-31T18:55:06Z,0,"Hello Sentdex, i have been watching your videos and im wondering with this RNN, it seems it only takes ""one feature"" (one image at a time), but if it is good an ""analyzing"" streams of data, how would i go about inputting many features each being a stream of data, like say ""every stream"" (the once that makes sense) of data i could find about every crypto currency from multiple exchanges, trying to ""predict"" the trend of one of them. not talking about how to gather the data, but how to funnel it into the RNN. if you have a few guiding words i would much appreciate it. thanx for the good videos!",True
@chaheschopra558,2017-08-12T10:58:36Z,0,"MNIST dataset is non-sequential, how could we use Recurrent Neural Net for such datasets? The output of one has no relation with the second input. Can we use RNN for non-sequential data?",True
@chendicao4491,2017-08-11T20:34:25Z,12,"1) Error:  File ""rnn_example.py"", line 20, in recurrent_network_model     x = tf.transpose(x,[1,0,2]) UnboundLocalError: local variable 'x' referenced before assignment  Solution:  add global x under recurrent_network_model function.  recurrent_network_model(data):  global x  layer = {'weights':tf.Variable(tf.random_normal([rnn_size,n_classes])),    'biases':tf.Variable(tf.random_normal([n_classes]))} 2)Error: ValueError: Tensor conversion requested dtype int32 for Tensor with dtype float32: 'Tensor(""Reshape:0"", shape=(?, 28), dtype=float32)'  Solution:  change 'float' to tf.float32.  x = tf.placeholder(tf.float32,[None,n_chunks,chunk_size]) y = tf.placeholder(tf.float32)  3)Error: AttributeError: module 'tensorflow.python.ops.rnn'  has no attribute 'rnn'  Solution:  from tensorflow.python.ops import rnn, rnn_cell   lstm_cell = rnn_cell.BasicLSTMCell(rnn_size,state_is_tuple=True)  outputs, states = rnn.rnn(lstm_cell, x, dtype=tf.float32)  changed it to  from tensorflow.contrib import rnn   lstm_cell = rnn.BasicLSTMCell(rnn_size)  outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)  http://stackoverflow.com/questions/42311007/attributeerror-tensorflow-python-ops-rnn-has-no-attribute-rnn   4) x = tf.split(0, n_chunks, x) changed it to: x = tf.split(x, n_chunks, 0)  5) cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logitsprediction,y) ) changed it to: cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(logits=prediction,labels=y) )  6) tf.initialize_all_variables() changed it to: tf.global_variable_initializer()  Hope this help! : )",True
@aymenmtibaa4582,2017-08-08T16:23:12Z,0,i have this error :  def train_neural_network(x):                                ^ IndentationError: unindent does not match any outer indentation level,True
@rogerganga,2017-07-20T03:54:35Z,0,To @sentdex and the others who commented below regarding the updates/ changes in code... thank you very much!!! :) :),True
@msp3551,2017-07-11T22:12:45Z,0,Any chance you can post sample code where you modified the neural network code with our own data from video 7 and not the build in MNIST example?,True
@nimbleninja12,2017-07-09T06:09:12Z,0,do you have any intuition as to why an rnn performs better than multilayer perceptron for mnist? it doesn't seem like mnist has any time series or sequence properties that can be exploited,True
@ShivamSinhaiiitm,2017-06-25T10:56:29Z,0,Instead of training 28 chunks each having 28pixels at a time can we train 1 chunk of 784 pixels,True
@allanng78,2017-06-19T14:46:46Z,0,"Hi,  Can the code be changed to a multi-layer one. Please help me.",True
@nimishjindal9271,2017-06-10T08:44:44Z,0,"hi, excellent tutorials! I had a little confusion about the accuracy function used in your codes. does it represent the percentage of correct predictions by the network? Or does it show how accurate each prediction is wrt actual Y ?",True
@AminUllah-jz9uu,2017-05-28T06:58:10Z,1,how can i pass different length of sequence from RNN like there is fixed length 783 which is divided into 28 chunks  i want to pass different length of sequences with chunk size 16  could you help me out,True
@tothesun,2017-05-21T22:17:59Z,1,"So basically what we're doing here is dividing each sample up into ""time steps"" that the LSTM cells will have memory of and that's what all the reshaping business is about?",True
@AminUllah-jz9uu,2017-05-16T03:21:28Z,1,How to save trained model for testing new samples?,True
@tanmaykulshrestha4193,2017-05-15T08:31:49Z,1,"I understood this tutorial but I am confused with modifying it to make RNN autoencoder for the same problem. I am wondering if you can make a video for that, it'll be great!  Thanks :)",True
@BinuJasim,2017-05-10T15:08:12Z,7,Use Jupyter notebook for demos. It is much better than typing in a text editor and then running it from the terminal.,True
@antiagonista,2017-05-10T03:09:59Z,1,"Great video! I envy your Python fluency.  :-)  I just have a quick question regarding generating new data (i.e. observing the output and storing the internal states) at every time step. For example, for an LSTM trained on a sequence of characters, how would I proceed to use the trained LSTM to generate new characters, one at a time?  Well, now I have a second question: Is there a way to export the trained LSTM + output layer's weights and biases so we can run inference outside of Tensorflow?  Thanks a lot!",True
@adityasai0692,2017-05-02T11:24:59Z,2,"ValueError: Only call `softmax_cross_entropy_with_logits` with named arguments (labels=..., logits=..., ...)  cost = tf.nn.softmax_cross_entropy_with_logits( prediction, y) to this: cost = tf.nn.softmax_cross_entropy_with_logits( logits=prediction, labels=y)""",True
@KanskeGanskeGod,2017-05-01T22:07:42Z,2,"Hi, if you are having trouble running try these steps: go here: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/compatibility get the tf_upgrade.py code, upgrade the sentdex's file.  #Changes:     Old:         sess.run(tf.initialize_all_variables())     New:       sess.run(tf.global_variables_initializer())      Old:       x = tf.split(0, n_chunks, x)                                       New:     x = tf.split(axis=x, num_or_size_splits=n_chunks, value=0)      Old:     cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(prediction,y) )                                                                                       New:     cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(logits=prediction,labels=y) )  Important: Also apply changes in Sukumar's comments.  Hope that helps  :)  PS: Thanks Harrison, you da boss, not sure I would get through this without you :D Having no real background in programming or math, you've provided the perfect match of theory and practice!",True
@labregah1,2017-05-01T19:36:36Z,1,"Great video, thanks Do you know any source that explain RNN with prediction example rather than classification?",True
@luka-anicin,2017-05-01T17:25:51Z,2,"Hey guys, I have confusion about these networks. So when you are using let's say RNN/LSTM for task such as: sentiment analysis, translation or chatbot. I suppose that you need to convert your text dataset to some type of vectors, every time before working with that data, right? And if so, is there any like ""the best way"" to do that  or it really depends on dataset itself?",True
@alexandredamiao1365,2017-05-01T05:26:11Z,32,"I have a newer version of tensorflow and I was getting an error on the line: x = tf.split(0, n_chunks, x)  After I changed it to: x = tf.split(x, n_chunks, 0)  everything worked out! Just a heads up!",True
@IonicCascade,2017-04-24T17:55:37Z,0,"Great tutorial, having an issue with tensorflow though, after following you and making all the changes, I get this, running it on MacOS:    AttributeError: module 'tensorflow' has no attribute 'spilt'  Any idea how to install this module or fix this?",True
@DiapaYY,2017-04-17T18:54:40Z,4,For newer versions of tensorflow do this http://stackoverflow.com/questions/42311007/attributeerror-tensorflow-python-ops-rnn-has-no-attribute-rnn,True
@pigzrulez,2017-04-13T04:31:33Z,1,couldn't get it working with tensorflow.python.ops. I used tensorflow.contrib.rnn instead for BasicLSTMCell and static_rnn (instead of rnn). I'm guessing it was deprecated?,True
@xichenzhang8984,2017-04-04T18:04:01Z,1,"Hi sentdex, thanks very much for your excellent video. I am only a beginner, I want to know you just built a RNN with one hidden layer, and in this hidden layer, there is only one RNN cell, am I right? Thanks again",True
@tirub8863,2017-04-01T13:27:14Z,2,"Hi can you plz help me , i have problem when i am trying to use pos.txt and neg.txt  data for this RNN(LSTM) ,  but i am not able to do it bcoz of below error  ValueError: cannot reshape array of size 54144 into shape (128,20,20)  Here my batch_size is = 128 and n_input and n_steps is 20 , it bcoz  feature  vector is having some 423 values  while taking batch of 128 rows   numpy array is having 54144 size which is not possible to reshape with given parameters   How can i proceed ?  how we will choose these parameters like batch_size and n_inputs and steps ,",True
@g_oti3601,2017-03-27T09:07:50Z,1,"if we wanted an ouput for each pixel in the 28x28 matrix i.e 28 outputs, is it only outputs[-1] that we'll change to outputs?",True
,2017-03-20T17:19:22Z,1,"Thanks a lot for the tutorial,   I have a doubt about it. My concern is related to the RNN input and how the RNN process it.  Contrary to CNN, RNN input is not the entire image, but a row by row input.  Thus, the input is an array of different images (just a row) at the same time (the first row of each image is going to the RNN at  t=1, then the second at t=2 and so on)...  doesnt these ""different images"" rows acting as input at the same time confuse the RNN?  Does these different images must be correlated in some way? (i.e. a video sequence) In MNIST, there is no correlation as we are trying just to identify the number, right?  I know that perhaps my way of interpreting this, is not accurate. If so, please, let me know.  Thanks in advance,",True
@Danikarik,2017-03-19T17:39:08Z,0,"getting ""Cannot feed value of shape"" of placeholder when using ""pos"" and ""neg"" text files from https://pythonprogramming.net/preprocessing-tensorflow-deep-learning-tutorial/?completed=/using-our-own-data-tensorflow-deep-learning-tutorial/  I converted to train_x, train_y, test_x, test_y to numpy array and set n_classes = 2  other variables: hm_epochs = 3 n_classes = 2 batch_size = 128 chunk_size = 28 n_chunks = 28 rnn_size = 128  where did i make mistake?",True
@xro7117,2017-03-15T10:40:42Z,0,As far as i can understand the depth of the lstm network is dependant on the number of chunks (timesteps). In other words the network unfolds n_chunks times. Is my understanding correct?,True
@muditjain7667,2017-03-06T08:37:05Z,0,What does chunk_size and n_chunks mean here?,True
@faraazmohammed3693,2017-03-05T14:28:28Z,1,Hi Thanks for teaching RNN.. can you please have a tutorial on nlp (text classification) using RNN.well you have one with nltk but doing with neurons will be great,True
@yimingyan6390,2017-03-03T16:20:17Z,1,"I'm assuming 'n_chunks' is the number of time-steps and 'chunk_size' is the input vector dimension for each time-step, then what is the 'rnn_size' represent?",True
@hajirahafsa4193,2017-03-01T12:05:37Z,0,sentdex : can u please cover a tutorial for image captioning using show and tell code given on github? Bcz I really need help on this,True
@whatthe2530,2017-02-27T00:40:11Z,1,"Getting the following error using Windows 7 Python 3.5.2 w/ TensorFlow GPU CUDA 8.0.  from tensorflow.python.ops import rnn, rnn_cell ImportError: cannot import name 'rnn_cell'",True
@glongoria8004,2017-02-24T18:40:25Z,0,"Awesome video! I implemented a ""use_rnn"" function to use the rnn in the video. It seems to be working but I have a question, is the output ought to be non-deterministic? That is, every time i run the code, with the same input file (e.g. two.jpg) i got different results. Thanks.",True
@sixalphaone,2017-02-19T13:49:52Z,36,"tf.split has changed arguments order (https://github.com/tensorflow/tensorflow/blob/64edd34ce69b4a8033af5d217cb8894105297d8a/RELEASE.md):  ""tf.split now takes arguments in a reversed order and with different keywords. In particular, we now match NumPy order as tf.split(value, num_or_size_splits, axis).""  Now you need to type: x = tf.split(x, n_chunks, 0)",True
@sukumarh3646,2017-02-18T05:17:09Z,42,"For people using the newer version of tensorflow, you may get this error:   AttributeError: module 'tensorflow.python.ops.rnn'  has no attribute 'rnn'  go to this link to get the solution: http://stackoverflow.com/questions/42311007/attributeerror-tensorflow-python-ops-rnn-has-no-attribute-rnn",True
@cristinaheghedus1281,2017-02-15T10:01:37Z,0,"Hi, great video, I ran the code and it work super fine. But I have a question. Does this really count like an LSTM neural network? Or it's a simple RNN and we are using the LSTM cell?  I just need an LSTM code and I want to make sure this is good for me :D",True
@urvishnakum914,2017-02-09T05:51:52Z,4,"sir , i get this error can i get some help ?   ValueError: Variable RNN/BasicLSTMCell/Linear/Matrix already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:    File ""<ipython-input-4-dbc0fb083256>"", line 10, in recurrent_neural_network     outputs, states = rnn.rnn(lstm_cell, x, dtype=tf.float32)   File ""<ipython-input-5-ad727660c55a>"", line 2, in train_neural_network     prediction = recurrent_neural_network(x)   File ""<ipython-input-6-7c7cbdae9b34>"", line 1, in <module>     train_neural_network(x)",True
@DanielWeikert,2017-02-08T19:31:43Z,0,"Great tutorial. Is there a good way to learn how to reshape/transpose,... the tensors? I got confused with that.",True
@lkwjohn,2017-01-30T13:38:50Z,0,"Hi, any advice on what perm should we pass for the tf.transpose function?",True
@chrisv5330,2017-01-26T22:39:54Z,3,"Hi Harrison,  Thanks again for this video. Would you consider doing a video or two describing and showing how to implement an RNN + encoder + decoder for a translation problem? The few explanations about this on the web truly suck and the official Tensoflow explanation about this is the worst. This would be extremely interesting and useful!",True
@TheCanon03,2017-01-14T15:45:31Z,1,Can u please explain the actual significance of RNN size ? thanks in advance ...,True
@aneekdas8320,2017-01-14T06:13:24Z,156,"for those having problems understanding the format of the input :  say , u have a 5*5 image and u have 1 such image then it is :  x = np.ones((1,5,5))  so u have ,   x  =  array([[[ 1.,  1.,  1.,  1.,  1.],                      [ 1.,  1.,  1.,  1.,  1.],                      [ 1.,  1.,  1.,  1.,  1.],                      [ 1.,  1.,  1.,  1.,  1.],                      [ 1.,  1.,  1.,  1.,  1.]]])  now for the rnn u need to convert each row of pixel into a single chunk. so , u would have 5 chunks of 5 values each so, u need to convert each row to an array  x = np.transpose(x,(1,0,2))  this swaps the 0th dim with the 1st dim . so, u get shape of x as (5,1,5) which is 5 arrays of 1 chunk each of 5 elements   x = array([[[ 1.,  1.,  1.,  1.,  1.]],                    [[ 1.,  1.,  1.,  1.,  1.]],                    [[ 1.,  1.,  1.,  1.,  1.]],                    [[ 1.,  1.,  1.,  1.,  1.]],                    [[ 1.,  1.,  1.,  1.,  1.]]])  now , u need to remove 1 pair of extra braces . so flatten by one dimension  x = np.reshape(x,(-1,chunk_size))  so, u will have :  x = array([[ 1.,  1.,  1.,  1.,  1.],                   [ 1.,  1.,  1.,  1.,  1.],                   [ 1.,  1.,  1.,  1.,  1.],                   [ 1.,  1.,  1.,  1.,  1.],                   [ 1.,  1.,  1.,  1.,  1.]])  and finally u will need to split the entire thing into 5 chunks(5 arrays) x = np.split(x,n_chunks,0)  so, finally u have :  x = [array([[ 1.,  1.,  1.,  1.,  1.]]), array([[ 1.,  1.,  1.,  1.,  1.]]), array([[ 1.,  1.,  1.,  1.,  1.]]), array([[ 1.,  1.,  1.,  1.,  1.]]), array([[ 1.,  1.,  1.,  1.,  1.]])]  hope this helps :)",True
@xinpingzhang4506,2017-01-09T16:57:19Z,0,Why do we need to store states if it is not used anywhere?,True
@vinayakkailas,2017-01-03T09:32:31Z,0,Can you please cover a tutorial for sentiment analysis using LSTM,True
@quangtuonglam9067,2017-01-02T09:25:11Z,0,Thanks for the great video. And Can you help me how to use RNN to text summarization with TensorFow?. Thanks a lot!,True
@thegeniusfool,2016-12-07T10:48:37Z,1,"Epic epoch :-) Otherwise, love your videos, man. Wish we could exchange some knowledge. You --> me = ML. Me --> you = Python coding practices.  Keep it up!",True
@anmolsjoshi,2016-12-01T03:33:11Z,0,How would one use this method for text data?,True
@vineetkaushik5044,2016-11-18T22:57:43Z,0,How do we process stock data using this?,True
@gissemari,2016-10-23T16:30:00Z,0,"Hello. I still have trouble understanding the concept of cell, can we see rnn_cell.BasicLSTMCell as a definition of a layer?",True
@mohammadrezazahiri7490,2016-09-24T23:29:54Z,1,"Hey Harrison, thanks for your great videos. Actually there are two things that I don't understand, 1- The input format does not make any sense to me, it seems the input is a 2D matrix with size of (batchsize*chunck_size,n_chunck) which I guess it means that for e.g. the RNN is being trained at first with the first row of all the images in the batch and then gets trained with  all the second row of images and so on, is that right ? If so this doesn't make any sense to me. 2- Can you clarify on size of the 'outputs '? is it (batchsize, RNN size)? If so, by considering outputs[-1] in the next line, we just pass the last row of outputs (the last row of all images) to matmul which this also does not make sense to me . Thanks",True
@DaRealDJ,2016-09-24T04:35:49Z,0,Any tips for a time series with continuous data forecast version of RNN? I'm having a bit of trouble understanding how the chunk_size and n_chunks with the transposition would translate for that code. Nearly everything I google is focused on sentence or MNIST data or overcomplicated for a basic example to backwards engineer.,True
@Sunnyc432,2016-09-23T04:29:20Z,0,tensorflow-0.5.0-cp27-none-linux_x86_64.whl is not a supported wheel on this platform.   i got this error and i can't fix it?,True
@MasthaX,2016-09-22T10:35:51Z,0,"I've been following allot of  you video's. I was working on some NN's in Caffe which also worked pretty well. I really like the hands-on approach which is way easier for me to understand (as a long time programmer) than all this academic terminology which is usually the case when it comes down to neural networks.   I was trying to get the epoch number saved in the model by assigning a new TF Variable counter variable (as described in the docs) and increment it every epoch and after that saving it to a checkpoint with the saver. However my counter never increments, but that's just a little thing I have to find out, it is possible. Looking forward to more stuff!",True
@chrisv5330,2016-09-20T20:26:57Z,0,"Hi Harrison. Would you be able to do a tutorial on using a RNN + LSTM on sentence translation? For example from English to French. That is truly sequential data and the sentences/sequences are of varying length. It would be awesome to see you explain this, given that the Google tensorflow documentation about this is extremely bad.",True
@schoneschone,2016-09-19T15:42:35Z,18,"great tutorials as always! question tho... you explain you're doing reshaping/transpose/etc to fit the requirements of the rnn, would love if you could elaborate more and explain those three lines better.  Also why didn't epoch_x be reshaped for the final needed shape already and had to do further reshaping inside the recurrent_neural_network(x)? why couldn't it be shaped already as per the requirements of the rnn which i assume is - [batch_size, input_size] ? (thats the only thing i could find in the API docs)",True
@chrisv5330,2016-09-15T23:48:11Z,0,"Thank you, thank you, thank you!!!!!!! You're the best sentdex!",True
@cebas9472,2016-09-15T02:42:20Z,0,dude you rock  holy fucking christ never seen another yt channel like this before i don't have words to describe it thank you so much man,True
@sixthinsomniac,2016-09-14T22:25:21Z,0,"Hey Harrison, thanks a lot for the invaluable content that you've been uploading. Have you considered using Jupyter notebooks to write your code ? It'd make it a whole lot easier for anyone to jump straight in without having to copy paste or type out again.",True
@kevinz1777,2016-09-14T22:19:48Z,5,Thinking of covering Keras sometime down the line?,True
@DaRealDJ,2016-09-14T19:00:50Z,0,I want to thank you for these amazing tutorials. Its great for both learning the concepts and the coding in extremely easy to understand ways. And the website tutorials is amazing for practicing the code on my own.,True
@acelere,2016-09-14T18:20:35Z,7,"Hi Harrison, as always, great video. But I lost you there when you reshaped, transposed and split the input data... on the classic NN, it was easy to understand you had ""unfolded"" the image... but now I could not follow... could you explain a little better? perhaps and example? tks!",True
@blaksand1,2016-09-14T17:49:18Z,0,your so awesome brother I respect you alat,True
@RaoufGnda,2016-09-14T15:27:45Z,0,amazing as usual  and still waiting for your tutorial about the ConvNets for text classification .,True
@K6G8M9P0,2016-09-14T14:29:54Z,0,Thank you for your videos :),True
@toprakozturk3150,2016-09-14T13:43:26Z,10,"Those tutorials are awesome, keep them coming!",True
@ImGooblie,2016-09-14T13:42:51Z,0,you rock man,True
