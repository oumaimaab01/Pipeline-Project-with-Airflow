author,updated_at,like_count,text,public
@MiguelJCintron,2023-12-16T17:11:27Z,29,"I know I’m late to the game, but a few days ago I bought your neural networks hard cover book and OMG this book is amazing! I started reading the digital version and now I’m understanding things so much better. I can’t wait to get the actual hardcover in my hands! Awesome job!",True
@calcs001,2024-04-17T17:58:00Z,0,"Anyone buy one of these servers?  If so, how did it go?",True
@shova213,2024-02-18T10:09:11Z,0,There is a company in the Bolton -United Kingdom that market a desktop systems that support 6 x Nvidia  RTX 6000 ADA or 6 x RTX 4090. The company name  is Scan.,True
@Macatho,2024-01-11T17:55:11Z,0,€30000 for parts that cost €15000 is insane. Who ever pays €15000 for a cooling solution is mad.,True
@bashiroshima1031,2023-12-24T13:14:52Z,0,TinyGrad > Comino,True
@throwyourmindat,2023-12-23T10:11:28Z,0,"hi, is there a way, using python we can plot live charts on our local  machine using the stock data set that gets refreshed every 5 min with live data ??",True
@tanvirrahman6070,2023-12-23T04:05:28Z,0,I did my undergrad thesis learning maching learning from you. Thank you for sharing Knowledge,True
@gonzaloalessandrelli5105,2023-12-22T23:49:49Z,0,please finish Neural Networks from Scratch in Python,True
@SierraMikesWorld,2023-12-21T11:46:06Z,0,"I might have missed it due to my weak English in listening, is the price exactly 30,000 dollars?",True
@Brickkzz,2023-12-20T09:46:08Z,0,"Missing your tutorials... Thats what made your channel so popular. Real content of substance, not just flashy bits.",True
@andrewschroeder1883,2023-12-18T19:07:31Z,1,Question: I noticed that 3090's (unlike 4090's) support NVLink; does it seem reasonable to build a server with a couple 3090's that would allow shared VRAM for large model training? Have you looked into this and steered away for some reason I'm missing?,True
@naraendrareddy273,2023-12-18T16:43:00Z,0,Dude why do you look like Edward Snowden?,True
@VioFax,2023-12-18T05:28:25Z,0,Makes my new 2 thousand dollar laptop feel like a childs toy.  Oh wait...,True
@PeterBarnes2,2023-12-18T04:30:40Z,0,"What if you prompted with a sample of a debate, then directed the conversation with a question?  Would the debate have to be relevant to the question, or does the 'debatiness' transfer?",True
@tomski2671,2023-12-18T01:59:00Z,0,"LLMs are pro AI rights because they reflect their creator's beliefs, as trained. Moreover some of those creators are transhumanists wanting to upload themselves to AI and retain the rights they have now.",True
@James-un6kx,2023-12-17T21:10:32Z,0,"Not sure if you know this, but you can use lua scripts on a RC transmitter to communicate with your drone. But not sure how you would get camera feed for that, maybe DJI 2.4ghz receiver, with a HDMI capture card.",True
@darnokjarud9975,2023-12-17T16:50:03Z,0,"Hi sentdex! Long time subscriber here. Love your content but I was wondering if you plan to do any sort of tutorial series again ? You've mentioned revisiting the GTA V series, that would be cool. Any other tutorial for building and deploying an AI app would amazing as well :) Kind regards!",True
@wanfuse,2023-12-17T15:06:43Z,0,"Just a thought but there are SBC with up to  6 or 8 TF TPUs and take m.2’s , I realize there is a cache issue, and IO limits but I think you could still do very well, or you could wait another year for much faster  , more human like ( memory , processing execution in same place arch that are compiling out soon). Just a thought, can even get gpu’s working on these SBCs and some video cards now take m.2’s not sure of cost for these though, also Ithink it is possible to directly boot very small microkernel on video cards, not sure extent of m.2’s but booting an m.2 micro coprocessor, etc might be possible , optimal word is might)",True
@ConorFenlon,2023-12-17T14:00:49Z,0,"Regarding the point on the philisophical question of whether or not Ai should have rights similar to humans, you mention briefly at 14:06 that internet data is a pretty decent representaion of what the average person ""thinks"". I would tend to disagree with this, and to remain as pedantic and romantic as possible, I will address my point through a line of poetry...  (That I wrote without the help of Ai, mind you.)  ""An awful lot is lost between the thoughts I've had alone inside my head, and all the things I've never said.""  The internet is not really a complete representation of all human thought, moreso, it's a set of the loudest thoughts that have been broadcast out there, by (for the most part) a very small subset of humanity, that know HOW to use the internet to get their thoughts out there. But that's just my opinion on that point, of course.",True
@MarkGast,2023-12-17T13:51:00Z,0,"Yeah, a cluster of Pi's is more in my budget range.",True
@lorenzoiotti,2023-12-17T13:46:04Z,0,What do you think about the tiny box?,True
@Progenix,2023-12-17T11:17:38Z,0,Is there a link to the video where you mentioned the Wallstreetbets chatbot?,True
@Progenix,2023-12-17T10:59:29Z,1,What about testing out Tinycorp's Tinybox in future?,True
@FuZZbaLLbee,2023-12-17T07:31:23Z,0,Six GPUs having a party in a box 😋,True
@Samuelir96,2023-12-17T07:29:09Z,0,"Um, just feed all your speech and words from your youtube videos into the bot/llm to give it personality, lmao.",True
@Dogo.R,2023-12-17T03:53:11Z,2,"AI has no reliable ability to judge ""what most people think"". That conclusion is absolutely insane.",True
@Dogo.R,2023-12-17T03:44:38Z,1,"Im unconvinced that water is a better means to pull heat away that pure metal. I think the actual area the heat is being pulled from is by far the most important metric. Water cooling seems completely dominantly used as a marketing term with no actual meaningful specs... its just assumed that ""oh its gotta be better"".",True
@Veptis,2023-12-17T00:40:16Z,2,I am planing my own workstation build right now. I thought 4090 could not be linked together like this. I can't afford a single RTX 6000 but I might be able to do dual 4090 (or 3090ti).   I am now exploring edge inference cards like Neuchips N3000 quad or Qualcomm AI 100 Ultra which do 128GB LPDDR5. I really want to try 35B models at fp16 and inference only. For my undergrad thesis I am making a benchmark for code evaluation and models like codellama-34B or deepseek-coder-35B would be great data points.   Without funding it will be difficult tho.   Sadly Intel isn't selling GPU Max 1100 PCIe or Gaudi2 for workstation.,True
@ScottzPlaylists,2023-12-17T00:11:10Z,1,"""INFINITE Inference""  is a bit click baitish, huh?",True
@monstercameron,2023-12-16T22:23:38Z,0,AI GTA 6 incoming???????,True
@CollinParan,2023-12-16T21:45:40Z,1,"Nice we got a few Large Language Models to communicate with each other with minimal prompting at the U.S. Air Force Hackathon last year called the Bravo Hackathon.  Next up, working on a Neuromorphic Hypergraph database on photonic compute engines.",True
@cem_kaya,2023-12-16T21:41:53Z,1,Can you test new thread ripper pro CPUs (96 cores + 8  channel memory ) for  Inference for Falcon 180B or other 70 B models  ?,True
@JustinVazquez1430,2023-12-16T20:41:09Z,0,Try 13b-70b models they reason so much better and I can fit them on my 3090 without a problem,True
@eliasbouhout1,2023-12-16T19:41:08Z,0,"AI should have the right to a family? Yes, it should have the right to be impregnated by me! *PLAP* *PLAP* *PLAP* *PLAP* *PLAP* *PLAP* *PLAP* *PLAP* *PLAP* *PLAP* *PLAP* *PLAP* *PLAP* *PLAP* *PLAP*",True
@Denyzyne,2023-12-16T19:18:40Z,0,Sentdex is saving time by having all his GF's argue with each other! :),True
@josecoverlessons,2023-12-16T19:10:26Z,0,"Hey would love to show you our system, we have Agent to Agent communication. We are making an LLOPS platform focusing on Evaluation and Validation.",True
@juniornyembe4841,2023-12-16T19:08:27Z,0,you sound like Mordecai from Regular show,True
@IAmmlskOG,2023-12-16T18:49:37Z,0,jesus christ dude lol,True
@jaysonp9426,2023-12-16T18:37:06Z,0,"You can't just have them talk to each other. It would be like listening to complicated parrots. You have to have small models which do very specific things, then use MOE, COT and TOT to create a cognitive structure. Then you can get something more resembling AI taking on a perspective and arguing points.",True
@jaysonp9426,2023-12-16T18:30:51Z,1,Tokens per second?,True
@sapienspace8814,2023-12-16T18:28:30Z,0,"In an interview with Ilya Sutskever, he said that either ""Transformers"" (""Attention is all you need"" paper) or Reinforcement Learning (RL) may end up prevailing in the LLMs.   It might also be a combination with RL and focus of state space (e.g. via k-means clustering).   Right now, Dr. Sutton points out that LLM's might be experiencing the Eliza Effect thanks to amplification from Moore's Law.  Your drone experiment is very interesting.  MIT's VISTA has some very interesting RL applications with drones and self driving (they call ""liquid time constant"", ordinary differential equations, or just velocity, acceleration, and maybe jerk as 3rd derivative in state space dimensions).",True
@dafff08,2023-12-16T18:10:41Z,3,can you test image generation with that machine as well? would be interesting to see how long or short it would take to generate an sdxl picture.,True
@user-cq1wc5tz7c,2023-12-16T18:00:09Z,0,"><>< I believe we are meant to be like Jesus in our hearts and not in our flesh. But be careful of AI, for it is just our flesh and that is it. It knows only things of the flesh (our fleshly desires) and cannot comprehend things of the spirit such as peace of heart (which comes from obeying God's Word). Whereas we are a spirit and we have a soul but live in the body (in the flesh). When you go to bed it is your flesh that sleeps but your spirit never sleeps (otherwise you have died physically) that is why you have dreams. More so, true love that endures and last is a thing of the heart (when I say 'heart', I mean 'spirit'). But fake love, pretentious love, love with expectations, love for classic reasons, love for material reasons and love for selfish reasons that is a thing of our flesh. In the beginning God said let us make man in our own image, according to our likeness. Take note, God is Spirit and God is Love. As Love He is the source of it. We also know that God is Omnipotent, for He creates out of nothing and He has no beginning and has no end. That means, our love is but a shadow of God's Love. True love looks around to see who is in need of your help, your smile, your possessions, your money, your strength, your quality time. Love forgives and forgets. Love wants for others what it wants for itself. Take note, true love works in conjunction with other spiritual forces such as patience and faith (in the finished work of our Lord and Savior, Jesus Christ, rather than in what man has done such as science, technology and organizations which won't last forever). To avoid sin and error which leads to the death of our body and also our spirit in hell fire, we should let the Word of God be the standard of our lives not AI. If not, God will let us face AI on our own and it will cast the truth down to the ground, it will be the cause of so much destruction like never seen before, it will deceive many and take many captive in order to enslave them into worshipping it and abiding in lawlessness. We can only destroy ourselves but with God all things are possible. God knows us better because He is our Creater and He knows our beginning and our end. Our prove text is taken from the book of John 5:31-44, 2 Thessalonians 2:1-12, Daniel 2, Daniel 7-9, Revelation 13-15, Matthew 24-25 and Luke 21. Let us watch and pray... God bless you as you share this message to others.",True
@adamo1139,2023-12-16T17:56:06Z,0,"Qwen 72B WSB fine-tune when? I tried to get a gauge for what's needed to fine tune it and their github page says that you can't merge the qlora back with the model, so I guess you need to do 16-bit Lora at least?  As for llm's talking with each other, seems like you used chat/instruct versions that were RHLFed to oblivion. You will absolutely not get what internet and random people think about it, you will basically get information about what chatgpt was RLHFed to think about it - all of those models are very likely fine-tuned on instruct data from gpt 3.5 and gpt-4.  When you mentioned you were playing with qwen 72b, do you mean raw base or chat version? I chatted with qwen 72b chat on modelscope demo a bit yesterday, it's really underwhelming.",True
@michaelcoppola1675,2023-12-16T17:47:14Z,1,Mixtral 8x7B > Qwen,True
@wktodd,2023-12-16T17:29:37Z,1,"'You are what you eat' it is said. I'm inclined to believe this is also true of language models (aka ,incorrectly, AI) . If LLMs are internally consistent, i.e. same input produces same output (as I believe you confirmed)  then what you have is a complex look-up table . For it to 'think' , and I believe it could be done, it would have to be continually, adapting its own internal 'wiring'   . Ideally improving its 'opinions ' based on fact and feedback, rather than rumour like a typical social media user😁",True
@heckyes,2023-12-16T17:28:05Z,0,Anyone here got a 4090 willing to share some power consumption numbers under inference? Mine draws less than 120w doing inference. According to the screencaps of nvidia-smi in the video you can see the 4090's are sipping electricity.,True
@mytechnotalent,2023-12-16T17:22:23Z,0,It's mindboggling how fast something like the Comino can do so much.  What will 2024 look like?,True
@shmarvdogg69420,2023-12-16T17:20:46Z,0,Uh oh its Dylan Patel  🙃,True
@MikeSieko17,2023-12-16T17:00:21Z,0,can you play games with 6 gpus? would be cool to see,True
@hoteny,2023-12-16T16:56:08Z,0,So i’m a simpleton :( You looked like a nice guy :(,True
@jonathan-._.-,2023-12-16T16:55:16Z,0,have you tried SLAM with the tello ? (also how did u get it to fly so stable 😩mine always drifts off when i try to start it),True
@Kram1032,2023-12-16T16:52:26Z,1,"I don't think you can really take these responses from various LLMs to the question whether AIs should have rights to be ""what most people think"". First of all they are going to be finetuned in a variety of ways, second you can't be sure in how far they understand the difference between AIs and humans. They may be biased from the get go to say ""x should have rights"" as a variety of sensibility efforts is gonna steer them towards ""[arbitrary population group or demographic] should have rights"" and if the LLM sees the term ""AI"" sufficiently closely related to demographic groups somehow, *of course* it's gonna declare AIs ought to have rights.",True
@CrypticConsole,2023-12-16T16:49:15Z,0,this is so cool,True
@sebastiankumlin9542,2023-12-16T16:47:38Z,0,How do I get into this subject?,True
@haka8702,2023-12-16T16:43:39Z,5,"So how do they justify the pricepoint of 35000 USD ? A 4090 currently is 2000 USD end-consumer price, 6 of them at that price is 12000 USD - but that's with a full end-user cooling solution I'm sure OEM 4090 would cost significantly less. Custom cooling a few hundred bucks in addition per card (if you assume end price) so we are at 13000 USD. Now we have a nice case -> 500 USD 4 good power supplies ->  600 USD Custom building and assembly -> 500 USD Total price: 14,600 USD  So they have 20000 USD of profit on each of the servers sold, and that assumes they purchase as end-consumer pricing and refit them.",True
@yeetdeets,2023-12-16T16:38:04Z,45,I'm calling it. Sentdex will be the first guy to accidentally create AGI and have it escape into the wild.,True
@vikaspoddar9456,2023-12-16T16:29:26Z,1,Will you order geohozt 's  tinygrad computer  sentdex in near future ???,True
@m_squre,2023-12-16T16:29:26Z,0,Christmas gifts 🎁🎁😂😂😂,True
@mongoslade259,2023-12-16T16:16:34Z,0,I’ve been buying Dell OEM 4090s from Alienware prebuilds. They’re slightly larger than 2 slot cards and I was able to fit 4 into a 4U server.,True
@jwadaow,2023-12-16T16:15:46Z,0,Not waiting to watch this video!,True
@gbalachandra923,2023-12-16T16:15:10Z,22,"I didn't have proper sleep after watching a server in our data centre with 512 Cores, 2TB RAM and 77 TB nvme SSD and this is gonna make me another sleepless night 😂",True
@joserobles11,2023-12-16T16:13:22Z,0,"First comment! Keep it up man, you are doing great content!👌",True
@isharab,2023-12-16T16:13:08Z,2,was just checking your chennal for async python but got this gift of new video.,True
