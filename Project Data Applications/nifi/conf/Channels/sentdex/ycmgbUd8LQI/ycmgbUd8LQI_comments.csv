author,updated_at,like_count,text,public
@holdhold345,2024-02-08T17:11:47Z,0,what version of number or opencv was used in this because all the code works except it will not save the training data and can not open the training data because it does not like it have two different shape array in the file,True
@iamtree4764,2023-12-12T01:58:04Z,0,I am sorry but did you make gas blue and minerals green for the visualization. It does not matter but why flip them.,True
@vladimirtchuiev2218,2022-06-17T12:22:53Z,0,"I don't understand the data that you are saving. With images I would expect saving a full game will take about tens of gig, but your file is about 2.5mb. For supervised training you need both the network inputs and expected outputs, and you only described the outputs. Is the input the representation you are feeding? Because if it so I would expect it to be very large in size.",True
@FirstLast-gk6lg,2020-10-21T01:03:33Z,0,"Very unclear about saving the training data. you make it sound like people should just drop the entire cloned repo into the file containing the current project, then you mention something about paths that you already changed but don't show in the video.",True
@nesmaashraf3427,2020-02-28T15:39:34Z,0,"this is so helpful ,thx alot . but please where can i find the training data ?",True
@davedumas0,2020-02-15T22:50:30Z,0,"is there a way to go online and ""train"" with real players ?",True
@ymcho4037,2020-01-29T18:01:00Z,0,"For those who got stuck on saving the training_data on Windows this worked for me:  1.copy and replace over all of the sc2 contents from Daniel to .Python3x\site-packages\sc2 of course make sure you have SC2 game path corrected.  2.make sure you use backslashes   example for me ""D:\\sentdex\\Starcraft\\train_data\\{}.npy""",True
@wyxam6849,2019-03-27T20:38:31Z,0,WaIt tHaTs NOt PyChARm,True
@goodguidegreg,2019-03-17T19:28:25Z,0,not sure how i can let multiple  instances run at the same time. how can i do that?,True
@pawehajdecki9245,2019-03-14T18:26:44Z,0,"I think you went into wrong direction here. Relation between choice 1,2,3,4 and winning is to hard to learn. Your reward/goal need to be structure that happens in 1-2 minutes. F.E. collect as much minerals/gas as possible in 2 minutes, Bot has to choose, build workers, build nexus, build extractor, build pylon. Or goal is to get to 200supply ap in shortest amount of time possible. But hte most important thing - Come'on man after deepmind presentation in January we beg for MORE of the series. It's the most informative I found, I am learnign neural nets, tensor flow based on that. Put some idee into work. DOn't make us beg. Serious is awesome. Keep up good work Sente",True
@masonm600,2019-02-09T19:43:07Z,0,So the training data is based on your code playing bots? How do we update the training data when we have better algorithms?,True
@thedosiusdreamtwister1546,2019-01-31T05:38:18Z,0,Any thoughts on this project in light of the recent developments with AlphaStar?,True
@Xaminn,2018-12-26T04:33:47Z,1,"How would I go about upgrading the weapons and armor of my void rays? I've read through some of the documentation and I'm not finding anything. If anyone knows, the answer would be much appreciated.:)  Merry Christmas!",True
@sevabr3167,2018-11-24T18:16:47Z,0,"In russia, pls",True
@MackTheTemp1,2018-09-23T12:27:03Z,0,"It'd be cool if your mac workers function accepted #nexus, #mineral patches w/in 15 of nexus, and maybe clock/time as variables.   It may be possible to try and scrape build orders from replays and have the bot try and replicate the ordering used by pro players who match their timings/builds/ordering vs tho clock. Resources gathered, spent  and build orders are typically matched against the clock for pro analysis. Seems like this fits well in learning because the network can be trained to compare actual build order vs pro build.",True
@rohanpaleja,2018-08-30T05:29:09Z,0,"Just for a clarification, is the simplified diagrams made with opencv being saved and used as the training data into the neural network? And if so,  is each frame being fed into the neural network as one training example, or is the set of frames that correspond to a win being fed in as one example. Is the neural network learning what action to take, given the input opencv image, to win the game? or what action to take to move into another state that will win the game? or both?",True
@Wurstfinger-rl1zi,2018-08-07T01:57:58Z,0,"Hmm... for me it just won't work. I tried nearly everything to save the training data, but it doesnt create a file in my directory. Could someone please help me?",True
@adfggdddvg,2018-08-05T18:00:17Z,0,How many different fancy cups do you have :) ?,True
@SeamusHarper1234,2018-08-04T21:46:54Z,0,"Question: Why do we have to draw out all that info with opencv to feed it to the network? Can't we just feed it directly with all the data that py-sc2 delivers? Like feed it with self.units, self.known_enemy_structures, self.known_enemy_units? Wouldn't that be more precise?",True
@evanrk,2018-08-02T01:35:17Z,0,I found a time module in bot_ai.py it says that time() assumes that the game is played on 'faster' I don't know what that means though,True
@MaksUsanin,2018-07-25T13:31:22Z,0,where I can find information how to build the training data for myself ? a specifically how to run multiple games at same time ? how to run in background mode? its because for better understanding I want to repeat for myself,True
@animavesta955,2018-07-19T07:07:29Z,0,What do I do if my train data is not saving?,True
@Seeker265729,2018-07-17T07:20:10Z,0,I think you might want some persistence with the known enemy  units.  In particular it looks like once in fog of war the known enemy units method drops off those units.  It might make sense to essentially copy known enemy units list and elements that drop off known enemy units can continue to persist in the copy for some period of time.  Because there is physics involved units can only move so fast so known enemy units don't actually disappear just because you can't see them.  They are probably still nearby,True
@herryfrd2740,2018-07-13T17:15:01Z,0,i wanted to do this for my MS thesis over a year ago. my advisor wouldn't let me pursue it :(,True
@Cyphlix,2018-07-13T11:59:33Z,0,"if you're using anaconda(windows), first *pip uninstall sc2* *python **setup.py** install* ..then ^ on the forked repo. ‚ú´ÂΩ°",True
@s10rollinon20s,2018-07-13T08:11:38Z,0,What about using game loop to track time more accurately  https://github.com/Dentosal/python-sc2/issues/29#issuecomment-403017950,True
@Gravity360,2018-07-13T03:03:48Z,0,"Need to build some sort of db or index of all the enemies possible units.  From there you could make the system do calculated / weighted scoring so that it can determine the best counter units to the predicted attack.  Anyways, I am absolutely loving this.  PS if you're not aware there's an SC AI tourney held on Twitch called SSCAIT,  check it out here.  https://www.twitch.tv/sscait",True
@tormentedbacon4573,2018-07-12T05:46:49Z,0,"Here's some easy code to buff the voidrays.    I noticed they have an ability that boosts their damaged against armor for 14 seconds, so this code just activates it everytime it's available.   Not the most efficient way to use it, but better than never using it.   Just call it from the on_step function.   async def activate_voidrays(self):   for vr in self.units(VOIDRAY):    abilities = await self.get_available_abilities(vr)    if AbilityId.EFFECT_VOIDRAYPRISMATICALIGNMENT in abilities and self.can_afford(EFFECT_VOIDRAYPRISMATICALIGNMENT):     await self.do(vr(AbilityId.EFFECT_VOIDRAYPRISMATICALIGNMENT))",True
@tormentedbacon4573,2018-07-12T01:09:43Z,0,how many victories do you need for the training data?,True
@momomo951,2018-07-11T21:51:25Z,2,"just starting sponsoring! Because of you, i'm now doing a computer science degree.",True
@fodort,2018-07-11T21:46:06Z,1,"I am so excited about this series, I can't keep on waiting the next episode!",True
@tommyjado127,2018-07-11T21:17:31Z,1,great mug,True
@erickgm8467,2018-07-11T21:12:39Z,5,"Melhor canal, estou vendo todos os seus v√≠deos, abra√ßo do brasil /Best channel, I'm watching all your videos, hug from Brazil",True
@konopyanov,2018-07-11T20:22:33Z,0,"Hi, when will be next video?)",True
@Yousef95a,2018-07-11T15:06:53Z,0,For in game time you can use self.state.game_loop which is 22.4 per second,True
@bartsikorski,2018-07-11T12:03:08Z,2,You can get game time in seconds using:   game_loop = self.state.game_loop self.timeinseconds = game_loop / (22.4),True
@atifshaik9329,2018-07-11T07:26:55Z,0,need help in memory card game pls contact me,True
@shyampadia,2018-07-11T06:53:22Z,0,You can get the game time using self.state.game_loop * 0.725 * (1/16) and this is real time (you can check this in main.py). Also an iteration is 8 game loops.,True
@afbdreds,2018-07-11T05:36:43Z,3,is it possible for league of legends?,True
@tormentedbacon4573,2018-07-10T19:21:15Z,0,"Here's some alternative scout code I wrote.   It gets more information.   I actually have 2.   The first one I tried just went to the base and then used the ability to extend range.    I'll share it as well if that's what you want to do, but I find the 2nd one works better, while the ability code isn't really any better than the small roaming code from the video.  Basically what it does is it searches for the closest expanding points to the enemies base(and the enemy base itself), and then it randomly moves to each one, then the next, etc.     I currently have mine set to build 3 observers, they start dying pretty fast eventually, but you can tweak that.  You can also tweak the number of points to scout.  A good way of doing it would be to add to both as time goes on, but I don't have that coded.  Only started python a week ago, so if code can be improved, let me know.     You need to add 2 imports  from math import sqrt from operator import itemgetter  And here is the current code.   async def scout(self):   if (len(self.units(OBSERVER).idle) > 0):    locations = [[0, self.enemy_start_locations[0]]]    for possible in self.expansion_locations:     distance = sqrt((possible[0] - self.enemy_start_locations[0][0])**2 + (possible[1] - self.enemy_start_locations[0][1])**2)     locations.append([distance, possible])    locations = sorted(locations, key=itemgetter(0))    del locations[5:]    for s in self.units(OBSERVER).idle:     await self.do(s.move(random.choice(locations)[1]))   And here is the other function.     If nothing else it shows how to use an ability.     It doesn't require any imports, but you do need to add the ability to the constants list(I use * to import all).   async def scout_old(self):   if (len(self.units(OBSERVER)) > 0):    for s in self.units(OBSERVER).idle:     if s.distance_to(self.enemy_start_locations[0]) > 30:      await self.do(s.move(self.enemy_start_locations[0]))     else:      abilities = await self.get_available_abilities(s)      if AbilityId.MORPH_SURVEILLANCEMODE in abilities:       await self.do(s(AbilityId.MORPH_SURVEILLANCEMODE))       print (""Observer in Surveillance Mode"")   Alternatively you can combine the 2 and just send a scout to each node and have them sit in surveillance mode.     But the moving one above seems to provide lots of information.  PS:  Your tutorials are awesome.     This code wouldn't have been possible without them, I've watched a bunch of them including the basics.   Thanks a ton for them.",True
@Kleinernervenkeks,2018-07-10T18:07:19Z,2,"Sentdex I really love your videos, they made me love python and im always looking forward to them. Especially as a gamer Im very happy abput this series. But for the sake of the performance of this network you should really get into sc2 first. learn some of the stretegies and information that is needed for a good player. For example suing an observer as your first scout gives you information about the enemy WAY to late . most people send one of their enital probes or the first or second probe you build, etc pp   Of cource i can understand that you want to build a working network and a proof of concept first but It would be so much wasted time if you build up a pile of training data which is more or less bad  thanks for all the effort you put into this!",True
@MrFadbamsen,2018-07-10T10:08:46Z,0,"When I'm running the script against a hard bot I never win, but against a medium, I almost always wins. I can't really see how its supposed to learn that much then. Well, guess I have to wait for the next episode then :) And also I had a couple of divide by 0 errors maybe its an idea to change that part of the code. But this for the series it's really interesting.",True
@fanjerry8100,2018-07-10T02:43:31Z,1,What if stuffs move into the area you're graphing the bars for minerals etc?,True
@vmikeyboi323,2018-07-09T23:13:19Z,5,More of this series please!,True
@benjaminjaton3597,2018-07-09T21:31:43Z,0,"If you do sentebot AI vs sentebot AI , won't you repeat the same game over and over again?",True
@oxrock2k1,2018-07-09T21:07:39Z,0,"I've been following along making a Terran bot with this series and I've found some solutions to problems that I think that you may find useful: https://github.com/oxrock/RockBot_python_sc2_bot  Among those solutions are a more robust scouting function, army retreat functionality, military upgrades, a means of accurately tracking game time and a few Terran specific headache solutions that other adventurous fans of your series might encounter.   Hopefully yourself and/or my fellow fans find this useful.",True
@Petch85,2018-07-09T16:55:20Z,0,"I used the constant=run_game. If you are playing only one bot against an game AI or a human it will return only one value. If you are playing bot vs bot it will return two values. also you can end up in a tie... I got all that working. But now I cannot play bot vs bot anymore. The game refuse to load. it will just open two SC2 windows and leave them black, and then nothing. I have tried reinstalling the game, deleting the cash but nothing works. If someone have found the solution to this problem please let me know.",True
@ethanwade9394,2018-07-09T15:42:40Z,0,"For the Supply ratios, because they are ratios you could make them bars of fixed length that vary in color between two colors.  For example, a ratio of 0 for any of the lines would just be (0, 0, 0), then as the ratio approaches 1 it would be (255, 0, 0).  Each ratio would have its own end color.  The network would potentially have a better time learning those color gradients of a fixed length bar; rather than the variable length bar.",True
@compactwoodhplcladding,2018-07-09T13:34:28Z,2,coolÔºÅ,True
@tomar5e115,2018-07-09T11:04:02Z,1,Gotta attack the workers first mate and not waste time on attacking buildings üëç,True
@archiatrus1093,2018-07-09T08:59:17Z,0,Regarding time: look here https://github.com/Dentosal/python-sc2/issues/29#issuecomment-403017950,True
@EmberQuill,2018-07-09T01:57:36Z,2,"I tested pitting two bots against each other and it looks like run_game returns a list of results instead of a single result when more than one bot or human is playing: [<Result.Victory: 1>, <Result.Defeat: 2>]  So it shouldn't be too hard to have two bot objects (bot1 and bot2, for example), and then just check which bot won and save that bot's training data after calling run_game.",True
@nznoir,2018-07-09T01:28:45Z,0,"+SentDex self.time_ = self.state.game_loop*0.725*(1/16) << Will calculate time. In real seconds. Also, tagged you in Discord with some more information and a mistake :)",True
@alexs477,2018-07-08T21:58:18Z,1,"You could also build a nn to choose which attack units to build.  You could simply input the map you already built and output the probability of building each unit, cancel building the unit, or wait.",True
@nathanwhittle1,2018-07-08T20:06:15Z,0,"Your issue with defeat/victory detection could potentially be solved by detecting when the game should be conceded by a bot- say when you have no units and buildings left for example, then quitting the game via the API call after setting a class field in your bot class to store that decision. In your run game loop, you can view the bot class objects after the game is complete and check that field and save the other bot's training data as a victory there. That would speed up training times as well since defeats would be detected quicker depending on the complexity of the detection logic (you could train an AI to do just that!)",True
@MistaT44,2018-07-08T18:48:46Z,0,A little off-topic. I followed ur nltk series. I copied the whole source code but reduced the size of the all_words list to adjust according to my laptop‚Äôs processing power. But the module is making basic predictions wrong :(. ‚ÄúThis movie is good‚Äù is being predicted negative with 1.0 confidence. Any clue what might be wrong. Many thanks,True
@AbhishekKumar-mq1tt,2018-07-08T18:11:59Z,0,Thank u for this awesome video,True
@chessmaster914,2018-07-08T18:02:15Z,7,"In the intel method where you draw enemy buildings, you have two for loops doing the same loop but for different if conditions. Also in the sc2 package, there is a data.py file that contains dictionaries with the names of all the townhalls and worker names. This will prevent the command center from ""disappearing"" when it transforms into an orbital command. Also, the color coordination for minerals and vespene gas is reversed on the drawing",True
@idacal,2018-07-08T16:55:32Z,1,you are the best man,True
@shaxosYT,2018-07-08T16:48:05Z,0,"I'm confused on how to start using the new on_end method. I have the game in ""C:/Program Files (x86)/StarCraft II/"". The maps are in there. My working directory for this project is something like ""Documents/ML starcraft/"". Do I clone python-sc2 in there? Does it need to replace the previous python-sc2 installed via pip? Why do I have to change the path to the maps?",True
@Veeq7,2018-07-08T16:32:14Z,0,Why would you reset target every iteration? I think you need it...,True
@glorytoarstotzka330,2018-07-08T16:23:16Z,1,nice cup,True
@ElizaberthUndEugen,2018-07-08T15:21:31Z,0,"Can't you somehow vectorize the entire game state and feed that to the network, rather than a super lossy color map encoding? This approach feels like you are throwing away tons of data and reconstructing data that you already had in the first place.",True
@freddychen1,2018-07-08T15:17:39Z,0,"Great content, But i dont know if just having a win or lose label at the end of each game will be enough to train a good AI. maybe could add labels like this choice kill certain amount of units or destory a nexus etc...",True
@user-lq8gg2uv9z,2018-07-08T15:09:53Z,0,How do u begin learning new library like this one for Starcraft? Do just read the documentation ? I can‚Äôt seem to get a grip around new library quickly enough.,True
@yahyan8748,2018-07-08T14:59:46Z,1,Do you suggest i watch your machine learning with python series before these series ??,True
@Alex4n3r,2018-07-08T14:57:05Z,0,"Shouldn't there be any kind of ""gravity"" (1/dist^2) between your troops and the enemy's? I also wonder why so many computations can be performed in more than realtime. I rather would have thought that one needs to use fast datastructures.",True
@sibyjoseplathottam4828,2018-07-08T14:39:29Z,0,"Thank you for this series. Making an AI for an RTS like SC2 is something that I always wanted to do. Not to sound nit picky, is there any reason why you are using 'if' statements to limit values of x and y (line 35 to 42). Wouldn't using  max(0,min(x,self.game_info.map_size[0])) implement the same logic?",True
@Emily_Entropy,2018-07-08T14:36:34Z,4,"This seems like an odd application of OpenCV. It made sense for GTA, but here you already have all the data in py-sc2. You're basically taking data from a visual source, to build another visual source to pull data.",True
@Gissel1989,2018-07-08T13:53:25Z,17,"I love this series, i really wanna see more of this kind.",True
@crittercel,2018-07-08T13:39:41Z,1,"Dr sentdex, I want to start doing stuff with AI (specifically for games). However, I'm not sure if I should take the rigorous route of learning all the linear algebra and multivar calculus relative to machine learning or just dive straight into the really high level Python stuff. I always feel like I never know Python well enough to start and sometimes I don't even know what I should know about Python before starting (disregarding the basic stuff)",True
@herambhrunthla8010,2018-07-08T13:13:18Z,0,Bro from where you learned such a good level of AI,True
@quebono100,2018-07-08T13:10:52Z,4,I love your content =),True
@premierleaguematches4307,2018-07-08T13:06:32Z,0,great job man.,True
@ironmonger4498,2018-07-08T13:06:03Z,2,Cool. How much CPU time each game takes??,True
@Lucas-fw6op,2018-07-08T13:05:30Z,8,"I think it would be more effective to add the ratios / additional info to the final, fully connected layer of your network, instead of making the convolutionnal network learn it : why make it learn to mesure the lenght of a segment, when you can directly give it these values ?",True
@huhulili9021,2018-07-08T13:03:21Z,0,Is it possible for the AI to detect a win or lose by counting the number of structures the AI has?,True
@shamaldesilva9533,2018-07-08T12:42:56Z,4,Ever thought of a collaboration with siraj raval =),True
@jonpablo1321,2018-07-08T12:41:19Z,27,One of my fav series,True
@fckyo333ujhjjkrrrr,2018-07-08T12:38:50Z,0,Cool,True
@fuba44,2018-07-06T21:00:54Z,4,Great video thanks. How are you running so many games in parallel? Rented vm's?,True
@Kevin_KC0SHO,2018-07-06T19:55:23Z,2,"Very cool tutorial, thanks.",True
