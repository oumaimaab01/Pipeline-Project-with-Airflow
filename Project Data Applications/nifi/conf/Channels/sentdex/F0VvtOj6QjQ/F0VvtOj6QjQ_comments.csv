author,updated_at,like_count,text,public
@joshuasellers4434,2023-12-04T18:49:18Z,0,There are some functions that require visual feedback to humans as long as we have preferences that require it ie. Shopping for clothes. Some people probably want to see what they would look like with an article of clothing. So that information..for now.. needs to be conveyed. We don't even need to see prices if the budget is in our initial interaction. We could just have a generative model that transposes the items on you and displays in VR/AR - granted those devices need to be created first and AI will still need to improve. Recommendations systems will probably become super aligned to the preferences of the individual. A lot of the point of UI systems today are to give the user the most information that we think they can take. Scrolling through 100 dresses is only done because the system knows next to nothing about the individual. Now if AI can lower the number of dresses from 100 to 10 actually relevant dresses than scrolling/trying on 1 by 1 is not as bad.,True
@averagedudeusa9722,2023-08-17T21:35:09Z,0,Driving relieves  my stress. If I can’t be in control I would be extremely stressed out.,True
@phils744,2023-08-13T20:24:01Z,0,"How is w os, still the thing today. Strange",True
@user-qs2rw3dd1c,2023-07-24T02:42:21Z,0,"been thinking a lot over the past several months. gui is something we're used to, and kind of the best working option we have right now. but that doesn't mean it will never change. i think the era of api/llm/robotic based ui is soon to come. btw, amazing video, keep it up!",True
@pirateonmeleeisland2973,2023-07-13T07:37:35Z,0,i think pure text conversation interfaces will never be as good for the end user as a graphical interface. otherwise every (non technical) person would use the shell terminal - and that's apparently not the case and that's a proof for me that graphical interface makes communicating with a computer easier.  So the future is probably  AI powered graphical user interfaces,True
@nemis123,2023-07-12T11:46:59Z,0,Internet has become VISUAL the latest years. It is about simplicity and fast information exchange. There is no way text based interaction will take over. We won't be back to the command line.,True
@aungthuhein007,2023-07-10T19:57:39Z,0,There's a lot of visionaries about the future of AI and civilization recently. 99% of which not worth pay attention to IMO.,True
@ryz177,2023-06-08T17:01:04Z,0,Watching this post-Generative AI. It seems like the Future of UI can highly likely be VOICE.,True
@phils744,2023-05-24T00:00:36Z,0,"Hello everyone, having a ""UI"" that runs an any device that recognizes you in on software language. It's very dependent on hardware. Simple. No more monopoly via any software language. Be safe everyone Phil",True
@andybrice2711,2023-04-04T08:56:11Z,0,"I think it will become a fusion of _""natural verbal language""_ and _""natural gestural language""._ Just like when you're working on a project with another person. You'll be able to say things like _""Change this x to y.""_ whilst looking and pointing toward the _x_ you mean.",True
@uHasioorr,2023-01-10T17:08:46Z,0,"The problem with audio inputs is that there are many people that wouldn't want to use it, for example, in a bus or a train. Also it would be annoying to people in the surrounding, just think about all those 13 yo playing their shitty music from their phone's shitty speakers and now multiply it by 10 if everyone would be using it.  Yeah, no, it's not happening.",True
@shadowdragon3521,2022-12-22T02:19:28Z,1,It will be very exciting once someone gets a non-invasive brain-computer interface working with AI,True
@awesomebearaudiobooks,2022-12-10T19:53:30Z,4,"I think, just as GUI didn't fully replace the terminal, the natural-language interfaces will not fully replace the GUI! I mean, think of it. Just about 30-40 years ago, most people only used the terminal. And now, most people in the world use GUI. And yet, there are still millions of people who use the terminal on a daily basis! IMHO, the same thing will happen with GUI. Billions of younger people will only be using the language interfaces, hundreds of millions will still use GUI, and millions will probably still be using the terminal.",True
@tobiaswegener1234,2022-12-08T17:32:49Z,1,"A little more than two months later and here we are, chatGPT gives us a taste how programming could look like in the future.",True
@user-mv3cg7hi7g,2022-11-07T21:30:58Z,0,Really fantastic thought provoking video about how the ways that technology influences us may not be in the ways we think.,True
@geraldsmith7240,2022-11-04T04:53:03Z,0,"Bio, 3-D Printing On The Brain,  Concerning UI By AI.",True
@geraldsmith7240,2022-11-04T04:51:30Z,0,"We Will Cohabitate With UI,  Through  Thought, Soon Enough.",True
@geraldsmith7240,2022-11-04T04:49:14Z,0,"Wet Cubits Inserted In The Brain, Using Quarks To Interface, Without Voice command . 🚘",True
@geraldsmith7240,2022-11-04T04:45:44Z,0,"I Much Prefer My 1928 Rolls Royce Wraith, Wilson.",True
@geraldsmith7240,2022-11-04T04:42:50Z,0,Voice Command. Much Like Present Day Navigation.,True
@geraldsmith7240,2022-11-04T04:40:56Z,0,"Let Me Say,     I Wish My Tesla Plaid Had More Airbags, Especially Outside Of The Vehicle.     Makes Me Nervous…😳",True
@PaulFeakins,2022-11-02T18:18:26Z,0,"Loads of good points, especially the self-driving car analogy. Something to consider though is that although we all have phones that can do voice calls and send short voice notes, most people prefer to send and receive textual messages, even if in some cases those are transcribed by an AI, perhaps for convenience of the reader?",True
@nsgoneape9899,2022-10-30T19:48:52Z,0,r2d2,True
@ezraszandala,2022-10-29T03:18:45Z,2,"I definitely think people will always like GUIs, it's just that tactile nature we have. I'm sure however that GUIs will become very advanced, whether they are holographic or touching your skin or bending different fingers.",True
@barneymattox,2022-10-26T19:05:13Z,1,"I honestly feel that LCARs (conceptually, not literally) from the Star Trek movies was a really good example of AI driven interfaces.  Particularly the scene in Star Trek IV where they’re writing a program to parse out the whale sound interactively with the computer and a mix of conversational, visual, touch feedback through the process.  The Okudas were far ahead of their time in their meta thinking of future computer interactions.  This has driven a tremendous amount of my work and research over the years since first seeing that scene. …though I think the visuals of the LCARs interface are becoming very dated, the principles and designs behind it were very well considered and insightful.",True
@Photomonon,2022-10-26T17:36:25Z,0,yeah the human interface will be a wristband and vr headset. drive by wire ???,True
@triton_princeofatlantis,2022-10-25T19:03:29Z,0,ai that process on device and not on a server like ggodls's phone,True
@series1054,2022-10-25T15:56:32Z,0,"Buttons will remain, either physical or digital.",True
@George97477,2022-10-24T08:50:05Z,1,"Some of this misses the point, how do you speak to your computer in an open plan office if what you saying is confidential and your work entails confidential information? What if every employee works with confidential information that shouldn't be broadcast out load? It will be a heck of a noisy office. Is open plan offices a thing of the past?  Do you want to work without human contact in a little sound-proof cubicle/office/home office forever?  You can't even speak to your college while speaking to your computer at the same time. Your boss is sitting there trying to speak to a computer using a spreadsheet trying to whisper to it people's salaries without a screen with no GUI.  It will never replace a GUI in an office setting. It feels to me that making noises with you meat flap and broadcasting it doesn't make any sense in an open space as superior. Your mouth can't target sound waves to just one target without it leaking everywhere.  Typing and touching can be completely silent (depending on your keyboard).",True
@jw6953,2022-10-24T08:16:49Z,0,There's nothing good about building technology that can lie to us and outsmart us and then not be responsible for it.. How do you tell a computer to stay in its Lane?,True
@jw6953,2022-10-24T08:05:33Z,0,I still use a sharp number two pencil and I like it but there's a whole generation that has never been in the same room with a sharp number two pencil...,True
@jw6953,2022-10-24T07:59:25Z,0,News reporters could be replaced with an avatar but the owners of the news networks would then be responsible for the avatar they'd rather be able to fire a human...,True
@jw6953,2022-10-24T07:56:38Z,0,What if this is used to commit fraud? This type of technology should not be allowed on bank statements or on any other type of official report. There should be no narratives when it comes to investigating. A narrative is a story and investigation is based off of the facts the truth the whole truth and nothing but the truth.... Do the police use this type of technology to generate a report for the database?,True
@inspiringeducators,2022-10-24T07:46:26Z,0,It's a thing of basic human psychology and manual physical input provides a sense of control.,True
@lakshyagoyal5560,2022-10-23T21:33:02Z,0,"A great example I can think of for this is call screening menus. They always have to list out each menu option one after the other. This is clearly super slow and frustrating since you have to wait to find the one you want. Some are even worse because they make you speak the answer, for instance a number, which is much faster and easier to just type rather than say.",True
@miguelacevedo8649,2022-10-23T18:31:36Z,0,What happens when it’s faster to use a GUI rather than text?,True
@miguelacevedo8649,2022-10-23T18:28:12Z,0,Do you think programming will be automated? Or someone still needs to have an understanding of the technical system?,True
@hardwareful,2022-10-23T13:25:22Z,0,"Thanks, I hate it.",True
@silberlinie,2022-10-23T00:29:39Z,0,absolutely,True
@justinshankle,2022-10-22T18:21:33Z,1,"The ""natural language"" of humans is visual.  Spoken language is a relatively new concept in evolution.  Humans are much better at quickly processing what they see than what someone says to them.  I see the near future of AI as being able to read the eyes, face, gestures, expressions, and reading between the lines of what people are trying to say in order to produce what they actually want.   After that, a direct link to the brain for both input and output will be a game changer.  Just think and the computer knows exactly what you want, no time wasted translating your thoughts to words or movement.  Visualize something in your mind and the person your ""talking"" to sees the visual instantly, or the scene is projected to the world.  I see spoken language as the ""relic"" that will go away.",True
@Kevin-rr1nm,2022-10-22T17:31:03Z,0,"I think that when the average consumer can get a100 chips at home...this is very possible. So we are probably a few years away from these kinds of things being viable at home. If you have some kind of AI tensor core main brain interface for the computer at home you in theory could run a personal AI for online tasks and a cloud service so it can apply to whatever tech you connect with, a phone, a car whatever. As long as the processing was capable, GUI would be a step that actually gets in the way of translating desire of a task to actual completion. And yeah copilot completely changes things, it will be a point like stable diffusion is....type what you want to make... and full package will be ready to deploy.",True
@WarrenParks,2022-10-22T15:05:26Z,1,Somewhat agree but there have been low/no code solutions that come out all the time that always claim to be a lot easier and faster but usually they don't pan out very well. It's normally something like they can do easy and happy path situations but once you start needing much customization or optimization then they start falling short.,True
@WarrenParks,2022-10-22T14:50:05Z,1,"Looking at latest stackoverflow survey javascript is still most popular, python is 4th but they have html/css and sql in the list before it.",True
@amiman23,2022-10-22T13:58:56Z,0,"AFTER WATCHING A LOT OF HOW TO DO AI ANIMATION BY TYPING INSTRUCTIONS, IT SEEMS POSSIBLE TO GUIDE YOU VISUALLY THRU SUBCONSCIOUS SUGGESTIONS.",True
@amiman23,2022-10-22T13:46:52Z,0,MORE INFO COMES WITH VISION. YOU CAN DEVELOP NEW ABSTRACT REASONING WITH COMPLEX REPRESENTATIVE MEANINGS. MORE LIKELY DEVELOPED FOR HUMANS BY AI,True
@Vetrivel.Shanmugam,2022-10-22T07:50:28Z,0,Can you add visuals on what you are talking about please?,True
@Luredreier,2022-10-20T04:16:25Z,0,"GUIs aren't really that intuitive unless you already have some previous knowledge about GUI conventions. Text based interfaces may at times be easier to deal with, so may natural language. My mother often struggle with GUIs on her phone, but can use voice commands.",True
@labdo_,2022-10-19T14:19:17Z,0,GUI is here to stay.,True
@tygorton,2022-10-19T11:52:38Z,0,"I hope people realize that ""self-driving"" cars cannot exist until there are ONLY self-driving cars on the road: meaning, no human drivers would be allowed. Like the entirety of this digital reality much of the world is racing toward, it is an ALL or NOTHING scenario. You will not get to pick and choose this or that... you will either be all in with the digital or you'll be living outside of it. There can be no self-driving vehicle with the unpredictability of human drivers on the roads simultaneously, it's literally impossible. Giving up all of our autonomy in every aspect of our lives is really not a great idea, is it?",True
@VisibleMRJ,2022-10-19T05:44:55Z,0,"We all want the perfect slaves so ai base Ui is a natural progression from that. The ultimate goal is for us to tell something, ai probably to go build a space ship or something and the ai just go fund raising gain money build a spaceship and give it to you.",True
@DMexa,2022-10-18T21:12:21Z,0,Language still a very inefficient way to communicate,True
@aiarttoday,2022-10-18T20:19:43Z,0,I just want to argue with my ai and win! lol,True
@imranq9241,2022-10-18T00:06:05Z,0,What if the AI generated a UI?,True
@Equilibrier,2022-10-17T19:08:40Z,0,GUI will be tweaked but will never dissapear.,True
@laurenswissels8480,2022-10-17T17:07:08Z,0,It already exists. It's called the terminal!,True
@oliverpolden,2022-10-17T14:22:32Z,0,"This reminds me of the phrase: ""This is what you need, not what you want."" e.g. People wanted faster horses, but what they needed was a car. Paradigms as you say will completely change and we will need to shift our mindsets away. I think you're correct that a graphical representation of data will persist as it's so easy for humans to be presented with a whole bunch of data and for us to pick out what we want, after all, that's literally what the eyes and brain have evolved to do. So I think that's clear from a feedback point of view. From the point of view of data input?... that must be thought or brain impulses right? Consider how much we do by just walking. The thousands of muscles all working together, even handling our breathing and moving our eyes. So input into AI systems will probably be brain interfaces which is an abstraction above natural language, or wait is it the other way around and we will be removing the need for that extra abstraction from thoughts into language. Will this mean we will eventually be able to communicate with machines telepathically before we could do it with other people? How sensitive will these machines be? Would we need some sort of interface we wear or would they be able to pick up on our thoughts from a few feet away?!",True
@ChrisField13,2022-10-16T05:41:53Z,2,Great thoughts. I love the way you are able to zoom out and see the big picture rather than getting caught up with the details. My perspective is definitely shifted in a more holistic direction after watching this.,True
@nrao8977,2022-10-16T02:30:52Z,1,"Yes, abstraction has been and will always be the way to go - humans need easier ways to do the same thing.  However, IF Python is much slower than, say C, why would one deploy a solution in Python?",True
@bq2461,2022-10-16T00:58:18Z,0,"Neural Link seems to be the future of UI, the human senses are simply, slow.",True
@larrybird3729,2022-10-15T03:34:46Z,0,thank googles algorithm for me forgetting sentdex for all these years,True
@jonathanmantello3974,2022-10-14T23:09:31Z,0,"You just gave me an idea... what if we spoke into it, and it gave us a graphical output? Lol",True
@karlfimm,2022-10-14T21:08:32Z,3,"We've seen the future of UI in tv shows going back to Star Trek Classic. The captain looks at a big display (hopefully 3D) and tells an underling what he wants to happen. It's just that the underling will be an AI, not a human. Voice input (possibly combined with a vague hand-wave in a general direction) and visual feedback (perhaps with a verbal summary) seems very believable to me.",True
@francisdelacruz6439,2022-10-14T17:58:33Z,0,"Yes, with current AI voice is slow due to current very  limited capabilities ie AI driving cannot even be insured as all AI accident and deaths are preventable. Think of a capable executive assistant, you'll just be using voice at a very high level where the assistant is capably doing the work where your reply would be just yes, no or lets discuss and the discussion would be just an explanation of the approach or conceptual solution and the rest is worked on by the assistant.",True
@BrandOnVision,2022-10-13T23:08:18Z,0,If you believe this and can see it you will build on it. Most people do not know the fundamental building block of Facebook. No new tech built Facebook it was simply that Facebook said use your real name. Facebook put a face to a name. The majority of people don't see this simple concept to this very day.  Voice UI is the future and there is something as simple as the Facebook problem that will change the voice interface like Facebook changed the my space forum.  I do not need to tell you because we are building it.,True
@kyegomez4946,2022-10-13T20:39:31Z,0,"If you think the mainstream AI companies have cool UI's wait you use Athena, your mind is going to be shocked in awe for years I PROMISE",True
@finestford007,2022-10-13T13:04:51Z,0,GUI will always be there ......imagine deaf people,True
@dreamphoenix,2022-10-12T23:24:12Z,0,Great commentary. Thank you.,True
@Synthalog,2022-10-12T22:26:32Z,0,We are using our brains less and less. It makes sense.,True
@JB-fh1bb,2022-10-12T20:26:26Z,1,"What do you think about a distant future where the AI takes over the “decision making in response to the response”?  Dense UIs are usually important because we need the information to make (a series of) secondary choices. “What’s the CPU usage?” could be followed up by deciding whether there is enough headroom to start another process. “What’s the weather?” informs what outfit we wear and what we take with us as we prep to go outside.  So if AI is informed and intuitive enough to make those choices for us, do we still need dense UIs?  “What time is it?” “It’s 5:55, and you still have time to grab your coat before you leave”  As a personal example: I used to keep CPU, HD, and network stats on my screen at all times but I shifted my behaviour so that downloading/processing was done overnight with low QoS and further optimized with AQM. Now I don’t need those stats be visible because I don’t run in to bottlenecks. Systems have removed my need to care about the dense information on a day to day basis.",True
@vc.moser.ferrier,2022-10-12T15:18:44Z,0,"See it exaclty as you do. I envisioned this to come at university, many years ago. Great to see, it becomes more realistic now.",True
@Gigusx,2022-10-12T01:29:18Z,0,"Isn't that the purpose of Elon Musk's Neuralink? To bridge that gap between our thoughts and the interfaces we interact with, so that we don't have to command the devices with clicks, texts, voice, etc. but with thoughts? I think THAT could be the next generation of user interfaces if (when) they ever figure it out.",True
@franksonjohnson,2022-10-11T18:49:41Z,0,"I'm sure you had this in mind when you discussed ""this is how productivity works, we build on top of things and abstract the rest away"", but I think it should be said that these higher-level abstraction are (and will be great) for *solved* problems. Abstractions are optimizations right?, always trading away low-level control for conceptual clarity. So the lower levels absolutely will continue to be critical as soon as you meet the end of the road for what the abstraction can do.  Say Copilot goofed and didn't know what very specific implementation I wanted them to make for some implementation reason I know but it doesn't. Either the natural language has to be sophisticated enough to know what I mean by ""factory pattern"" or whatever, or it's on me to type up that version and know how to write the Python/C++/C/BrankF*#& for it. My car doesn't know what I mean by ""give that construction worker up ahead some breathing room"", so either I rephrase it to something it understands like ""move a little to the left in the lane"" or I reach out and override it.  Abstracting interfaces to higher levels is almost always a lossy transformation, so there will continue to be a need for the lower levels, as well as a well-designed graceful handoff between the levels in the case of failure.",True
@lancemarchetti8673,2022-10-11T18:01:57Z,0,Most informative 👌🏼,True
@michaelpangilinan9568,2022-10-11T06:10:35Z,0,"Thank you, it works perfect!",True
@bbaker6212,2022-10-10T22:35:31Z,0,"You know what's even more inefficient than obtaining information via a VUI (voice UI) or natural language? Watching videos!... and yet people do it A LOT.  Why? Because it's more natural and enjoyable, at times, and depending on what type of information it is.",True
@Cominotech,2022-10-10T21:43:39Z,0,"Good point, Harrison! More intuitive, and probably by a large portion, predictive",True
@assassinjohn,2022-10-10T21:10:43Z,0,I agree with you. Imagine an Advanced OS that takes into account eye tracking and voice input with minimal latency using ML models.,True
@hi9313,2022-10-10T18:17:19Z,0,It’s going to be an interface with an ai that has already done what you want before you even think it,True
@muresandani,2022-10-10T13:52:47Z,0,"Yeah I'm not gonna be talking to my phone/laptop in public, that's ridiculous, GUIs will be with us until we figure out direct brain-machine interfaces.",True
@nimrodhegedus1511,2022-10-10T09:26:42Z,0,"One of the main problems with communication via language is the 'lost in translation' issue, where an idea or communication is incorrectly interpreted. The human brain has only recently (that's within the context of evolutionary history) adapted and expanded to process complex language. Those parts of the human brain that do process language, when articulating thought, are much slower to process those thoughts than those thoughts that are not derived through the use of words to form them. In a nutshell, words are a layer of thought that overlies more fundamental types of thought, words were and are a way in which social creatures can interact to communicate in such a way as to organise themselves to work together, which has contributed to the success of the human species, but in some cases such communications are not as efficient or can be misinterpreted with catastrophic effects. To sum things up, one does not need to think in words, thoughts that are articulated by words are only one aspect of thought, one is able to think without words (you may want to try this yourselves), and this type of thinking is usually faster, but less easy to communicate such ideas.",True
,2022-10-09T23:54:53Z,0,"GUIs are more accessible and work in more circumstances. Think of times when you would rather not speak or are unable to speak. I think interfaces are going to become ambient. Use whatever you prefer. The AIs around you will interpret words, button presses, gestures, and looks equally well",True
@privet20005,2022-10-09T22:35:30Z,0,Russian site for public services implemented ai assistant a few years ago and it's turned out really useful! It's incredibly fast now to get some questions answered or order some paper. You just say what kind of paper/service you want to get and it answers with big button to order that thing. Same thing with banking apps! It's very convinient and I'm looking forward to see it being implemented more and more,True
@XerosOfficial,2022-10-09T20:41:28Z,0,"GUIs are so much faster to use. Natural language is not what's going to overtake GUIs, brain interfaces are far more likely to.",True
@rumble1925,2022-10-09T19:34:13Z,1,The reason voice commands will probably not become the default is because the interface is not discoverable. I can click around and discover functions in a gui. Voice implies I already know what the software can do.,True
@tylermansmann1065,2022-10-09T18:57:23Z,1,"This is a great video and very educational, although I think theres two major points I partially disagree on. Firstly, the car example was a race car. Racing is a sport where winning is determined by a combination of physical specs and the drivers skill.  There is such thing as AI/self driving races, but people enjoy traditional racing for the human aspect of it. AI will never replace human racing because the human endurance/skill side of racing is part of what people are watching for. When it becomes AI self driving racing, it becomes a different sport.   Second, a point on programming via natural language interface. You can code via natural language, but typing will always be faster for many people than using your voice. The best programmers minimize the amount of time they spend with their hands off the keyboard, so its a natural progression that we might be able to ditch the mouse with better natural language programs, but we will not be programming with voice as efficiently as we could with a keyboard.   We could get to a point where you can ask for a program via voice and have it right away, or be able to use voice to ask for complex tasks and have AI program itself to execute this task, but text input will always be faster if your job is to actually program things for a living, even if its just to enter the same prompts you would otherwise speak",True
@avithedev,2022-10-09T08:14:28Z,0,Bro looks like an AI,True
@drizel462,2022-10-09T07:40:52Z,0,It's essentially Iron Man technology.  We just need the auto prototyping but we're already working on that too.,True
@felipefairbanks,2022-10-09T03:40:08Z,0,"I think where NL interfaces will shine is in stuff that people don't really know how to do easily in GUI. For instance, if you're writing a paper, I think you will edit it via GUI without any thinking about formatting. then, when you finish, you'd ask the computer to format it using the needed standard. Other area I see it flourishing is with specialized software (such as video/picture editing, 3D creation), because these softwares are too complicated. even when you know how to use it, it is not unusual to forget the path to a specific menu and that sort of thing. So it would be easir to just tell the computer ""no, I want it here"" or ""now add a mustache to it"" than doing it via GUI. but for stuff that is already easy to do via GUI, such as web browsing and stuff like that, I don't think we will see NL interfaces taking over any time soon.  That might and probably will change, though, with the metaverse, when we are surrounded by our OS, instead of looking at it in a screen. might be more intuitive to use your voice than a hovering keyboard in front of you in situations like that, who knows?",True
@srb20012001,2022-10-09T01:01:34Z,0,"The Quickening, approaching the Singularity.",True
,2022-10-08T19:32:11Z,0,"Where NLP and more particularly Large Language Models are required for human - machine interfaces is Robotics. As soon as humanoid robots will be a reality, they will have to understand and speak generic and even technical human languages at a level not reached today by speech to text and text to speech today. It is where models such as whisper are important.",True
@Gilotopia,2022-10-08T18:10:15Z,0,I expect future AI interfaces will be like in star trek tng: you can describe complicated commands to the computer but the basic commands are still done through the LCARS GUI.,True
@jond532,2022-10-08T16:41:23Z,0,i will never not see you as edward snowden lol,True
@ahrenadams,2022-10-08T15:37:10Z,0,Everything humans do is based on an abstraction of consciousness,True
@cuentadeyoutube5903,2022-10-08T13:38:35Z,0,"Your car example is not really right either. Even interacting with a car driving ai is too slow if done by voice. I mean, talking to Siri is usually a slog. Waiting for Siri to finish reading a message sends my anxiety to the roof, trying to remember what to say to Siri whenever I want something is cumbersome. Voice assist is great for when I can’t use my eyes and fingers to just click things on a screen. But otherwise I thing GUIs like the ones we have on an iPhone are much better.",True
@krunkle5136,2022-10-08T13:02:32Z,2,"My main concern is the power consumption of AI technology. It's bad enough how much power is wasted on shit web apps and advertisements causing the browser to slow, and it's important to see how that all adds up throughout the day and with millions of people.  Also, some ai could be nice, but I don't think humanity exists to frollic and do the scant amount of things that haven't yet been replaced by ai in the future.",True
@gandoffboss197,2022-10-08T11:57:55Z,0,"In the near future (continuing with your build on top off idea), what if our phones become our UI. For example, you could tell your phone (note natural language used here) to connect to my bank. My bank would support a computer to computer interface in which the bank app would inform my phone as to the available commands. My phone would then tell me it has connected and show me a list of available commands. I could then tell my phone to transfer $100 to my wife's account. In this scenario, the services (like the bank in my example) do not have a direct UI. The bank app simple uses an available library which provides communications with an endpoint device (like my phone).   This could work in your future self driving car example as well. I get into the ""taxi"" pull out my phone, scan a QR code which connects my phone to the car. Then my phone receives available commands from the car and shows them to me. I select/say take me to address ""X"". And I am on my way. At my destination, the car asks me to submit payment (yeah I know it could be automatic but wait). The car locks the doors until payment is submitted or the authorities are called by the car. When I pay, the doors are unlocked and I am free to go on my way.",True
@festro1000,2022-10-08T10:38:58Z,0,"Personally I like the idea. Sure there will be situations where GUIs will be superior like the examples Rasmus gave, there will always be use cases for a GUI of some sort especially in scenarios where speech is impractical like a crowded stadium, or among sleeping family members. But there are many others where it will be a clear choice, take dictation writing for example; people naturally speak faster than the most seasoned typist, and considering how digital assistants like google work, you don't even need to use a mouse or keyboard to get the weather, date, or, or events that people usually forget, and scouring the long list of nested directories to find that file you misplaced are practically a thing of the past as well. So long as the AI is competent in contextual differentiating and actually understanding what the user says and wants there are few cases where an AI would be shadowed by a GUI.",True
@eduard_soul,2022-10-08T06:20:40Z,0,Very nice video!,True
@coder0xff,2022-10-08T05:54:11Z,0,"You're focusing too much on the acoustic nature of interaction, when natural language interfaces have just as much potential over text. But text came before GUIs, and still hasn't transitioned to natural language. Because the issue isn't a design problem, it's a computational one. The difficulty is not designing a paradigm around natural language. Natural language *is* the paradigm.",True
@xToTaLBoReDoMx,2022-10-08T05:38:47Z,0,What about using voice for input and something like dall-e to visualize the output? Should get the point across a lot faster than a bunch of paragraphs,True
@loknathshankar5423,2022-10-08T05:16:29Z,0,"Idk, let's wait and see",True
@cnaccio,2022-10-08T05:02:14Z,0,Honestly I've seen a similar thing take hold as a Salesforce developer and with their Flows functionality... Over time I've moved from writing a ton of code to only writing code when I absolutely have to; all other functionality is developed in a flowchart like visual environment.   Just not having to write unit tests when using Flows is enough reason to shy away from writing new custom code.  I never would have anticipated this change in my own behavior.,True
@DardanAirlines,2022-10-08T05:00:30Z,1,"Think “Computer” from Star Trek. UI will be created and rendered on the fly via neural network, as directed by the user, and defaulting to whatever output makes the most sense, given a query or task.  Thought-sense will radically change how we interact with software and could allow for high potential bandwidth between the user and the software.   By comparison, language and physical interaction based interfaces, such as that on iPhones, digital assistants, and command line terminals, may seem absurdly slow, cumbersome, and lacking expressivity.",True
@victorpinasarnault7910,2022-10-08T01:30:27Z,1,"The Python compiler is written in C, not C++.",True
@jestempies,2022-10-07T23:16:46Z,2,"Copilot is useful in the same way copy/paste is useful. I wouldn't program without it, but you can't program using only copy/paste. I'm happy to use any new tools that become available, but I find it hard to imagine they'll be able to write completely new, original code. Currently 90% of what I'm doing while coding is reading, tweaking and debugging. I'm happy to have smart tools do some of that for me, but unless they write complete, working code that I'll never have to see, I'll have to have a way of moving things around, renaming things etc. Like they say, there are two difficult problems in programming: cache invalidation, naming things, and off-by-1 errors. I expect AI to certainly help with the last one, but the other two seem like they'll still need a lot of tweaking and manual input.",True
@noahbarrow7979,2022-10-07T14:01:23Z,2,Mind completely blown. Dude you've introduced me to so many exciting concepts and apps. Keep it going!,True
@Zachucks,2022-10-07T02:34:53Z,0,"If everyone in the world had AI driven cars, I would imagine the risk of car accidents would be significantly lower as the AI matures. So then insurance would be useless?",True
@IamusTheFox,2022-10-07T02:12:07Z,0,"The one problem I've seen is; when you exist with one platform, say C++, you tend to only see problems from a C++ prospective.",True
@lucaskruger1416,2022-10-07T01:41:09Z,0,"Imagine yourself twitting while you are on a bus, or in a meeting Thera are some stuff you want to do in silence",True
@ShamusMac,2022-10-07T01:28:49Z,0,Homie never heard of rally driver assistants. Shouting left and right works.,True
@danielsan901998,2022-10-06T21:09:43Z,0,"Mouse is not necessary for software development, any VIM user already know that, AI UIs will be like the mouse, only an option for people that are not expert in keyboard based command line interfaces, the most efficient tool.",True
@jones1618,2022-10-06T17:34:05Z,0,"Good thoughts & worth discussing but I think you are conflating AI ""interfaces"" with two concepts:  1) Verbal input - As you said elsewhere expressing intent with speech isn't very accurate or efficient for many domains. Sure, I could ask for a piece of software with a broad architecture & components & get an AI to produce some scaffolding pretty quickly but how much extra work would be required to learn/undo the AI's assumptions & work around them?  2) Abstraction - Take current Stable Diffusion / Dall-e text-to-image AIs: Right now it is enthralling to get a credible image (along w/ a few freakish sideshow rejects) that abstractly  matches concepts from my prompt ... but what's missing is ability to hone in on & refine details, style & tone.  So, initial expressions & abstractions only get you so far. These tools will really make an impact when they are trained on & tuned for incremental refinements and that won't always be possible from an abstract distance. The artist/producer will want the AI ""user interface"" to dive into details & aid improvements.  Current AI in/out-painting tools point in that direction  I foresee a combination GUI & verbal interface where you paint over a section & say/type ""make this shinier & more colorful"" or ""make the muscles of this arm more tense & pulling against the gate.""  In short, AI tools have to get good at more than just abstractions, roll up their sleeves & get down & dirty into the details with humans to refine the output. Then they will be true tools we can leverage to create great things.",True
@DRKSTRN,2022-10-06T16:50:57Z,0,As a functional programmer. I believe that it's the best tool for the job when it comes to language. The difficulty there is having the fluency of libraries and optimizations across languages to use what when.  Which in of itself would be a model. That and you can never avoid semaphores.,True
@cuszco,2022-10-06T14:57:46Z,0,"I don't see GUIs going away any time soon. Even just for privacy reasons I can't see it happen. Natural language is fine for use in your home, in your car, a private office, etc.. But imagine everyone on public transport or in an open office just talking out loud to their devices all the time.",True
@PVivekmca,2022-10-05T21:56:44Z,0,"Various personalities driving car through voice,  Left, right, faster,  Turn f***left idiot Yo go left sorry right, 😃😃😂😂😂😂",True
@hewas321,2022-10-05T09:56:08Z,0,Great intuition no doubt. What he said is all on the ground of experiences.,True
@yabdelm,2022-10-04T21:16:27Z,0,"I think for user interfaces, whatever gets the job done: fastest, easiest and go furthest for the user for that specific context (depends on the application), will win.   If I had to bet on the future, I think it'll be something like neuralink + all apps that exist + a transformer/some neural net that tries to predict what we want based on our past history in interacting with these apps, and then 'zooming us forward' before we even state what we want.  Instead of saying ""take me to destination X"", the AI will get extremely good at predicting what destination we want to go to based on past events that just happened. E.g. If I say to my friend on the phone ""I'll meet you at 4 at X""... and so on.  So we'll go from these delayed feedback loops, to the feedback coming before the action:  action .......... reward.  To action ... reward.  To act- reward.  To a-reward. To reward.",True
@mkrichey1,2022-10-04T16:20:40Z,0,"I like this summation and agree with the approach, the interesting thing will be the balance of AI inference vs having enough feedback to know that the inference is what you actually want.",True
@darkcoder5799,2022-10-03T14:21:55Z,0,Is it nowadays 😅 still worth learning C++?.... Because I have no so much free time 🥲and it would be suppose for me a great effort. Thanks for your opinion! 🤗,True
@f1l4nn1m,2022-10-02T20:01:01Z,1,"Beautiful video and insight. I feel I can add a very interesting and relevant anectode in the discussion.  When I was a uni student, my professor of Algorithms and Data Structures told the class that when the mouse came up, tecnicians used to joke that the real reason behind it was to make computer look faster, because compared to instructions at the keyboard you needed sooo much more time. ;)",True
@kurdi_x5842,2022-10-02T16:26:54Z,0,smart talk,True
@sofiaonaga5352,2022-10-02T14:33:19Z,0,accept @Jabrils challenge!,True
@DJR3H,2022-10-02T09:42:49Z,0,I already don't like speaking to people. Would hate being forced into talking to my devices.. :'D,True
@EelkodeVos,2022-10-02T06:05:16Z,0,"Visual interfaces seem to work fast, but just compare someone experienced working with a graphics interface and someone working with just a commandline. In certain areas the first will be faster (cad/cam, 3d animations, movie editing). But in other areas a commandline is way faster (programming, debugging, searching for regexps). The difference is that the mental model needs to be shown visually in the first case, like 3d modelling.   But in the second case (programming, etc) the model is purely mental and needs no visual representation. In fact the mental model is expanding in each development step and no visual representation would speed that up, in my opinion. It would only unnecessarily add a new layer of interpretation.",True
@EelkodeVos,2022-10-02T05:44:07Z,0,"You correctly state that higher languages create more productivity and that our interaction will be more and more towards naturalisatie language. I think beyond that lies a new language, derived from natural but also programming languages, which we wil use to interact with computers. But eventually we will incorporate it into regular speech too. Something along the lines of Esperanto combined with Python, inserted into your native language (English, Dutch, Spanish, German, Swahili,...)",True
@adamoreilly6546,2022-10-01T20:11:19Z,0,Fear is the mind killer. Great video,True
@firstlast6796,2022-10-01T08:31:21Z,1,"@2:51. He said RACE CAR, not a normal car. Obviously saying ""drive me to x location"" would be better or simpler with natural language, but not if you are doing something that requires lots of precise and subtle inputs in a short period of time. Also, speaking of normal cars, everyone is moving towards all touchscreen interfaces because that's the trend, but there are now studies that show older manual buttons a switches are safer and easier to operate while also using the car. Basically i get what the original tweet said, but GUI's will ALWAYS be a thing in certain contexts. Like video games just as one example. I'm not saying ""okay computer, play this game for me."" I'm going to want a health-bar and a minimap etc.",True
@albertwang5974,2022-10-01T05:41:12Z,0,"The information density of language is pretty low,  it will never take over GUI and CLI, but the language will be a trend of popular UI",True
@MarcusBS,2022-10-01T05:22:37Z,0,Think of a ui elements done in stable diffusion. Why should any element choose between inputs or outputs. State goals in a ui and then have the interaction of that ai create the required output. I'm dyslexic may be audio tones could be my best or arrows  you can train the ai thew the interaction of your abilities,True
@rufiromang,2022-10-01T05:11:17Z,0,"At the end of the day, light travels at much faster speed than sound",True
@ab1577,2022-10-01T04:43:32Z,0,picture worth a thousand words,True
@ominguti6345,2022-09-30T23:00:44Z,0,"I would love to try copilot, but I'm not giving all my(and more importantly my client's code to github for free). Another thing is, because github copilot requires Internet use there is no way you'll be able to use it in high security environments. Good luck going back to ""normal"" writing code after AI have been writing it for you for few years...",True
@shiveeshfotedar,2022-09-30T22:46:44Z,1,"An effective heuristic of thinking about interfaces is to think of them as declarative interactions and imperative interactions. Driving a car today with steering wheel is an example of imperative interaction. Having an AI agent control the specific changes and Customers interact them in a managerial position is an example of declarative interaction. Today for most of the imperative interaction as humans  we use our limbs , like hands and fingers and for declarative interaction we mostly use our voice.",True
@rogerorchard2317,2022-09-30T20:57:32Z,0,"I am 1 of the large group of people with speech problems, Telling anything what I want it to do using buttons, misce ....... there are thing I can no long do as the interface to then is now voise control, and 75% time it does not understand me.",True
@ronaldronald8819,2022-09-30T19:42:47Z,0,I feel like a relic programming C++?     ehhh. No i don't 🙂,True
@headrobotics,2022-09-30T16:16:06Z,0,"Ideally nature language and GUIs can be complementary. Visual prompts are very useful, and a dual parallel system, with a robust fuzzy feature search capability.",True
@gaggy7448,2022-09-30T15:55:32Z,0,Accept @Jabrils Challenge,True
@jonesbbq307,2022-09-30T15:50:22Z,0,"The thing exists, it’s called command line",True
@dnmurphy48,2022-09-30T11:42:05Z,0,"many years ago a programme was released called the Last one - which proclaimed young will never need to write code again.  Good tool, bu7t just enhanced existing tool in some areas, never achieved what it claimed.  I have seen numerous ""replace people"" tools over the years none deliver in the promise even though they provide benefits.  The death of the coder has bene predicted for decades and yet we need more every year.",True
@dnmurphy48,2022-09-30T11:36:55Z,1,Use of natural language is decades away except in specialised use cases. I can imagine using language for eg setting a goal (drive me to London for example). but for e.g. entering all the data required for a claims handler in insurance?  I don't think so.  You make lots of good points.,True
@MorebitsUK,2022-09-30T11:12:54Z,0,"I tried voice interaction in Tom Clancys Endwar, and it was nearly impossible to use. If they can improve it, i'd love to see it done. A good example is Windows 11; Endwar a bad example. I studied UI at college and have done a course in WPF and have just finished learning JavaFX. So its really interesting to see. Keep it up Sentdex.",True
@SierraMikesWorld,2022-09-30T09:35:32Z,0,"Hello, there is no Turkish option in automatic subtitle translation.  If you do not have a prejudice against Turks, can you activate the Turkish option?",True
@mfasco84,2022-09-30T09:11:43Z,0,"I was wondering, Copilot uses existing codebase to develop its ""predictions"" but, if more and more people use this technology and stop writing new code, how do Copilot will keep himself up-to-date?",True
@87vortex87,2022-09-30T09:06:04Z,0,"Why do we need direct interaction at all? If systems know everything we do, all factors, and is trained on all people. It can probably predict what we want to do, and suggest. For example: every year in September I book a skiing holiday for January, it can just suggest me in September some destinations. Then my insurance can see that and suggest, or even automatically arrange insurance.  Or a kitchen appliance breaks, my smart home can see that and automatically arrange an appointment to repair.  It boils down to the fact that ""why"" we interact with an ui is to put information in something, but we will need to do that less and less because more and more information will already be known. So we don't need to put it in, and we can use that information to predict and even lower the amount of interactions even further.",True
@wktodd,2022-09-30T07:59:22Z,2,Will AI mean the end of the syntax   error? Will it mean the end of 'self.' ?   Will it require a thousand core cpu and a cloud based gpu to flash a light bulb or print 'hello world' ?,True
@HT79,2022-09-30T07:51:05Z,1,15:45 Wait... Isn't Python (CPython) built on C and not C++? Iirc C++ wasn't mainstream back when Python was being developed.,True
@wktodd,2022-09-30T07:46:22Z,1,"We have voice controlled cars in England, they're called Taxis ;⁠-⁠)",True
@LukePuplett,2022-09-30T07:20:44Z,1,"Remember: someone has to build all this.  Given our regime is capitalism, a force that's likely to survive or catalyse much technological change, the endeavour needs to have a return on investment.  That means all the mundane interactions, apps, and all the bizarre old-fashioned ways people do things, need to be replaced by some fancy new way that generates income and benefits the buyer. And that's not even the hard part.  The hard part is educating everyone that your thing even exists at all, and that their use of time or profit margins would be vastly improved by your new thing, and that they must find the thing compelling enough to take the actions to implement your new product. It's like getting your toddler to try a new food you know they'll love. ""I'll give you FIVE dollars if you JUST TRY IT"".  And you have to convince others to invest and people to work on it with you, and that you will be able to pay them. Even then your business might fail, the idea might be too early, you might give up, not have the help network, run out of money, or have a family member that suddenly needs your help.  Until you build something to sell, you don't realise how almost everything has been forced into the world in this way. All these cool ideas won't happen unless someone, perhaps you dear reader, can see a way to make money with it, and are willing to dedicate about 10 years on it.  In conclusion, some dumb ways will stick around for a long time because there's no business in its disruption, it's too expensive to sell, or the brainy folks have more profitable or interesting problems to solve.",True
@TheShorterboy,2022-09-30T07:16:01Z,0,"No not happening, GUI's provide a view of function you don't get with natural language (NL) ,NL are opaque, you could supplement a GUI with NL but replacing a GUI with a pure NL interface just creates a knowledge barrier where you spend a week just trying to work out what you can ask.",True
@manamsetty2664,2022-09-30T07:09:49Z,0,Yes yes great video,True
@RobLang,2022-09-30T06:48:39Z,0,"I agree with the vast majority of your video; the future is abstractions. The only thing you say that is laughably wrong is that ""all AI is written in python"". Writing business logic that consumes AI is often with python but the actual algorithms that do the complex learning tasks are much lower level. If you tried to train a non-trivial neural network with python, it would take the length of the universe to converge. You might be using python for your app but under the hood Tensorflow isn't.  This kind of proves your point about abstraction. The learning algorithm is so abstracted away from you that you have no idea what it's coded in.",True
@pawlack,2022-09-30T06:44:43Z,0,"Right now I'm more afraid of having to use stones and sticks to find food in the future, then AI making keyboard a thing of the past :D",True
@sirynka,2022-09-30T05:49:23Z,3,"Not only natural language UI would be slow but it won't work in all environments. Humans are not the only things that are making noises and all those environmental noises would interfere with you.  Furthermore, it's more straightforward to create shortcuts (fast actions, macros) with current UI. And even if you would be able to compress a sentence to a single word and let ai remember it, you'd need to get used to the command. It's fine when you've made them yourself and using on a daily basis but what about the chortcuts that are available out of the box? You wouldn't even know about their existence.   So, purely voice interfaces are strange idea to consider but the combination on current UI technologies with proper support of voice commands or even ability to talk to the algorithm as you're talking to the person would be interesting way to go forward.  But, don't we need agi for it? GPT style conversational model that would support voice interaction with the latency of human speaker.",True
@Bogdan-dg9yk,2022-09-30T04:40:12Z,0,"I would prefer to have a GUI regardless of how tech advances... If I'm out in public I don't want everyone else around me to hear what I might want to search for or what apps I'm using... Everyone values their privacy in one way or another, natural language interfaces will never be the norm, especially considering the fact that not everyone can speak in perfect eng or a lot of people have some sort of accent and the interface might not get what you're saying properly... In my case when I use google it always confuses start with stop for me... don't know why as they are really different sounding words..",True
@drhilm,2022-09-30T04:21:05Z,0,Future interfaces are generated graphical visualizatiom. Language is just a small part of it.,True
@drhilm,2022-09-30T04:18:18Z,0,I feel exactly the same.,True
@dr.mikeybee,2022-09-30T04:08:50Z,1,"By the way, I'm switching from python to swift.  Why?  because I love the new M1 systems.  The ANE in my Mac Mini has 2048 ALUs -- analogous to CUDA cores.  So a cheap $800 Mac comes with an ANE that is comparable to a 1070.  And it can access all the unified memory and even swap.  A Huggingface model runs 10 time faster after it is converted to the coreml format. So I can even run the 7 billion parameter Bloom model on it.",True
@ojussinghal2501,2022-09-30T04:04:24Z,0,Please do a QnA it's been such a long time :(,True
@flowqi212,2022-09-30T04:01:28Z,42,"As someone who's developing open-source voice assistants (in Java and Javascript and just a little bit of Python 😉) I'm pretty sure graphical interfaces will always dominate because they are just way faster. Even in my mobile app (SEPIA Open Assistant) I tend to use short-cuts and suggested buttons more often than voice input. There are specific inputs like timers and search though where voice just makes sense.  I think many inputs will be replaced by automations in the future similar to your car example. You will not say ""do this and that"" but simply define a goal like ""bring me to xy"". I also believe there will always be some extra manual input device (besides a touch screen) that will make input even faster, maybe not a keyboard but version 4.0 of it 😄",True
@dr.mikeybee,2022-09-30T03:59:39Z,0,Prompt engineering and generative engineering are the future.,True
@thatsalot3577,2022-09-30T03:19:02Z,0,"If you think of doing tasks in a declarative way then yeah AI would eventually able to do anything  But if you think of doing the same task in an imperative way then you'll just be pissed at it Like tell the AI driver your destination and let it handle the steering, tell the copilot to write a function (maybe with a given time complexity) Even though you can't trust them, I think if we wanna use them properly we should let them handle the ""how"" without asking too much ""why ?"".",True
@BaseRadian,2022-09-30T02:54:53Z,0,"Welp, thats it. I've gone from JS to C++. It's not enough anymore. I'm skipping assembly and going straight to binary. After that, I'm using my body's natural electrical current to tap a piece of wire that inputs directly to my processor.",True
@rumanahmedshaikh9720,2022-09-30T02:43:48Z,1,The more you abstract the more you get away from lower levels and thus lock yourself out of other possibilities. Future generations will forget how to work at those levels and this is how technology degrades.,True
@helpmeget100subs,2022-09-30T02:42:10Z,0,Video editing. Video game and game developing. Homework/ typing to remember. CODEC and file storage containers. And anything based off numbers.,True
@jonathanacuna,2022-09-30T02:17:23Z,0,Amazing insight!!,True
@classified022,2022-09-30T02:12:47Z,0,"The problem with natural language is it can be very vague, what happens when there is multiple interpretations of an instruction, what about contradictory instructions, what if we don't agree on the definition of a word. I could see it taking over for fairly simple tasks but for something more complicated I think a human or a GUI would make the most sense.   I also see this being a problem with fully automated software writing, Python has a high level of abstraction but there is one interpretation of a python program. Again human language is too vague to specify a whole system, covering every edge case, you would need some more formal structure to human language so it can be verified, which at the end of day is going to start looking like a declarative programming language, which we have had for decades",True
@Maxjoker98,2022-09-30T02:10:00Z,5,"I think mice and keyboards might be going away eventually, but I do think some concepts will stay for a long while longer, for example the concept of buttons. I could totally see most of the  user interface being build around natural language, but I doubt you could archive actions per second-level interaction. Maybe the future will just be like on Star Trek, you can ask the computer to do stuff, but you also have panels of buttons for doing common things quickly. I also think the ""doing things manually"" approach will have to live on, or civilization will fall after we've forgotten what makes the AI tick(but that's more a philosophical problem).",True
@dvandamme00,2022-09-30T02:03:35Z,0,"so many points to this discussion..  like the slide rule, or graphical calculator, or anything else that gets superseded. tech changes. new thinking, new tools moves into new spaces of endeavour. Our choice is to keep up, get stepped on, or move out of the way. progress does not care, and it does not stop. progress is also not linear, or any any singular direction.   Your abstraction concept is the kicker in this, of course. we have the tools now that do the work we need it to do. if the work changes, the tools need to as well. trying to use a different tool for a task just means a failure is more likely. GUI's are for the kind of tasks that need them.",True
@sevret313,2022-09-30T01:55:35Z,14,I think a more relevant next step for UI is context menus that can better predict what you want. (While still allow you to go directly to what you want if the UI guesses wrong),True
@go_better,2022-09-30T01:53:31Z,0,The thing is - there are no open source self-hosted voice command handlers. All available options are from creepy corporations. And I'm sorry that there were some misunderstandings with fellow programmers.,True
@dovacmarlon7493,2022-09-30T00:34:21Z,0,"Yeah, Python sucks!",True
@crackwitz,2022-09-30T00:13:11Z,0,"Combine speech recog, a vision model, a large language model, and a diffusion model, and you've got an AI that you can use to make all kinds of diagrams... Flowcharts, electronic circuits, sequence diagrams, outlines of books, story boards, game levels, PowerPoint decks... Anything! Just think out loud and the AI takes it down. Change things as you stare at them. And referencing those diagrams, AI can generate the details, again with human feedback in the loop",True
@marklonergan3898,2022-09-29T23:53:10Z,1,"With what you were saying that abstraction is king and everything will become higher and higher level, i'm not by any means saying you're wrong (i think you're right to be fair), but the thought of it does make me sad.  I'm not saying i use assembly or lower languages like C any more, but if i needed to write my programs in assembly, i could. I understand enough about the low level workings of a computer that i can. The problem with getting this far abstracted from the machine itself is that there's a much lower level of knowledge of how it actually works these days, and it feels like the future of people that write code to tell a computer what to do won't actually know how a computer actually does any of it.",True
@qzorn4440,2022-09-29T23:51:28Z,0,Elizebeth Smith Friedman (1892–1980) cracked hundreds of ciphers during her career as America's first female cryptanalyst... cool history. 👧,True
@CrashingThunder,2022-09-29T23:37:41Z,5,"Github Copilot really sped up my development, at least until the trial ended. I can't say I'm willing to shell out the money to continue to use it, but I definitely do miss having it suggest autocompletions for fairly boilerplate Django code all the time. It probably worked even better for me because of the kind of code I write for a living being primarily in that framework and there being so much of it to pull from online. One of the nicest things though was that it often would suggest the proper code for things I constantly forget how they're specifically called in Django/DRF. That time of quickly opening up a tab and clicking the first link to figure out a trivial piece of code can really add up.",True
@Stinosko,2022-09-29T23:17:53Z,0,"Poeple that argue never ever want to use Github Copilot are somewhat similar to poeple in the past that never ever want to use big machinery to produce products but agrue that hand made is supperior.   While hand made tools could be superior to high volume industrial products, being able to mass produce is the backbone of our society advancement. We are able to do more with less workers or even better we can do more with equal workers.   Copilot makes it able write quick, simple programs but being able to mass produce those ""simple programs"" makes it able for software engineers to focus on the more complex tasks instead and perform more work with the same amount of developers ",True
@ramtinnazeryan,2022-09-29T23:13:02Z,31,I always tell my student to look in the past if you wanna see the potential of the future. Imagine telling a person 170 years or so ago that you would be using a video chat for the purpose of daily communication instead of telegraph and writing letters. Those who think mouse and keyboard is never going to go out of fasion should consider how much pen and paper they are using these days for their daily tasks. Amazing topic!,True
@OneShot_cest_mieux,2022-09-29T22:26:13Z,1,"Thank god, video games are not powered by Python",True
@ferdyg3520,2022-09-29T22:24:43Z,0,"I know it's been like this for a while but I really like the new setup and the look of the background and everything. It makes the videos feel a lot more high quality. For years it always felt like the videos were a bit crappy, but (don't get me wrong) had like insane amounts of knowledge in them and all the projects you made were always so insane, so it's totally understandable that you tried to streamline the video making process as much as possible, but this new style makes it even more of a pleasure to watch them.",True
@LukePuplett,2022-09-29T22:19:39Z,3,"It's fun to consider how AI will negate many activities that we currently use GUIs for, like driving. This lensing bias is what makes predictions so hard. As an example, consider how useful charts are for conveying data. But we may rarely need to look at a chart in the future since the wider user story for looking at a chart for insights may have been automated away.  When I think deeply down the orders on these things, life changes so dramatically from anything we've ever known that I wonder if it could be disturbing to live through. I think we'll retain certain designs for sentimentality and enjoyment, maybe in a safe virtual space we'll race old cars, or maybe a real track will still prove hard to beat.  If you went back 100 years when most people worked in farming and told them that by 2022 machines will do all this and only 4% will work in farming, people would wonder what on Earth everyone could possibly be doing for money. Making YouTube videos.  Here's a fun clip from a natural language + graphical user interface from 1982,  Blade Runner; ""Enhance. Stop.""  https://www.youtube.com/watch?v=QOlPNZzneGw",True
@DingoAteMeBaby,2022-09-29T22:17:28Z,1,"Man ive been saying this for a long time. It's more specific than just 'natural language'. If you look at discord, the chat basically already uses low-code. The way that young people are trained to search google in ""search engine syntax"" is again, a sort of low-code.",True
@macbaryum,2022-09-29T22:14:18Z,0,I heard that we would be driving flying cars 20 years ago or use completely autonomous cars today or be driving 100% electric cars in a few years.,True
@WomboBraker,2022-09-29T22:13:17Z,1,"I think it vastly depends on your cognition. By that I mean that some people think ”visually” and some ”with words”, i personally am a latter one and find verbal methods of input to be very intuitive, thus im glad you phrased it like you did. Cool ideas!",True
@user-du9ch3tn2v,2022-09-29T22:11:40Z,0,To this python thing we still need c++ so maybe we will debug the code more like now (we will see). And also we have to think and than regulate what copyright we enforce on AI (like copilote),True
@serta5727,2022-09-29T22:04:21Z,0,Cool Idea to replace the UIs by AI interfaces. I think neural networks will do a lot of the work that programs do today. This means that many complicated buttons and menus and functions are replaced by a simple to use neural net. :)  This will make many software way more user friendly.,True
@kh-en7ul,2022-09-29T21:57:37Z,4,"I think that the pros and cons between GUIs and NLP/voice commands are equal and opposite, more or less.   Although voice input is slow, when NLP becomes more sophisticated, it should be able to take in abstract inputs. Conversely, GUIs allow for quick interactions, but what can be done on them are rigid and specific. So I don't think natural language will end GUIs—I don't think that they ever will. Rather, I believe that they will coexist as each is good at what the other lacks.",True
@mannycalavera121,2022-09-29T21:55:13Z,1,"An adpative UI, sam base functionality, but custom generated appearances for each individual user based on their meta data",True
@abdulmeliksaylan3292,2022-09-29T21:50:44Z,0,I think abstraction make the main subject's experts more valuable,True
@owlmostdead9492,2022-09-29T21:45:37Z,2,"Language itself is an intermediary we rely on to communicate with each other, it’s compute heavy, lossy, slow and prone to data loss. In contrast if I show you a picture of a tree or a colour, information is relayed basically as fast as our conscious brain can compute it. Visual is the key and not language based imo.",True
@meguellatiyounes8659,2022-09-29T21:41:16Z,0,I think natural language can be used like inner voice for ai. and the generated images used as imagination.,True
@hope-kz6tb,2022-09-29T21:36:58Z,0,bro please dont be a boring person just make more coding videos,True
@eliaskouakou7051,2022-09-29T21:28:34Z,0,They'll still be a large propertion that will want to use their limb instead.,True
@StoianAtanasov,2022-09-29T21:25:45Z,0,"A lot of effort in GIU is to make it flexible and pretty, it's not about speed at all. And in most cases when you show a lot of data it is about flexibility. You leave it to the user to analyze the data and extract knowledge. NLP + intelligence will skip all of that and go directly to the core of what you are looking for in the interaction, just like talking to an human expert.",True
@myelinsheathxd,2022-09-29T21:24:22Z,0,Let's watch this  youtube video without Video but via Natular Language,True
@markusbuchholz3518,2022-09-29T21:18:47Z,17,"Unbelievable summarization of the current AI trends, software direction, and human interaction. Since I love C++ mostly  I hope it will never disappear. Yes, the channel and Sentdex are brilliant. Have a nice day!",True
@li_tsz_fung,2022-09-29T21:15:41Z,1,"Discoverability!!!! Unless there's another invention between voice/text input/feedback and brain-computer interface. Otherwise, graphics will still play a major part or UI.",True
@antopolskiy,2022-09-29T21:15:31Z,0,"I caught myself thinking something similar last time I rewatched Iron Man. The scene where Tony is using Jarvis for designing the suit, he uses a combination of the holographic screen and voice interaction with Jarvis. And I thought to myself -- hell, like in 5-7 years with a haptic VR rig and a new generation of copilot it is going to be so close to reality.",True
@julienblanchon6082,2022-09-29T21:15:28Z,0,I WILL ALWAYS USE A MOUSE AND A KEYBOARD !!!,True
@MizzMaster_,2022-09-29T21:12:08Z,0,python sucks,True
@lizardy2867,2022-09-29T21:11:20Z,0,Ambiguity is the main drawback for natural language text to action translation.,True
@scurvydog20,2022-09-29T21:10:33Z,0,I remember a study a while back that found young people generally preferred guis while older people preferred voice commands,True
@_edd.ie_.o.8101,2022-09-29T21:07:18Z,0,For the car one they can take the cyberpunk 2077 taxi approach,True
@tobias-edwards,2022-09-29T21:04:05Z,0,"If you can code a UI with code pilot, then skip the NLP part and just code the UI with graphic software that takes your designs and spits out code. Copilot just seems like a means to an end, personally I don't see it being used like it is now in the future.",True
@user-cc8kb,2022-09-29T21:03:47Z,0,Interesting ideas,True
@foxabilo,2022-09-29T21:03:12Z,0,You say python rules the roost for AI when it is in this case the scripting language used to link the C code AI is based on. Being a scripting language is fine but if the actual root code were in python it would be unusably slow. For anything that is high level abstracted there will always be a computational budget to play with and lower level languages will always give you a larger number of calculations to use that budget on.,True
@thatotherguy4245,2022-09-29T20:59:33Z,0,"I don't have enough knowledge/intelligence to have an opinion on this topic, but thank you for explaining it so well.",True
@Zebred2001,2022-09-29T20:58:50Z,0,"Gives a whole new meaning to ""backseat driver!"" Actually, we will be interfacing with the internet/cloud etc. through an audio/visual XR experience in which we ""talk"" to the system possibly through the more familiar method of creating a customized avatar to represent it.",True
@tobias-edwards,2022-09-29T20:55:19Z,2,"Honestly feels like tech has stagnated for the past few decades, things have got faster but not necessarily smarter. With that being said, once there's a breakthrough everything else will rise to that level.  Keyboards will stick around for a while longer, the mouse not so much: mouse -> gesture trackpad -> eyes",True
@isaacandrewdixon,2022-09-29T20:49:22Z,1,"thanks sentdex, this is a very thoughtful and interesting video",True
@h.e.a311,2022-09-29T20:46:07Z,0,whats going on everybody,True
@Illmare,2022-09-29T20:43:08Z,3,Me who recently just finished a UX/UI certification: 🤡,True
@temporallabsol9531,2022-09-29T20:42:02Z,0,As more people come into it people will develop it.,True
@brambeer5591,2022-09-29T20:40:41Z,0,I will never use Github Copilot. (This comment was written via speach to text software),True
@chickenp7038,2022-09-29T20:39:19Z,2,"i often have a moment where i try to describe a friend how to do something on a phone, but then do it myself as they are just to slow and words often have not very high bandwidth",True
@Veptis,2022-09-29T20:38:43Z,17,"The more advancements are made, the more I realize how appropriate my choice 3 years ago was to do a computational linguistics course... But I kinda want to get done with it now and get beyond just language.   But think of all the interfaces that currently use natural language (like talking to other humans or writing emails), it essentially builds the basis for all interactions. And anything a human can read and process in their meaty brain to then write a different email or answer ... Could be replaced by a good langauge model and retrieval network.   And nowadays, Copilot helps me write homework by knowing the context of my code and notes in a separate .txt file.  In a few weeks I will be helping out in teaching a python intro class, and I strongly consider to tech the basics for 13 weeks and then just show them the ""cheat code"" of using copilot in the last week.   Brain interfaces will win in bandwidth over language and vision, but I haven't seen a good enough technical demo yet.",True
@punkogo,2022-09-29T20:35:51Z,3,"Sentdex, I have been learning a lot of thinks with you 3 years ago. For instances, you learnt me to use pandas. And this interesting topic I think is incredible hype, but I need to take this information with great care. Probably We can see amazing project in a year. Thanks to take the time to explain this kind of things…",True
@werthersoriginal,2022-09-29T20:34:31Z,5,The problem with NLP (audio wise) is it's linear. You can ingest more visually than you can auditorily. Think about reading voicemails vs listening to voicemails. It's rather agonizingly slow.,True
@7dedlysins193,2022-09-29T20:33:33Z,0,Hey @sendex would you say that your machine learning course is enough to jump to deep learning courses and apply to robotics ?,True
@satanistbear4388,2022-09-29T20:31:11Z,0,Not first;( Great topic! Thanks for the video :),True
@RicoElectrico,2022-09-29T20:30:14Z,2,It seems that Google overly relies on natural language matching for its search results. Now it often returns semantically close results with no verbatim occurrence of the phrase user queried. Think closest word2vec embeddings or so. Maybe this is responsible for the degradation of Google results that is often lamented on Hacker News?,True
@whatthefunction9140,2022-09-29T20:30:13Z,117,Voice to text was supposed to overtake typing. Still waiting,True
@cleoingles2827,2022-09-29T20:29:07Z,0,I’m not first,True
@Neerajpl7,2022-09-29T20:27:41Z,0,"oh yeah, I'm first 🥇",True
@Brickkzz,2022-09-29T20:27:05Z,0,"Oh yeah sentdex, first :)",True
@danielmueller8974,2022-09-29T20:27:00Z,0,First,True
@ibrahimabushawish2839,2022-09-29T20:27:00Z,1,First,True
