author,updated_at,like_count,text,public
@RealMcDudu,2016-05-16T20:13:00Z,0,"the code (well, my take on it):  import re from re import sub import time import urllib.request import http.cookiejar import difflib  cj = http.cookiejar.CookieJar() opener = urllib.request.build_opener(urllib.request.HTTPCookieProcessor(cj)) opener.addheaders = [('User-agent', 'Mozilla/5.0')]  keyWord = 'Sinead' startingLink = 'https://twitter.com/search?f=tweets&vertical=news&q=' endLink = '&src=typd'  def Main():     oldTwit = []     newTwit = []     listSim = []     y = 10     while 1<2:         try:             source = opener.open(startingLink+keyWord+endLink).read()             # print(source)             #https://docs.python.org/3.4/library/stdtypes.html             sourceCode = str(source)             splitSource = re.findall(r'<p class=""TweetTextSize  js-tweet-text tweet-text"" lang=""en"" data-aria-label-part=""0"">(.*?)</p>', sourceCode)              for item in splitSource:                 #print(item)                 print('')                 print('')                 print('')                 print('_______________________________')                 # print(re.sub(r'<.*?>','', item))                 #time.sleep(555)                 aTweet = re.sub(r'<.*?>','', item)                 print(aTweet)                 newTwit.append(aTweet)              comparison = difflib.SequenceMatcher(None, newTwit, oldTwit)             howSim = comparison.ratio()             print('############')             print(howSim)             listSim.append(howSim)             oldTwit = [None]             for eachItem in newTwit:                 oldTwit.append(eachItem)             newTwit = [None]              if len(listSim) < 5:                 time.sleep(y)             else:                 print(listSim)                 x = sum(listSim[-5:])/5                 print('the average similarity is ', x)                 if x > 0.5:                     y += 10                 elif x > 0.05:                     y += 5                 elif x > 0.02:                     y = y                 else:                     y -= 10                  print('waiting now ', y, 'seconds')                 time.sleep(y)                 listSim.pop(0)          except Exception as e:             print(e)             print('error in main loop')             time.sleep(555)  Main()",True
@nidhichawla8677,2015-01-17T06:44:26Z,0,"Thank you very much for these videos. Really helpful for beginners like me. Using this approach I can get only the latest 20 tweets. Is there any way to get tweets from last week or so. Like when I scroll down the search results page, they run into several pages. Is there a way to scrape all of that. Sentdex Indicator ",True
@padmanu,2014-09-28T22:07:51Z,1,"+sentdex, how can I get unique tweets with certain keywords within a timeframe say an hour or a particular day?",True
@padmanu,2014-09-28T20:24:45Z,0,"Hi, I am not getting any  tweets from twitParse.py, which I used to get a couple of weeks back. Has anything changed lately on the twitter site?",True
@0xsuperman,2014-09-09T22:28:13Z,0,Is this the last video of this Twitter series? I can't seem to find Part 5.,True
@MattDziadus,2014-07-11T13:16:00Z,0,Anyone know if there is a video where he explains how to replace the '&#39' with an apostrophe?  EDIT: anyone looking this may help http://stackoverflow.com/questions/10088318/decode-html-entities-using-beautifulsoup,True
@sentdex,2013-10-01T18:12:42Z,0,"Sure you could, why not?",True
@dfrusdn,2013-10-01T18:02:04Z,0,I am guessing there is not a good way to compare the dates of the tweets and compare the tweet dates to the last time the algorithm checks twitter,True
@sentdex,2013-07-08T02:00:06Z,0,Happy to help!,True
@mohamadhussien3575,2013-07-07T22:24:02Z,0,Amazing solution for scratch.. thank you so much.,True
