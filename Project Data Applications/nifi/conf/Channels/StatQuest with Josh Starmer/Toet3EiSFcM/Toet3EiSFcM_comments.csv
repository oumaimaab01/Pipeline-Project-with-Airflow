author,updated_at,like_count,text,public
@statquest,2022-05-08T19:17:50Z,8,Support StatQuest by buying my book The StatQuest Illustrated Guide to Machine Learning or a Study Guide or Merch!!! https://statquest.org/statquest-store/,True
@gunamrit,2024-02-06T05:43:27Z,0,Hello at 6.04 you said why is it a dot product is beyond the scope of this video.. can you help me materials which can help me go through it to find out why it's a dot product and not a cross product? maybe a book will do.  Thanks,True
@aaditstudent,2024-01-27T02:17:48Z,0,"Hey guys, did any of you figure out why we only need to transform the data to compute the dot product, and not tranform it ?  Thanks in advance! :)",True
@billykristianto3818,2024-01-19T02:17:42Z,1,"Thank you very much, the explanation is easier to understand compare to my class!",True
@osamajaved5029,2024-01-09T10:59:00Z,0,So much annoying while teaching. Your voice is so cringe. What is this pssttttt? üñïüñïüñïüñï,True
@faezeabdolinejad731,2023-12-19T19:09:51Z,1,üòçüòçüòç,True
@raktimnaskar2333,2023-12-11T16:56:01Z,0,Can anyone explain to me how the dot products of the feature vectors can find the separating hyperplane?,True
@ankushpandit7708,2023-12-07T11:02:11Z,0,What does the 'higher dimensional relationship' mean here?,True
@srianshumahadas7178,2023-11-01T11:38:35Z,1,Justice for Fred button!,True
@asifnewaz9391,2023-10-19T21:25:25Z,0,why do we need to calculate the dot products?,True
@itsfabiolous,2023-09-29T13:45:10Z,2,Bro you're just a blessing. Never stop with the dry humor. Lot's of love for you!,True
@jeongeunhwang1454,2023-09-22T09:26:51Z,0,"What is the role of r? d looks important, but r is always ignored because they are the same. Then why is the polynomial kernel is (a*b+r)^d instead of (a*b)^d? I bought your book but couldn't find the answer to this.",True
@atharvapatil6003,2023-08-31T05:34:52Z,8,Best machine learning playlist I have encountered on the  YouTube . The animations and your funny way of teaching makes it easy to understand concepts.  The amount of work you put to create these videos deserves great appreciation.  I would definitely recommend to go through the videos for anyone who is reading this comment.,True
@tinacole1450,2023-08-22T00:07:27Z,1,Does anyone laugh at how silly yet genius Josh is? Loved the robot.. I rewinded to do the robot.,True
@MinhTran-ik5dg,2023-08-20T22:21:01Z,1,"The ""BAM""s are so unnecessary and annoying. Anyhow, amazing animation and explanation!",True
@willw4096,2023-07-14T03:47:05Z,0,1:56,True
@shailchoksi,2023-07-11T15:23:43Z,0,Does anyone have notes for made from this video,True
@davydfridman3001,2023-07-04T08:37:12Z,0,Does anyone have a link to a good article that explains all the math behind the kernels?,True
@pratyanshvaibhav,2023-06-30T07:13:51Z,0,"respected josh sir, thank you for such amazing explanation..sir please help me i have a doubt. will we take the dot products for every pair of points like first red point with all the green points and then so on or we will take first red point with first green point and so on..",True
@MohitSharma-xy7xc,2023-06-04T13:27:54Z,0,"Guys at 06:45  what do I do with the value of 16,002.25??Also what does a relationship mean between two points?",True
@erenenadream,2023-04-17T01:51:08Z,0,Why do you make stupid sounds while teaching the topic ? which is so irritating and cringe...,True
@iisc2022,2023-04-03T18:00:12Z,1,thank you,True
@johnjung-studywithme,2023-03-05T21:23:08Z,1,This is how concepts should be introduced to students.. makes so much more sense,True
@newbie8051,2023-03-05T15:35:26Z,0,"I didn't actually get where are these used, like I've read abt stuff you explained in the first video regarding SVM's. Any supporting text you recommend that I should read to grasp this better...  Like I understood the formula, what is it for, what are the terms abrd and all that, but I feel something is missing",True
@chenghuang4724,2023-01-16T19:46:19Z,1,"Sir, this is the best video for explaining the Kernel!",True
@repackgamers5191,2023-01-08T09:57:22Z,0,"from where did you get values (9,14) at 5:35",True
@wong4359,2022-12-26T03:04:50Z,1,"I wish if there are 10 like bottoms, so that I can click all of it ! I will make sound of bibibubibu when I am clicking the like.",True
@shivoham5939,2022-12-21T04:31:54Z,1,"ü§£ü§£ double bam triple bam, pst....",True
@thawinhart-rawung463,2022-09-15T01:55:55Z,1,Good job Josh,True
@dimitrismarkopoulos3964,2022-08-11T07:10:43Z,0,First of all congratulations! your videos are super explanatory! One question: The equation of the polynomial kernel has always the same form?,True
@beshosamir8978,2022-08-01T19:33:14Z,0,"quick question : why it is useful to calculate the relationships between every two point regardless in any dimensions , how it can be useful for calculating the decision boundary ?",True
@stoicism-101,2022-07-22T15:16:35Z,0,"Dear Sir, Kernels are basically used for finding the relationship between two points using the formulae. How do we further find the Support vector classifier?",True
@hamidomar3618,2022-07-17T19:49:21Z,0,"Hey, great video, thanks! What happens after the transformation though? I mean, how does the final result. i.e. a scalar corresponding to relationship between each observation, help in identifying an optimally classifying hyperplane?",True
@trashantrathore4995,2022-07-10T13:52:26Z,1,"Earlier i had an intuition of all Algos which was incomplete and which could not be explained to others, Concepts are getting cleared now. Thanks STATQUEST Team, Josh Starmer, will contribute ASA i get a job in DS field.",True
@kwok9298,2022-07-06T18:28:57Z,3,I really appreciate how the way it is explained.  Please keep on the good job!,True
@aryamahima3,2022-06-13T12:09:16Z,0,"@5:09, u said that we need to calculate dot product between each pair of point. How do we use this dot product further? could u please clear to me, u r the only person on whole internet who can clear this. :D",True
@commentor93,2022-06-08T19:54:19Z,0,I've understood more than I ever expected to understand in this topic all thanks to your videos.  But now I've stumbled a bit: How do you solve a constant like the one in 5:50? Or what does solving mean in that context now that it isn't a formula? Could you please expand on that?,True
@The_Mashrur,2022-05-28T19:34:50Z,0,"When you say relationships between observations, what exactly do you mean? You didn't really go over how such relationships allow you to find an SVC in the higher dimension?",True
@utkarshagrawal4708,2022-05-02T03:23:05Z,0,Any resources for understanding why the dot product?,True
@marcelocoip7275,2022-04-29T14:59:30Z,0,"Visually thinking about the last set of data: if you can draw a line to separate the data if you square each observation to the y-axis, then you can draw a line independently of the scale/ratio of the x-axis. Then I see is that the only thing that it is adding ""solving/math value"" is increasing the order of the xi-axis to fit a hyperplane (d value). What r contributes to arrive to a better solution?",True
@aravindsuresh7234,2022-04-28T18:19:26Z,0,Hi sir!  how do you find the value of r as 1/2,True
@suyashmishra8821,2022-03-21T11:27:53Z,0,"Hello sir, In the above example It was clear that new transformed axes were a,a^2 but It wasnt clear the mechanism how classifier draws line. Do we get the equation of that classification line from kernel function,dot product or something related?",True
@cookie6299,2022-02-22T14:01:52Z,0,22222,True
@rajatsankhla9261,2022-02-22T07:31:27Z,0,Hii Josh could you help me understand how one should choose the value of r in the kernal function.,True
@eric752,2022-02-10T18:22:19Z,0,"One suggestion: if at the beginning, if the all the topics are listed in a logical way, it would even better. Big thanks for the videos, really appreciate it üôè",True
@TaylorSparks,2022-02-01T04:00:13Z,1,bam. love it homie. keep it up,True
@iliasp4275,2022-01-27T10:05:40Z,1,send my love to fred <3,True
@guyelovici4940,2022-01-12T15:01:11Z,1,◊û◊ú◊ö!,True
@ronitganguly3318,2022-01-12T01:06:58Z,0,The high dimensional relationship you calculated at the end is a number which tells what exactly? How does it help to pseudo transform into higher dimensions?,True
@shivakiranreddy4654,2022-01-11T17:39:06Z,0,"Hi Josh, I couldn't get how 16002.25 will help us in drawing the Support Vector Classifier, In comments below you mentioned: ""In some sense the ""relationships"" are similar to transforming the data to the higher dimension and calculating the distances between data points."" even this above explanation did not help, if 16002.25 is one of the 2-dimensional relationships that we need to solve for the support vector classifier, what is the other one? how do we get the classifier?",True
@vianadnanferman9752,2022-01-08T20:37:56Z,0,"Thanks for the amazing video. Please, if I have 100 samples for training and each with 5 features and try to apply 2D polynomial. So how my data is converted to a higher dimension? in other words what do we mean by the two input vectors in the polynomial equation?",True
@dok3820,2021-12-22T13:52:49Z,1,Thank you Josh. Just..thank you,True
@muhtasirimran,2021-11-27T17:34:06Z,1,Mr. Starmer almost unconsciously changing machine Learning's future üòÄ,True
@RHONSON100,2021-11-17T09:36:59Z,74,Your videos should be mandatory tutorial for Data Science/ ML courses in all the Universities. Students throughout the world would get benefited  after watching the best ML video.Hats off to you great Josh Starmer..............,True
@harishh.s4701,2021-10-25T12:23:04Z,0,"Hi,  Thanks a lot for your content. It is very easy to understand and I appreciate your way of explaining things. I had one doubt. Can you please explain how does Cross-validation help to determine the optimal degree of the polynomial kernel used in SVM's?",True
@p-niddy,2021-10-19T08:05:23Z,0,"What does the ""relationship"" between two points actually signify? Based on this video, it looks like a number without much meaning that you can map onto the graph.",True
@andrei642,2021-10-11T11:34:59Z,0,Am I the only one who gets really disrupted by those cringey BAMs?,True
@bharathsf,2021-10-09T11:24:17Z,0,What does the number 16002.25 actually mean though?,True
@rajdeepkumarnath8944,2021-09-16T11:28:31Z,1,"I once knew a kernal, whose name was Fred, But thats not the path we are gonna tread. (thats a better song Josh :D )",True
@manaspatil4316,2021-09-01T08:44:48Z,2,God bless you !!!,True
@lonandon,2021-08-31T15:22:55Z,0,What does the result of the dot product mean when it represents the relationship of two dots?,True
@manasadevadas8685,2021-08-01T13:44:00Z,3,"First of all thankyou so much for explaining with such amazing illustrations. One doubt, how can we actually use relationship between points to find the support vector classifier?",True
@geogeo14000,2021-07-02T18:27:06Z,0,"Great video thank you. But I don't understand why the kernel with dot product is more computationally efficient than transform the data in 2 dimension, because in any case we have to raise a and b, the observations (the data so), to the square, and that is transform the data in 2 dimensions no ? and then we do the dot product... So I'm missing sthg here but I can't see what. thank you very much !",True
@hamedbahramiyan,2021-06-25T12:52:43Z,0,"I didn't get how the kernel relationship value is used to transform the data. In the theory, the kernel relationship is a square  matrix, containing kernel values for all samples 2 by 2. You calculated one of these at the end, but how to use them to transfer the initial data? what is the function or algorithm?",True
@madhuvarun2790,2021-06-23T06:15:04Z,0,could you please provide an example where 3d data is converted to 4d data using polynomial kernel? I am stuck,True
@moisesdiaz9852,2021-06-14T21:02:27Z,0,5:27 But what happens if your classes are not balanced?,True
@yancheeyang2918,2021-06-14T01:53:16Z,0,Question: The video ends as getting the relationship. I wonder what does it mean and how can we get the optimal hyperplane from here? thanks!,True
@alternativepotato,2021-06-11T14:21:29Z,1,i love u my man you really are a life saver. Just because of that i am gonna buy a tshirt,True
@harshitsati,2021-06-03T14:18:56Z,1,Thank you angel,True
@surajjoshi3433,2021-06-01T15:26:07Z,0,"Sir ,From where did you learned all these in such a detail ,please make a video on best resources to study for machine learning or just reply my comment please Josh Starmer Sir :)",True
@sagarmehla2102,2021-05-29T11:38:57Z,0,where can I get all stat quest pdf??,True
@61_shivangbhardwaj46,2021-05-29T04:19:36Z,1,Thnx sir great explanation :-),True
@notapplicable7292,2021-05-26T09:36:22Z,1,"So this is why my uni doesn't bother trying, they know they are going to be outdone by statquest anyway.",True
@digitalzoul57,2021-05-17T02:57:01Z,0,"Hi StatQuest. you said the 'a' and 'b' are two different observations is this means that the k(a, b) depends on the number of classes. For example, if I have 4 classes does it means k(a, b, c, d)?",True
@rezasaifuddin3967,2021-04-20T08:38:10Z,0,Can someone explain to me what is the affect of our SVC due to the selection of r value ?,True
@vincent-paulvincentelli2627,2021-04-19T17:16:13Z,0,Great video ! It would be very nice to have such an intuitive one for kernel PCA :),True
@madhuvarun2790,2021-04-07T08:02:35Z,68,"Dude, You are amazing. The best tutorial on SVM. I have searched the entire Internet to understand but couldn't. Please continue to make videos.",True
@Han-ve8uh,2021-04-03T14:34:04Z,0,"1. Is there a relationship between the values of d and r in polynomial kernel, and the number of output dimensions?   2. At 3:27 why is the 3rd term ignored, is this part of the kernel trick? Are the 3rd terms always the same no matter what d or r is used? 3. It seems that the dot product exists only because d=2 which after expansion allows the expression to be expressed as a dot product, if d=3 then we cannot express as a dot product of 2 terms anymore? 4. Does this whole video apply to other kernels too?",True
@znull3356,2021-03-29T20:16:19Z,0,The more I get into math the more I realize a lot of it is just making stuff up and then going back and correcting for the thing you made up. Adding a pretend axis just so you can find a good model on one-dimensional data is no different than adding or subtracting a number on both sides of an equation. It's the art of forcing a convenient balance.  And to think I once thought any of this was difficult. Bam?,True
@tymothylim6550,2021-03-19T03:52:30Z,1,Thank you for this video! It was very helpful in terms of understanding the details of how the kernel function leads to certain equations that need to be solved to obtain the relevant Support Vector Classifier!,True
@stanlukash33,2021-03-12T11:39:05Z,181,I will make it easy for you guys:  3:38 - BAM 4:49 - DOUBLE BAM 5:54 - TRIPLE BAM,True
@geo1997jack,2021-03-01T16:48:48Z,0,I did not understand what that 16000 value means or how it helps us. Could you please clarify? Everything else was crystal clear :),True
@nafassaadat8326,2021-03-01T11:54:38Z,1,"BAMMMMMMMMMM!!!!!!!!!!!!!!!!!!!!! great , thank you",True
@abhinavvishwakarma6078,2021-02-28T06:56:32Z,0,Sound great at 2x,True
@sinarb2884,2021-02-18T21:05:02Z,0,"I could be wrong, but I think there is a slight mistake in this video. The kernel function should be of the form (ab-1/2)^2. This is because the support vector classifier is essentially thresholding based on whether x>y or not. Let me know please if I am wrong. And, thanks for your cool videos.",True
@abhishekanand5974,2021-02-08T12:28:40Z,0,What exactly is meant by relationships between observations?,True
@technojos,2021-02-07T16:41:40Z,1,"Thanksss Josh Starmer.I am facinated because of your videos.  Please make a video about how 16002.25 is used bam?. Moreover I think that you can make video playlist about how machine learning algorithms has coded  double bamm . Keep going man, we love you triple bamm!!!",True
@nick_g,2021-01-04T15:50:47Z,1,I get the feeling some linear algebra might help with this stuff. I‚Äôm no expert here but it kernels remind me of how an extra column is added to a matrix in order to transform to a higher dimension without changing the original values I saw in a computerphile video: https://youtu.be/vQ60rFwh2ig  Also there‚Äôs a video I watched about factoring polynomials with matrices in the numberphile channel that might apply: https://youtu.be/wTUSz-HSaBg,True
@varunmanjunath6204,2020-12-31T14:58:07Z,0,cs229 by andrew ng explains it,True
@varunjindal1520,2020-12-16T18:02:20Z,0,"Hello Josh, I have a question. Could you please address?  We took the dot product of a and b and found the high dimensional relationship to be 16002 without even transforming to 2D.  Do we need to do it for every pair and solve it separately? How do we solve this number, is there any next part to this?",True
@FeddFGC,2020-12-09T01:01:20Z,0,I wanna know about the Kernel named Fred,True
@axa3547,2020-11-05T08:45:05Z,0,machine learning algorithimss!!! is it just me or other who has to learn these again n again to fill the gap in knowledge,True
@edmondkeogh4057,2020-10-28T17:11:25Z,2,the beep boop thing was hilarious,True
@evelillac9718,2020-10-27T20:15:10Z,1,You literally saved my homework with your videos,True
@rishabhmalhotra127,2020-10-17T08:32:32Z,4,This StatQuest isn't about a kernel named Fred coz it's about a kernel named Polynomial. Hilarious xD,True
@MrZidane1128,2020-10-10T19:27:57Z,20,"First of all, thanks for your explanation, after plugging two data points into polynomial kernel function a and b then get the value 16,002.25, then you said we get higher dimensional relationship. Could you elaborate further what ""relationship"" did you refer to based on the value 16,002.25? Sorry I was not quite sure about that",True
@JuanMendoza-hz2vj,2020-10-05T00:36:01Z,0,"en el segundo grafico, cuando graficas sqrt(2)*a y a**2, los puntos del eje Y deberian ser los mismos que el primer gr√°fico, en cambio, los quemuestras son los puntos en el eje Y (sqrt(2)*a)**2 , gracias¬°¬°",True
@naveenraju6138,2020-09-05T20:03:13Z,0,what is the significance of r?,True
@annusrivastava4425,2020-09-05T16:52:43Z,1,"To find the value of r and d, can we use GridSearhCV as well?",True
@donaldmahaya2689,2020-08-28T03:23:53Z,1,I'm always left with the illusion that I understood what you just said.,True
@abrahamjacob7360,2020-08-19T19:39:09Z,0,"Josh, this is a great video. One question on the Polynormal Kernal derivation. So the original problem was to find a classification point to find drug usage limits that cures or doesnt cure the disease. When we increased the value of 2, you mentioned it introduced a second dimension. I understood, how squaring the value helped to find a better Marginal classifier line, but ideally there is no meaning to the y axis here right, because the case still remains the same. We are just finding if the drug usage had a positive or negative impact. we could still use the y axis to determine its efficity, but if we increase the value to 3, what would Z axis represent here. Sorry if the question was confusing",True
@shubhrajit2117,2020-08-08T05:18:45Z,0,What's this BAM all about?,True
@XoXkS,2020-08-01T10:45:06Z,0,"Another Great thing, besides the astonishing easy explanations, is the way you talk. You talk so slow, that I can watch the easy parts easily on 1.5 Speed and the hard parts on normal speed. Most people, when they talk slow, talk slow by making long pauses in between words, this way watching at a higher speed sounds very unnatural. You sound just fine on normal and 1.5 Speed!",True
@zheyuanzhou3165,2020-07-30T03:07:46Z,1,"super clear tut. Thank you very much! But as a non-English native speaker, I am a little confused, what is BAM trying to express?",True
@chinzzz388,2020-07-12T16:58:55Z,0,"When we calculate relationships between 2 data points, do we calculate relationships between all the points w.r.t all the other points? Ex: if we have 4 data points (1,2,3,4) do we calculate relationship between (1,2) and (3,4) OR do we calculate relationship between (1,2),(1,3),(1,4),(2,3)...etc",True
@nightawaitsusall9607,2020-07-06T09:30:07Z,2,You my friend are a champion. Yes.,True
@priyangkumarpatel9317,2020-07-04T22:10:47Z,1,"This is one of the best explanation for support vector machines... If anyone is interested in why dot products are integral to the idea of SVM, please refer to Professor Wilson's MIT lecture on SVM... It is another great explanation for SVM...",True
@DeepakSingh-fo2wm,2020-07-02T13:24:30Z,1,I am still not clear what happened after finding a relationship in higher dimension like in the video what happened after finding 16002.25 ?? Can you please add a short video over the same if possible.,True
@harshitamangal8861,2020-07-01T15:21:30Z,3,"Hi Josh, the explanation is amazing. I had a question- you said that the equation (a*b  + r) ^d is used for finding the relationship between two points, how is this found relationship used for getting where the Support Vector Classifier?",True
@sornamuhilan.s.p,2020-06-27T20:01:58Z,1,"John Starmer, you are a genius sir!! <3 !!",True
@L.-..,2020-06-27T18:43:17Z,1,"After we find the dot product, with that value how we decide whether the new sample belongs to positive class or negative class?  Please clarify Josh.",True
@preeethan,2020-06-25T18:36:31Z,3,Amazing explanation:) We find the High Dimensional Relationship between 2 points to be 16002.25. Practically what do we do with this value.? How do we find the Support Vector Classifier with this value.?,True
@marijatosic217,2020-06-23T10:16:16Z,2,"Thank you for the video! And now, what does this number 16002.25 tell us? :D How will we know what the right dosage?",True
@hrdyam865,2020-06-16T12:07:14Z,1,"Thanks for the videos üòä, Can we use SVM for multinomial classification?",True
@learningwheel8442,2020-05-20T15:12:15Z,0,"https://youtu.be/Toet3EiSFcM?t=346 Using the Kernel trick,does it mean that if we have n observations, then we have n^2 points (each representing a pair wise dot product) in a higher dimension on which the classifier finds a good decision boundary?",True
@sabbirakhand7120,2020-05-20T05:26:51Z,0,After getting the value of r and d by cross validation we get the value of 16002.25. But how to use this value to determine the high dimensional relationship?? This video was really helpful to understand the topic despite of me being from a different background. Thanks.,True
@khanhtruong3254,2020-05-17T10:22:03Z,0,"You mentioned ""We need all pairs relationship in high dimensional space to find the Support Vector Classifier"". But how? For example, we have 10 data points in 1-dimensional space (i.e. 10 scalars), each of them is either Red or Green. Suppose we use Polynomial Kernel with d=2. So we would end up with 10C2 pairs relationship. From these 10C2 numbers, how can we define the Support Vector Classifier?",True
@MrWincenzo,2020-05-15T18:16:48Z,1,"since the kernel requires to calculate the dot product for each couple of points, suppose we  have 10 points when we do it just for each point with respect to the others and itself we should obtain 10 different dot products for each single point. Which one of those 10 dot products become the new ""y"" dimension of the point?",True
@zeynabmousavi1736,2020-05-15T06:49:09Z,0,How overfitting is evaluated in SVM? How do you check whether the output of SVM is generalizable or not?,True
@benardmwanjeya8371,2020-05-10T19:48:21Z,4,God bless you Josh STARmer,True
@nehamanpreet1044,2020-04-29T19:10:23Z,0,d tells us in which dimension we want to take our data to right ??,True
@606Add,2020-04-27T04:12:02Z,5,You are videos are simply amazing! And the level of abstraction is right at the sweet spot! Thank you for the extremely thoughtful and precise illustrations!,True
@flaviodefalcao,2020-04-21T03:01:05Z,1,It is awesome and satisfing to be able to learn an intuition with these videos and reading a textbook understanding everything. THANKS,True
@pradeeptripathi1378,2020-04-20T17:41:31Z,0,where is part 1? i am able to see part 2 and part 3 only.,True
@yogeshyadav-te8sg,2020-04-19T09:03:57Z,0,Sir where we use the 16002.25 this high dimensional,True
@hassanjb83,2020-04-16T14:37:26Z,1,‚ÄãAt 6:33 you mention that we need to determine the value of both r and d through cross validation. If we have one dimensional data then shouldn't be d = 2 only?,True
@deashehu2591,2020-04-11T16:53:06Z,38,"I have grown to love your little songs. They sound like Pheobe's songs!!! I have a little question , what do you use for visualization?",True
@jaysonklau3683,2020-04-09T09:33:24Z,0,4:19 a means red ? b means green ?,True
@ranitchatterjee5552,2020-04-06T15:15:22Z,0,"Do you have a course on Udemy for machine learning? If not, please make one...... I'd love to purchase it!!!",True
@iliya-malecki,2020-04-06T15:03:29Z,0,"why on earth is the difference between each point is not sqrt(x1+x1^2)-sqrt(x2+x2^2), like it would make sense in 2 dimentions(if x^2 represents y)? In n dimentions it would simply be root(base n)(x1+x1^2+...+x1^n) - root(base n)(x2+x2^2+...+x2^n)! How is that formula of yours represents this equation?",True
@keltonwang4834,2020-04-05T08:53:17Z,0,"One doubt, though u multiple a and b by sqrt2, shouldn't u calculate a^2 and b^2 using original a and b rather than sqrt2*a and sqrt2*b on y-axis?",True
@muhammadiqbalbazmi9275,2020-03-05T02:44:04Z,0,"Sir, will you please give us a link to your presentation that you use in these videos.",True
@marcoharfe9812,2020-02-09T07:37:18Z,13,"I want to thank you so much for all your videos. I was lost in a forest of vectors matrices and greek letters when I heard about these topics in lecture and I did not understand a thing. As I was practising for the exam, I discovered your videos and now I do actually understand what is happening. Really love the practical, example driven approach!",True
@yashmishra12,2020-02-09T06:04:56Z,0,So what do we do after we have the value for every green and red dot? Draw the hyperplane between the pair which had the maximum value (doesn't make a lot of sense though)?,True
@temesgenaberaasfaw5076,2020-01-21T18:05:44Z,2,"best tutorial for SVM , YOU DID IT THANKS",True
@ayoubmarah4063,2020-01-16T20:49:45Z,0,"Great content as usual BIG THANKS to you I hope you are having a nice day    i have questions  if you dont mind : i got confused with the problem of the imbalanced classes , when the classes are imablanced we do either upsampling or downsampling so that we have a balanced data  1) does the accuracy score always wrong using imbalenced data? what about f1_score then ?  2) how to decide which sampling method is good ? should we run them both ?  i do my best to try and search for solution but there is so much opinion and im lost , i saw your video last week but when i got my hand dirty with projects i confront new problems that are complicated  Thank you again for your help",True
@krzysztofkolmus6936,2020-01-16T07:34:14Z,0,"In a nutshell, why do you need to calculate dot product or does it require a separate video?",True
@redaouazzani7120,2020-01-15T00:11:17Z,0,Great explanation ! But what are the math reasons to choose RBF Kernel or Polynomial Kernel ? It depends on what ?,True
@NathanPhippsONeill,2020-01-09T23:39:42Z,2,Amazing vid! Thanks helping me prepare for my Machine Learning exam üòÅ,True
@harithagayathri7185,2019-12-18T09:32:21Z,3,"Great explanation üëç Thanks a ton Josh!!. But, a bit confused here on how to calculate appropriate 'r' coefficient for the eqn.I understand that 'd' value is calculated using Cross Validation",True
@amalboussere9270,2019-12-09T17:42:25Z,20,thank you a lot you are such a big help in this harsh student world god bless you .,True
@Beenum1515,2019-12-05T01:06:17Z,0,What I understood the function of kernel is to transform the data into high dimension so that there exists a classifier in that dimension which seperates those points. Right?   If yes than why not just square each value instead of getting each pair to kernel function?,True
@jonathannoll3386,2019-11-29T10:40:03Z,6,My man. I'm so happy I have my presentation about SVM's after your uploads... Keep up the great work!,True
@ruowentan2771,2019-11-28T14:41:23Z,0,"Sorry, why green dots are below red dots in 2D? If you compute dosage^2, green dots should be above the first few red dots, right?",True
@muhammadavimajidkaaffah7715,2019-11-27T14:44:26Z,1,"SVM for multiclass please, I like your video so much.",True
@slirpslirp,2019-11-26T09:19:40Z,0,"so polynomial kernel takes the x values of two one dimensional vector (in this example a and b) and returns a single number ? well, how this work when i want to classify a single vector a ? i mean , i need all the pair kernel relationship to do so?",True
@UjjwalGarg09,2019-11-25T19:25:30Z,1,please make a video on this 5:58,True
@yokeshnsr1976,2019-11-20T15:23:58Z,0,How do you transform 2D data to 3D? How will you get the Z-coordinate?,True
@ThePentanol,2019-11-20T12:22:31Z,0,I didnt understand why your express the square of the values in the dosage axis as the product of a and b. Why you didnt just choose to square the values ?,True
@takshkamlesh9914,2019-11-19T12:15:16Z,0,What do you mean by high dimensional relationships?,True
@banashreeshiva4506,2019-11-13T17:58:11Z,0,Are a and b data points of 2 different group or same group? Can we have values from same group as a and b?,True
@berknoyan7594,2019-11-09T12:34:45Z,1,"Hi Josh,Thanks for the video. You are helping me a lot. I have just one question. What do you mean by ""high dimensional relationship""? Because It can be achieved by any 2 numbers that has multiplication result of 126 which is Infinite.Its just a dot product of two 3 dimensional data.Cross Validation uses misclassification rate to select best r and d as far as i know. Do CV use these numbers on any calculation?",True
@hayskapoy,2019-11-09T12:29:09Z,100,Would love to see more math after seeing the big picture behind these algorithms üòÑ,True
@ahming123,2019-11-09T07:25:47Z,74,What do you mean by high dimension relationship??,True
@slirpslirp,2019-11-06T10:47:42Z,1,"awesome, so the dot product is equal to the result of the kernel function ?",True
@jhfoleiss,2019-11-05T12:41:08Z,1,"Great explanation, thanks! One question: what happens when a and b are vectors? I understand that in this quest you wanted to give a simple example (with a single feature) to make things clear. If the answer to this question is in another quest, i'll gladly wait for it :)",True
@yulinliu850,2019-11-04T23:59:13Z,1,Awesome! Josh is back.,True
@shahbazsiddiqi74,2019-11-04T18:30:50Z,0,One doubt. How is SVM better than Gradient Boosting?,True
@shahbazsiddiqi74,2019-11-04T18:29:16Z,1,waited too long... Thanks a ton,True
@balajip8711,2019-11-04T16:25:27Z,2,Baam,True
@edmundchan8923,2019-11-04T15:19:13Z,0,If there arw 3 variables the formula would be (axbxc + d)  ^ r?,True
@tumul1474,2019-11-04T13:51:40Z,3,this is damn amazing !!,True
@rrrprogram8667,2019-11-04T12:40:25Z,7,After a lonnnnggg waitttt..... MEGAA MEGAAA MEGAAAA BAMMM is back,True
@tuongminhquoc,2019-11-04T12:03:54Z,2,First comment! I have turned on notification for your videos. I love all of your videos!,True
@leonugraha,2019-11-04T12:03:17Z,2,"Thank you for SVM follow up video, by the way, do you maintain a Github account?",True
