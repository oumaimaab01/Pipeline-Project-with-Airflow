author,updated_at,like_count,text,public
@statquest,2022-05-08T19:16:56Z,6,Support StatQuest by buying my book The StatQuest Illustrated Guide to Machine Learning or a Study Guide or Merch!!! https://statquest.org/statquest-store/,True
@patryxsterv4523,2024-05-29T17:33:31Z,1,"Wow, I hate reading the theory for my project, but love your videos, make it better to understand these chinese math equations",True
@lauriesteveescoses590,2024-04-16T15:56:09Z,1,"holy shit, i didnt expect series expansion to come at the end. so cool",True
@unlucky_coder8983,2024-04-14T18:41:32Z,0,Sounds like K-nearest neighbours...,True
@KiranDhakal8848,2024-04-08T21:55:52Z,1,As I continue watching your video the satisfaction of understanding BAMSS EXPONENTIALLLY!!!,True
@richf.9211,2024-04-03T12:46:52Z,2,This man just answered questions I didn‚Äôt even know I had!üòÇ Excellent job thank you for the videos!,True
@user-dh4ud1dr8u,2024-03-25T06:11:04Z,1,you are my professor,True
@yashkumar9671,2024-03-24T13:40:04Z,1,The maths isnt that mathy tho....but still loved the video. Thanks!!!,True
@hawaiicashew3237,2024-03-23T09:47:51Z,8,Holly cow this one is flying high. The guy who figured out all the maths must have been on fire!,True
@r0cketRacoon,2024-03-16T08:27:55Z,1,"wtf, I love that part 9:25, u enlightened me",True
@foluobidare957,2024-03-10T23:45:08Z,0,But what about classification?,True
@caiochaves9550,2024-03-08T23:13:42Z,1,Amazing!,True
@mitsuinormal,2024-02-24T07:33:27Z,0,OMFG,True
@DeMatzen,2024-02-09T14:27:38Z,0,"I know I am late to the party, but as far as I understood, the projections of the data a should only depend on a and not b, but at 14:50, s would depend on a and b for both a and b. Wouldn‚Äôt it make more sense to split exp(-gamma(a^2+b^2)) into exp(-gamma*a^2)*exp(-gamma*b^2) and pull each part into the corresponding vector of polynomials?",True
@user-gq3uo8dl1l,2024-01-29T22:10:11Z,1,üíå,True
@horanj.1022,2023-12-22T18:28:45Z,0,"Great series on SVM, good job!  one little comment: @ around 14:45, when you take `s` into the Taylor Series: s is a function of both `a` and `b` so it's not quite correct to place it on both vectors for the dot product.  it may be a better trick to first write `s` as exp{-a^2/2} + exp{-b^2/2} and then multiply each term by their corresponding counterpart in the dot product:  ... = (exp{-a^2/2}, a x exp{-a^2/2} + a^2/sqrt(2!) x exp{-a^2/2}, ...., )                                       dot prod.         (exp{-b^2/2}, b x exp{-b^2/2} + b^2/sqrt(2!) x exp{-b^2/2}, ...., )",True
@AI_Financier,2023-12-13T11:19:01Z,1,"Great video again, in parallel world everything is linear. Can you please make video on Kalman Filter too?",True
@KayYesYouTuber,2023-12-10T18:09:53Z,1,Super Super Super !!!,True
@mohammedessam581,2023-12-09T05:14:33Z,1,"from now onward i will quote you with this : ""okay time to take a deep breath  we've done alot but we still have a few more steps before we're done and get to eat snacks""",True
@vncoolestguy,2023-12-08T15:52:08Z,1,"+ 3 views, thanks for awesome tutorials Josh.",True
@HeavyBoredRabbit,2023-12-06T16:36:12Z,0,"Hi Josh, or anyone else who may know. Can you only use SVM for single variables? If you have multiple features, can you do SVM for each one? Then how do you combine the results?",True
@ritshpatidar,2023-11-27T13:35:18Z,0,SVM is the most beautiful ML Algorithm.,True
@ritshpatidar,2023-11-27T13:33:05Z,1,The guy who came up with RBF is genius.,True
@skelgamingyt,2023-11-21T20:02:57Z,4,Please take our professor's job. We need you.,True
@user-gk9ku4el1f,2023-11-21T10:10:01Z,1,beep beep boop boop beep beep boop,True
@kankog,2023-11-15T18:13:17Z,2,Hello starmer bro! Will india win cricket Word cup this year statistically?,True
@debasmitroy4513,2023-11-14T19:39:25Z,2,My reaction to this video : üòê,True
@anannyodey7782,2023-11-14T19:33:50Z,4,Dhur Bam,True
@shauryavatsa595,2023-10-29T16:39:07Z,1,I wish I could be taught by you physically. I know nothing about machine learning and I am going through some of the topics for my internship and I cannot tell you how easy you are making things for me. Quadruple BAMM!!,True
@ManojGupta-tb3ei,2023-10-09T18:08:46Z,1,Well explained Thank you....,True
@devindoinmonkmode,2023-10-03T01:13:56Z,1,"3hours lectures in 15 mins, and it's super funny. Super Bam for StatQuest",True
@phongapex3741,2023-09-28T14:00:12Z,0,"Hello, at the time of 14:34, you multiply both parts of dot product by the square root of the first term to make the radial kernel all in one dot product. Why do you do that? I cannot get it :(",True
@MOHSINALI-bk2qo,2023-09-28T08:25:55Z,0,in 14:05 min where does the square root come? can you plz explain,True
@sinkseeker,2023-09-17T06:35:17Z,1,The way you explain the math is astounding! I hope you'll continue making videos like this!,True
@hieuthepunk,2023-09-16T16:25:26Z,0,"Can i ask a question? In python, there are gamma and C that's important to the model. Can you explain how they're related to the equation in this video, please?",True
@yaorongge,2023-08-24T23:19:25Z,1,Thanks!,True
@tinacole1450,2023-08-22T00:32:24Z,1,"Did the robot a lot on this one.... Thanks , good times.",True
@leecharlie2513,2023-08-18T07:31:19Z,0,"Those medium bam , triple bam, bi bi boo boo boo is actually very annoying",True
@yourfutureself4327,2023-08-16T22:40:34Z,1,ü©µü©µü©µ,True
@konstantinlevin8651,2023-08-07T17:00:16Z,1,"wow, this actually rocks but I've lost after taylor series expansion of e to the x. nice try be back here later!",True
@tampopo_yukki,2023-07-15T07:24:13Z,2,"When I was struggling to understand what the use of kernel is intuitively, I found this video in StatQuest series. Now, this seems to have fixed my shaky comprehension about the kernel! Your video series are one of my favorite explanations for base of ML. I'm so glad if you'd keep making these kinds of interesting videos on your pace, BAM!",True
@willw4096,2023-07-14T05:44:11Z,0,15:11,True
@filipfolkesson3865,2023-07-04T11:29:08Z,1,"This was so funny and educational, thanks man",True
@prabhakarkaujalgi3549,2023-06-25T15:34:58Z,0,"Good explanation about RBF kernel, hats off. But please stop saying BAM, Double or Triple BAM. Also, stop saying terminology alert...",True
@fatihboyar9697,2023-06-09T07:26:00Z,1,calculation noises are so realistic and horizon widening experience,True
@peterng.,2023-05-18T03:50:38Z,1,worth to spend times on! thank you Josh!,True
@manishkumark3462,2023-03-31T09:17:54Z,0,Everything is fine. But you did not explain what to do with the value we got?,True
@kk___kk___kk,2023-03-20T19:44:43Z,5,"I find some beep boop sounds a bit cringe, but it's crazy how good you are at explaining and showing things step-by-step. Thank you so much !",True
@e555t66,2023-03-13T23:40:14Z,1,Really explained well. If one wants to get the theoretical concepts one could try doing the MIT micromasters. It‚Äôs rigorous and demands 10 to 15 hours a week.,True
@SometimesMagii,2023-02-28T14:08:20Z,5,"the mathematical reasoning behind the radial kernel has been plaguing me for so long, finally after many tries now it starts to click and my mind can visualize better what is happening and why. Thank you so much :)",True
@morpheus1586,2023-02-27T00:51:39Z,0,I'm still confused. So how do I find the centre/classifer using Radial Kernel again?,True
@SyS591,2023-02-20T05:12:07Z,0,"14:47  Isn't this wrong? s already consists of  a and b, shouldn't we take exp(-a^2) and exp(b^2) and then multiply those into expression then split the terms of a and b as vector dot product?",True
@user-tv2wj9mi8y,2023-02-12T06:23:43Z,1,◊™◊ï◊ì◊î!,True
@MinhazCanada,2023-01-23T08:54:28Z,0,"I understood Kernel to maximize distance, but how do you derive classifier out of it. It would be nice if you showed that too.",True
@pushpendarchoudhary1667,2023-01-14T16:59:49Z,0,worst intro for an educational video,True
@ilyabykov2437,2023-01-05T19:44:04Z,0,"If I ever get a job in data science, it'll be thanks to this guy.",True
@Ganeshkakade454,2022-12-27T06:11:22Z,2,bam.. after understanding this .Now I can eat my snack.,True
@wong4359,2022-12-26T08:09:02Z,1,I thought I need to watch few times then only can go to eat snack. I was wrong.,True
@kiyok8849,2022-11-19T12:53:14Z,1,The latter part is indeed extremely mathy but too beautiful to skip!,True
@josefsieber6226,2022-11-06T19:17:26Z,0,Hi Josh - I watched this a few times and was struggling . I am not getting the jump from (a dot product b )^ 2 to a^2 times b^2 . I can‚Äôt seem to find anything online to help me understand - if you have a minute would appreciate a little more explanation. I never thought dot products with an exponent were distributive ?,True
@diarmuidbrady927,2022-10-29T18:22:13Z,0,"For the last part where you say s = e^-1/2(a^2 + b^2) and add it to the TSE, does this mean that for point a in infinite dimensions, it is dependent on b because b is part of s?  Could you instead split s into   w = e^(-1/2(a^2)) v = e^(-1/2(b^2))   and place them on their respective sides of the dot product and this would still produce the radial kernel except that each point in infinite dimensions would only depend on either a or b. For example, a in the infinite would be   a in infinite dimensions = (w, w*sqrt(1/1!)*a, w*sqrt(1/2!)*a^2 ... w*sqrt(1/inf!)*a^inf) where w = e^(-1/2(a^2)) b in infinite dimensions = (v, v*sqrt(1/1!)*b, v*sqrt(1/2!)*b^2 ... v*sqrt(1/inf!)*b^inf) where v = e^(-1/2(b^2))    Am I missing something or is this a viable approach? I would really appreciate your feedback. Thanks",True
@edwardj.warden5072,2022-10-13T10:48:18Z,0,How much math does a data scientist need to learn or have knowledge when working with machine learning models?,True
@parthsharma8269,2022-10-01T10:16:16Z,1,"What are you Josh? Clear - Done, Concise- Done, Amazing -Done,   Infinite BAM!!",True
@MominSaadAltafnab,2022-09-29T17:12:20Z,3,"""pipipu pipipu"" hits every time üòÇ",True
@user-ee3qt2fb7i,2022-09-13T02:52:45Z,1,"Every time I watch your visualized explanation, I just got amazed",True
@andersoneduardo749,2022-08-16T13:58:36Z,2,you are the best math professor I ever had.. thanks a lot!!,True
@erfanmoosavi9428,2022-08-09T09:12:21Z,1,niceeeeee!,True
@pushkinarora5800,2022-08-04T22:51:30Z,1,This video is Triple Bam!!!,True
@hamidomar350,2022-08-02T07:45:48Z,0,"So that would make SVM with kernelisation heavy during run time no? As it would be in Order of N, where N is number of train data points?",True
@tanmaymehta9696,2022-07-08T15:55:54Z,2,Thank you so much for making all these ML and stats terms so understandable! Great work!,True
@justthethingsitlike,2022-06-25T20:42:34Z,0,Bro you explain stuf well but I have to speed this up to 1.75 to be able to focus.,True
@LITHIUMINWATER,2022-06-09T08:43:19Z,1,bi bi bu bi bu. Awesome video!,True
@VivekSrinivasanDSE,2022-05-28T18:07:35Z,1,Thanks!,True
@Maciek17PL,2022-05-18T13:59:20Z,0,Really nice explained but another video on how to actually built classification boundries having higher dimension distances would be super nice,True
@adamoja4295,2022-05-18T01:18:01Z,0,Damn,True
@monoarul_islam_3,2022-05-17T19:39:29Z,0,I have something bugging me since yesterday. I want to know how long did it take to master all of these for you.,True
@Sanatani_adiyogi,2022-05-14T16:06:36Z,1,you are the best,True
@todianmishtaku6249,2022-04-22T18:55:27Z,1,Amazing!,True
@user-zy8sf7tv2f,2022-04-19T10:54:23Z,1,"Hey man, I have to thank you a lot for describing these things so well ! Thank you very much !",True
@joxa6119,2022-03-25T03:16:49Z,1,I just regret not found your channel during my degree.,True
@ruihanli7241,2022-03-17T08:07:33Z,0,"I remember Taylor performs better when x is around a, for example if we choose a = 0, then x nearby 0 would be better approximated by Taylor then those points far from 0, so should we first normalize data points with mean 0 std 1 and then apply RBF Kernel?",True
@angelguzman477,2022-03-12T01:05:28Z,1,"Fucking hell I just started high school and I understand nothing of the math, but at least I finally understood the concept with this video series, thanks.",True
@winstonzhang6352,2022-03-07T02:38:10Z,1,"Amazing video, this saved me for my ML midterm. THANK YOU.",True
@chaitanyaagrawal1146,2022-03-01T12:49:30Z,1,"hello Sir, Thanks for this awesome video. Can you also post one video how Support Vector Regression works!",True
@cookie6299,2022-02-22T14:01:59Z,0,22.2.22,True
@MCRuCr,2022-02-21T19:16:02Z,0,"""A Number very close to zero"" is quite a vague description. Every number except zero can be considered ""very close"" - depending on context. When you usually handle numbers in the billions, 10 seems to be ""very close to zero""... Remember that on a logarithmic scale, every positive Number is infinitely far away from zero",True
@jackbrown1206,2022-02-20T21:48:56Z,0,"I have a question. For the Radial Kernel equation, what is the purpose/advantage of representing e^(ab) as a Taylor series expansion? Wouldn't it be more computational efficient to simply use e^(ab) than a long convoluted equation?",True
@radsimu,2022-02-20T21:10:30Z,1,INFINITE BAM!!!,True
@yuqing3667,2022-02-04T16:30:41Z,2,"Now we can eat snacks! Thank you so much, your visual explanation makes things so much easier to understand.",True
@harshitlamba155,2022-01-21T15:20:24Z,1,You are Richard Feynman of this era!,True
@saunaknandi1814,2022-01-11T18:34:41Z,2,Nice song,True
@hustler212,2022-01-09T03:14:32Z,1,You're a life saver.,True
@feynmanc303,2021-12-26T13:58:39Z,1,thank you .. you make things super easy to understand.. amazingly good,True
@kds5535,2021-12-20T16:19:44Z,0,"Thanks very insightful content I highly appreciate if anyone can clear my doubt here And as far as i understands in simpler terms RBF calculates relationship of new obs with each existing data point and classifies new obs based on how close it is to observed/training data,  So my question is wouldn't that extremely overfit on training data or doest RBF also use soft margins to leave some bias , or did i missing/misunderstood something ?",True
@oiramormedeiros,2021-12-10T05:00:16Z,1,"Man, I wish you were my professor.",True
@ArunKumar-yb2jn,2021-12-03T03:06:37Z,1,Legends: Now we can go eat snacks! 15:22 Me: really!!!,True
@savvasnikolaosanastasiadis5245,2021-11-29T09:01:47Z,1,you deserve 100m subscribers,True
@ashinkajay,2021-11-16T18:40:34Z,1,Thanks a ton !,True
@p-niddy,2021-11-10T08:47:50Z,0,"At 14:34, why did multiplying both sides of the equation result in the left-hand-side of the equation remaining the same? The math escapes me.",True
@alejandromorgan9295,2021-10-26T13:53:44Z,1,those computing sounds man! hahahaha i love that!,True
@dougIas1,2021-10-26T01:47:08Z,1,That's soo good :'). Thanks man!!!,True
@naufalamiruddin5798,2021-10-22T13:23:06Z,1,"I love the ""beep boop boop"" part of this video !! ü§£",True
@shivkrishnajaiswal8394,2021-10-14T12:37:59Z,1,Bam!!,True
@himanshu1056,2021-10-09T18:55:40Z,1,Awesome explanation üëç,True
@thexht7927,2021-10-09T03:32:49Z,0,1 of rare videos I feel slow at 2x speed,True
@amyma2204,2021-10-06T21:11:52Z,1,The best,True
@jinyunghong,2021-10-06T20:04:45Z,1,This is such a great lecture!!,True
@Hermioneswand1,2021-10-03T08:52:19Z,1,I love this channel. Much love! :),True
@danielmilyutin9914,2021-09-24T23:15:46Z,1,"Imaginee, you overstudy with statquest and then begin saying ""pepopepopo"" during interview.",True
@taotaotan5671,2021-09-21T00:04:07Z,1,"I learned RBF from the Gaussian process, and seems the idea of ""kernal"" has numerous applications!",True
@manojkumar-cm2ym,2021-08-22T15:43:56Z,0,"good information regarding kernel in this lecture, actually I want to know how to set the parameter's ( epsilon, gamma and cost value) range in support vector regression in grid search method that get good model complexity and flatness. if you explain it. it will be great.",True
@RM-zx9ee,2021-08-03T15:40:18Z,27,"This video deserves an Oscar. Seriously, that was incredible. Infinite BAM!",True
@mypure,2021-07-30T18:55:04Z,2,Watching Josh is like feeling like Flash of statistical concepts.. Every skipped concepts in stat class seems becoming crystal clear here..,True
@yulinsun8873,2021-07-27T04:10:08Z,10,Infinite Bam! This is the most understandable ML video I ever watched. Thank you for sharing this.,True
@sy3002,2021-07-25T21:48:15Z,1,"@15:12, you should have nuclear BAM!!!!!!! for such revelations, awesome series loved every part. Thanks for your good work.",True
@manishsahisonline,2021-07-15T03:16:24Z,1,and subscribed! infinite BAAAM :),True
@jasonfaustino8815,2021-07-05T15:01:38Z,4,Can‚Äôt believe I used my knowledge on Taylor series expansion. Thanks for not wasting precious brain space for that,True
@PradeepSharma-fl2uy,2021-07-04T06:26:24Z,0,The way Josh Explains the algorithms it looks like we are studying 1st standard mathematics.,True
@yafoniahutabarat6793,2021-07-02T03:41:07Z,1,you should collab with Phoebe to create some StatQuest jingles!!!! love it,True
@buh357,2021-06-09T09:39:06Z,5,"wow  wow  wow, the relationship between two objects in infinite dimension. absolutely beautiful and amazing. thanks for ML and you :)",True
@sherylzheng7698,2021-06-08T16:52:36Z,0,Distance between two points in infinite dimensions!!!ü§Øü§Øü§Øü§Ø,True
@61_shivangbhardwaj46,2021-05-29T04:39:00Z,1,No words for you sir You are great!,True
@umeshphadke6745,2021-05-22T14:54:15Z,0,"This channel is absolute gold ! Thanks for your help mate , and also you should consider teaching mathematics too.",True
@trenton7,2021-05-20T21:16:02Z,2,"The initial singing and the double, triple, quadruple bam grows on you, didn't like them much at first but it is now an essential part of the learning experience for me.",True
@sidkapoor9085,2021-05-20T17:19:07Z,1,Not all heroes wear capes.,True
@Heyday0848,2021-05-19T08:37:27Z,0,But you didn't tell me how to find the classifier right? That's the most important thing,True
@mehmetkazanc5855,2021-05-17T06:01:32Z,0,Thanks for this great video. I missed a point. Do we use this distance vector as new data in high-dimensional space after we calculated the distance of each pair?,True
@williamobando4159,2021-05-10T09:40:04Z,1,This blew my mind lob u Josh ty,True
@quinnpisani180,2021-05-08T23:47:09Z,0,Question: Are your original songs about statistics?,True
@xlmentx,2021-05-02T03:24:58Z,4,"Damn, good job dude. At first I felt like I was being talked down to, but eventually grew to like it lol. You're way better at teaching this stuff than my professor is.",True
@praveerparmar8157,2021-04-27T14:09:24Z,1,Extra Large Mathy BAM !!!! üòÖ,True
@ThunderStrike2022,2021-04-23T07:56:43Z,0,What are you eating for snacks?,True
@guesswho1705,2021-04-21T09:52:07Z,0,"Hi, can anyone help with understanding what higher dimension relationship is? I don't get what the number represents. How does it relate the pair of observation points to each other and what does it mean? Please explain or point me to any source you feel would be helpful. Thank you very much",True
@ygbr2997,2021-04-20T07:35:20Z,0,my gut tells me it's not named after Taylor Swift,True
@chemgreec,2021-04-14T10:47:38Z,41,Excellent! There is a higher dimensional space where this video is linearly seperable from anything else on youtube. What I love is that you use both math and intuition in good measure. You dont sacrifice intutition over math or math over intuition like most other attempts. This balance you ve got here is excellent.,True
@RanjeetSingh-pp4uu,2021-04-08T18:36:41Z,1,LOVED IT! THANKS!!,True
@md.mizanurrahmanchowdhury5545,2021-04-04T13:40:57Z,0,Sir Josh!!!!!!  Can not I use here Maclaurin's  Series,True
@95019124,2021-04-03T22:00:06Z,1,you saved my grades in data mining and machine learning courses,True
@yuktikaura,2021-03-30T13:00:23Z,1,Taylor Series Infinite BAM!!!! Keep it up!,True
@tymothylim6550,2021-03-19T05:25:27Z,2,Thank you very much for this video! I learnt a lot from this step-by-step math guide! Great to eat snacks too!,True
@abir95571,2021-03-18T08:26:47Z,1,"Not gonna lie , I have read a few other books understanding how RBF computes relationship between data points in infinite dimension ... none of them are as simple and comprehensive as your video.  Thanks a lot",True
@bhishanpoudel8707,2021-03-13T19:50:40Z,1,"I was expecting the last ""Triple Bam"" to be ""Infinite Bam""!",True
@justgame5508,2021-03-10T23:58:16Z,1,"Ahhh thankyou electronic engineering for having difficult mathematics, it‚Äôs makes it easy to branch out into more statistical domains such as machine learning and still be able to keep up, also equips me with other techniques such as Fourier and Laplace transforms which can be useful in data analysis and feature extraction. Great derivation btw",True
@karangoyal9602,2021-03-10T07:06:32Z,0,"Josh, I think taking the term 's' in each of the two terms in dot product is incorrect because the projection of one point in higher dimension should only be a function of that point itself. So, the way to handle e^(a^2+b^2)/2 should be taking e-(a^2)/2 with the first term and e-(b^2)/2 with the second term in the dot product. I would be happy if you can confirm my rationale. Thanks for the this wonderful explanation of kernel trick.",True
@kevinmanuel6711,2021-03-09T18:08:41Z,0,do you start with singing in the actual class? it would be fun if it's true,True
@gamalaburiyana7651,2021-03-08T04:04:24Z,0,"Sorry, what does aka means?",True
@sakshambali3040,2021-03-07T18:47:47Z,1,"Just amazing stuff man. God bless you, love from Indian..!!",True
@cheshtagupta7491,2021-02-28T14:40:13Z,1,"this video put an instant smile on my face <3 amazing amazing amazing i have no words <3 I just regret why i did not know about this channel before!!! Plus, I understood all of it and you have explained it so so well",True
@RahulSharma-tf6zk,2021-02-25T18:28:53Z,0,"You  helps me understand what my professor says in ml mandarin, Thanks",True
@perstarke1295,2021-02-20T12:30:10Z,1,Wow. Just WOW. Hella good explanation!,True
@toxic_narcissist,2021-02-12T15:47:10Z,2,but how underrated is this video,True
@maverickop4134,2021-02-12T15:04:04Z,1,this explanation made it look too easy. Good job . Thanks for making this video.,True
@emrullahcelik7704,2021-02-10T16:33:32Z,4,Radial kernel intuition with polynomial kernel was wonderful.,True
@Lee-vs5ez,2021-01-26T18:43:20Z,1,ü§ó,True
@kumarabhishek5652,2021-01-26T12:44:45Z,0,is gamma a hyperparameter and also i have seen rbf equation is written as e^-(x1-x2)/(sigma^2)?? how does both of the equation relate to each other??,True
@jiayiwu4101,2021-01-24T03:06:02Z,2,"Such a nice, crystal, clear explanation!! Awesome job!!!",True
@siddharthpilli62,2021-01-21T07:07:39Z,1,I Love the videos you make keep up the good work!! BAM!!,True
@rezasoleimani6636,2021-01-19T06:11:34Z,0,This guy reminds me of Andrew Bernard,True
@nabeelhasan6593,2021-01-17T13:27:23Z,3,"Your videos are like magic, making such a difficult derivation look so much easy. God Bless You",True
@varunjindal1520,2020-12-22T19:39:53Z,0,"Hello Josh, Could you please address a question kindly.  When we do actual prediction for new unlabeled data, then do we use all the training set and find the similarity with new data and calculate the prediction, or do we only use support vectors rows and calculate similarity and predict?  I think is we use Support Vectors to create a decision boundary for SVC or SVR but after then for any predictions, we use full data set if we use Kernels and we just use linear equation if we use SVC with Linear kernel.",True
@ArnabJoardar,2020-12-22T13:43:23Z,0,"Upon getting the relationship value, and the original values, how do I use them to realize a separating hyperplane?",True
@vanesaalcantara2265,2020-12-15T20:58:59Z,1,Your songs are very catchy some times I realize I am just singing them jaja,True
@gautamdawar5067,2020-12-12T17:35:41Z,3,"A beautiful video, I had tears of joy after watching this. Sir you are amazing!",True
@TD-in5qe,2020-12-03T01:32:37Z,0,"Your song sounds like Phoebe's song, and I really like it!",True
@harvey2242,2020-11-22T08:11:37Z,0,Under what circumstance would we prefer RBF over polynomial kernel function and vice versa?,True
@mcarthuralford4872,2020-11-21T02:37:18Z,1,Bam!,True
@mrunalbattise1213,2020-11-07T15:16:30Z,1,Pi pi pu pi pu,True
@axa3547,2020-11-05T09:01:14Z,0,those who say data science can be studied in 3 months show them this video,True
@tonysand69,2020-11-04T22:09:55Z,2,"Oh man, thanks you for your videos, i mean, you're really awesome. You don't only explain the concepts, but also you keep it real and fun. I have learned a lot from you, when i have money i will donate every penny of it.",True
@ArunKumar-sg6jf,2020-10-12T17:26:35Z,0,Hinge loss is not explain,True
@SaumitraAthlekar,2020-10-06T12:50:33Z,2,3:38 pee pee poo pee poo,True
@rethickpavan4264,2020-09-27T06:57:03Z,1,"why all teachers are not teaching like this ,IDK but he exists in earth.",True
@kamran_desu,2020-09-22T22:14:36Z,0,"Amazing explanation as always. Can you please also touch on the concept of ""landmarks"", how do they fit into this logic?",True
@henryatehortua6149,2020-09-09T21:45:40Z,1,I don't understand much English but I notice that you are a lot of fun teaching.,True
@xuemeiwang1881,2020-08-30T02:53:32Z,1,"GREAT MAN, GREAT CHANNEL.",True
@aligerami2111,2020-08-23T09:58:27Z,1,Thank you so much sir,True
@chandubhargavi8497,2020-08-21T15:43:23Z,0,"7:52 if r=0 and d=2 how can we get a^1b^1+a^2b^2 .  Because (axb+r)^d if r=0 then (axb+0)^d=(axb)^d and if d=2 then above becomes (axb)^2=a^2b^2=(a^2).(b^2) and same with d=3,4,...... when r=0",True
@MsIHateMiley,2020-08-15T18:05:27Z,2,"god bless, this channel is amazing",True
@ketkiambekar7607,2020-08-14T21:27:45Z,4,"Thank you for making one of the best videos out there for understanding SVM (and log likelihood maximization, and countless other concepts). I am going to make a good contribution to your Patreon once I get start earning because you so so deserve it, omigosh.",True
@kartikbhanot4692,2020-08-12T22:37:50Z,4,I was finding it hard to understand the concept of RBF and this video helped me immensely. Thank you Josh for the amazing work that you doing.,True
@sjupi7941,2020-08-10T22:35:49Z,2,13:27 where is BAAAAM here? it was definitely a BAAAM deserving moment,True
@sohaibamrani4175,2020-08-03T22:47:48Z,1,AMAZING,True
@karishmasaikia3549,2020-08-01T17:18:01Z,1,You are an angel to me!,True
@RH-zp1ry,2020-08-01T08:07:38Z,28,"15:18 I would say ""INFINITE BAM!!!""",True
@muskankhajuria1038,2020-07-31T17:33:01Z,1,Amazing teaching! Thank you sooo much!,True
@EngIlya,2020-07-27T06:03:17Z,0,"Still not sure why we need individual distances between all points in higher dimensions. For the classifier, what should matter is only distance from separating hyperplane (1 number per point, not N numbers). Thanks for your work!",True
@leanneZzz08,2020-07-13T12:31:01Z,2,"Thanks for the amazing  video. Just one quick question. When calculating the relationship between two observations, the larger the distance between the two observations, the smaller the high-dimensional relationship results. You says it is because there is less influence between the two. But, as in the example, the observations (red) are spreading on the both sides of the green observations, while they are in the same classification. According to the distance rule mentioned above, the high-dimensional relationships results between the two red observations ,laying separately on the both side of the green observation, will also be very small. How to explain the weak relationship between  observations in the same classification? Is that also because of weaker influence?",True
@DesertHash,2020-07-13T00:04:50Z,0,"Hi Josh, at 14:40 why do you specifically multiply the dot product by the square root of the first term [ e^-1/2(a^2 + b^2) ], and after doing so, why does the first term go away at 14:45 ?",True
@user-bz8nm6eb6g,2020-07-10T13:21:16Z,1,Best explanation! Wow wow,True
@priyangkumarpatel9317,2020-07-04T22:55:33Z,197,You make statistics and machine learning so much fun. Your channel is binge watch worthy. Keep spreading good education in fun way. :),True
@sanjivgautam9063,2020-06-27T04:49:14Z,1,This man is genius,True
@gspb4,2020-06-22T19:40:24Z,0,"at 8:15 you plot the transformed data on the x-y axes, but then immediately follow up by saying we don't do the transformation. so are you just showing the transformation for clarities sake? it seems like you're only able to find the support vector classifier once you've transformed the data.   as a follow-up, if we don't actually transform the data, how are we using these high dimensional relationships (calculated from dot products) to produce the support vector classifier?",True
@nehamanpreet1044,2020-06-19T22:35:52Z,0,"Can we use SVM for multi-level classification, that is when the classifying variable is not dichotomous and has more than 2 levels ??",True
@MGRVE,2020-06-15T17:09:44Z,1,Brilliant!,True
@saravananm2280,2020-06-14T06:44:26Z,0,"I would have ended the song like ""...I know that it  sounds kinda Crazy but its actually NOT THAT LOUSY.""  Great video",True
@ccuny1,2020-06-11T21:14:12Z,1,"Really good vid, easier to understand for me, somehow, than the polynomial kernel. Not sure why. Maybe it's because my brain also made that sound when I did the math...",True
@AP-eh6gr,2020-05-22T06:29:40Z,1,mind blown,True
@ashishtiwari1912,2020-05-15T19:45:31Z,0,Thank you for the videos. i have learned a lot of things from your channel. What I would like to know is the scenarios where the SVM algorithm will fail. How do we make a relative comparison while choosing the different classification Algorithms?,True
@swarajshinde3950,2020-05-09T12:49:37Z,2,Just Loved the way  you explained the proof using Taylor series : ],True
@alanlybus4352,2020-05-03T04:23:46Z,1,Large Bam!,True
@well....7751,2020-05-02T10:58:37Z,5,I wanted to know what relationship do we get after doing the dot product between the values and can you do a video on support vector regression or give some links?? (Great video though),True
@srtist040,2020-04-30T23:41:20Z,0,"Hello Josh, Many thanks for making these complex concepts very simple to understand. I have got  a question, what if the data is categorical (nominal) then it is not numeric right! how would you perform all the mathematical operations. Looking forward to your answer.",True
@ruthvikanchuri2106,2020-04-29T09:39:09Z,0,i feel as if a robot is speaking!!üëç,True
@ysmashimaro,2020-04-26T06:46:32Z,0,This video has a mistake from 13:03 and the following. For inner products (ab)^2 does not equal to (a^2)(b^2).,True
@hashiska.5358,2020-04-20T08:56:18Z,1,nobody explains the concepts better than you do. I have to study ML for a project and I haven't found a channel better than yours. That is why I have a request: please make a video on Support Vector Regression.,True
@yavdhesh,2020-04-13T01:38:15Z,1,"Namastey, you are the best person.",True
@Peter1992t,2020-04-10T04:01:54Z,0,"This was a great explanation, and I followed the math. But I don't quite understand what is the benefit of calculating the relationship in infinite dimensions? At least in our drug dose example, it seemed like determining the relationship in 2 dimensions was enough to get a good classifier. Are there cases where the best classifier is one where we determined relationships in infinite dimensions?",True
@chanduiit42,2020-04-07T13:12:10Z,1,Triple BAAAMMMMMM!!!,True
@zeynabmousavi1736,2020-03-28T22:33:35Z,0,"In the kernel trick videos, all examples were for 1 dimensional data (only dosages). How about 2+ dimensional data? How does the dimensionality of the data affect the kernels?",True
@yinwong667,2020-03-23T15:11:37Z,0,"In 14:50, why can you put s into the expression? s depends on both a and b. As I knew, kernel K(a, b) = <g(a), g(b)>. If you put s in both sides, wouldn't it become K(a, b) = <g(a, s), g(b, s)>?",True
@CheGourav,2020-03-09T05:55:50Z,0,So getting the relationship in infinite dimension is only possible if gamma=1/2 ?,True
@arpanghoshal6910,2020-02-13T17:32:27Z,0,i m dead .. fcck :/,True
@koshak2139,2020-02-10T10:25:53Z,0,"Another one wonderful explanation, Josh.But I have the most important question: why the hell will we even need correlation in infinite dimensions?What does it give us?We used different degrees at polynomial kernel to better find correlations, does it mean that RBF strives to find almost ideal(considering Taylor's remainder) correlation?Whatfor?I assume we can make classification good even without infinite precision for correlation.",True
@suyashneelambugg,2020-02-08T14:14:12Z,0,Precisely - The sum of relation between two observations in infinite number of dimensions,True
@sabrinapatania7810,2020-01-28T11:48:48Z,0,Beautiful video! Thank you so much! I have a question. May you explain why we can use Taylor series assuming a=0? Why can we do this assumption?,True
@sabrinapatania7810,2020-01-28T11:48:38Z,0,Beautiful video! Thank you so much! I have a question. May you explain why we can use Taylor series assuming a=0? Why can we do this assumption?,True
@opheliagame,2020-01-27T16:44:20Z,2,How does he have such regularly modulated voice? It is almost like I could get hypnotised by it if the explanations were not pure genius.,True
@krzysztofkolmus6936,2020-01-16T07:50:02Z,0,Great work! I was wondering if you could spare a moment and make a video on using SVM algorithms in R?,True
@limxiuxian349,2020-01-15T15:08:51Z,1,"Thanks for the video ,excellence explanation!! But I have one question,since RBF able to classify data with infinite dimensions, wont it always be the best classifiyer as compared to polynomial ?",True
@hoangtrunghaipham5999,2020-01-07T14:11:23Z,13,"I have gone through 85% of the full list and found this series extremely useful. The instructions are simple to understand and give the sufficient overview into Machine learning. Highly recommend for starters like me. Looking forward to the advanced parts, e.g. Deep learning. Many thanks!",True
@ayoubmarah4063,2020-01-06T11:14:11Z,129,i bet there is a place in heaven named statquest where you gonna live an internal life there,True
@samyadeep906,2020-01-03T20:01:56Z,1,"This was really good, thank you ‚ô•Ô∏è",True
@aghileslounis,2019-12-27T19:29:49Z,2,"You are a Legend !  but what to do to understand maths like you , books are so hard to understand and teachers explains to themselfs lol",True
@amoghbharadwaj9252,2019-12-26T19:02:16Z,0,"Hey, Josh thank you for the wonderful explanation. However, I had a couple of questions in the conclusion part of how we classify the new observation. Once we find the influence of the other observations with respect to new observation in infinite dimensions, how many samples do we consider in the nearest neighborhood to arrive at the final result?",True
@akashjain35,2019-12-24T10:38:17Z,3,This video and in fact the whole playlist of machine learning is so amazing. Your way of teaching makes it so easy to understand the mathematics behind these concepts. Don't ever stop making these videos!,True
@prashant4814,2019-12-23T16:26:56Z,4,"wow, god bless you  we need good teachers like you",True
@ryanzhong2542,2019-12-21T08:37:36Z,0,"Hi! I love your videos. But as you said, SVM does not transform data but only calculates the relationship between them. So how the line (boundary) can be inferred from the relationship? :-)",True
@harithagayathri7185,2019-12-18T10:19:29Z,1,Very clear explanations and far better than the videos on udemy  !!,True
@swapneeldatta2297,2019-12-13T21:36:17Z,2,Saved my ass.,True
@akrylic_,2019-12-13T04:42:14Z,12,"What an interesting application of the Taylor Series. Such a beautiful explanation, thank you!",True
@amishgoel2377,2019-12-10T03:22:55Z,2,"Awesome Video and clear explanations! I had one doubt. In the end when forming dot product of RBF kernel, you have used s to multiply the two dot products. But s is a function of both a and b. In the dot product of a pair of observations in high dimension, each term in the product should be a function of one observation since it corresponds to high dimensional feature of an observation. I think one should multiply e^(-0.5a^2) to the first term and e^(-0.5b^2) to the second term of the dot product.",True
@boranzhou937,2019-12-09T02:40:20Z,1,"thanks, man! this is really helpful!",True
@clapdrix72,2019-12-07T22:35:13Z,1,One of the most clearly explained proofs I've seen in a while,True
@skumarr53,2019-12-07T13:44:44Z,0,"I'm a little confused. You said RBF uses the nearest neighbor to classify the new data point. Isn't SVM uses the same trick (indirectly, the relationship between pairs) for other kernels as well for identifying the decision boundary that separates classes.",True
@dels323,2019-12-02T18:35:55Z,0,"Thanks for the content, very clear vid. In my uni lec slides, the RBF has an additional sigma, so exp(-||a - b||^2/2œÉ^2). Confused about where this 2œÉ^2 comes from, :(",True
@firassami7399,2019-11-29T11:34:44Z,0,thanks for your useful vedio in radial bases kernel what do a and b mean?,True
@wangwenyu9052,2019-11-28T13:35:52Z,3,"Thanks for the wonderful video! It really helps in both forming the intuitive, as well as connecting key math concept together!",True
@jeongwonkim247,2019-11-26T03:12:49Z,1,"The best machine learning statistics video. Came from confused at a coursera course for data science, taught by u mich faculty, and this video does that 100000x better. Thank you so much!",True
@dome8116,2019-11-22T22:22:22Z,3,Thanks for creating this amazing video. After watching the lecture on RBF from Caltech I was so lost and felt so bad since it was the first concept that I didnt understand at all. Your video gave some good intuition why it works and how. Thank you Statquest :D,True
@shritube123,2019-11-19T13:03:45Z,1,Please post a video about XGBoost!,True
@EtherealMetal,2019-11-18T02:30:28Z,157,This channel is so amazing„ÄÇFor the past few months I have been trying to catch up on concepts in statistics that my university never taught so that I have enough knowledge to go into the data science and machine learning fields„ÄÇ The way you teach concepts in clear concise and short videos is extremely valuable„ÄÇI have learned much in such a short time from just watching your videos and taking handwritten notes„Éºthank you for all the hard work you have put in delivering this invaluable knowledgeÔºÅPlease continue making videosÔºÅ,True
@auraprince9303,2019-11-17T11:18:54Z,0,Where to see the derivation of radial basis kernel... Please suggest book or paper,True
@victorhenriquealvesribeiro9944,2019-11-17T01:50:27Z,2,Infinity BAM!,True
@DinaEl-Kholy--,2019-11-15T11:27:30Z,2,Thank you! You made it so easy and just saved my course project üòÇ‚ù§,True
@jeevanraajan3238,2019-11-14T18:38:00Z,9,There is soo much of effort put into making these videos and it has come out soo welll  !! When you die...You ll leave behind a legacy and will be known as a legend !!..,True
@MrTSkV,2019-11-13T15:10:07Z,2,"Josh, if you make an 60 minutes long album consisting of your 'calculation pipupipu music', I'm so buying it.",True
@mariafirulyova5020,2019-11-13T08:34:00Z,2,"Dear Josh Starmer, thanks for all amazing videos! Your channel is really helpful for me. Could you please explain how UMAP works? Also, comparison UMAP with tSNE will be nice )",True
@haochang4293,2019-11-12T00:11:58Z,1,I benefit so much from your video. From a Chinese Ph.D.,True
@myyoutubeaccount4537,2019-11-10T17:08:46Z,0,this is a great video. But loosing time with Taylor expansion seems unnecessary.,True
@mustufakerawala1796,2019-11-09T22:51:37Z,3,"I love your videos!!! I understand this content better, even better than my data science lecture at uni. I hope you keep up the great work, I'm officially gonna get some Statquest merch to support this chanel.",True
@ahming123,2019-11-09T07:41:09Z,2,OK got what diamension relationship means now. You the best,True
@ganesha.k.s,2019-11-08T06:49:30Z,1,Thanks a lot bro. This saved me,True
@juntianwang1158,2019-11-07T06:22:56Z,0,Would you like to make a video about back propagation algorithm?,True
@VidyaBhandary,2019-11-07T00:59:56Z,1,The website link has link to video 2  under radial. Tried to post a comment there but it keeps asking me to login.,True
@gauravgogia9939,2019-11-06T11:27:46Z,1,"I am a big fan of your stuff, when are you planning to upload XGBoost Video",True
@shayanmoghaddam3600,2019-11-05T21:22:57Z,17,Na√Øve Bayes classifiers please!!!,True
@samuelmarger9031,2019-11-05T18:02:52Z,0,"Sorry for breaking the mood, but I felt very bad seeing you write Taylor series with an end and actually treat ""infinity"" as a number.  The math is, infinity is a concept, not a number, so... using it as a number, such as putting it in the denominator with a factorial etc. just ... doesn't feel right. I know people use that notation for the sake of simplicity, but since many people on this channel seems to focus on the applied math rather than pure math, using such notation without understanding the idea behind it can be... idk, misleading. I recommend using dots without showing the end, e.g. (1, a, a^2, a^3, ...) ‚Ä¢ (1, b, b^2, b^3, ...), instead.  Sorry if this is difficult to understand or perceived as ruined the Quest mood. D:",True
@ccuuttww,2019-11-05T03:34:55Z,1,"what's next Gaussian kernel ? BEE BEE BO BEE BO and I think u should talk about how to solve the margin first before the topic of kernel, soft margin advanced solver BEE BEE BO BEE BO (If u don't make videos for it i will paste my own tutorial because your viewer is very thirsty)",True
@hellochii1675,2019-11-04T23:42:28Z,33,First comment! BAM!,True
@wolfisraging,2019-11-04T18:04:04Z,2,Just can't wait for more svm's,True
