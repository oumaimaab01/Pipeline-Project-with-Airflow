author,updated_at,like_count,text,public
@statquest,2020-03-07T02:09:44Z,36,"Correction: 1:35 I mistyped the gini impurity. I wrote 0.29, but it should be 0.19.  Support StatQuest by buying my book The StatQuest Illustrated Guide to Machine Learning or a Study Guide or Merch!!! https://statquest.org/statquest-store/",True
@Why_I_am_a_theist,2023-11-22T12:28:55Z,1,BAAAMM!!! JOSH,True
@user-jj3we9jv9i,2023-10-28T20:33:56Z,2,Liked and Commented to help you with the YouTube algorithm!,True
@willw4096,2023-09-01T03:53:15Z,0,1:42 1:49,True
@watsoncarter9782,2023-07-01T04:23:59Z,0,"Hey Josh , where is the part 1 video of decision tree ... Can you please give me the link",True
@tomaszbabiarz8227,2023-04-02T18:31:21Z,0,"Hi Josh. I am going over each of Your lessons in time-of-upload order (from oldest to newest) and I wonder why this lesson is called ""Part 2"" while earlier there was no Part 1. I assume that Part 1 is ""Decision and Classification Trees, Clearly Explained!!!"" uploaded after this video, correct? BTW: excellent work!",True
@MaxKlimov,2022-12-26T05:40:42Z,1,Thanks!,True
@romanvasiura6705,2022-12-07T09:05:54Z,1,Thank you!,True
@earnesttechie1494,2022-12-02T06:17:02Z,0,Where is the part 1 of this video?. I couldn't find it.,True
@zhengwei2559,2022-08-28T17:04:09Z,7,"Very good job making these videos, I can image how much time you spend on it. Wonderful job.",True
@inwonderland9842,2022-08-24T14:55:36Z,1,üèÜ,True
@bt_HridayAgrawal,2022-06-13T21:27:48Z,0,"Hello :) , thank you so much for this amazing video! I have a query:  to handle missing data, you used the column whose values is most correlated to it, as a guide. But generally, we drop those columns from our dataset and avoid high correlation due to its negative impact on model prediction. Should we really follow this practice?",True
@beautyisinmind2163,2022-02-20T12:57:16Z,0,"Teacher Josh I have one question: if we apply feature selection techniques say Filter method ,wrapper method, embedded method on our dataset we may get different result from each method which features are relevant or which are not. Overall how we actually make evaluation analysing result coming from each method that which features should be chosen? if features and target variables both are numeric, hope you got my point",True
@gimanibe,2022-02-15T22:51:39Z,1,"Awesome video! Thank you Josh. Would be very useful if you can make a video about ""double dipping"" after feature selection in random forest or machine learning in general?",True
@nackyding,2022-01-26T06:53:40Z,0,Do features have to be stationary when applying ML models to time series data? Or any data for that matter?,True
@cookie6299,2022-01-09T13:37:17Z,1,2022 01 09,True
@nayeemislam8123,2021-12-18T05:48:50Z,0,Can you make a video on how surrogate split is used in decision trees for handling missing data and computing feature importance?,True
@SHARATH2596,2021-08-11T17:23:15Z,0,"Hello! First we will perform  EDA,FEATURE ENGINEERING and then MODEL BUILDING right? so, my question is in EDA AND FEATURENGEERING we will handle missing values right?  anyway we'll handled missing values there, even after  that will we get missing values?",True
@karsunbadminton7180,2021-05-25T09:04:06Z,1,You are geniusÔºÅRespect from china,True
@pallavgupta1302,2021-04-16T10:10:16Z,1,"Hey Man , U make ML look like a cake walk.  Great work.... AND I am loving ur theme songs, so I am awesomeüòÇ and decision tree algo is proving itü§£",True
@billyericksonsamosir551,2021-03-27T11:12:46Z,0,"Please make catboost video, i'm working on my thesis :')",True
@nishantpandey9802,2021-01-13T15:12:34Z,1,I love the way you start your channelü§©,True
@dikshaprabhukhorjuvenkar6240,2020-11-17T06:30:35Z,2,I love the intro.! Just so unique every time. :),True
@weiyangshi4729,2020-10-13T09:20:41Z,0,Can we use a decision tree or random forest to impute missing value? Great work as always!,True
@chloeh7119,2020-09-03T06:12:26Z,1,YOU are the BEST!!!!!!!!,True
@21bagong,2020-08-31T07:56:48Z,0,"Hi Prof Josh,  Suppose, I already have the selected features by using random forest algorithm. Then, I use this features for PLS-DA. Will the model I build by PLS-DA more valid? Thanks",True
@ca177,2020-08-14T16:52:16Z,6,"YOU RAWK (again).. Best stats explaining series on YouTube EVER, in the whole wide world !! Mega BAM !!",True
@adiflorense1477,2020-07-17T14:31:34Z,0,"Sir, is it the same between missing data and outliers , noisy data ?",True
@BeSharpInCSharp,2020-06-16T10:11:36Z,0,selecting a second best gini impurity will reduce over fitting?,True
@shubhamgupta6567,2020-06-14T11:07:18Z,1,"how dose feature selection helps in overcome of overfitting, please explain I'm not getting this?",True
@iaaan1245,2020-06-13T12:38:32Z,0,"Hi Josh, I am a big fan!  I'd just like to ask something as I'm still in the midst of learning. In multiple linear regression, we are taught that multicollinearity is a big issue and a red flag. However, here it is mentioned that it can be used as a way to fill in missing data, if the missing data is of a variable that is highly correlated with another one that is known.  Is it because they are different models and thus the issue doesn't apply here?  Thanks, once again, a big fan!",True
@aligh18,2020-05-20T09:42:59Z,117,"I should redirect my tuition fees to Josh Starmer, because he deserves it more than my university.",True
@jiehu1337,2020-04-30T00:06:41Z,0,Clearly explained. but how to measure the correlation btw two binary columns.,True
@Anonymous-54545,2020-04-23T01:40:35Z,0,"Yelling ""oh no!!!"" over and over is pretty irritating. I don't mind the other repeated yells as much because at least they aren't infantilizing... I get that you're trying to be relatable and stylized, but this is not pleasant.",True
@abhilashsharma1992,2020-04-06T05:22:31Z,3,I got StatQuest!,True
@shrikantdeshmukh7951,2020-03-24T05:54:17Z,0,"please can explain main difference between ID3,CHAID,CART",True
@rajarajeshwaripremkumar3078,2020-03-19T07:07:10Z,0,Is this how feature importances are assigned? Can you elaborate a little on this?,True
@ssanand3,2020-03-06T23:35:56Z,0,at 1:35 the gini impurity calculation goes like : G1 = (1 - (7/33)^2 - (26/33)^2) * (33/115) = 0.09591567852437417 G2 = (1 - (6/82)^2 - (76/82)^2) * (82/115) = 0.038920932157359756 G1 + G2 = 0.13483661068173391 How come you are showing it as 0.29 ? Where did I go wrong ?,True
@fabianoprado4066,2020-02-25T19:50:36Z,0,"Hello Josh!! I was thinking in a manner to reduce false negative in diagnosis, so is there some parameter to control the number of false negatives outcomes in a decision tree??",True
@tanweermahdihasan4119,2020-02-21T21:33:52Z,18,This is the best statquest song so far.,True
@MrMarieric,2020-02-14T10:05:08Z,1,You are awesome Josh!!,True
@andreaxue376,2020-02-09T01:03:07Z,15,Josh I am a huge fan of your videos!! You helped me understand all those complex ML concepts better than one year in grad school...  I wonder if you can make some videos about how feature importances of random forest are calculated and DBSCAN clustering works (and how its parameters are chosen). Thank you so much!!,True
@SIO2HF,2020-01-22T19:12:53Z,1,Thank you!,True
@yilizhang790,2020-01-16T22:31:57Z,3,"Hi, will you be able to do a video on how to numerically calculate the Random Forest Feature Importances? I couldn't find clear explanation anywhere on internet...It would be really appreciated!",True
@alecvan7143,2020-01-03T22:06:00Z,1,Next level starting balad,True
@haneulkim4902,2020-01-03T06:52:41Z,1,Your the best ! thanks!,True
@vincentmayer2816,2019-11-18T12:44:45Z,15,"I love you Josh, you and your intros.",True
@tuongminhquoc,2019-11-04T11:42:54Z,2,Great video as always!!!,True
@muhammadmuneeb8255,2019-10-08T18:39:01Z,0,"Hi Sir, Josh Starmer... I hope you are good. Kindly make a video on pre pruning and post pruning. I have seen your videos and Information Gain 3 is also missing from the series.. Thanks in anticipation..Have a good day.",True
@looploop6612,2019-06-19T12:14:21Z,1,"if weight is highly correlated with height, why not remove weight column?",True
@adosub,2019-05-20T09:42:27Z,2,@UCtYLUTtgS3k1Fg4y5tAhLbw is filling the knowledge gaps that we have due to some vintage( being polite and avoiding the word inadequate) teaching methods in Universities. Would it be unfair to ask teachers to give up a percentage of their earnings for Josh who is our real teacher? I have some teachers in mind that should be forced to buy and listen to Josh's awesome(again being polite) albums!,True
@adosub,2019-05-20T09:42:27Z,0,@UCtYLUTtgS3k1Fg4y5tAhLbw is filling the knowledge gaps that we have due to some vintage( being polite and avoiding the word inadequate) teaching methods in Universities. Would it be unfair to ask teachers to give up a percentage of their earnings for Josh who is our real teacher? I have some teachers in mind that should be forced to buy and listen to Josh's awesome(again being polite) albums!,True
@kwangminkim1735,2019-04-04T00:49:09Z,0,Could u upload the video on pls and pls-DA?,True
@tianxingwang8408,2019-03-27T15:45:17Z,4,"Hi Josh, somehow I calculated the Gini impurity for chest pain as 0.19 (with separating), I got weight value on the left 0.334 = 1-(7/33)^2-(26/33)^2 and right 0.1356 = 1-(6/82)^2-(76/82)^2. Then, I calculated the Gini index = (33/115)*0.334+(82/115)*0.1356 = 0.19. Can you correct me what's different from yours? Thank you",True
@archimedesspiral,2019-03-27T01:45:55Z,0,"Best video..""..BAAaaaaMmm",True
@michaelcao9483,2019-01-28T10:21:14Z,1,BAMMMM!!!!!!!!!!!!,True
@random-ds,2019-01-22T15:44:58Z,0,"Hello again, i thank you for this so interesting video, and here is my question:  In an article that i've read (and that i have to prensent) about MissForest, it's said that:  ""The RF algorithm has a built-in routine to handle missing values by weignting the frequency of observed values in a variable with RF proximities after being trained o the iinitially mean imputed dataset. However, this approach requires a complete response variable for training the forest"".  What does he mean by ""the complete response""? What is the complete reponse in the example that you showed? And why it can't handle all the missing values as you showed here in this video?  Thanks again for your efforts and kindness for answering my questions.",True
@j00hyun,2019-01-21T21:45:37Z,1,"Instead of predicting the missing values, couldn't you treat missing as just another level? For example, with color, could ""red or missing"" be a node as well?",True
@muhammadsulaiman6,2019-01-12T17:52:40Z,1,Thank you sir its a very easy way for machine learning,True
@saurabhtayde2810,2018-10-18T15:27:38Z,1,Hey Josh.. Watching your videos is as good as watching FRIENDS TV series.. You explain in simplest possible way that too with lot of fun.. I do have one request to you.. Could you please take a Decision Tree sample data and explain its model in R in detail..  I hope you will add the video soon.. Thanks for making Data Analytics concepts simpler !!,True
@sonicking12,2018-10-12T16:23:50Z,3,"Hello, what is the R package you recommend for running Decision Trees?  Thanks.",True
@lakshya209,2018-09-14T17:49:37Z,2,You're just too good! Too good!,True
@yodhakei,2018-06-30T13:59:30Z,6,Liked your video even before started watching the video. Thank you for making these videos,True
@fkhan4504,2018-06-30T06:24:30Z,1,Hellloooo..... Excellent video,True
@rrrprogram8667,2018-06-09T11:24:35Z,5,Fantastic videos Josh..... BAMMMMM,True
@Adamseekerfan,2018-03-25T10:07:12Z,0,sriously  379 views    bro you taught  better than udaity mit or stanford fuck this youtube make a course on udemy about this each and every topic  you will be billionrie,True
@maximuskumar502,2018-02-04T01:54:34Z,19,"Hi Thank you for this awesome video, i am a big fan of your videos Could you please upload video on boosting methods like Adaboost, GBM , XGboost, Catboost and LightGBM Thanks in advance !",True
