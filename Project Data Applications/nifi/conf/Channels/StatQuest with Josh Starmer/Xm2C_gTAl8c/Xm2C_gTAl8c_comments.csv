author,updated_at,like_count,text,public
@statquest,2022-05-08T11:24:16Z,5,Support StatQuest by buying my book The StatQuest Illustrated Guide to Machine Learning or a Study Guide or Merch!!! https://statquest.org/statquest-store/,True
@lizhihuang3312,2024-05-10T14:31:25Z,1,this one has official korean subtitle!?,True
@katielui131,2024-02-08T00:28:58Z,1,This is amazing - thanks for this,True
@aliaghayari2294,2024-01-18T19:36:38Z,1,dude is creating quality videos and replies to every comment!  talk about dedication!  thanks a lot <3,True
@user-fo3sw8nw3f,2024-01-09T20:53:42Z,1,Thank you so much Blessing from Spain/Morocco,True
@xvmmazy4398,2024-01-09T13:07:30Z,1,"Dude you succeed at helping me and at making that thing funny as I'm struggling with my ML homework, thank you so much",True
@charan01ai,2023-11-24T16:16:03Z,2,unfortunately no one asked me ðŸ¤£ðŸ¤£,True
@hopelesssuprem1867,2023-11-11T16:54:21Z,2,"Many people on the Internet explain regularization of regression using polynomial features in the data that ridge and lasso are allegedly used to reduce the curvature of the line, but in fact in this case you just need to find the right degree of the polynomial. You are one of the few who have shown the real essence of regularization in linear regression and the bottom line is that we simply fine the model by exchanging the bias for a lower variance through slope changes.  By the way, real overfitting in regression can be well observed in data with a large number of features, some of which strongly correlate with each other, as well as a relatively small number of samples, and  in this case that L1/L2/Lasso will be useful.   Thank you so much for a very good explanation.",True
@ll-bc4gn,2023-11-08T21:36:07Z,1,"""Unfortunately, no one asked me."" I almost fart loud in a library.",True
@martinflo,2023-11-03T07:09:21Z,1,"Hi thanks for the great videos. I don't understand why we get this ""kink"" on Lasso regression and not Ridge",True
@vishnuprakash9196,2023-10-26T05:39:32Z,1,The best. Definitely gonna come back and donate once I land a job.,True
@blameitonben,2023-10-08T02:39:01Z,0,"But how do we pick the right penalty? As a college professor in econ, your lectures and dry humor are perfect for me as I tool up in ML.",True
@shawnkim6287,2023-10-07T17:06:09Z,0,"Hi Statquest. Thank you for the video. Just have a question. Let's say we have a categorical variable with 4 levels. After running the LASSO regression, if we see 3 dummy variables' beta (i.e. 1 level is in the base level) are 0 then do we drop that categorical variable? I know if the LASSO drops only 1 dummy variable, not 3, we are just merging that dummy variable with the base level. Thanks as always",True
@surendra1764,2023-08-23T11:47:29Z,0,"the least sum of squared errors is possible only when lamda value is zero  (which is what i think important to have low error) but slope is high tough , for lamda value 40 the slope is low compared to lamda = 0 but  sum of squared errors is high compared to lambda = 40 . why we are looking to minimize slope when sum of squared error is  important",True
@anshvashisht8519,2023-07-18T06:07:10Z,0,your videos are amazing but how to practise all these algorithms or implement them with a real life example,True
@juanete69,2023-06-04T19:27:41Z,0,"It would be great if you created a tutorial about the ""Boruta method""?",True
@sravanlankoti5244,2023-05-15T19:11:55Z,1,Thanks for taking out time and explaining ML concepts in an amazing manner with clear visualizations.  Great work.,True
@jaskaransingh0304,2023-03-29T20:33:54Z,1,Great explanation!,True
@Imrans_Chronicles,2023-03-20T03:55:39Z,1,The explanation can't be any better than this....!,True
@raultarufi2817,2023-03-15T14:34:13Z,0,Bam what? When is one preferred over the other?,True
@sane7263,2023-02-15T05:48:08Z,1,"That's a great video, Josh! 6:10 they should definitely have asked you ðŸ˜‚",True
@FernandoMorales-oy1iz,2023-02-12T19:08:30Z,0,I have a question. How would you call to L1 penalty? (So you don't tell nobody answered ;) ),True
@ganpatinatrajan5890,2023-02-06T11:31:53Z,2,Excellent Explanations ðŸ‘ðŸ‘ðŸ‘ Great work ðŸ‘ðŸ‘ðŸ‘,True
@knightedpanther,2023-02-05T19:24:15Z,0,"Hi Josh, thanks for this awesome video. Is it true that Lasso regression is also somewhat slower to fit than Ridge regression because the ridge regression has a closed form solution.?",True
@germantempo,2022-12-12T12:06:10Z,0,In 6:05 isn't it L1 penalty? thanks,True
@Lovely_Pihu,2022-12-11T14:26:01Z,0,"What is aka? --> Is it ""also known as""?",True
@sandeepmishra3275,2022-11-18T04:20:33Z,0,"Hii Josh ,   Must be a very naive question but could you shed some light on optimal slope. Is it the same as slope or something different?",True
@Ganeshkakade454,2022-11-17T13:09:31Z,0,Just  wanna say..U r my Guru..means Teacher..In data Science ...more love to u from India,True
@nabeel123ful,2022-11-17T07:13:49Z,0,"disagree ... the overall Lasso/Ridge SSE is basically the fixed base SSE + a very curved quadratic as a function of slope, if the curved quadratic over-take the fixed SSE curve, then the center would surely lie at the minimum of the curved quadratic.",True
@designcredible8247,2022-11-16T03:38:32Z,0,"Hi, thanks for this explanation, it really helped! In my previous work place almost everyone said that lasso could be used for feature selection and it was kind of given. Like no matter what the lambda value is but it solely depends on the lambda right? It may not remove any features at all? And increasing lambad value to the maximum isn't always most beneficial?",True
@rishipatel7998,2022-11-14T13:25:54Z,1,This guy is amazing.... BAM!!!,True
@ZinzinsIA,2022-10-25T18:06:57Z,1,"Great, many thanks, very understandable and clear. it gave me a good intuiton of how lasso regression shrinks some varables to zero.",True
@yavarjn2055,2022-10-10T16:35:57Z,0,"How do you interprete the circle and quadratic shap that is associated with these two concepts? In terms of model complexity, weights, t1 + t2 < value",True
@ruonanzheng2019,2022-10-09T10:48:54Z,1,"Thank you, regularization seris videos from 2018 to 2020 are so helpful.ðŸ˜€",True
@ling6701,2022-09-22T19:41:27Z,1,Nice. Thank  you.,True
@anonymanonym3160,2022-08-15T13:24:21Z,0,"I personally love the content of your videos but I absolutely hate the way you try to make songs out of it or go ""BAM"" to a point where I would love to view your videos but first search whether there is ANY other decent alternative because of the annoyance factor.. maybe you could do more serious videos as well for those that find that a bit too much? I know some will disagree and I am sorry for the feedback but if anyone knows anyone who is a little less like that from the way of explaining but just as good content wise, please let me know. I would prefer that any day. Otherwise good job, it's really the only thing keeping me from viewing more.",True
@DM-py7pj,2022-08-11T09:51:53Z,0,Have you done a video on Huber Loss?,True
@SuperBasketball007,2022-07-21T05:33:26Z,0,The line is *orange*. Mind = blown,True
@ainiaini4426,2022-06-26T13:32:31Z,1,I wish someone asked you before naming those penalties then it would be much simpler to remember their names ðŸ˜,True
@MorriganSlayde,2022-06-22T04:23:07Z,1,I died laughing when you sang the intro.,True
@tvbala00s27,2022-05-16T16:53:48Z,3,Thanks a lot for this wonderful lesson...loved it ..seeing how the function behaves with different parameters makes it etched in the memory,True
@joxa6119,2022-05-10T04:12:18Z,2,"So you mean this statquest answered the question ""why Lasso regression can remove useless variable and Ridge cannot"", am I right?",True
@flavio4923,2022-04-08T17:54:24Z,1,I've never been good with this kind of math/statistics because when I encounter the book formulas I tend to forget or not understand the symbols. Your videos make it possible to go beyond the notation and to learn the idea behind these concepts to apply them in machine learning. Thank you !,True
@usamahussain4461,2022-04-03T18:21:10Z,1,"Excellent.  I have just one question. In case of L1 penalty, isn't the line with lambda equal 40  (or slope 0) giving a bad line? I mean with blue line, we were getting a better fit since it didn't completely ignore weight in predicting height and sum of residuals is smallest?",True
@kseniyaesepkina3734,2022-03-23T08:53:19Z,1,Just an incredible explanation!,True
@oanphong61,2022-02-22T12:43:29Z,1,Thank you very much!,True
@markkirby2543,2022-02-18T16:56:52Z,0,This is very helpful. I just have a couple of questions: Why does the y intercept always remain the same for all the examples? What would happen if the y intercept changed?,True
@case540,2022-02-11T22:59:46Z,1,But why... I cant wrap my head around why absolute value has this property,True
@Nader95,2022-02-01T17:42:18Z,0,where do you get lambda from? I think it's by cross-validation but not sure if you have video to clearly explain the lambda part,True
@tats21a,2022-01-27T03:35:22Z,0,curious is it possible to learn the optimal y-intercept or the optimal bias term with regularization ? any insights? Like get a worse fit straight line with slope zero but cutting y axis at a different height?,True
@saranyakumaran459,2022-01-26T15:52:25Z,0,Thank you very much for the video!!! All u r Videos are really easy to understand... thanks alot.. could you please!!.... upload a video for SCAD (Smoothly Clipped Absolute Deviation Method) Regularization Method....,True
@yidong7706,2022-01-24T05:19:39Z,1,thanks to this video I finally understand why lasso and ridge have the so called shrinking effect.,True
@berkceyhan5031,2022-01-12T09:46:12Z,1,I first like your videos then watch them!,True
@huzefaghadiyali5886,2021-12-30T18:11:44Z,16,I'm just gonna take a minute to appreciate the effort you put in your jokes to make the video more interesting. Its quite underrated.,True
@andyn6053,2021-12-28T03:45:26Z,1,"Hi, I dont get why we have a kink at zero in the Lasso regression case",True
@trotts1221,2021-12-22T20:44:43Z,0,Hahaha holly shit I like your intro,True
@stiffrichard9301,2021-12-13T15:51:29Z,1,baaaaaayyuuum,True
@Dave-lc3cd,2021-12-08T10:57:30Z,1,I love you Josh,True
@nikgabrovsek3236,2021-11-18T14:51:22Z,1,Genious!,True
@Spamdrew128,2021-10-29T01:16:11Z,3,I needed this information for my data science class and didn't expect such a well crafted and humorous video!  You are doing great work sir!,True
@albertomontori2863,2021-10-14T21:05:44Z,1,this video.....you are my savior â¤ï¸â¤ï¸â¤ï¸,True
@philwebb59,2021-10-05T11:49:15Z,3,"Best visuals ever! No matter how much I think I know about stats, I always learn something from your videos. Thanks.",True
@cenyingyang1611,2021-09-20T08:36:26Z,0,"Hi Josh, great videos as always!!! I am wondering is there any guidelines on how we should pick which one? Under what cases will ridge be better and under what cases will lasso be better?",True
@BangaruAmarnath,2021-09-01T17:02:06Z,0,"@5:02, could someone please explain how the lowest point is closer to 0 when lambda = 10 than when lambda =0? I can see that the lowest point when lambda=0 is closer to zero.",True
@Jack-mz7ox,2021-08-26T06:49:14Z,1,This is the perfect explanation I am searching for why L1 can be used for feature importance!!!,True
@aliguzel2030,2021-08-11T14:34:42Z,0,"hey josh ur videos are great, Ä± m really appreciate for that but i have a question: at 0:46 when u choose the line with 0 slope, why did u choose its intercept at that value, bcs if u choose another intercept value u ll get totally different L1 and L2 graphics.ty",True
@amirrezamousavi5139,2021-08-09T19:50:46Z,1,baaam,True
@mostafatarek5088,2021-06-23T03:15:57Z,1,baaaaaaaaaaaaaaaaaaaaaaam,True
@lakshitakamboj198,2021-06-15T11:17:17Z,4,"Thanks, josh for this amazing video. I promise to support this channel once I land a job offer as a data scientist. This is the only video on youtube, that practically shows all the algo's.",True
@shivanshjayara6372,2021-06-14T07:05:48Z,0,@4:58 the lowest point in blue line is close to zero here what i see when lambda =0 but u are saying orange line....? I didnt get it.. By zero u mean value for slope in x-axis...right?,True
@ckoegl,2021-06-06T17:01:40Z,0,What about the influence of the y intercept?,True
@nightnavin,2021-06-03T02:04:52Z,1,"Really well done, excellent job, even this dummy can get it! Thanks!",True
@NRienadire,2021-05-26T16:46:41Z,1,"Great videos, thank you very much!!!",True
@Jjhvh860,2021-05-15T22:57:24Z,1,The more cringe the 5 second intro is the better explanation statsquest gives,True
@Sello_Hunter,2021-05-09T21:29:24Z,2,"This explained everything i needed to know in 9 minutes. Absolute genius, thank you!",True
@tanbui7569,2021-04-30T13:04:49Z,2,Thank you for your work as always. Its AWESOME. I just got some questions. Why is there a kink in the SSR curve for Lasso Regression ? Is it because we are adding lambda * |slope| which is a linear component ? And Does the curve for Ridge Regression stay parabola because we are adding lambda*slope^2 which is a parabola component ?,True
@srs.shashank,2021-04-26T13:53:30Z,1,"As a result when the slope becomes 0 for large lambda in lasso, then we can use lasso for feature selection.  Nice Video Josh!!.",True
@MrSanghan1990,2021-04-14T04:00:06Z,1,bam!,True
@pradhyumnjain3970,2021-04-08T01:45:19Z,0,Can you explain a case when one would prefer Ridge regression over Lasso Regression?,True
@praveerparmar8157,2021-03-24T19:56:31Z,11,"""Unfortunately, no one asked me"" ðŸ¤£ðŸ¤£ðŸ¤£",True
@satyashah3045,2021-03-13T09:25:06Z,0,"When I used Boston house prediction data set and used lasso and ridge I found that all coefficients didn't decreased as compared to linear regression, though for some of the features coefficient values increased as compared to linear regression. Why did this happen? Should all the coefficient value decreased EVERYTIME?",True
@tymothylim6550,2021-03-07T10:48:04Z,1,Thank you very much for this video! It helped me visually understand how Lasso regression can remove some predictors from the final model!,True
@bedirhangundoner9627,2021-03-05T20:42:45Z,0,"""Why can't it be zero?"" I struggled with this idea. But I think I finally found it! Could that be the reason for this? Slopes = (x ^ T.X + aI) ^ - 1 * (X ^ T.y) equation ...  Even if we increase a (Reg Term) infinitely, it cannot be zero!",True
@manjushang,2021-03-03T13:21:59Z,0,â€˜Unfortunately no one asked me â€˜ ðŸ˜€ .  Unique content . Hats off !,True
@eminatabeypeker6305,2021-02-27T17:22:49Z,1,"You are really doing great great job. This channel is the best way to learn a lot, right and important things in a short time.",True
@baharb5321,2021-02-26T18:11:31Z,1,"Awesome! And I should mention actually: We are asking YOU!""",True
@sebastiencrepel5032,2021-02-18T14:15:47Z,1,Great videos. Very helpful. Thanks !,True
@ngochua6679,2021-02-17T09:01:02Z,1,"Fortunately, I asked you :)  I agree squared and absolute penalty are better word choices for these regularization methods. Thanks again for making my ML at Scale a tad bit easier.",True
@siddhu2605,2021-01-25T06:45:31Z,1,Your are a super professor and I'll give you a infinity BAM !!!!!!!!!!!. I really like the way your repeat the earlier discussed topic to refresh the student memory and that really helpful and you have a-lot of patience. Once again you proved that a picture is worth a thousand words.,True
@abhishekbhattacharjee6208,2021-01-22T07:40:11Z,0,"best video I ever found for knowledge,  but your idiotic sounds irritating a lot,  don't do those shits in this kind of outstanding videos",True
@stevelittle7219,2021-01-09T19:23:02Z,1,Love the They Might Be Giants-esque intro.,True
@platanus726,2021-01-07T06:06:36Z,16,"You are truly an angel. Your videos on Ridge, Lasso and Elastic Net really helps with my understanding. It's way better than the lectures in my university.",True
@sunritjana4573,2021-01-02T08:26:24Z,1,"Thanks a lot for thes awesome videos, you deserver milllion followers, and a lot of credits :) I just love these and they are KISS. so simple and understandable. I owe you a lot of thanks and credits :D",True
@dudeyosemite1890,2020-12-16T02:04:56Z,0,"Josh, great video, I got a quick question: In your plotting, when lambda goes bigger (say lambda =10), (the sum of squared residual + penalty) is always overlapping or higher than the case when lambda = 0, then why do we want to use Ridge/Lasso even the sum is bigger than when lambda = 0.",True
@mihailtegovski4028,2020-12-02T16:29:02Z,1,You should receive a Nobel Prize.,True
@TheCheukhin,2020-11-26T21:12:27Z,1,Underrated,True
@geovannarojas2580,2020-11-21T18:21:59Z,3,"These videos are so clear and fun, they helped me a lot with modeling and statistic in biology.",True
@gavin8535,2020-11-11T04:14:28Z,0,"How come adding a squared term and a absolute term end up so differently? They both are positive except one might be larger and one smaller, but they would contribute the same to the sum square residuals. So how come lasso would  make it to 0? It does not make sense to me just by looking at the formula and math.",True
@TerroranschlagAmTagM,2020-10-28T00:40:14Z,0,"wow, u r a mace Inc.",True
@ehg02,2020-10-13T03:47:07Z,54,Can we start a petition to change the lasso and ridge names to absolute value penalty and squared penalty pwease?,True
@thryce82,2020-10-06T18:12:08Z,4,this channel is saving my ass when it comes to applied ml class.  so frustrating when a dude who has been researching Lasso for 10 years just breaks out some Linear algebra derviation and then acts like your suppose to instantly understand that......  thanks for taking the time to come up with an exhbition that makes sense.,True
@amazingchannel9038,2020-09-19T22:49:40Z,1,Bamm,True
@chetangupta3018,2020-09-17T20:57:35Z,0,Why did you removed weight while predicting height ? And really nice videos sir.,True
@yunfan7034,2020-09-15T13:25:02Z,0,"Thank you. Do you know why  the optimal slope get closer to 0 for ridge regression, but not 0?",True
@mansoorbaig9232,2020-09-09T06:22:37Z,2,You are awesome Josh. This one always bothered me why L1 would make coefficients to 0 and not L2 and you explained it so simply.,True
@mitchelllokey8530,2020-09-07T14:05:14Z,1,Heyo! A great part 4 addition could be SSVS to compare. Thanks for helping me prep to read papers. https://www.mathworks.com/help/econ/implement-bayesian-variable-selection.html,True
@charanjeetkaur5086,2020-09-06T09:14:08Z,0,"why does a slope of 0 in case of Lasso, means that feature can removed?",True
@niyousha6868,2020-09-03T13:47:22Z,1,Thank you Josh,True
@gladdema236,2020-08-30T14:54:32Z,1,you are crazy and you are the best,True
@zehuilin8783,2020-08-29T08:46:28Z,0,"Hey Josh, I really like this video but I am kinda confused about the kinked part. Since the cost function is a second-degree polynomial and adding a first-degree term, the shape of function will still be a Parabola. Isn't it? I mean I know you are right. However, I don't know where went wrong with my thinking. Could you help to address the question for me?",True
@filipbar5109,2020-08-28T07:44:40Z,0,"how to choose lambda correctly? Is there a standard way? (thank you, great video)",True
@younghoe6849,2020-08-27T05:50:03Z,1,"Great master, thanks for your great effort",True
@jawwadsabir4620,2020-08-26T03:04:58Z,0,Hey Josh! Whats lambda here?,True
@DreamyGirlChannel,2020-08-12T15:38:56Z,1,Just too much awesome!,True
@ammarkhan2611,2020-08-12T13:59:02Z,0,Thanks Josh. I have a small doubt. What is the reason of the LASSO plot becoming Linear (when the slope values are negative ),True
@mik8760,2020-08-06T15:59:59Z,1,THAT IS SOOOOOO GOOD MAN,True
@sabrihamad,2020-08-02T17:17:50Z,0,Thank you for such a great video. I have a question though: What happens to the intercept term during regression? Do you also shrink it? Here you have it fixed and only vary the slope but in your older ridge regression video you changed both!,True
@suryan5934,2020-08-02T04:48:20Z,1,"Amazing video as always Josh! Just to be sure if I got it correctly, the plot between RSS error and slope represents a parabola in 2D. So when we do the same thing in 3D i.e. With 2 parameters, does it represent the same bowl shaped cost function that we try to minimise?",True
@haxlwaxl997,2020-07-31T20:41:35Z,1,"And why is there now kink in the Graph? I understood that Lasso can get to Zero and this has its benefits, but why can it ?",True
@gireejatmajhiremath6751,2020-07-26T15:14:26Z,1,why does that kink exist in Lasso regression?,True
@kzengineai,2020-07-11T12:14:22Z,1,your videos're very explanatory for studying this field...,True
@mayukhdifferent,2020-07-09T06:12:36Z,0,Lasso is kinky!,True
@Seff2,2020-06-28T13:30:22Z,1,Another example on why lasso and ridge just makes no sense. The best fit was the normal linear regression. Lasso and ridge both made the line fit worse. So I conclude that lasso and ridge are pointless and best avoided.,True
@jeffchoi6179,2020-06-16T00:25:35Z,1,The best visualization I've ever seen,True
@akermiyu,2020-06-11T06:32:09Z,0,How does lasso get some weights to become zero?,True
@minhaaj,2020-06-09T21:44:04Z,0,Why don't you make a written index of all your playlists into a book content page. Save me the trouble :),True
@moisesdiaz9852,2020-06-09T19:45:36Z,1,[Video liked] AKA You are awesome!,True
@bikramsarkar1484,2020-06-06T14:56:34Z,1,You are a life saver! I have been trying to understand this for years now!! Thanks a ton!!!,True
@edmundchan8923,2020-06-04T01:08:43Z,0,Actually i saw some statment that l1 will result in coeff values to be zero while l2 wont. Can explain more for that?,True
@edmundchan8923,2020-06-03T16:03:21Z,1,Awesome!can explain elastic net regression as well?,True
@PerfectPotential,2020-06-02T15:10:01Z,2,"""I got ... calling a young StatQuest phone"" ðŸ˜  (The Ladys might love your work fam.)",True
@finderlandrs7965,2020-06-02T13:59:14Z,0,"Please make a video about Radio Basis Function Networks, i cannot understand it at all....",True
@thedanglingpointer8411,2020-06-01T20:47:11Z,1,God of explanation !!! ðŸ™ðŸ»ðŸ™ðŸ»ðŸ™ðŸ» Awesome stuff ðŸ™‚ðŸ™‚,True
@samuelhughes804,2020-05-31T21:00:39Z,1,"All your videos are great, but the regularization ones have been a fantastic help. Was wondering if you were planning any on selective inference from lasso models? That would complete the set for me haha",True
@cat-.-,2020-05-30T12:22:26Z,1,I just became the 104th patron of the channel!,True
@gavinaustin4474,2020-05-30T08:30:13Z,1,"Really enjoying these videos, Josh. Please keep 'em coming. Although I understand the distinction between correlation and interaction, I'd be interested to see how you might explain it in your inimitable fashion.",True
@--..__,2020-05-27T16:03:03Z,0,L1 and L2 norm are very common phrases. if you aren't familiar with them that is on you... They are much more clear language as it makes it immediately clear that this is just a distance defined by whichever norm you are using in your space. calling it square or absolute value obfuscates the fact that it is a norm and not some other motivation.,True
@juanmanuelpedrosa53,2020-05-26T18:24:09Z,1,"Hi Josh, would you consider explain the nuances of arithmetic, geometric and harmonic means?. I couldn't find it on the quests.",True
@weikangwong1591,2020-05-24T18:38:40Z,0,Will the slope always decrease? Are there instances where it will increase,True
@ericklestrange6255,2020-05-24T17:49:50Z,1,please do: Wasserstein metric (earth movers distance),True
@RaviShankar-jm1qw,2020-05-24T05:16:57Z,4,You simply amaze me with each of your videos. The best part is the way you explain stuff is so original and simple. Will really love if you could also pen down a book on AI/ML. Would be a bestseller i reckon for sure. Keep up the good work and enlightening us :),True
@josherickson5446,2020-05-22T21:32:54Z,1,Dude you're killing it!,True
@pmsiddu,2020-05-22T12:25:34Z,1,Very well explained this one video cleared all my doubts along with practical calculations and visualization. Kudos for the great job.,True
@myunghee7231,2020-05-21T18:48:36Z,3,thank you!!!!! i have question do you have time series model or time series forecasting??   please please make those video  with you amazing explanation!!!! :):),True
@mathildereynes8508,2020-05-21T14:40:09Z,3,"Could be interesting to see the explaination in the case of a multidimensional problem with more than 2 d features, but very nice video!",True
@chrissmith1152,2020-05-21T09:19:52Z,5,"incredible videos, been watching all of your videos during quarantine for my future job interview. Still waiting for the time series tho. Thanks sir",True
@afaisaladhamshaazi7519,2020-05-21T07:56:49Z,6,I was wondering why I missed out on this video while going through the ones on Ridge and Lasso Regression from Sept-Oct 2018.  Then I noticed this is a video you put out only a few days ago. Awesome. Much gratitude from Malaysia. ðŸ™‡,True
@RAJATTHEPAGAL,2020-05-21T01:32:08Z,0,"L2= weight penalisation (smooths out weight losss curve but and reduces overfitting , but higher lambda can kill model training)  L1 = weight imputation (dragging it to zero, useful for learnable ignoring of variables, useful for high dimensional data at times) . I have used both of these earlier with similar mindset. Earlier even in Deep Learning i used a similar analogy to reason about what was happening. The visualisation really did helped, so just wanted to know is this simplistic way of viewing the behaviour makes sense ??? Or am I missing something ....",True
@soulegacy,2020-05-20T16:47:09Z,0,"Pardon me, but what exactly is lambda?",True
@user-bz8nm6eb6g,2020-05-20T11:44:37Z,1,ðŸ˜€ðŸ‘,True
@nitinjohri3645,2020-05-20T05:48:47Z,0,Awesome explanation!!!!!!!! Can you please make a video on LightGBM and CatBoost?.?.???,True
@chunchen3450,2020-05-19T21:23:38Z,5,"Just found this channel today, great illustrations! Thanks for keeping the voice speed down, that makes me easy to follow!",True
@deojeetsarkar2006,2020-05-19T18:55:59Z,1,You're god of studies,True
@vijayendrasdm,2020-05-19T16:14:26Z,0,"Hi Josh Thanks for the amazing video. I have few queries/require clarification 1. Lasso Regression is a convex loss function, but it is not differential at certain points (optimal points)? Is this correct? 2. In the example at  lambda = 40, the weight of the feature becomes zero.  If I have to think of intuition in  higher dimension,  if we start with 5 features(F1,F2,F3,F4,F5) and lambda=0, The optimal would correspond to some non-zero weights. Now if I start applying regularization,  i.e increase lambda, lets say lamda=10. Then subset of weights might go to zero , what could we say about the kink here ?",True
@omnesomnibus2845,2020-05-19T15:57:36Z,3,"Really excellent video Josh. You consistently do a great job, and I appreciate it. Could you make a video showing the use of Ridge regression and especially Lasso regression in parameter selection? I had to do that once, and it is complicated. From your example it seems that using neither penalty gives you the best response. So, in what circumstances do you want to use the regression to improve your result? If you are using lasso regression to find the top 3 predictive parameters, how does this work? What are the dangers? How do you optimally use it? A complicated subject for sure! I'm sorry if this is covered in your videos on Lasso and Ridge regression individually, I am watching them next. I agree with your naming convention btw, squared and absolute-value penalty is MUCH more intuitive!",True
@MasterofPlay7,2020-05-19T15:55:29Z,0,gradient descent?,True
@anthonym9130,2020-05-19T15:14:04Z,0,Just to clarify would we use these two methods specifically when we have a small sample size? Also would you also be checking for multicollinearity in these instances?,True
@adibhatlavivekteja2679,2020-05-19T11:25:26Z,3,"Explain stats to a 10-year-old? Me: ""You kid, Subscribe and drill through all the content of StatQuest with Josh Starmer""",True
@siddhantk007,2020-05-19T11:19:31Z,1,Your videos are super intuitive.. thanks alot sir,True
@statisticaldemystic6817,2020-05-19T09:39:01Z,1,Very well done as usual.,True
@arjunpukale3310,2020-05-19T06:48:42Z,1,And thats the reason why lasso does a kind of feature selection and sets many weights to 0 compared to ridge regression.  And now I know the reason behind it thanks a lotâ¤,True
@Azuremastery,2020-05-19T06:42:23Z,30,"Hello Josh, Ridge and Lasso clearly visualized :) I must say that if one thing that makes your videos clearly explained to curious minds like me is that the visual illustrations that you provide in your stat videos. Glad. Thank you very much for your efforts.",True
@anshpujara14,2020-05-19T06:08:45Z,1,Can you do a lecture on Kohonen Self Organising Maps?,True
@adhiyamaanpon4168,2020-05-19T05:54:22Z,1,Hey josh!! Can u plz make a video for K-modes algorithm for categorical variables(unsupervised learning) with an example..plz?,True
@chyldstudios,2020-05-19T05:07:23Z,57,The visualization really sells it.,True
@mohitnagarkoti4086,2020-05-19T04:53:40Z,0,"Was about to start this topic.  Thanks @Statquest  Hellowww , I just have quick question.  by what time we should expect your video on Neural networks?   And I have a request, could you add your upcomming videos on your website in a separate sections.   By looking at the topic and the date odr month it will be uploaded. It will be very helpfull for students to buy a subscription plan of your channel  in order to get early access to your videos.",True
@Mabitesurtaglotte,2020-05-19T04:25:44Z,158,Still the best stat videos on Youtube  You have no idea how much you've helped me. You'll be in the acknowledgments of my diploma <3,True
@shrikantdeshmukh7951,2020-05-19T04:22:08Z,0,Are there other penalties available ? Rather than L1 and L2,True
@anuragshandilya3556,2020-05-19T04:22:05Z,1,Perfect!!!!,True
@priyanatraj5634,2020-05-19T04:22:01Z,0,Thank you for helping us to understand statistics! May I request for a video on Dirichlet regression?,True
@pkmath12345,2020-05-19T04:09:36Z,4,Ridge regression! Good topic to cover as always!,True
@rrrprogram8667,2020-05-19T04:08:19Z,1,MEGA BAMMMMMM..... For the video,True
@markevans5648,2020-05-19T04:02:21Z,6,Great work Josh! Your songs get me every time.,True
@premnathkn1976,2020-05-14T05:29:15Z,2,Clear and apt..,True
@hemaswaroop7970,2020-05-13T19:58:29Z,35,"Fantastic, Josh!! Thank you very very much. We all owe you a lot many thanks. ""I"" owe you a lot. ðŸ˜ŠðŸ˜ŠðŸ‘ðŸ‘",True
