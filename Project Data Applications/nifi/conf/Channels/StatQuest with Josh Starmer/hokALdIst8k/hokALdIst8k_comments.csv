author,updated_at,like_count,text,public
@statquest,2022-05-09T19:02:22Z,2,Support StatQuest by buying my book The StatQuest Illustrated Guide to Machine Learning or a Study Guide or Merch!!! https://statquest.org/statquest-store/,True
@JagooTheBoss,2024-05-24T13:22:01Z,1,Best video so far,True
@Didmasela,2023-02-20T22:27:39Z,0,"Can you or anyone interprete this :   Residuals:     Min      1Q  Median      3Q     Max  -84.878 -26.878  -3.827  22.246  99.243   Coefficients:               Estimate Std. Error t value Pr(>|t|)     (Intercept) -5.566e+02  1.232e+02  -4.518 4.34e-05 *** incpc        7.239e-02  1.160e-02   6.239 1.27e-07 *** pop          1.552e+00  3.147e-01   4.932 1.10e-05 *** urbanpop    -4.269e-03  5.139e-02  -0.083    0.934     --- Signif. codes:  0 ‚Äò***‚Äô 0.001 ‚Äò**‚Äô 0.01 ‚Äò*‚Äô 0.05 ‚Äò.‚Äô 0.1 ‚Äò ‚Äô 1  Residual standard error: 40.47 on 46 degrees of freedom Multiple R-squared:  0.5913,	Adjusted R-squared:  0.5647  F-statistic: 22.19 on 3 and 46 DF,  p-value: 4.945e-09",True
@korman9872,2023-02-08T14:35:00Z,1,tx sir.,True
@Quetzal00358,2022-09-14T22:23:36Z,0,Is there a way to graph a scatterplot/linear regression in Excel? To have multiple lines for different covariates?,True
@yahiagamal937,2022-09-09T14:31:59Z,0,"Hi,  in multiple regression and we are using weight, tail and ears (or any 3rd parameter) to predict size, in the R coefficients, the weight line will compare multiple regression vs single regression?  BR  YG",True
@rongxuantan5406,2022-07-15T17:27:20Z,0,"But looking at the weight x tail graph, seems like there's a correlation between the two variables. So shouldn't one of the variable be removed to prevent multicollinearity?",True
@samwitty9735,2022-07-11T11:09:15Z,1,Thank you so much for these video! They were very helpful in helping me to build an MLM for my MS degree! Thank you!,True
@ajaikurianmathew7026,2022-06-19T23:18:44Z,0,"have you done any videos on how to do calculation of p-value from F-value? Also any video on explaining degrees of freedom? For example, why residual standard error is mentioned as 1.19 on 7 degrees of freedom at videotime 03:21?",True
@muhammedhadedy4570,2022-04-07T22:44:02Z,4,"Great video as usual. Can you please explain survival analysis and Cox regression models, and how to run them in R. I think you will be the best person to explain them. Thanks in advance.",True
@afianarohmani1179,2022-03-30T03:20:47Z,0,whats the different with multivariate regression. COuld u please make video about this üôÇ,True
@rizuri789,2022-03-17T02:17:23Z,1,"I love your video, I like the way you explain the regression. Thank you",True
@hafsashahzad7480,2022-03-14T06:08:24Z,0,Hi. Is there any way to perform multiple linear regression on raster time series images?,True
@kennethssebambulidde9238,2022-03-11T04:38:14Z,0,"Thanks for these amazing videos. Great explanations. One question, how do I add the output to the plots? Sorry for asking for R code, I find your codes easier to use and understand.",True
@ciaracuesta544,2022-03-02T01:24:22Z,1,wow this makes so much more sense than what my professor was trying to say thank you!,True
@athenanguyen442,2022-02-09T16:36:46Z,1,"Let's say that instead of writing size ~ weight + tail, we write size ~ weight*tail. how does the output change and how do we interpret that?",True
@juanwang3705,2022-02-07T15:49:19Z,0,"a small doubt. why don't you check multicollinearity? if we have more than one independent variable, that is needed.",True
@ARROBACOMPUTERS,2022-01-01T20:34:44Z,0,"Hi Josh . I would first like to thank you for your videos which have made complicated concepts easier to understand. I do have a question about the p-values in the multiple regression though. If there were more than two variables, is the p-value derived by comparing the linear regression model with the one variable in question, to the model using all the other variables, or does it always compare it to a single variable (simple regression)?  If it is the case that it is always compared to a single variable, how is the variable for the simple regression model chosen?    Thanks",True
@joanbrunet6,2021-12-16T12:29:29Z,1,i love you more than i love myself,True
@jamesly__vi1di,2021-12-13T21:45:21Z,0,"Hello Josh, first of all, thank you for your videos. Could you please answer one question about the multiple regression summary output? You explained p-value of each coefficient one by one. You said that the p-value of `weight` is comparing `weight` + `tail` to `tail`. Was this a mistake? The p-value for `weight` is not for comparing `weight` + `tail` to `weight`?",True
@guillermotellez8257,2021-10-01T19:46:45Z,1,"I wanted to kill myself after that intro but I've grown to love it now. But anyway thanks for the stats help, keep it 100.",True
@bibeksharma600,2021-09-24T16:44:51Z,1,"Yeah correct, adding a new variable weight actually reduces the Adjusted R^2 value,hence it is better to use tail alone to forecast the value as it as higher R^2 value.",True
@ahmed007Jaber,2021-09-20T16:24:27Z,0,thank u for this. trying to  create and plot a system for sales where the recommendation is coded in 0 and 1. tried to plot but I am getting straight lines on two cut offs say price points.  would you appreciate your help in this. to predict recommendation   this is for a training project for introduction to R,True
@AndrywMarques,2021-08-05T00:55:48Z,0,Thank you for the video! In a previous video you explained how to calculate the pvalue for the R^2. But how to calculate the pvalue for each coefficient?,True
@seonggi-hun7482,2021-07-20T13:31:36Z,0,"Thanks for the video. I know this is for numeric data, but is there a model for predicting a categorical value? Eg predicting what career a student will choose based on scores in different subjects in high school?",True
@jamesparson223,2021-07-18T18:42:44Z,0,"Thank for the video, however, the intro is very bad, especially the singing - why would you ruin the video with that intro?",True
@ELECTR0HEART,2021-05-07T16:07:02Z,8,I was exactly looking for this. Thank you so much! Very well explained :) saving my thesis :D,True
@marcoventura9451,2021-04-13T18:41:17Z,0,"The video is super good, the script on github fantastic; I feel so stupid but the output test in R which compares simple vs multiple model for me is pretty counterintuitive.",True
@surajprasad2291,2021-04-10T03:46:47Z,1,BAM!! :),True
@Han-ve8uh,2021-03-27T05:08:51Z,0,"At 7:20 you mentioned we can use tail alone rather than weight too to save time. How do we quantify the cost (eg. increased error, reduced R-sq, some other more interpretable business metric) of not using weight? Because I believe practically, people don't make decisions based on p-values alone but there must be some translation to more practical factors along the way.  For the 1st two metrics (error and R-sq), must we re-run the model by redefining the RHS of lm() each time we want to test a different predictor combination, or we can say something about the results of other predictor combinations from the summary() of 1 experiment alone. (Seems like both are true, which is contradictory). What would you say about the 3rd metric? (translating p-values to practical considerations) I'm also not sure if using tail alone definitely leads to a worse/equal result (as measured by error, or some other metric) than tail + weight? If I reason from the fact that using more predictors will never reduce R-sq, then this statement is true?",True
@ryantatton9983,2021-03-07T02:40:17Z,2,"These are great videos. So grateful for the clarity. Liked and Subscribed, keep going!!",True
@bertiefilms1,2021-03-04T14:55:38Z,1,Thanks so much for this!,True
@ilhomsadriddinov3627,2021-02-23T06:58:39Z,1,Great job! Exactly what I searched for!,True
@user-gw7nb3im4u,2021-01-05T15:20:19Z,0,"This was a great video. Does the same applies for multiple regression models with one numeric and one factor variables (for explaining the coefficients)? I understand that you can't design a pairs plot with factor variables as they need a box plot but are the rest of the steps same as with 2 numeric? Also, don't we need to run a diagnostic plot of our model to check for assumptions validations? Great videos!",True
@bhaktitarang04,2020-11-30T05:22:59Z,1,love your work,True
@Cuicui229,2020-11-26T17:23:48Z,2,Thank you for this video!,True
@danialdunson,2020-11-21T23:06:05Z,0,"stat teachers have the best personalities, try and change my mind.",True
@ryanmann799,2020-11-05T10:00:28Z,0,"Excellent stuff, Josh. I may have missed it somewhere, but have you done/plan to do a break down of multilevel (hierarchical) regression?",True
@hustle-kn5xp,2020-10-28T21:47:17Z,0,thanks. Spent like 5 hours trying to understand this,True
@dahailiu2067,2020-09-05T13:28:59Z,1,Hi Josh my hero. Can you explain VIF? virance inflation factor?,True
@anthonysun2193,2020-08-15T23:43:10Z,1,Hi Josh - Thank you for your video tutorial.  I used your data sample and ran a simple regression (size ~ tail) and got a  marginal slightly higher Adjusted RSQ (0.808 vs 0.800) and a much lower P-Value for the tail slope (0.0006 vs 0.0219) compare to the multiple regression (size ~ weight + tail).  Does that make sense?  Does that mean we can just use a simple regression instead?  (Assuming the data is already available and no additional effort for measuring the mice tails needed.)   - Anthony,True
@shajibkumarguha234,2020-07-25T03:12:35Z,0,For each explanatory variable you need to have at least 10 observation for each as of the thumb rule I know. But your sample size is too small!,True
@aryanverma3173,2020-07-22T12:25:33Z,3,"Your videos are literally saving my career. I don't know whether words would be sufficient to express my gratitude. I have just one request, will you please upload videos on factor analysis also just like you did for PCA ?",True
@baruchschwartz819,2020-07-17T17:56:06Z,0,"When you called the summary of the multiple regression, the computer told you that the multi model was not more significant than the simple model using tail alone. If so, why was the P score in the multi variate regression under ""Tail"" a little worse  than it was when you called a simple regression using tail only? I am referring to 6:45 in the video",True
@jacquelinelabovitz4613,2020-06-01T13:35:04Z,1,well done!,True
@elliotts2392,2020-05-06T18:49:01Z,4,Your songs are so metal when played at 2X speed,True
@yanweili6951,2020-04-28T00:13:57Z,0,"how do you plot the multiple regression line? Like in the first example you used abline(regression) and I thought it might also work for the multiple one, but abline(multiple.regression) doen't work.",True
@santoshbala9690,2020-04-20T07:01:00Z,0,"Ho Josh - Thanks for the video.. i wanted to understand more on the assumptions of  Linear Regression and check the Goodness of fit - pertaining to the Residuals - Normality, equal Variance etc...Looking for a Video... BAM BAM BAM....",True
@daneshj4013,2020-04-08T01:16:41Z,0,Do you have a video explaining what it means to control a variable statistically? Some of the explanations I'm finding on YouTube just use the words in the term as the definition and it's not intuitively clear to me to sink in :/ Btw thanks a lot for these clearly explained videos üëçüò¨,True
@kusocm,2020-04-07T10:13:17Z,17,Using tail alone actually results in an R^2 = 0.83 (p = 6E-4) compared to the adjusted R^2 = 0.79 for the multivariate model. Maybe could have been added to the video. Nice explanation regardless (y).,True
@Dominus_Ryder,2020-03-31T21:12:24Z,0,"Hello StatQuest, I have a quick syntax question. Lets say you are trying to predict mouse size based off of like 50 features measured from the mouse. Is there a way not to have to the names of all 50 features when you get to the:  lm(size ~ weight + tail + ...+ 50 feature) part of the code. I tried saving the column names of the data frame in an array and doing: lm(size ~ column_names_array) but I get an error.   Thanks in advanced.",True
@poonhing,2020-03-29T09:54:20Z,0,"thanks for the video,U are the best video I watched so far in this subject matter. However, I don't quite understand the p-values under weight and tail row.",True
@marystreet7661,2020-03-24T23:16:20Z,0,"this video was very helpful.  quick question - what made you come to the conclusion that an interaction exists between weight and tail through the graph visualization (approx. 5 mins)? is it because a pattern exists? I'm trying to understand how to identify an interaction between two numeric variables graphically. What would a scatter plot look like if no interaction exists - just highly randomized distribution of data with no identifiable pattern? I think that's right, but just want to confirm. Thanks for your help - these videos are a lifesaver.",True
@alexandrecruz7763,2020-03-11T13:29:30Z,0,"Thx for the video. But i have one question, where can i see the values for sloope1 and sloope2?",True
@tretsy,2020-01-29T03:48:12Z,0,"Could you go through some other basic data visualisation and stats methods in R? Your PCA video was very handy, but I'd love help with e.g. CVA, MANOVA",True
@jahhedouglas242,2019-12-29T03:15:41Z,1,"Hey Josh Great Video! say we have 5 independent variables instead of 2 (i.e mouse length, height, weight, color, breed etc). Does this same format of understanding p-values apply: Is the lm function comparing an additive regression model of 4 independent variables (height, weight, color, breed) without the variable of interest (mouse length) to an additive model of the total 5 variables including the variable of interest (mouse length, height, weight, color, breed)? Or is it doing something else?",True
@nasrintaghavi6877,2019-12-17T04:12:45Z,1,"Hi Josh. Thanks for the excellent videos, it really helps me to understand statistics. I have a question about different types of statistical methods: If you want to categorize different statistical methods, is it right to say that there are three main categories called:1)Orthodox statistics, 2)Data-Driven methods, and 3)Bayesian inference?",True
@paulti1396,2019-12-15T14:18:07Z,5,"I love your intro. The rest is also good but the ""totes cray cray"" bit was funny.",True
@georgevendras5450,2019-12-12T23:09:00Z,1,"Good morning. At the end of the video you prompt viewers for ideas. Well, I would like to propose you this:  we are given these woooowww Bioinformatics books, you know, data mining for Bioinformaticians, Introduction to Bioinformatics, introduction to Genomics and Proteomics... and well, I will be honest as for my sensation: I think that their writing style fails to get the reader to the point. We spend the whole day on half the chapter and at the end of the day we have acquired no knowledge and we just got tired without any particular reason. I mean, their stat approaches are qualitative (for example, there is no k-means algorithm or the way it is explained makes no sense) and since an bioinformatician has usually no background in ... Biology or Medicine, we cannot understand what stat method should be used when. Things became really hard in Biomarkers discovery and it seems that 'incomprehensible' stat methods outcrop (something like Rambo, who would suddenly appear from inside mad, imagine something like that). I mean, from a qualitative perspective, all angelic. But not sure about the whole stat procedure.  Would it be as a fatigue for you to make some videos on ""When we (should) use what?"" ? Also using a general, a catholic Diagram would help the most, I think.  Thank you!",True
@tocinoconrad3798,2019-12-10T15:40:02Z,38,Thank you for easily explaining something that my professor nor my book was able to explain well,True
@luka9843,2019-11-21T20:36:49Z,3,Can you explain how to use Robust  standard errors like in Stata,True
@hiteshpant,2019-10-23T08:03:13Z,1,"Hi StatQuest,  I have a basic question. You mentioned at the beginning to plot the x and y variables(mouse weight and size in our case) to see whether there exists a linear relationship or not before proceeding with the modeling. Its easy when you have 2-3 variables. Suppose I have 50 variables in my data-set(assuming all are important) I assume it will be a big pain to plot graphs for all of these. What is the more efficient way to go ahead in such a scenario.",True
@prasadchimalwar3951,2019-10-01T13:59:50Z,0,@Josh Starmer Can you please throw some light on multicollinearity and Variation Inflation Factor (VIF). These are useful concepts when it comes to multiple regression.,True
@patelprateekramesh2442,2019-07-25T06:43:49Z,2,"Could you please answer one question?   I did the SLR for Tail and the p-value was very small (0.0006) against 0.003 for MLR. The variance in R2 was also minimal (0.83 for SLR and 0.85 for MLR). In such case using only tail to predict mouse size seems better and it matches your inference.   Now I believe the comparison method shown in the MLR video would also apply to two MLR (one with lesser variables). In such case is it better to carry out the the comparison technique you showed  (the one where we compared SLR and MLR to find comparative R2 and p-value)? Or surmising the same from the p-values of each variable of the MLR summary would suffice? Here i believe we can get the p-value but still need to check R2 and would need to carry out another MLR with reduced variables anyway.   If so, is there way to carry out the comparative method in R?",True
@sumitdangat8159,2019-06-19T18:53:58Z,1,Hello Josh please help me to understand below points:  1. If we are considering p value to identify whether variable is significant or not then why don't we remove weight from final model.  2. After adding weight and tail in model our p value is significantly improved what is the reason behind that? 3. If combinations of weight and tail improve model then weight also needs be significant why it is not?  Thanks in Advance,True
@chickenpax1,2019-05-31T15:04:05Z,1,"Hi Josh, thanks for your videos, they are very helpful.  I am a bit confused.   Isn't the explanation at 6:30 backwards? When you have the red square on weight, isn't that line saying you are seeing the effect of weight on the size adjusting for tail? If this is the case, then the formula below should be the following: we are comparing the complex model where ""size=y-intercept + slope1 *  weight + slope2 * tail"" to the simple model ""size=y-intercept + slope2*weight"", not tail.  Wouldn't this be right?     And likewise, at 6:55, that's telling you the effect of tail on size controlling for weight.    I am a graduate student and I am preparing for a talk where I have to talk about my data, and I use linear regression to model effect of genotype and treatment on certain behavior scores. In case they attack me on my analysis, I'd like to be able to interpret just about every line that R puts out, which this is part of. Your lessons are huge help :)   Any feedback from anybody is welcome",True
@liuy6031,2019-03-08T23:57:11Z,0,"Thank you for your video! However, if I use more than 2 variables, e.g. 5 variables, to build a linear model, how could I interpret the summary of the linear regression. Especially the 6 lines for intercept and 5 variables, what will the p-value means for each variable? Will it compare the model to the model without that variable?  Thanks so much.",True
@truelysoham,2019-03-07T08:08:01Z,1,"after regression for the 3 variables, how do we plot all 3 in a given space together? abline was used for simple regression but here using it, cant be used for 3 variables.",True
@F4lipeC4rdoso,2019-03-04T01:35:34Z,2,Thanks !!,True
@riteshshahi9699,2019-01-11T04:30:38Z,1,"hi Josh,loved your video. Can you hint on a multilinear regression formula with a constant slope and changing intercept.",True
@elabassiayoub8700,2018-12-31T18:15:47Z,1,hi Josh can you explain to me why we use towby2 command in R,True
@panagiotisgoulas8539,2018-12-25T23:57:51Z,0,"I have seen in minitab an option where you can get a table that summarizes information (r sq, r sq adjusted, mallows cp and vif) for an dependent variable vs every COMBINATION of independent ones. Is there something similar in R and how can I do that?",True
@md.shahadathossain8171,2018-11-28T04:48:24Z,1,Thank you for your nice and organized presentation. Could you refer some statistics books for biologist which you find helpful for biologist?,True
@anggunsausan6738,2018-11-17T08:18:16Z,8,This what exactly i needed right now. Thanks a lot,True
@reneeliu6676,2018-09-26T00:19:20Z,2,Awesome! Do you have plans for polynomial regression?,True
@joerich10,2018-05-25T23:43:26Z,3,"Hi Josh -  I'm confused. In other video on linear regression you mentioned that when fitting a 'plane' in multiple regression, if adding a second variable doesn't reduce the SSE (i.e. explain more variation in y) then the coefficient of var2 would be set to '0' and the equation essentially ignores it.  But this video seems to say something slightly different - that is, if an additional variable doesn't add more explanatory power, then OLS will still assign a coefficient value, but the p value of that coefficient will be high signifying that the variable isn't significant.  One way to try bridge the difference, is that the second variable still reduces the SSE (i.e. line fit is better using the plane vs simple line), but that if we plot the second variable alone on a line, the residuals (errors) would be so large that we're not sure if the pattern we're seeing (desribed by the coefficient) is due to pure random chance. Have I got this right?",True
@wanhope3660,2018-05-16T19:25:40Z,1,OH BOY love me some stat quest. I have a hard time during lecture to grasp everything when its being kept abstract but with these examples and a good sense of didactics this is a piece of cake! thanks josh! spreading this channel for sure,True
@rrrprogram8667,2018-05-10T17:10:17Z,7,This is channel of treasure...,True
@Uynix1978,2017-11-01T14:12:02Z,5,"Thank you.  What makes me think is that since weight  and tail length are highly correlated, I would think using either one of them in the model is fine and these two predictors are interchangeable.   But the results showed otherwise.  I am wondering what might have made the difference?   According to the previous lecture, I am guessing it is because that the sum of squares of the weight-only model is significantly bigger than the sum of squares of the tail-only model?  Also, I remember there is a terminology about multicollinearity that if one predictor is highly correlated with the other, in multi-regression the matrix inverse will fail.  I wonder if there is any indicator in the output about multicollinearity here.",True
@quintens.9828,2017-10-30T18:46:44Z,0,First #craycray,True
