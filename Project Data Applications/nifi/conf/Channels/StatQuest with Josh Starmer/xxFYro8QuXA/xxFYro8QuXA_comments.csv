author,updated_at,like_count,text,public
@statquest,2020-04-20T11:09:59Z,40,Correction: 13:58 The formula at should be 2[(LL(saturated) - LL(overall)) - (LL(saturated) - LL(fit))]. I got the terms flipped.  Support StatQuest by buying my book The StatQuest Illustrated Guide to Machine Learning or a Study Guide or Merch!!! https://statquest.org/statquest-store/,True
@saltedfish_is_good,2024-05-23T15:35:07Z,1,I am finally clear. Time for relu logistic model,True
@PunmasterSTP,2024-04-17T14:06:35Z,1,"LL Cool J?  More like LL ""StatQuest is here to stay!"" üëç",True
@cezarystorczyk1722,2024-02-06T15:47:26Z,1,Dziƒôkujemy.,True
@cocoviano,2024-01-09T18:26:27Z,0,"Why is the use of R-squared so debatable? I have been having problems with it, and many people advise me to ignore it and find another fit indicator",True
@tysonliu2833,2024-01-06T00:21:19Z,0,"so essentially with a model where weight is a very poor predictor for obese, the best line that we can find will be as poor as the LL(overall probablity), therefore R2 is 0, otherwise with a perfect predictor, LL(fit) is dramatically different from the LL(overall probablity) so that R2 is 1",True
@omercoskun6042,2023-11-24T19:09:00Z,1,"I wonder why you mentioned SS(mean) as the worst fitting line. Clearly, there are worse lines that we can fit. I always thought SS(mean) as a base value, the line that minimizes the sum of squares if we only had y values and no x values (no input).   By the way, loving your lectures, they are all clearly explained and super helpful!",True
@BeginnerVille,2023-10-24T08:39:22Z,0,"If directly project the data into the S shape logistice regression, wouldn't can get same image as 5:04? Don't get why need to do these.",True
@phongapex3741,2023-09-20T13:07:29Z,0,"Hello! At the 8:24, you can determine the maximum likelihood with the intercept of -0.22. How can you know that? Which line do we have first? squiggle line OR straight line? I do not actually understand that at the beginning, we already had a squiggle line, then found p values of points to calculate log(odds) in order to get the straight line of the log(odds) graph. How did we have that squiggle line at the beginning? OR, we already had a straight line, then projected points to find the log(odds) values, next, calculated the p values in order to have the squiggle line. How did we have that straight line at the beginning? I AM STILL CONFUSED ...",True
@arshsadh7332,2023-09-01T21:09:42Z,0,"Hey Josh,  Thanks for sharing this. It really helped me clear some doubts.  I have one doubt, how do I find p-values using the chi-squared distribution if degrees of freedom is 10, for example?",True
@rishavdhariwal4782,2023-08-30T09:15:11Z,0,hi Josh i don't know if you will see this but i had a question how does one know which distribution to compare to determine the p values. Like in the video at 12:01 you said that the metric follows a chi squared distibution but how does one get the intuition fo when to use which distibution to get the coressponding p - value of the metric?,True
@russelllavery2281,2023-07-10T20:42:30Z,1,this series is great!  Thanks.,True
@bleakmess,2023-06-26T07:54:30Z,0,How is this true? ‚Äú residuals of logistic regression are all infinite‚Äù.,True
@user-xo1uk7uk6d,2023-03-27T17:35:50Z,0,"3:09 I, think worst fitting line perpendicular to the best fitting line",True
@tamerosman774,2022-10-30T04:37:59Z,0,Can you do the linear and logistic regression in matrix form please,True
@SS-ve1jm,2022-10-09T14:38:31Z,1,Amazing content please continue to upload videos always and grow this channelüéâ Triple BAMüéâ,True
@bennybenbenw,2022-10-04T06:35:41Z,0,"hi josh, log(likelihood of data given overall probability) isnt 0.56, but what u written is 0.55",True
@Nordlinger.Dr4ke,2022-09-25T16:59:43Z,1,"Thanks a lot, me and my friends really enjoy ur content. really appreciate ur content one of the best statistical video i had ever see",True
@ciegbiraj,2022-08-19T11:00:27Z,0,Great videos Josh! It would be great if you could also do StatQuest videos for Ordinal Logistic Regression.,True
@NazaninYari,2022-08-10T22:46:05Z,1,You are a GENIUS. Hats off to you!,True
@jonathanbarajas7940,2022-04-21T04:00:36Z,1,Que gran video!,True
@zhou6075,2022-04-17T11:13:34Z,1,so understandable,True
@xiaoyuqian5317,2022-04-04T06:33:54Z,4,"Hi, Josh. I started watching your video 3 years ago. At that time, I was a master in bioinformatics, I came across many questions in statistics while doing my research. Your video is clear and instructive, which allows me to put the models mentioned in your video into my research very quickly. It means a lot to me. Now I have already started my career as a PhD candidate in statistical genetics. Your videos have really helped me a lot at an important time in my career, I can't put your name in my journal article, but it deserves a place there, a sincere thank you for the video you uploaded. Wish you happiness every day.",True
@foreverpali,2022-03-22T19:39:58Z,1,"Your videos are amazing! You make statistic modules so simple and understandable, thank you!",True
@lprasai,2022-03-17T21:40:15Z,1,Who liked the way he says StatQueeest!,True
@rameshbabu2228,2022-03-11T15:01:45Z,3,"Your explanation always unique sir. I completed Masters in Statistics, my brother did PhD in Statistics had explained Logistic Regression  theoretically  but not satisfied. I have huge confidence on your explanation and hard work so listened got 200 % satisfication. Thank you so much sir",True
@marvinbcn2,2022-03-08T18:02:55Z,1,"Excellent video as usual. I'm just wondering where the formula 2[LL(fit) - LL(overall probability)] comes from. Please don't bear a grudge against us for asking for further developments, Josh. Your videos are exceptional at making things clear. It's simply, that, the more we learn, the more we want to learn!",True
@kt4nk95,2022-02-26T02:17:12Z,0,"This may be a silly question, but I'm still confused where the 2[LL(fit) - LL(overall probability)] came from. How do we know to use that to calculate the p-value?",True
@sajozsattila,2022-02-23T14:38:41Z,0,"I have a question about the p-value. The 2(LL(fit)-LL(overall)) a point estimation for the probability of this value. So Chi f(  2(LL(fit)-LL(overall)) ) just give us the probability of this single value. In your example f_{\chi^2}(4.82) \approx 0.0163.  So to get the actual p-value we need to use: 1 - F_{\chi^2}( 2(LL(fit)-LL(overall))  ), which is the area of the right tail where x > 2(LL(fit)-LL(overall)). In your example, the actual p-value is approx 0.0281. Am I right?",True
@remid5842,2022-02-22T17:08:05Z,0,Shouldn't it be 0.56 instead of 0.55 at 6:46? Or did I misunderstand?,True
@mahdimohammadalipour3077,2022-02-19T13:06:44Z,0,"I've heard that we can not apply LSE to find the best fit in logistic regression and honestly, yet I don't know why? (When it comes to log(odds) I know that residuals are infinity and we can't) but why don't we simply assume that our data is only 0 or 1 and simply use LSE just like linear model to find best fit. i.e. we have data that are obese (1) and  not obese (0) and we use logistic regression with specific threshold (0.5) to predict 0 and 1's and then we define cost function and try to minimize it?",True
@rabbitazteca23,2021-12-22T09:33:50Z,0,If my model has a high p-value (x variable is not correlated to y) but has a high R-squared value (meaning the variance in the y data is explained by x = our line fit our data well) what does this tell us? How can x be not related to y but at the same time our y's correspond to correct and reasonable values for x?,True
@rabbitazteca23,2021-12-22T09:07:26Z,0,Can we also use the maximum likelihood instead of its log version for calculating R^2,True
@punchline9131,2021-12-09T22:06:59Z,0,Is LL(fit) the same as the maximum-likelihood? And thanks for your excellent work! üëå,True
@deuteros,2021-12-08T14:44:26Z,0,"Josh, I have read that pseudo R2 is not a good metric to compare models which predict the same variable through different covariates (different models built from individual covariates, y ~ x1, y ~ x2, y ~ x3, etc..). What is, in your opinion, the best way to do this comparison?",True
@desmondturner5435,2021-11-25T21:12:42Z,0,"Thank you for the help! This series is amazing. at 12:31  would the degrees of freedom for 2 independent variables be 2? and for 3, 3, etc?",True
@Max-jf7sw,2021-11-18T17:57:14Z,0,One thing i dont understand is why you are using the horizontal-line as null-hypothesis?¬†  As far as i know it is far more common to use a model with only a constant in it (all other coefficient are 0) as a baseline model/null-hypothesis.  Is it for easier explanation? When is it ok to use the horizontal line as a baseline model in logistic regression?,True
@almonddonut1818,2021-10-01T08:29:21Z,1,Thank you so much for your videos!,True
@maidang4081,2021-09-09T05:45:52Z,0,"Your videos are very well explained and clearly understandable, your BAM is a huge hugeee plus. I learnt so much via your videos than my grad shcool's ML lectures.  Also, I have a small question. I am new to Machine Learning and also have a fear of it... so anw, can you please explain to me ""Why the residuals for Logistic Regression are all infinite?"" because the data point is probability so its range is between 0 and 1...? I just can't get my brain stretching out with it T.T",True
@anshulsaini5401,2021-07-27T10:31:14Z,0,"I had a doubt, that in logistic regression what does this R square value actually tells? In Linear regression it used to tell the amount of variance explained by our model. How do we interpret it in Logistsic regression? Is it really helpful in logistic regression or we can just skip it's interpretation?",True
@vincenttan6303,2021-07-25T15:11:55Z,4,I always wondered what the interviewers wanted me to say... I didn't know what I didn't know... until this.,True
@kanikabagree1084,2021-07-17T07:29:00Z,2,This is the best channel i've come across to understand the statsbehind the ML algorithms thaaankyou Josh ‚ù§Ô∏è love from India.,True
@coinatlas5953,2021-07-15T08:30:52Z,0,What about the assumptions of a logistic regression which must not be violated?,True
@moorthin,2021-07-11T21:20:30Z,1,BAM!!!,True
@guiyingyu3182,2021-06-04T06:16:12Z,0,"why log(1.25) = 0.22? I try on calculator, the answer is 0.097?",True
@nataliakos4932,2021-05-28T11:55:40Z,2,I watch this series with such commitment as if I were watching a good Netflix series. Just can't stop.,True
@karannchew2534,2021-05-18T05:49:26Z,1,"""Wow, that was a long sentence"" ü§£",True
@hang1445,2021-04-13T14:54:22Z,0,"13:40  Hello Josh, thanks for making this useful video list so that I can learn machine learning rather than studying in uni. And I would like to clarify sth.  The logistic model you have built has a p-value of 0.03, does it indicate that there is a strong relationship between weight and obesity? Just like what you have said in the video, it is not due to chance.  For the R^2 value, 0.39, does it indicate that the model is not good enough? We may need to add more parameters other than weight to classify whether the mice are obese or not.  Hope you can correct me if I get sth wrong, thanks üòÅ",True
@JohnWick-ls7yt,2021-04-12T19:46:22Z,1,You are the best musistician in the world!,True
@elrishiilustrado9592,2021-04-09T10:24:01Z,0,"It's very clear, thank you ! so the number of degrees of freedom its equal to the number of Xi variables? in this case we have a y variable and only 1 x variable, so we have only 1degree of freedom, but if we have 3 xi variables the degrees of freedom would be 3? bonus question : how do you compare  logistic models ? how can i choose the best ? Thanks !",True
@thomasamet5853,2021-04-05T23:41:30Z,0,"Great explanations !!! At 11:06, is it the log( likelihood of the data given the line) or the log(likelihood having this squiggly line given the data)?",True
@construenist6966,2021-03-30T20:17:03Z,1,Very useful content üî•,True
@billzen6229,2021-03-28T05:18:53Z,0,why is it that the logistic regression residual are infinite? didn't quite get it,True
@miguelangelpastorvalverde9196,2021-02-15T21:22:25Z,0,"Thank you very much Josh for clarifying my doubts. I am doing a logistic regression, and I have 2 questions 1) Why do I get a significant p- Value and I get an r-square of 2 percent for a specific independent variable? If I get a r-square of 2 percent, I should  get a pvalue greater than 0.05 (not significant)?   2) How valid that probability equation will serve me? Look residual ?",True
@jodischmodi,2021-02-14T08:38:39Z,1,you're better than my prof,True
@jaegermeistersfriend,2020-12-27T01:15:01Z,2,you are single-handedly saving my bachelor's thesis! I could not make sense of anything about logreg in text books. Thank you!,True
@adenuristiqomah984,2020-12-18T12:38:08Z,2,"I am currently on your Machine Learning playlist, Josh. Keep up the good work",True
@murselmusabasic4260,2020-12-16T10:32:22Z,0,What does it mean to project data onto the fit line? Thanks for great lessons!,True
@idarudable,2020-12-01T11:19:04Z,1,I love you.,True
@marcobarreto5429,2020-11-23T15:22:49Z,0,In the case of comparing a Ridge vs a Logistic model would R^2 be a good approach?,True
@henri9289,2020-11-11T12:48:53Z,0,"Hi, do you have any instrutions of multinomial ordinal logistic regression  ?",True
@ehg02,2020-11-03T03:34:35Z,0,In what situation does one get an R^2 <0? Is that even possible?,True
@ruxiz2007,2020-10-15T02:51:40Z,1,"This is great great explanation, thanks!",True
@CheGourav,2020-10-12T08:51:08Z,1,Intro song was a bit like lose yourself by eminem!,True
@evan168gt6,2020-10-07T01:12:41Z,1,"Hello, Josh! Your content is so useful, it‚Äôs single handedly carried me through my paper! I thank you very much and hope you continue to post content. Also as a side note, is there no possible way of calculating the correlation of a logistic regression? Any insight is greatly appreciated!",True
@narendrasompalli5536,2020-10-04T08:26:46Z,0,Sir how do we calculate the intercept and slop for logistic regression ? Please tell me with example,True
@kevinshah8471,2020-09-11T11:38:42Z,0,"Hey Josh! Great videos. I have a doubt though. In the first video, you used the intercept and slope of the log-odds graph to show that the p-value is not less than 0.05 (using walds). Here, for the same model, you used maximum likelihood and got a p-value less than 0.05. I don't understand why the two differ.  Is it that using walds is one method and maximum likelihood is another and I'll accept one of the two values? Thanks.",True
@jesscharon9146,2020-09-10T21:45:40Z,14,"Thank you Josh, I‚Äôm a PhD student from China, and I‚Äôve never learnt logistic regression before. But this is sooooo good for beginners like us, clear examples, clear explanations, humorous way of talking. I really appreciate you for making these fantastic videos. This gonna help me finish the most difficult quant. data analysis chapter. Thank you so much.   Btw the singing at beginning is cute as always XDD",True
@shivanidhawal8261,2020-09-10T11:22:09Z,0,"Hey Josh ! Loved every video of yours question :i have read many books saying R^2 has a range of -infinity to 1, negative r in the case where regression completely fails to explain varitions among the data , it fails to map it. is this correct ? but you took the range from 0 to 1. which one is correct?",True
@carloscamargo566,2020-08-02T18:18:49Z,2,"I'm watching your videos from Colombia and it's amazing how trivial has become distance and money to get access to extremely good quality  knowledge , I really appreciate the work you put on your videos it have really helped me a lot on improving my Statistical analysis skills , thank you!",True
@xuemeiwang1881,2020-07-05T04:05:15Z,1,great man,True
@mriduls95,2020-06-14T04:37:21Z,1,but what are the 2 groups of values on which we perform the chi square in the end? As chi square is performed on groups,True
@michael052075,2020-06-14T01:16:23Z,1,Very clear explanation. Thank you!,True
@jiayoongchong2606,2020-05-28T11:13:54Z,0,13:56 out in the wild R squared value commonly written as,True
@ivanrecalde8543,2020-05-27T03:03:00Z,1,Increible! Saludos desde Argentina,True
@willychen6967,2020-05-12T19:25:12Z,0,"Hi Josh, I really enjoy these videos. Can you possibly do one that relates extreme value theory ( I'm thinking of T1EV) to the logit function?",True
@iraidaredondo5008,2020-04-20T16:26:54Z,0,"Hi, Josh   I would really appreciate if you could help me with some doubts I have dealing with my own data. I'm trying to figure out if some morphological features determine reproductive status (0 = not reproductive in a given season; 1 = reproductive in a given seaosn) in a wild passerine. Instead of analyzing each phenotypic trait  separately, we decided to do a logistic regression where status is the response variable and morphological features the explanatory one. In my case, the capture year is placed as a random factor in our model. My question is: is there a better way to get an R^2 for mixed generalized models? I've enjoyed these series a lot since they'd helped me build confidence and knowledge about what I was doing! Thank you so much!",True
@iraidaredondo5008,2020-04-20T16:26:54Z,0,"Hi, Josh   I would really appreciate if you could help me with some doubts I have dealing with my own data. I'm trying to figure out if some morphological features determine reproductive status (0 = not reproductive in a given season; 1 = reproductive in a given seaosn) in a wild passerine. Instead of analyzing each phenotypic trait  separately, we decided to do a logistic regression where status is the response variable and morphological features the explanatory one. In my case, the capture year is placed as a random factor in our model. My question is: is there a better way to get an R^2 for mixed generalized models? I've enjoyed these series a lot since they'd helped me build confidence and knowledge about what I was doing! Thank you so much!",True
@bhargavpotluri5147,2020-04-05T12:08:18Z,1,"I found out your channel 2 days back. Since then, my learning curve is going towards infinity (Original axis & not on the log odds axis :P). superb videos & content. Thanks a lot MAN !! Also one more suggestion, can you also include the cost function of the respective model so that it is 100% complete.",True
@karakter3,2020-03-29T07:00:22Z,17,"I've been having difficulty going through grad level stats after taking a loong break from academics and found your videos very useful and so much fun, thank you !",True
@annillonaa,2020-03-06T19:01:25Z,3,amazing!!! So helpful !! the song makes it ever greater!!! Thank u!!,True
@JamesSCavenaugh,2020-03-05T09:38:27Z,0,"Very nice, but it's a bit distracting when I read or hear ""this data"" rather than ""these data"".",True
@UncleLoren,2020-02-07T21:30:04Z,5,"So we took log(5/4) = .22, plugged it into the (e/1+e) equation and got .56, which we could have gotten from 5/9, proving there are two ways to come up with the same number, with one inducing a migraine. That's OK; I got it.   Then, for some reason you plugged .55 into an equation -- not .56 -- and later used a NEGATIVE .22 to arrive at something that resulted in .45, the complement of .55...which you adjust to .44. WHY the .01 adjustment?? THROW ME A BONE, BRO!!! PLEASE.      ****Update****: I just noticed in the ""proof"" portion of video that you changed the ratio of obesity from 5/4 to 4/5 which explains how #s got turned upside down. You just HAD to pick something strikingly similar to the previous example to confuse me, right? But why, Josh? If your videos make 99.999% of the people viewing them smarter and one person ends up smashing themselves in the head with a hammer, can you see how this might be a problem? It reminds me of the class imbalance problem. For a certain audience, your videos are excellent, you're a saint for creating them and it's unfortunate that I am an imbecile. Thank you for reading.   (Only joking. I am getting smarter, just gotta stick with it. Thanks a million.)",True
@janinajochim1843,2020-02-06T15:57:30Z,0,"Hi there!  Thank you for this fantastic video! I've been struggling to understand the outcome of the pseudo-R square in my model and what this means for me to proceed. For McFadden's R-square, I got 0.03 for my final model. Whilst the internet tells me to be 1. Careful with the interpretation 2. That a score of 0.2 - 0.4 is desirable and that 3. The interpretation is 'not the same as for OLS R-square' and 4. That pseudo R-squares are smaller in general than OLS R-squares, it doesn't really tell me where to go from here. How bad is 0.03? Can I still interprete my odds ratios or do I need to re-specify my model? There is no doubt that I am lacking relevant variables in my model, however, none of them were assessed in the study! Thank you so much in advance (PLEASE HELP ME!!!!).",True
@soya1226,2020-02-02T15:56:52Z,6,this is extremely well explained!!much appreciated!,True
@hayagreevansriram326,2020-01-06T01:31:49Z,153,"4 days on this channel, I've learnt more than 12 weeks' lectures at college. Thank you, Josh!!",True
@ml6352,2019-12-23T21:35:58Z,1,"Hi Josh, really good explanations :) I have seen already all the logistic regression series. Just one question: I would assume that the Part 1 [Coefficients] is basically the last part occurring when performing a logistic regression, right? I mean the algorithm will first optimize the squiggly line to the best fit(Part 2) , then evaluate for the significance (Part 3) . Finally the results can be seen by interpreting the coefficients (Part 1) which are given in terms of log(Odds).   I hope  you understand my question :) Thanks in advance and happy holidays. Marcelo",True
@magtazeum4071,2019-12-19T12:33:08Z,32,I'm addicted to  these intro songs..,True
@dainegai,2019-10-26T01:04:05Z,1,"Enjoying going through the logistic regression StatQuestline (i.e. playlist) :D   Small nitpick @3:09 -- the horizontal line corresponding to the mean of the data is *not* the ""worst"" fitting line in a sum-of-squared-residuals sense (you can make some pretty bad-fitting lines if you wanted to ;p ). It's actually ""the best-fitting line (in a sum-of-squared-residuals sense) when you're forced to have a slope of zero"". (It's the best-fitting model with 1 less **degree of freedom** than the model that includes a potentially non-zero slope.) This corresponds to a flat line ""y = (mean of the data)"".",True
@abiyosopurnomosakti1994,2019-09-10T09:38:58Z,5,What a prolific teaching Josh! Enjoy your song as well! :),True
@alex_zetsu,2019-09-09T17:38:27Z,0,"10 different ways to calculate R squared? I'm just curious what they are so I can look them up. I can only find 4. McFadden's is the only one that seems to make sense to me since it's close to the linear models (presumably why you chose it), but I am curious as to what are all the ways to do it.",True
@doubletoned5772,2019-08-16T16:50:32Z,0,Awesome work sir! Any idea how I can execute Probit regression in Python?,True
@alexandrezajic4426,2019-08-12T04:58:21Z,0,"Hi Josh - appreciate your videos! I'm curious why you say that R squared only goes between 0 and 1, when it can go between negative infinity and 1. Any model can have infinitely poor fit - leading to significantly worse residuals than the mean's residuals. While this indicates your model is terrible, in the off chance that it happens (which it has for me), it would clear up any ensuing confusion that something must be broken with your programs. Thanks!",True
@EmoFusionCentral,2019-07-09T18:52:55Z,0,"Hi Josh, could you also please explain the loss functions?",True
@edwardfanboy,2019-06-28T15:29:31Z,0,"The value 5.0 * 10^-17 is not exact, it's an artifact of rounding. All of the arithmetic in whatever software you are using is performed using double-precision floating-point numbers, which basically means that everything is internally rounded to about 16 significant figures. https://en.wikipedia.org/wiki/Double-precision_floating-point_format",True
@casperhansen3012,2019-04-14T13:10:03Z,2,"Hey Josh, I was wondering about the projecting of points at negative or positive infinity onto the candidate line, or just any line in general. You just say that we project the data onto the line at 5:57. But how does the math work?",True
@manikdhingra1606,2019-04-11T04:04:52Z,1,"Hello Josh, again much thanks for the video.  QQ- @13:27 how did you calculate the p-value using formula [ 2*(LL(fit) - LL(overall Probability))]?  I've already watched P-value video but unable to figure out. Don't know what I am missing. Thanks in advance!",True
@margotalalicenciatura1376,2019-03-14T11:56:36Z,3,"First of all a million thanks for your work man! It's really outstanding and almost infuriating to think how bad teachers are most of the people in stats by contrast. Got two questions: first, you say we can't use least squares since in the log odds scale the residuals are infinite, couldn't we just use them in the probability scale with the squiggly line? Second, are you planning in eventually doing a MCMC StatQuest? That'd be reaaaaally handy. Thankss",True
@chuangchen5547,2019-03-08T08:36:19Z,0,"In the last part of the lecture, why it follows chi-square distribution when we calculate the p-value?  Further, why the chi-square value is determined by 2*(LL(fit) - LL(overall))??  Thanks.",True
@TheRamnath007,2019-01-23T17:42:22Z,1,the squiggle line is the best fit line right? which is -3.77. but in the later part of the video you take -6.18 and say it a LL(FIt). But that is LL(overall prob). Why is that so?,True
@jessicatan278,2018-11-25T06:39:23Z,1,and why is it 0.44 and not 0.45 at min 8:37? :'(,True
@jessicatan278,2018-11-25T06:02:13Z,10,why is it 0.55 and not 0.56? at min 6:47,True
@Mona-so9ss,2018-10-15T01:32:24Z,1,what if we have a discrete variable instead of weight? how do we find the best fit then?  also would love to see a video on multiple logistic regression!!,True
@hajer3335,2018-07-23T19:22:28Z,1,"The  data  i'm work in it  makes nonlinear system Ax = y, then i used PSEUDO-INVERSES instead of maximum likelihood to find the parameters that give us a best fitting line. Thus, the pseudo-inverse provides the optimal solution to the least-squares problem. Mr. Josh, What is your opinin? if there is any wrong in my work tell me Please. Thanks in advance.",True
@utsavprabhakar5072,2018-06-29T18:17:54Z,1,Whats R-squared and p ? Do you have a stat quest where ther are explained or mentioned for the first time?,True
@Felicidade101,2018-06-20T21:10:44Z,2,Amazing Thank you Josh!,True
@sharonlee5219,2018-06-20T21:02:05Z,60,I've been binge-watching many of your videos recently to learn more about stats & RNA-Seq and I just wanted to say thank you for all the work you do! these videos are amazing and have been so incredibly helpful in explaining things :),True
@tallwaters9708,2018-06-19T06:26:26Z,7,"Nice stuff as always! If you're still taking video ideas I'd love to see some stuff on Bayesian models, monte carlo, markov chains :)",True
@juheesingh1157,2018-06-19T06:25:00Z,2,Statquestttttttt ü§πüéµüéµüé∂,True
@alvaroaguado3,2018-06-19T03:45:43Z,2,Awesome vids!! I don‚Äôt miss a statquest,True
@StephenRoseDuo,2018-06-19T02:55:25Z,2,Now I can't wait for the deviance videos!,True
@wolfisraging,2018-06-19T02:39:44Z,2,Kudos to power kudos to you,True
@yulinliu850,2018-06-19T02:13:51Z,3,Excellent! Much appreciated!,True
@rrrprogram8667,2018-06-19T02:06:31Z,1,Here it comess.... Great teaching josh... Thanks for all ur efforts...,True
