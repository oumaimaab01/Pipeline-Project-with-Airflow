author,updated_at,like_count,text,public
@statquest,2022-05-09T09:00:59Z,3,Support StatQuest by buying my book The StatQuest Illustrated Guide to Machine Learning or a Study Guide or Merch!!! https://statquest.org/statquest-store/,True
@gabrielcrone6753,2024-05-28T21:20:16Z,0,"Hi, Josh. Excellent video! So helpful and clear! 😄I am using a new version of randomForrest, and I cannot seem to locate within my model object the err.rate vector. When I write, ""model$err.rate"", it returns nothing. Do you know if there are equivalent objects now inside of the model to extract the error rate info? Thanks!",True
,2024-04-11T16:46:51Z,1,"Awesome statQuest, did not know you can also impute data using random forests :) How does the analysis of parameters (ntree, mtry) change if we are doing regression instead of classification? Would also love to see a regression example.",True
@Nishan-ob4xu,2024-04-10T04:30:51Z,0,python please 🥺🥺😌,True
@isobahall2800,2024-03-16T22:27:36Z,0,"Hi, during the data.impute, I get the following message. Can you help me out?  data.imputed <- rfImpute(hd~., data = data, iter=4) Error in rfImpute.default(m, y, ...) : No NAs found in m",True
@jitenjaipuria,2024-02-17T19:13:39Z,1,thank youuuuuuuuuuuu. i will acknowledge you in my scientific paper,True
@joshstat8114,2024-02-08T14:12:52Z,0,"Fellow ""Josh"". Thanks to this video. Can you have a part 2 about random forest in R that uses `ranger` package? It still kinda the same but faster",True
@kasuroperation6590,2023-11-18T22:10:06Z,0,"sir...i have a confusing problem. i tried with NBC and SVM, the prediction results pretty much bad. now i tried with RF, but its also bad. i started to think that the problem lies in the dataset itself. i tried without unbalance-handling, handled with SMOTE, handled with down sampling, but the best and ""make sense"" result was a quitebalanced 50-60% accuracy, specification, sensitivity. i already removed the outliers, but thats the imputation i did. how can i make the percentage high anough, like 80%+, especially for the accuracy and the speci  NB: changing the dataset used is NOT an option",True
@ImGeneralJAckson,2023-09-27T01:50:45Z,1,that's it. I'm buying a shirt!,True
@imanesninate1059,2023-09-25T00:14:20Z,0,Please Why do you use rfImpute for Handling missing data and not another technique,True
@shahrizalmuhammadabdillah3127,2023-09-06T08:08:46Z,1,"The tricks so fancy, and help me. I'm cheering to watch this...",True
@shahrizalmuhammadabdillah3127,2023-08-29T20:29:57Z,1,"i cant believe it, i just watch it this now, and i love this Statquest. thank josh.. you make me open minded again to another job",True
@unyimeuboho1232,2023-08-12T18:39:24Z,0,"Hi, unfortunately the 'rfimpute' function is returning error in my console despite having installed random forest",True
@user-bk3dr1xp1y,2023-07-25T01:23:29Z,0,Great vídeo! Do you have an example about Random Forest in Python?,True
@beautyisinmind2163,2023-07-19T17:01:55Z,0,"one question: during train test split choosing different random_state value give different accuracy on test set why is so? for example in random_state 0 the accuracy on test set is 82 when we change random state to 42 accuracy change into 78, so why such issue is arising and which is the correct model here?",True
@olivermcneice8440,2023-05-23T12:47:18Z,0,I had to add 'as.factor(myOutputVariable)' because it needs to be numeric.,True
@anushkabanerjee2510,2023-03-29T18:48:58Z,1,Fantastically explained  !!,True
@nurinurlailasetiawan2689,2023-01-19T06:37:19Z,1,"Josh your channel is super awesome! I've been struggling to understand ML because I need to work with RF for my hyperspectral data. I read a lot of papers and books, but so far, your videos are the one that helps me the most! Very effectively communicated!!! Big thanks!!!",True
@fishfeelpain7764,2023-01-09T21:28:54Z,0,"Isn't the confusion matrix built with the predicted class as rows, and observed class as columns?",True
@ademolaadelekan8400,2023-01-02T12:50:20Z,0,Thank. How do you use Random Forest for feature selection?,True
@trestietumadur3426,2022-12-15T08:50:20Z,0,"What if your response variable has continuous values instead of categories like ""yes"" or ""no""? Can you still use random forests?",True
@JoelAgarwal-yl2kw,2022-12-07T13:35:56Z,0,"Hi Josh! Amazing video - has been super helpful in my understanding. Quick question, how would I find the AUC and ROC curve for the random forest model based on the code that you made? I'm trying to compare different models to see which is best (as well as compare to logistic regression).",True
@AngelBautistaVII,2022-12-05T07:32:42Z,0,"Hello! May I ask what would be the codes if I had an unknown sample, and we want to use the model we built here to classify if it was ""healthy"" or ""unhealthy""? Also, what if my unknown sample had missing values in some of the parameters?",True
@Wissro,2022-11-22T16:18:03Z,1,"Thank you so much, could you perhaps make more R tutorials for machine learning techniques?",True
@justarandomchannel5246,2022-11-16T05:20:18Z,1,I was falling asleep reading my coursework's material the ukulele touch and some fun bits u put in makes this dreading boring subject a bit interesting. Thanks mate!,True
@yt-1161,2022-11-08T13:24:41Z,0,@3:30 why can’t you convert strings directly into factors ?,True
@melaniemax6437,2022-11-01T10:45:38Z,1,thank u so much! really helpful for me as a beginner in machine learning.,True
@serman5671,2022-09-19T08:59:16Z,1,so well explained,True
@iBenutzername,2022-08-24T13:35:58Z,1,Awesome as always! Can I ask you to make a video about feature importance in RF models?,True
@lauraeli2286,2022-08-20T15:43:25Z,1,You really are the best here on Youtube at explaining these 'complex' topics I think - I put inverted commas because actually they're not so complex anymore after watching your videos! :),True
@indeeed0,2022-07-19T20:04:34Z,0,"Hello! Thank you very much for your work. I don't understand something. Could you explain me how to use randomForest to impute missing data for the response variable? Knowing that there is also missing data in the predictor variables. rfImpute does not allow missing data in the response variable. ""Error in rfImpute.default(m, y, ...): Can't have NAs iny"" I do have the impression that this is the ""type 2"" missing data (Random Forests Part 2) but I don't know how to put it into practice. Thanks a lot",True
@jingli8830,2022-06-25T07:58:55Z,0,How can I show the new sample in the MDS plot ?  We assume a ne patient is here and we want to know which groups he or she is in.,True
@kaam975,2022-05-24T09:52:37Z,1,and for the video of course :),True
@kaam975,2022-05-24T09:52:25Z,1,Thanks for the code!,True
@bryanparis7779,2022-05-01T07:36:43Z,1,"hd variable when converted as a categorical should have 4 levels:""0"",""1"",""2"",""3"". Instead we used the if-else function in order to produce only 2 levels of ""0"" and ""1""...Why is that?",True
@annaveraverschuur9553,2022-04-08T15:27:12Z,0,"Hii This channel is great!! I am actually trying to to make a RF myself, but I got some errors when I wanted to check whether 500 trees was enough for optimal classification:  Error in data.frame(Trees = rep(1:nrow(model$err.rate), times = 3), Type = rep(c(""OOB"", :  arguments imply differing number of rows: 1500, 3000, 2500  I used your code, so I am sure there are no typo's. Can you help me out?",True
@waasdelcolenwtn,2022-03-27T17:07:04Z,1,goat,True
@tl2uz,2022-02-28T00:47:51Z,0,He is Jesus in statistics,True
@cookie6299,2022-02-18T16:57:39Z,0,220219. i need to learn how to interpret mds plot :) thanks a lot,True
@drtlfletcher,2022-01-20T12:10:23Z,0,Why do you make the mds plot? Is it to analyse which variables are having the most effect on the classification by looking at the weighting of contributing variables to MDS1 vs 2? Or for more generally exploring the data?,True
@moniquebrogan7206,2022-01-06T12:49:25Z,0,Thanks so much for your great videos. Do you cover Variable Importance in any of your videos?,True
@jacquelinmontoyahidalgo6714,2021-11-28T21:46:24Z,1,great video! do u have any tutorial with regression random forest?,True
@ioanastanescu6690,2021-11-12T12:38:33Z,0,"Hey everyone, quick question. When you start building the model you write set.seed(42). Where does that 42 come from? Thanks for the videos, they are really great! :)",True
@languagetalk8141,2021-10-11T08:13:40Z,0,"Hello, thanks for the video. "" Error in randomForest.default(m, y, ...) : Can't have empty classes in y"" I get this error could you please advice me how should I solve it?",True
@user-dn5hg8ch4m,2021-08-27T08:08:56Z,1,You are so cute! Love your lessons!,True
@katherinechau5594,2021-07-18T00:23:57Z,0,Wait how do you get the model to do a regression or will it just somehow know the variable is continuous?? Is there an example video of random forests for continuous variables?,True
@dr.sangramsinha2784,2021-07-12T11:50:42Z,5,"Recently I have been a regular follower of your channel. This is awesome. I learned a lot being neither from mathematics nor from computer science background. Even if being a experimental biologist, I understood most of your videos on regression analysis and now getting familiar with machine learning. I wonder if you could create some video on protein-protein or protein-ligand interaction using machine learning.  I pay my deep respect to the effort you made to teach us all of the complex stuffs in such a simple way. Furthermore, you have beautiful voice too. I love to hear statQuest tunes.  Lastly I pray for your good health and wealth.",True
@mitchellharding2423,2021-06-07T17:25:16Z,0,"Can someone explain why we impute before generating the model? Imputing predicts values. The model predicts values. It feels like we're doing the same thing twice? I'm probably just ignorant on this, but it's tripping me up.",True
@user-ey2np8ff8k,2021-05-27T06:29:34Z,0,"Using the str command i don't get the same results as you. The ""ca"" and ""thal"" columns don't show the ""?"" values. How do i find the columns that contain ""?"" as values?",True
@MahdiSafarpour,2021-05-24T12:35:44Z,0,"I have two questions about optimization of RF hyperparameters (mtry and ntree):  1) Should we first find the optimum number of trees and then optimum number of variables? or we must consider the effect of these two parameters simultaneously?  2) In this video, we examined the pattern of OOB when number of tree increases. Is this a good decision rule to choose the optimum number of trees just based on OOB? or it is better to use other methods such as cross-validation (I am looking for a way to find the best bias-variance tradeoff )?",True
@sudiptomitra,2021-05-12T07:46:05Z,3,"This demo is end to end & complete in RF with R !! This can easily be rewarded as the ""GOAT"" in this subject. Thanks & looking forward to view more great demos on ML topics.",True
@IamCaptainMan,2021-04-29T19:54:05Z,1,"Thanks man, you're awesome!",True
@yousfoss4367,2021-04-25T17:44:07Z,0,"Than you for the video sir. This is the message error i received while trying to import the data. May i ask what should be done please. thks  > url <- ""http://archive.ics.uci.edu/ml/machine-learning.databases/heart-disease/ + procecessed.cleverland.data"" >  > data<- read.csv(url, header= FALSE) Error in file(file, ""rt"") : cannot open the connection In addition: Warning message: In file(file, ""rt"") :   cannot open URL 'http://archive.ics.uci.edu/ml/machine-learning.databases/heart-disease/ procecessed.cleverland.data': HTTP status was '404 Not Found'",True
@yumikowiranto4330,2021-04-09T11:56:36Z,1,Thank you so much!!!!! This is really helpful for my assignment,True
@andreaballestero7780,2021-03-28T17:09:51Z,1,"This was very helpful, thank you!! :)",True
@BT-jh3dq,2021-03-23T19:31:45Z,4,"I've got so much more out of a couple of hours watching your videos than out of a couple of weeks trying to understand RFs through papers/books. Going back to the papers now, but with much more of a handle on what's going on. Thanks!",True
@Lucrezio81,2021-03-06T23:52:11Z,1,"It's rare to find a video like this. Libraries,  scripts, methodology, processes  are so well explained and coherently organized. Even the technical language was amazingly clear for a not native English user like me.  I wonder that 12 mentally poor people did not like it!",True
@j30ma,2021-03-02T19:23:51Z,0,"When I print the model outcome (like at 6:44) I don't get the OOB estimate and confusion matrix. I get ""Mean of squared residuals"" and ""% Var explained"". Is this because of an update to the package? where can I find the OOB estimate and confusion matrix again, or how should I interpretate these outputs? Thank you! EDIT: Its because I did a regression RF, could you explain how to further analyse these kinds of RF?",True
@datdao6982,2021-02-09T19:21:22Z,0,"Hi Josh, just a question. In the argument Trees=rep(1:nrow(model$err.rate), times=3), I was wondering was the times=3 mean? When I tried RF on my dataset, if I change the times=1 or 2 then it works but when times=3 it doesn't work. I was hoping you dwell a little bit more on that. Thank you",True
@justinzhoule,2021-02-06T09:01:09Z,0,"2:18, 1 represents male, 0 represents females, that’s figurative😏",True
@tizhang9635,2021-01-27T22:22:29Z,1,Thanks very much for your channel!!!! Way easier  to understand than reading paper.,True
@mateuszjaworski2974,2021-01-07T13:20:24Z,1,Hi Josh! It would be great if u could show us how after building random forest get some predictions on brand new data ;),True
@christiansetzkorn6241,2021-01-03T09:51:24Z,0,"Could I please ask, how one could create a proximity matrix for the unsupervised scenario? I posted a question here: https://stats.stackexchange.com/questions/503201/obtaining-proximity-matrix-from-random-forest-for-unsupervised-scenario-in-r",True
@christiansetzkorn6241,2021-01-02T13:05:20Z,1,Great stuff! Thanks!,True
@BayAreaLakers,2020-12-26T18:16:54Z,0,Any chance you can make an R tutorial for gradient boosting? Thanks!,True
@sanrajmitra9776,2020-12-26T15:57:33Z,0,"Can I check, how do we incorporate the test set using the random forest?",True
@BayAreaLakers,2020-12-25T17:33:47Z,10,Can't believe I went from not knowing anything about Machine Learning to learning so much after just a few days. Thanks Josh!,True
@francinagoh2541,2020-12-15T07:13:45Z,1,Thanks I learn alot from your video. Have a nice day!,True
@hello-pd7tc,2020-12-14T20:18:25Z,0,how to test if there is overfitting? thanks!,True
@4ZaKing,2020-12-14T14:19:28Z,0,"Thanks for a great video!   Would be happy to get some guidence as I am trying to apply this to a ""real world"" model. It puzzels me that I dont see the division between training and testing data in this example. Is that happening by default when running the gml/random forest model? Sorry if I missing something obvious =o",True
@meharunnisam9346,2020-12-08T11:24:00Z,0,Can a random forest work well for factor variables as input? It always give 100 percent accuracy.. what does it mean?,True
@j.jayelynnshin4289,2020-12-07T18:33:54Z,2,"I don't understand ppl who clicked on ""dislike"" at all. Thank you for doing this!!",True
@steliosgiannopoulos8297,2020-12-04T16:28:34Z,1,"Change the nick to Josh R-Charmer , excellent work thank you for all of your videos !!!",True
@AR_Wald,2020-11-05T12:19:50Z,1,Hooray!,True
@enriquep4857,2020-10-26T10:56:24Z,0,"Wow. Thank you very much for this video. I have a question about my data. Can I apply this Random Forest to two targets? I mean, for example in Cox regression I use the Event (Death) and OverallSurvival. Thank you in advance.",True
@teetanrobotics5363,2020-10-10T06:59:26Z,12,"I love your channel and have almost finished the entire ML playlist. You're explanation, animations and diagrams are just amazing🔥🔥 and far better than most university curriculum. I had a request. Just like the R tutorials, Could you please make the python version of the machine learning models ?",True
@chase2879,2020-09-16T14:42:27Z,0,on the impute step i get Error: cannot allocate vector of size 846.9 Gb,True
@charliepierce6218,2020-08-27T16:43:56Z,1,Amazing!,True
@felixbonneau1834,2020-08-16T23:33:26Z,0,"At the step to call the ggplot, I have a warning message: Removed 1500 row(s) containing missing value :(",True
@mehraadi09,2020-08-09T06:48:31Z,0,Can you explain the code at 9:12 please ? Anyone,True
@hindustanmerijaan9657,2020-07-28T23:29:54Z,0,"Sir I had all the values as continuous and discrete numerical variables so I did everything quite easily (thank you for that), I'm predicting snow cover (ndsi) whose values are continuous variables (don't pay much attention to that ndsi_mean9). and got following info after calling model:  Call:  randomForest(formula = ndsi_mean9 ~ ., data = data, proximity = TRUE)                 Type of random forest: regression                      Number of trees: 500 No. of variables tried at each split: 2            Mean of squared residuals: 0.006993821                     % Var explained: 80.34t  Now, what I seek to do is 'oob.error.rate' thing and plotting in ggplot. I am novice and therefore hell of confused right now. Can you help a bit?  Please share some codes on GitHub. I'll be grateful.",True
@veducatube5701,2020-07-28T23:03:04Z,6,Dear Sir!  You saved a lot of my time and a lot of my energy. Thank You... God Bless You with health and Wealth.   Please keep making videos and keep saving our lives...,True
@zainabkhan2475,2020-07-28T10:24:24Z,1,"Thanks for this video but I have a question,  can you ad codes or some example for the RF regression? Please...",True
@lucpr4501,2020-07-13T22:22:27Z,0,Good Morning. Thank you for your video and your time. May I ask you why do you use the Random Forest package for a binary response variable (Y variable is equal to 0 or 1). Should not we use a Bernoulli loss function instead of the quadratic loss function when splits are performed in the tree?,True
@user-bz8nm6eb6g,2020-06-30T16:32:57Z,1,Thanks!!,True
@monicasteffimatchado1780,2020-06-28T13:18:32Z,1,Thank you so much for the clear explanation. I have a microbiome datasets with 133 samples 431 features. I would like to try RF. How do I decide the range of  mtry value ?,True
@imanep4902,2020-06-07T20:59:05Z,2,BAM haha thank you!,True
@angelique3062,2020-06-01T14:30:43Z,3,Thank you Josh! :) You really have a gift for teaching! Could you please do a random forest regression in R?,True
@balaji.r2735,2020-05-22T13:52:47Z,1,Thank you very much,True
@sanjuvodwal6585,2020-05-22T12:31:00Z,0,Thank you sir for the wonderful vedios. Sir i want to apply the machine learning techniques to longitudinal or panel data and struggling a lot to find the start. kindly let me know how can i apply the machine learning programming for panel data ..pls reply,True
@rubenpinnata4626,2020-05-22T04:05:54Z,0,"hi Josh! Great videos as always a quick question: once you have declared a variable as factor, can you use MDS? you said it is very similar to PCA and from what I know, PCA needs scaling which I am not sure will work with categorical variables until you hot encode them, which I dont see any here.  Can you verify its okay to use MDS plot for data with both continuous and categorical? thanks and stay safe",True
@sonicking12,2020-05-21T15:19:10Z,0,"For binary numeric variable (like gender) being used as a predictor, does it make a different if you make it a factor or not?  Thanks.",True
@chrisvaccaro229,2020-05-03T04:32:22Z,44,"Jesus Christmas this is incredibly useful. I code in R and  A) it's almost impossible to find ML tutorials for R B) it's really hard to find straightforward ML tuts that are free of jargon ANYWAY C) it's hard to find tuts in plain english and without talking about ""y-hat"" and crap i don't even remember from calculus D) it's hard to find stat videos with such a good musical score ;) and E) these are just awesome.  I'd literally given up on finding decent ML tuts for R and just said ""screw it, I'll learn python"" but then I found these accidentally. These are freaking epic. I literally just went through like 25% of your videos hitting ""Shift + N"" then liking them (next video, like button, next video, like button, next video, like button, etc.)  These videos are the BEST. You should make a MOOC. Yours would be better and easier to follow than Andrew Ng or Jeremy Howard (who are the superstars of ML.)  Maybe even make a course on DataCamp. You can make interactive ones that way.  Either way, these videos are starting from AI heaven.",True
@AOLFlyersNewsletters,2020-04-28T16:12:30Z,1,Josh - you are like a god! Thanks man.,True
@MikhailGavryuchkov,2020-04-22T21:21:38Z,0,I've run the sample code 3 times and MDS1=19% and MDS2=6.6% (not 47% and 14.1% as in this video). Has the dataset changed or you do something else in the sample code?,True
@PeterKingnz,2020-04-17T00:27:43Z,0,"This is a great educational resource. But I can't help wondering why when i copy and run your code I get slightly different results. Call:  randomForest(formula = hd ~ ., data = data.imputed, proximity = TRUE)                 Type of random forest: classification                      Number of trees: 500 No. of variables tried at each split: 3          OOB estimate of  error rate: 16.83% (vs 16.5%) Confusion matrix:           Healthy Unhealthy class.error Healthy       142        22   0.1341463  (vs 141      23    0.14024..) Unhealthy      29       110   0.2086331(vs 27      112   0.1942446)",True
@rehab4e2,2020-04-15T02:54:55Z,1,"Thank you very much, it is clear and very detail. I also love your introduction!",True
@curtisee5963,2020-04-09T18:06:15Z,0,"After I run this  data.imputed<- rfImpute(MIS_Status~.,data=data,iter=6) with my own dataset and the error happened : Error: cannot allocate vector of size 1929.6 Gb. How can I solve it?",True
@reimiranda3213,2020-04-09T03:02:18Z,1,If you have any ecology examples for these stat quests that would be really useful!,True
@minhthinhnguyen2884,2020-04-08T14:11:43Z,0,"I got some problems when I run rfImpute() with my data set and the error is : Error in rfImpute.default(m, y, ...) : No NAs found in m. Should the predictor variables must contain missing value or NA value?",True
@abohisham3088,2020-04-04T15:31:06Z,1,"helpful and funny, continue",True
@keithypatootie,2020-03-20T14:55:24Z,0,"How come my healthy samples (red) are on the left of the MDS plot? :( Up until the oob.values i had almost the same outputs and values as in your video.   # we need to make sure we are considering the ## optimal number of variables at each internal node in the tree oob.values <- vector(length=10) for(i in 1:10){   temp.model <- randomForest(hd ~ ., data=data.imputed, mtry=i, ntree=1000)   oob.values[i] <- temp.model$err.rate[nrow(temp.model$err.rate),1] } oob.values  #-------------------------------------------------- # we want to use the random forest to draw an ## MDS plot with samples ### This will show us how they are related to each other distance.matrix <- as.dist(1-model$proximity) # run cmdscale on matrix mds.stuff <- cmdscale(distance.matrix, eig=TRUE, x.ret=TRUE) # calculate the percentage of variation in the ## distance matrix that the X and Y axes account for mds.var.per <- round(mds.stuff$eig/sum(mds.stuff$eig)*100, 1) # draw the graph with ggplot() mds.values <- mds.stuff$points mds.data <- data.frame(Sample=rownames(mds.values),   X=mds.values[,1],   Y=mds.values[,2],   Status=data.imputed$hd)  ggplot(data=mds.data, aes(x=X, y=Y, label=Sample)) +   geom_text(aes(color=Status)) +   theme_bw() +   xlab(paste(""MDS1 - "", mds.var.per[1], ""%"", sep="""")) +    ylab(paste(""MDS2 - "", mds.var.per[2], ""%"", sep="""")) +   ggtitle(""MDS plot using (1 - Random Forest Proximities)"")",True
@bernardromey4084,2020-03-17T01:02:22Z,0,How do you now use your trained RF model to make predictions for data with no response variable.  Easy with regression.,True
@revenez,2020-02-12T02:26:27Z,1,Brilliant and enjoyable! Thank you and please keep up the good work.,True
@hiteshpant,2020-02-11T10:15:19Z,1,"hi Josh, I really enjoy watching your videos and like the way you have made statistical topics so easy to interpret. Do you have a video for Feature Selection(varImp) using Random Forest?",True
@adityanjsg99,2020-01-23T09:41:51Z,1,You are such an awesome narrator! I depend more on your videos than my teacher.,True
@glauberbrito8685,2020-01-22T15:13:20Z,6,"You saved my day, Josh. You did a GREAT JOB !! Congrats.",True
@alecvan7143,2020-01-04T16:58:06Z,1,"Super helpful, thanks Josh",True
@souvikmanna4840,2019-12-19T14:40:14Z,0,Can you share the data set?,True
@sterlingwong9589,2019-12-10T17:08:11Z,0,"Great video! Thanks for the step by step guidance. I have a question is that would it be possible that we can program the results of the random forest into the Excel so that people can use it as a tool. For example, in the Excel sheet, as long as we input the values for independent variables included in the random forest model, we can get the predicted result (have heart disease or not) through an Excel sheet right away. I know it can be extremely time-consuming if you manually type into the Excel since you might have 500 trees. So I was wondering if there are any easier ways/packages that can do this. Any help is appreciated! Thanks!",True
@cajogos,2019-12-08T20:02:48Z,11,These videos using R are a lifesaver (quite literally!) Thanks a lot for these Josh!,True
@vivianhu3389,2019-12-06T19:38:11Z,1,Super Clear! THANK YOU!,True
@rubenpinnata4626,2019-11-13T17:23:19Z,0,"@statquest on 4:10, the thal values change from thal: 3 = normal; 6 = fixed defect; 7 = reversable defect to 2,3 and 4,   is this a problem? Thank you",True
@alyerart,2019-11-09T22:18:44Z,0,"Josh, I see that you've optimized the RF model's hyperparameters ntree and mtry using OOB error in fairly simple way. The package CRAN radomForest comes with tuneRF() and rfcv() to do the same thing (sort of) using (nested) cross-validation. Have you tried these yourself? I'm trying to understand the documentation (and use case examples) but still don't understand how to use them proper  ...",True
@SergeySkripko,2019-11-06T10:49:39Z,0,"Maybe a stupid question but I can't understand why do we use dist() function? In your video about imputing missing values, you told that ""1 - proximity"" means a distance between samples. I understand it. Why do we need to compute distance over distance? What's the point? As I see, every column, say column ""i"", in ""1 - proximity"" means distances between the ""i""th sample and all other samples. And then we calculate the distance(?) between these distances of ""i"" and another sample, ""j"". That's weird :) On the other side,  1. dim(1 - proximity) ==  n_samples * n_samples. 2. dim(dist(1 - proximity)) == n_samples * n_samples (as well). This blows my mind. I see redundancy as a recursive call: dist(dist(dist(...(1 - proximity)))",True
@PetalGamesStudios,2019-10-30T20:23:08Z,1,Awesome video! Thanks again!,True
@slirpslirp,2019-10-19T16:51:19Z,0,"hi Statquest, i'm having some troubles using randomForest algorithm in R, i've made some screenshot... how is it possible that in my case randomforest has a 98% of class 1 error in the confusion  matrix and the class error increase as the number of tree increase, please help me master ! ;) https://drive.google.com/open?id=1X3qUtwhw0Le2nRyqc0jP_KAauVri4K8M    https://drive.google.com/open?id=1iYrK54F4VhVGtd9GypC86DtcbBVxyuNR",True
@ulrikborgbjerg2482,2019-10-09T20:57:32Z,0,great video - is the code found somewhere. Or will I have to type if while looking at the screen?,True
@slirpslirp,2019-10-06T19:29:13Z,0,"awesome! in the example you have 303 OOB samples that gave 141 true positives, 27 false positives, 23 false negatives and 112 true negatives, but you started with a 303 samples dataset , for each bootstrapped dataset you have (1/3)*303=101 OOB samples  multiplied for all the trees (500)....you should have 50.500 OOB samples , after removing duplicates remain 303 samples ? Or it is because 303 OOB samples are the only one that didn’t compare in at least one training bootstrapped dataset ?",True
@tsarnature6587,2019-10-05T11:26:15Z,1,Bamm thank you very much,True
@hunadamfeher,2019-09-29T16:02:34Z,0,"Dear Josh! What should i do, when i get extremely high class.error value in the confusion matrix (around 79%)? (But total OOB error stays around the satisfactory level of 13%). Details: I used RF for  classification (categorical variable: 0/1) with many continous and categorical variables, and the proportion of ""0"" points were ""dominant"" (86%) over ""1"" points (14%) in my dataset. 1) Should i create a representative subset from ""0"" points? 2) Throw away this model and find some suitable with cross-validation?  3) Or conditional random forest can be useful for this (i fear that produces the same btw)?",True
@kkondur7619,2019-09-07T08:15:32Z,0,"Hi Josh! If I am not worng, rfImpute(..) cannot be used if the target variable had missing values, right? What would help me in a case where in my Training dataset has a large number of missing values in the Target variable?",True
@petemurphy7164,2019-09-05T09:25:51Z,1,"500 likes, Awesome",True
@mangomilkshakelol,2019-08-25T02:30:45Z,1,zot zot zot!,True
@BrianUrlacherPoliSci,2019-08-06T01:18:38Z,2,This was awesome.  I've been working for 2 days to wrap my head around the R implementation of this.  The code I was working with now makes perfect sense.,True
@alexandersierraa,2019-07-21T03:57:50Z,1,"Thanks a lot Josh,  your presentation is very clear and depth",True
@thuanpin,2019-07-15T10:19:43Z,0,"Hei, Thanks so much for your great lecture. May I ask you questions? 1) why did you label for sex and hd, not for the other categorical variables? the levels of ca and thal changes after converted, do they influence to model? 2) Do we need normalize continuous variables before conducting random forest? Many thanks!",True
@PaulO-mv6ku,2019-07-11T09:20:47Z,1,Brilliant - many thanks.,True
@himanshu8006,2019-07-06T06:31:06Z,1,"cant be explained easier then this ...... great job Josh, thanks a lot",True
@amitt9053,2019-06-21T14:55:40Z,0,How to fill in missing values if they are numeric? (For classification samples could be created using possible classes say Y or N),True
@SergeySkripko,2019-06-14T17:31:16Z,1,"Josh, you used cmdscale() on a default dist(method=""euclidian"") matrix. Does it mean that you did PCA, according to your MDS and PCoA video?",True
@nathaliatf,2019-06-02T20:20:27Z,1,Great Video! Efficient and not boring at all!!,True
@InfinitesimallyInfinite,2019-04-28T16:16:09Z,0,Booooooo.....,True
@luciapintoferro7747,2019-04-13T11:50:48Z,0,"First of all, thank you very much for your video! I really appreciate your teaching method.  I've got a problem since the variable I'm trying to predict has NA's in it and when using the function rfImput(name of the vble~., dataset, number of iterations) R returns the following error: ""Error in rfImpute.default(m, y, ...) : Can't have NAs in y""",True
@HarshKumar-zc4ox,2019-04-09T06:01:21Z,2,"Great job Starmer. You explained everything quite nicely.  However, while explaining the confusion matrix,  you went wrong as the vertical columns are for ground truth and horizontal rows are for predicted values. The explanation should have been 28 healthy patients were miss classified as  unhealthy patients but you explained opposite. Same case with false positive. I saw you confusion matrix lecture, there you have correctly explained the confusion matrix.",True
@amirgharavi4082,2019-04-05T10:42:49Z,0,Thanks so much for making these great videos. Really appreciate it,True
@mamahotel1308,2019-04-01T09:24:49Z,0,"Love this, thank you!",True
@peerzadimusavir9557,2019-03-26T11:19:28Z,0,Sir please  tell me how can i calculate f measure for this program.,True
@jasperobico1459,2019-03-20T07:04:59Z,1,Your tutorial video was really helpful! I am not sure if I would be able to do Random Forest without seeing this one! Great job on making a tutorial video that is easy to follow and to understand for non-R users like me. Kudos!,True
@user-uz1wz4gp9d,2019-03-07T14:12:02Z,0,"Fantastic vedic! Very clear! Just have one more question, does RandomForest work with multiple columns of missing?",True
@kinwong6383,2019-02-26T21:30:49Z,2,Love the way you show both ways of doing certain thing. It really helps R beginner like me a lot! Thank you very much! Wish I can go visit you at performance one day.,True
@DanTaninecz,2019-01-31T23:53:54Z,1,That mtry trick is pretty slick.,True
@ffloresalfaro,2019-01-29T17:36:56Z,2,Love your videos! Proximity matrix is excellent. Thanks so much for making these great videos!!,True
@random-ds,2019-01-22T15:29:52Z,1,"Hello, thank you again for you excellent video, however, I still have on question: what is the difference between what you did (RFimpute with 6 iterations) and the MissForest algorithm Thank you again!",True
@victormalmsjo5613,2019-01-12T12:03:01Z,1,Is there any good way to impute missing values in the test data ?,True
@taghoutighofrane9439,2018-12-25T20:01:59Z,1,thers is a video that explainclassification with logistic model ?,True
@srinivasv3268,2018-12-21T16:53:49Z,2,"Hi, Could you please upload some multi class prediction, example : we have one train and test data set  first we need predict train data than prediction on test data  Thanks",True
@TheEyeofJun,2018-12-20T22:04:01Z,1,Hooray!!!,True
@manaryounes2101,2018-12-10T12:04:29Z,1,"Thanks Josh for the useful video. However, how can I know if my model is over fitting my data ? the very low class error is intimidating.",True
@andy1992uk,2018-12-07T18:08:54Z,1,"Once these types of black box models are created in r. What's the purpose of them? Can we use them outside of r? Regression, I can easily produce the function and apply this to anything..",True
@fritz3555,2018-11-22T02:41:53Z,1,"Thanks for the great video series. What about randomForestSRC package? If we have data with missing values, is it better to use the randomForestSRC package? Or should we use the randomForest package?",True
@wsgsantos,2018-10-24T20:13:46Z,1,Very good explanation! Thanks from Brazil! :-),True
@ChunLin_UoE,2018-10-19T09:57:09Z,6,Thank you very much - very detailed explanation! It may be easier to convert the err.rate matrix to a data frame and use tidyr::gather() to transform it for ggplot2.,True
@charangrewal6113,2018-08-30T03:06:16Z,1,How do we know which variables the random forest chose to use in the final model?,True
@mihaipruteanu3502,2018-08-29T18:15:09Z,1,Thank you,True
@aop2182,2018-08-16T04:22:21Z,1,Can you make a video about dealing with extremely unbalanced data?,True
@RPDBY,2018-07-31T14:56:39Z,1,"Thank you for the great tutorial. I am confused though why do we need to impute our outcome variable, is it justified? Wouldn't it be more reasonable to treat the NAs in our outcome variable as unlabeled data and train the model on labeled data only? Imputing an outcome variable seems like a dubious practice, but maybe i am wrong.  Also, on a technical side, how can we access the actual predicted values per id (i.e. in this case per patient)? Thanks a lot for the video once again!",True
@andrezaluko,2018-07-28T15:29:04Z,2,"Josh Starmer, I am your fan! You are very funny =D",True
@fkhan4504,2018-07-01T06:14:06Z,1,So the next thing after Randon forest should be xgboosting .....  Please cover most important 30% concepts which will do 70% of ML jobs...,True
@afcc777f,2018-06-25T06:37:35Z,14,Can make a video about random forest for regressions in R ?  Thanks,True
@rrrprogram8667,2018-06-10T11:24:28Z,1,Back for revision/////,True
@Rpekeno,2018-05-10T21:11:59Z,0,"This video is SO good. I'm a newcomer at this, and your materials have helped me a lot! Thanks!",True
@rrrprogram8667,2018-05-10T16:46:29Z,0,Visiting again and again,True
@angeld5093,2018-05-08T23:48:28Z,0,"for some reasons, the link to the code can't be opened?",True
@rrrprogram8667,2018-05-01T01:45:25Z,0,Penta bammmm,True
@Pavijace,2018-04-16T13:23:39Z,0,ukelele...lol.....serious concept explained with fun...tq..keep goin...:-))am going home to you...nice song ...btw,True
@MrRoshanchoudhary,2018-03-04T09:57:32Z,0,"Hi Joshua, Your explanations are mindblowing. I'm loving it. The way you explain each and every notes are simply awesome. I'm grateful to you. Thank you so much. Keep making such videos. Waiting eagerly for Logistic Regression. Bammm!!!!! :)",True
@lifeboston853,2018-03-03T18:21:49Z,1,"Hello Joshua, I watched all your videos and they are so awesome! Will you be able to teach us Shrinkage Method (Ridge, Lasso and PCR), Neural Network, Deep leaning, Image analysis, and video analysis?",True
@sam_AI_Dr,2018-02-28T09:37:21Z,1,"Hello Joshua, at the point where you were determining the optimal number of variables at each internal node, is there a reason why you selected the empty vector length to be 10?",True
@benben0814,2018-02-26T18:19:19Z,0,Hey Josh this is very helpful and thanks for all the work! Does your code include cross validation for the random forest?,True
