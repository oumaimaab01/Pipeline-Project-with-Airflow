author,updated_at,like_count,text,public
@TimFromPerth,2024-05-26T02:41:18Z,1,Outstanding. Clear and simple. Thank you.,True
@ommprakashjena8366,2024-05-01T13:28:10Z,0,what do you mean by iframe sir,True
@kapibara2440,2024-02-26T17:52:44Z,0,Just another perfect video from Corey‚ù§‚ù§‚ù§ Thank you man!,True
@markkennedy9767,2024-01-27T03:36:08Z,0,"You da man, Corey! Great stuff.",True
@chandamark7301,2023-12-24T17:35:24Z,0,Nice video with clear explaination,True
@Vijay-cz7pe,2023-12-04T10:35:58Z,1,"ConnectionError: HTTPConnectionPool(host='coreyms.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029C009CBCD0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))  This is the error I see whenever I try to retrieve the source code from your website.",True
@nadeemghaffar8531,2023-12-02T05:01:14Z,0,"Great work ... covered a lot of knowledge in a very efficient and concise way... Thank you, Corey Schafer",True
@sonal008,2023-10-20T13:10:39Z,0,What in case of diff div?? I have 4 articles with different div tag,True
@DJ-ct6so,2023-10-03T00:51:53Z,0,"Excellent Corey. Very comprehensive, well explained, step by step, easy to follow. You're a very talented teacher imho.",True
@kelvinrubix4010,2023-09-05T17:39:59Z,0,"what if you split the url at the question mark .thats easier.......your vidoes are always on point,you never fail us",True
@suparnaprasad8187,2023-08-30T17:19:31Z,0,One word. Legend.,True
@marvinluyombya2659,2023-07-12T21:55:26Z,0,ü´Çü´Çü´Ç,True
@PankajKumar-tr7bg,2023-06-25T19:41:10Z,0,Thank You Sir for a nicely explained..,True
@ibrahimoladipupo5794,2023-06-15T07:03:53Z,0,"Thanks, Corey, for this awesome tutorial. It is definitely the best available.  I would really appreciate your tutorial on how to use Web  API for Web scraping. Once again, thanks.",True
@centralscrutinizer5116,2023-06-12T04:01:45Z,0,"You sir, by far, have the best structured videos for learning from.  Great job there young feller!",True
@omonjonyokubov6204,2023-06-02T20:36:53Z,0,how do you make money web scraping?,True
@faheemkhan9786,2023-06-02T10:35:21Z,0,How use selenium in web scraping,True
@rachrach9871,2023-05-14T07:22:41Z,0,You‚Äôre an amazing tutor. Thank you so much for sharing your knowledge üôèüèΩ I‚Äôve learned so much from your channel and I‚Äôm looking forward to more tutorials,True
@mangaart3366,2023-04-24T10:14:04Z,1,Love how you explain things so clearly. Corey you are the best!,True
@maxsalfer,2023-04-23T12:33:02Z,0,"Here your production thru the years...could not include the df.plot() but many thanks! headline	headline_cum date		 2013-12-31	3	3 2014-12-31	17	20 2015-12-31	45	65 2016-12-31	18	83 2017-12-31	34	117 2018-12-31	18	135 2019-12-31	27	162",True
@z.heisenberg,2023-04-22T11:22:17Z,0,"please help ...[<p>Welcome back. Just a moment while we sign you in to your.......its saying this when i say paragraph=soup.find_all('p') print(paragraph)  please help what to do..im stuck",True
@user-wn3eq6tq7o,2023-04-11T20:18:20Z,0,"As always, fantastic content!",True
@heartbreaker7021,2023-03-26T12:27:11Z,0,when i try to scrape websites like Glassdoor or indoor it says access denied by cloudflare what should i do ?,True
@angelicking2890,2023-03-11T20:07:08Z,0,17:00,True
@ImVedanshAgarwal,2023-03-08T07:19:48Z,0,Thanks,True
@gh-sb1dy,2023-02-19T13:39:37Z,0,is this being done in command prompt or python terminal plese clarify,True
@mansbjork5721,2023-02-18T15:29:19Z,0,"very understandable, thank you from a uni student making a project on web scraping",True
@noslackyak,2023-02-07T21:58:42Z,0,"Great video, better than the others I watched. Thanks.",True
@user-ln6hz2nb7o,2023-02-05T19:55:49Z,0,Great Explanation!!!!!!!!!!!!!!!!! Thank You Sooooooooooo much.,True
@proxyscrape,2023-01-18T15:04:00Z,5,"5 years ago, this video was already a great tutorial. Now, it's even more valuable. Thanks for the great content!",True
@prashlovessamosa,2023-01-15T08:17:46Z,0,Thank you,True
@TotallyNotAuroras2ndChannel,2023-01-02T19:24:54Z,0,Corey is very clear and concise.,True
@TotallyNotAuroras2ndChannel,2023-01-02T19:24:22Z,0,"Hi Corey.  You're the best.  Could you pls continue your python series into aws, cloud computing, lambda, serverless,  ...",True
@santosht5790,2022-12-31T13:23:57Z,0,How to extract the data if paragraph<p> is not there. Like - You are accessing the data from Google Patent website. There is no <p> as such in the HTML. Please reply,True
@aneeshkalita7452,2022-12-05T01:12:59Z,0,"Thank you so much, Corey... I have been following your tutorials. Really improved my concepts. In gratitude!",True
@user-qn5by5iv7u,2022-12-04T10:17:43Z,0,2022,True
@waseemmagray6209,2022-11-23T04:37:33Z,0,Mind blowing .. Keep it up,True
@eziola,2022-11-22T23:43:12Z,0,"Please come back, Corey!",True
@blessdog,2022-11-22T02:46:52Z,0,"Thank you, this is awesome",True
@ayoadeomoniyi1538,2022-11-21T23:12:13Z,0,i love this tutorial because i feel confident to write even write python with this tutorial .God bless you.,True
@kwameappiahkumi5833,2022-11-14T17:19:11Z,0,Great video however is it possible to scrap images from websites?,True
@Hassan-zd9it,2022-11-02T08:24:32Z,0,"thanks so much, I really enjoyed watching it and learned a lot. I also really like your fast American English accentüòäüòÖ",True
@dnyaneshwar53,2022-10-30T11:23:50Z,0,Corey you're a blessing for guys like myself who wish to learn Python.   üòÉüòÉüòÉ,True
@marcolearner,2022-10-24T16:48:26Z,0,10/25 9:31,True
@galnadjar,2022-10-24T12:02:49Z,0,great video as always,True
@illegalsmirf,2022-10-24T01:49:24Z,0,You might be a southern rogue and a chancer but you're amazing nonetheless!,True
@mohammedsalih5865,2022-10-19T16:17:33Z,0,One thing that I notice is missing in alot of videos is how to traverse through a website for example login in -> then type something in a search bar-> click on one of the links,True
@rishu4225,2022-10-06T10:52:54Z,0,"upgrad(an online learning platform) recommended one of your videos, and damn they are so fine thanks for your hard work",True
@mauarou4172,2022-10-04T21:28:27Z,0,WOW NICE thankYou([{ YOUR_NAME}]),True
@yaroslav1892,2022-09-17T08:58:42Z,0,"Best video for beginners, thank you!",True
@briananderson2283,2022-09-13T23:36:01Z,0,I can't find the file. Where is the html file? I can't find the website you are scrapping. Was it taken down? Some help will be appreciate!,True
@leslievanelsie7545,2022-09-08T06:43:53Z,1,"I'm not really a video type of person, I learn faster with books but I always find myself coming to your channel to clarify things. You are the best Corey",True
@anishchhabra5313,2022-09-01T13:18:48Z,0,Amazing Video! Thank you,True
@yu-chengchang6011,2022-08-22T03:55:13Z,0,This video is sooooooooooooo great!!!,True
@ontheskyblue,2022-07-14T20:09:19Z,0,Great Video,True
@daksheshgusain6683,2022-06-22T07:33:52Z,0,How do we deal with dynamic data generated by javascript using Beautiful Soup and Requests?,True
@oluwadamilaretijani1777,2022-06-21T08:36:01Z,0,"Mr Corey, please wherever you are, keep safe. I really miss your content on YouTube. You're a legend when it comes to teaching.",True
@veiisk,2022-06-14T01:29:56Z,0,"i got this error =    Input In [2]          ^ IndentationError: expected an indented block  at the very end.",True
@Mike-vj8do,2022-06-11T20:30:07Z,0,"Very informative video, thank you!",True
@cykachu9720,2022-06-04T14:32:49Z,0,Great Video,True
@edwin6294,2022-05-29T14:19:55Z,0,Web scrapping using software tools vs python programming say me diff bro,True
@sanjaisrao484,2022-05-28T03:35:56Z,1,Thank you very much it was very useful,True
@dhssb999,2022-05-25T15:22:42Z,0,This is definitely the best web scraping tutorial I've ever seen!,True
@lefebvre4852,2022-05-21T11:16:25Z,0,Thank you very much! It's well understandable for a beginner like me (also non-native english speaker) and 45 minutes have flown by quickly.,True
@richardsreviews8820,2022-05-17T01:56:41Z,0,Can we scrape your website? I was copying your code as shown in the video.,True
@saisrikanthdvn6901,2022-04-29T03:52:04Z,0,"Excellent video on web scraping. I watched few videos in my National Language and local language. But didn't understand what they are doing. Might, the way you explain the things and use case of particular points in the right place in your video makes all understand better.Thank you so much.",True
@faroukyusuf4066,2022-04-26T13:44:36Z,0,One of my best for learning...much respect,True
@EStudios009,2022-04-26T07:34:16Z,0,i really wish i was here when your videos were being published regularly its seriously amazing content very easy to understand. Thank you so much,True
@andres777video,2022-04-21T14:42:15Z,0,"Great video, learned a lot...  best voice, best speed and coverage... (I will be watching more of your videos!) The only thing that I encountered that didn't work for me, is handling special characters and symbols in the posts, I get errors like this... return codecs.charmap_encode(input,self.errors,encoding_table)[0] UnicodeEncodeError: 'charmap' codec can't encode character '\U0001f525' in position 53: character maps to <undefin 53: character maps to <undefined> Anybody knows how to handle those ?  Thanks!",True
@aiimagined,2022-04-20T11:43:20Z,0,20-4-22,True
@samuelkuhn1338,2022-04-15T08:12:39Z,0,love you so much,True
@kobile790,2022-04-09T10:24:51Z,0,"13:58 - I get ""None"" instead of the footer  Any suggestion? Thanks",True
@fitzgeraldchambwa3050,2022-04-05T17:10:44Z,0,"Easy to follow and helped me understand web scrapping in a few minutes, worth the sub 4 times over. You have gained a new follower :)",True
@tigrastijaodtigra,2022-04-05T14:10:47Z,0,This is a beautiful tutorial! Made me super excited about web scraping. Thanks Corey!,True
@mohitupadhayay1439,2022-03-17T16:58:58Z,1,This guy is a pure Genius!,True
@FireFly969,2022-02-25T23:40:33Z,0,"thank you, one of my best channels",True
@abdallahalaa492,2022-02-23T03:23:03Z,0,"What a great teacher, I never wanted to watch any tutorials about scraping as it was explained in then most boring way by others, but when it comes to you , you did a great job (y)",True
@arthur_p_dent4282,2022-02-09T17:33:32Z,0,This was super duper helpful.  Thanks much.,True
@mohammadkhalili1289,2022-02-08T18:58:26Z,0,Best youtuber ever,True
@relaxtoday7752,2022-01-31T18:50:47Z,0,"i keep getting this error ""AttributeError: 'NoneType' object has no attribute 'find'"" how can I fix this, apparently the problem is in ""summary = article.find('div', class_='playerpage').text""",True
@ayanghosh8226,2022-01-31T01:30:52Z,0,Excellent guide to web scraping!,True
@drewfrench8784,2022-01-28T02:10:18Z,0,This is one of the most impressive tutorials I have followed. Fantastic info!,True
@pan3x,2022-01-27T15:47:41Z,0,"nice vid pal, I tried to run your code but get the error in sublime text when run it: ModuleNotFoundError: No module named 'bs4'. Have installed everythin an my mac. Any idea why?",True
@archytekt,2022-01-27T04:47:26Z,0,How can avoid cloudfare security on a webscraping?,True
@timfulton6920,2022-01-25T21:22:53Z,0,I love this training. I am going to subscribe for sure. I pasted with a questions about an error I was getting. Then I clicked play to continue and realized you answered that question next. Great video. Thanks for the help this is my first endeavor into Python. Thanks,True
@vrajeshsomani8205,2022-01-23T11:05:08Z,0,"Hello your video is awesome, but there is one doubt I did everything myself whatever you taught but the information we are getting is of the first page of website only, what if we need the information of all the pages at same time.",True
@eliottsmallwood2140,2022-01-20T19:17:53Z,0,is there a tutorial in windows??,True
@fayzafahmy9585,2022-01-10T11:12:46Z,0,Thank you sir.,True
@mak3214,2022-01-08T11:07:43Z,0,Excellent video this clears my concept clearly Thanks ‚ù§Ô∏è,True
@davideschreiber2821,2022-01-06T13:51:07Z,0,"Well done! I've duplicated on my computer what you're showing in your video, writing comments at every step. It will be my guide for any web scraping I do in the future. Thank you!",True
@sidharthanand9946,2021-12-25T11:06:32Z,1,Just learnt something cool that can be easily done with python.  But I do want to apologise because I've already scraped your website by the time you shared the advisory.,True
@SableWinters,2021-12-17T23:09:24Z,1,"The best and quickest tutorial for small to medium sized website data scraping I‚Äôve encountered. You are clear,  concise, and you voice is easy to listen to and follow void of irritation. I actually have confidence now to achieve my tasks after years of placing them on the back burner.üëçüèºü§ó",True
@asapusrinivas,2021-11-28T02:53:35Z,0,Thank you for easy and fast video,True
@anatolysavin3175,2021-11-27T01:07:44Z,0,Does anyone know how to display extracted data on my own website ?,True
@boomboom-pro,2021-11-25T10:41:18Z,0,"I am a complete beginner, yet I understood everything! That‚Äôs fantastic. Thanks very much.",True
@lastdance903,2021-11-22T12:36:02Z,0,"When I try to scrape the first article from Corey's website, the hyphen ' - ' in the headline returns 'ÔøΩC' in the output. Any idea why?",True
@TheSibyjohn,2021-11-12T18:46:30Z,0,very bad ... I could not follow at all... pip install not working... please guys while making videos make it simple to understand.... short and clear and precise,True
@emimartin7044,2021-11-11T22:01:34Z,0,"wow, super well explained, thank you very much :D",True
@thebuggser2752,2021-11-06T01:14:22Z,0,Another great video.  Very well organized and focused.,True
@funwithariyan7347,2021-11-01T12:45:56Z,0,okay so i have a 2 spans with the same id but i want to get the second one how do i do that?,True
@Edwin-ri8xu,2021-10-27T18:15:39Z,0,"Wow....didn't even notice that the video was 45 minutes long. Thanks, Corey for the wonderful explanation!",True
@shivanipatel4063,2021-10-21T17:45:06Z,0,What if I want to run this code on entire category of products on a website? Is that possible?,True
@christophechouinard7619,2021-10-20T16:03:30Z,0,"Amazing, as usual...  simple question: am i the only one that has a problem at 27:00 ? I dont get the article summary, i get an error ""    summary = article.find(""div"", class_=""entry_content"").p.text AttributeError: 'NoneType' object has no attribute 'p' """,True
@dastanmirzayev7135,2021-10-20T00:44:20Z,0,Awesome step by step explanation,True
@akhilvabbilisetty4026,2021-10-19T06:34:48Z,0,"I really loved your video, quite clear and concise, no non-sense stuff!! Thanks Corey!",True
@MC-hm1dk,2021-10-15T20:05:01Z,0,Soooooo good... Thank you!,True
@marijka_romaniuk,2021-09-30T15:18:54Z,0,"Thank you for this video, everything is understandable and you explain easy!",True
@RUTM2,2021-09-21T05:14:59Z,0,Thank you for all u do,True
@anurodhchoudhary1689,2021-09-15T11:17:31Z,0,"This man is a legend, all your explanation is easy to understand",True
@serhiyranush4420,2021-09-11T21:34:50Z,0,I think that a person that has no idea about HTML has no business starting web scraping.,True
@aliimrancheema8166,2021-09-08T19:36:54Z,0,Superb Bro,True
@christinahachem7532,2021-08-29T12:57:27Z,0,"hello, great video! can you pls tell us how to scrape elements that aren't shown on page source??",True
@fawadkhan8905,2021-08-28T05:55:22Z,0,"The least I can do to liked,  very step by step worked out, Appreciated",True
@peace-ye2lm,2021-08-27T17:20:09Z,0,Awesome video,True
@hamidrezaghafori4200,2021-08-26T16:57:46Z,0,"first of all thank you for your wonderful videos,  I exactly follow the steps but in the excel file the rows printed in a way that an empty line is inserted between each line can you help me to fix this?",True
@quenyanwarrior8741,2021-08-26T04:40:50Z,0,"I see that ""indent"" is very important, without a proper indent, the code wont execute correctly. perhaps this is exclusively on python, never been so important on bash or java language since they got the closing tag, just like html. but, I think simpler is better, i like python more, and I'm trying to learn to be more tidier in writing code.",True
@quenyanwarrior8741,2021-08-25T07:10:16Z,0,"i got this, ModuleNotFoundError: No module named 'bs4'",True
@piyushchaudhary5283,2021-08-18T17:00:06Z,1,Corey - You're a god among Programmers! Keep up the good work,True
@HarmonicHub7,2021-08-09T03:45:27Z,0,"Please help, I tried following the process but getting this name error at  print(soup)  NameError: name 'soup' is not defined >>> print(soup)   File ""<stdin>"", line 1, in <module>",True
@mathewrtaylor,2021-07-31T21:33:54Z,0,"Great method!  I made a slight tweak to add to a dataframe and pump out an excel file, but very comprehensive tutorial, thanks!",True
@derekwest8636,2021-07-30T15:21:43Z,0,"Well done, excellent teacher",True
@shaileshdas7274,2021-07-30T13:35:57Z,0,"what is the python code to get text which is not in any div, id or class?",True
@r7918,2021-07-25T22:02:36Z,0,"Hi Corey,  Thanks for posting such an amazing video tutorial. As I am new to python programming, I want parse multiple pages on the website. How can I modify this code to do that?  I am stuck on it.  Could someone help me out?  Thanks, Pratt",True
@tochukwujoshua9774,2021-07-25T20:03:40Z,0,Awesome video. Thank you sir!,True
@LopezZ_Z,2021-07-25T11:20:03Z,0,thank you im finally gonna make google search in python!!,True
@ani68,2021-07-24T18:11:41Z,1,This has definitely made my concepts crystal clear.....üòÉü§©,True
@worldwideweblearning,2021-07-24T03:02:41Z,0,"Hi Corey, how to extract only the <div class=""name""...> and its match closing tag </div> with inner html stuffs. Firefox has a functionality to allow us to copy in the element inspection option.  But I don't know how to do this automatically. Thanks",True
@lastravaganza2385,2021-07-13T22:34:19Z,0,"Excellent video, not difficult understanding at all.",True
@2006renec,2021-07-09T23:04:03Z,0,"I tried this and ('dive', class = 'article') didn't work. Use attrs = 'article'). And when using the For loop, add the "":"" at the end.",True
@mahmoodhonarvar3520,2021-07-02T04:07:51Z,0,perfecto!,True
@painpills66,2021-06-21T05:53:10Z,0,"Dude, i'm from colombia and i'm tryng to lear how to do web scraping. The point is that I don't know much English but it seemed to me just by listening to you a little that you were giving important information, so I saw the entire video translating every word that I didn't know, and I learned much more than with the information I find in Spanish, huge thanks and new sub. <3",True
@discovertop10any,2021-06-17T09:40:55Z,0,It would be great if you made the video of complete playlist of Scrapy,True
@LAChinthaka,2021-06-15T07:53:59Z,0,Thanks a lot. Highly recommended!,True
@anjaliunnikrishnan5814,2021-06-12T15:45:30Z,0,I enjoyed learning. Thank You,True
@poorvikjain5323,2021-06-04T17:30:55Z,0,why i didn't find you before sir  i just wasted my time by seeing unhelpful tutorial of others   you are one of the beat teacher of my journey in python üíìüíìüíìüíìüíìüíì,True
@ZakhariDarksorrow,2021-06-01T16:29:31Z,0,"Oh wow, I'm the 1000th comment! I'm looking for scraping prices of products across a website giving me the item category, the item name, item price and per quantity. I'm sure this is possible through scraping but it's definitely something that's going to take some time.",True
@lakshyachopra_,2021-05-28T17:19:27Z,0,Thankyou very much !,True
@serazummunir790,2021-05-27T04:24:38Z,0,It's just a mind blowing tutorial man! Really appreciated!,True
@hamzakhalid8668,2021-05-23T02:24:58Z,0,This video helped me so much I gotta comment a second time,True
@hamzakhalid8668,2021-05-23T01:47:56Z,0,This guy is the best. Hands down. For python tutorials. My man slayin',True
@Male_Parent,2021-05-22T21:45:57Z,0,Thanks for the tutorial. Very useful to know :) Now I just need to figure out how to do this without requesting the same page every run. Like caching. And also how to add a timeout thingy to wait a second before requesting the next page.,True
@divinekingsman,2021-05-22T09:23:44Z,0,"What if i want to create a search engine, that when a user search on the search box, it will bring out the results of what they search. What do i need to do and learn. Cant seem to understand. I need your help.",True
@steveboel12,2021-05-20T21:53:11Z,0,How to scrape multiple pages?,True
@jackbird5839,2021-05-19T08:55:10Z,4,"great solution and tips bro!! thank you for your video., I will definitely try to improve my scraping skills with your tutor. but as non-tech user  Also I have found good alternative to scrape amazon reviews e-scraper maybe it helps to somebody too.",True
@sukhammittal7630,2021-05-18T23:00:43Z,0,"Hi there! Thanks for creating this video, it's great! This video is aiding me to learn extracting data from websites. Though I have a question that how to extract data from a website where our interested information is present in the middle of the page let's say and all sections use the same kind a tag (say 'div') and these tags have same values for 'id' and 'class' variable. Also, how to only extract that interested data and not the whole page with these following conditions and append it to a csv file. I am working on a project where we require to extract data from journal websites for their manuscript requirements. Your comment on this would be great!",True
@karenmelikyan377,2021-05-16T11:59:02Z,0,"Oh my got... how you bored me... 45 minutes of monotonous  speech. Please, create your videos shorter",True
@joelwembo,2021-05-12T12:53:12Z,0,You such a great tutor!,True
@surabhidevgun6954,2021-05-12T02:09:16Z,0,I am a big Fan...Thanks a ton for doing this...Regards from India,True
@Utkarshkharb,2021-05-10T17:16:00Z,0,Very helpful. Thanks a lot!,True
@gamebreakers6437,2021-05-10T14:45:34Z,1,just Amazing video....Thank You for sharing with us.,True
@krit.k8318,2021-05-08T20:38:15Z,0,"Hello, I have a question and I cannot find any solution on this. Is it possible to check using beautiful soup if the next line is tag <a> or <p> or just text? Example <td class=""id""><p><a href="""">test</a></p></td> <td class=""id""><a href="""">test</a></td> <td class=""id""><p>test</p></td> <td class=""id"">test</td>  The class on td has the same value.",True
@bodwiser100,2021-05-08T15:36:19Z,0,"Great work. Thanks, Corey!",True
@antoniosalto4333,2021-05-08T08:54:18Z,0,"Hi, thanks for the tutorial. Could you explain in a video how do you webscrape a sportsbeting website please? i have already scraped yahoo finance but when i try to requests.get in a sportsbetting website my program only gets part of the website. Thanks a lot!",True
@sufyankhanbest,2021-05-07T19:43:30Z,0,"how can I scrape data from em tag and b tag,  <li><span><em>April</em><i> &nbsp;</i></span><b>2021</b></li>",True
@sufyankhanbest,2021-05-07T04:57:16Z,0,how do I scrap from nested tags like: span > div > li > span > em > b. Information which I need is stored in em and b tag. PLEASE HELP,True
@gopinathchandrasekaran3351,2021-05-04T13:54:20Z,1,Wow!!  COREY SCHAFER you are a legendüëè,True
@cynaranyahoda9206,2021-05-03T12:43:42Z,0,"Hi Corey, I just found your videos and they are incredibly helpful. Quick question though, are you using Pycharm or sublime text or Visual studio code for your coding in this video?",True
@Ihsan_almohsin,2021-04-28T22:30:51Z,0,"great reference for bs4, thank you man",True
@mandarraut122,2021-04-23T19:04:37Z,0,"Thank you ,If you would have added page navigation on how to navigate to next page and scrape the data till the page ends would have been perfect üî•",True
@devenjain7079,2021-04-22T04:00:14Z,0,"16:54 This is not working for me, giving me an erroe that It is None-Type and it cant access the embedded tags inside that particular div class. Please help me!",True
@ktay895,2021-04-21T08:11:06Z,0,Made a convoluted topic crystal clear. Such a master teacher -- you're my go-to resource for coding!,True
@ronenoren8267,2021-04-19T08:54:10Z,0,Great tutorial. Thank you!,True
@ikki411,2021-04-12T16:23:51Z,0,"This tutorial was incredible. I've done 2 Python courses that touched the 'Web Scraping' subject, but I wasn't able to fully understand it. This video was one of the two videos that made me fully understand it, and I couldn't be more happy about it.",True
@free_coursesforyou6861,2021-04-10T10:51:05Z,0,"FUCK YOU i tried parsing facebook with this but nothing only hours of struggle I tried everything but nothing ,just fucking errors i vene changed pcs nothing ,i even got help,nothing again",True
@muratsokucu5891,2021-04-09T17:10:06Z,0,Again... Learned much more than a semester. Thanks a lot Corey!,True
@f.2funky,2021-04-07T16:32:31Z,3,"Hi Corey I'm a new python learner from China.  Listen a class in English is still a little hard for me, not to say with the things I am completely unfamiliar with, like Python. But your English speaking and tutorial are very clear for me to follow! I can't believe that I have just finished this 45-minute-long video with Python in English.   I have never thought the I could did this before. You videos helped me a lot in my Python learning. You are amazing. Your tutorials are amazing. Without them I probably have already gave up. You are the best Python teacher. Thank you so much! ^^",True
@sylverecauzard,2021-04-05T16:34:21Z,0,Hi dude your video's are juste perfect. I'm French and i have to say that i find your video more clear that some of the french one! So thx a lot and continu like that!!,True
@DifficultWorld7,2021-04-03T18:13:18Z,0,"Thanks, man! for explaining specifically each and everything  I even bought an Udemy course but I didn't understand a thing and you explain python so good for free Thanks.",True
@kaustavdutta8484,2021-04-03T13:06:28Z,0,"I was wondering if someone could shed some light on navigating from one page to the other? In the present video, it scraps the content only from page 1. I would like to continue to the subsequent pages. Much thanks in advance!",True
@michaelhiggins315,2021-04-02T05:10:22Z,1,Starts at 20:00,True
@lutfugurluk,2021-03-31T10:57:20Z,0,I can easily say that the best to understand in youtube. thanks.,True
@Captinofthemudslayer,2021-03-25T23:28:08Z,0,bs4 content returned different than page im viewing for example target.com. any ideas,True
@jobbot8435,2021-03-23T09:23:19Z,0,you are a genius! thanks !,True
@thewhiterabbit661,2021-03-21T23:58:07Z,0,But this isnt webscrapping you are parsing from a filet a url,True
@techknowbabble,2021-03-21T14:30:28Z,0,"Thanks for the video, using actual HTML language to explain helped immensely. Most tutorials just seem to be reading from a manual",True
@darkhacks5743,2021-03-19T11:22:23Z,0,"wow thanks u, after waching this video I have been able to make a discord bot that searches for the definition of a word in a website using web scrapping",True
@thewhiterabbit661,2021-03-18T08:55:23Z,0,Love how i am learning some html at the same time,True
@christopherburke323,2021-03-18T05:55:10Z,0,"By all accounts, phenomenal! Gracias!",True
@BoxingPills,2021-03-13T19:06:59Z,2,Im doing IBM data science certification. Understood nothing. After 2 minutes of this video I m already hooked! you re phenomenal!,True
@branderbuilt8908,2021-03-11T17:08:45Z,0,"I was watching another video on web scraping, and then I read the comments, and someone told me to come here and watch your video first because you explained things more coherently.  Keep producing great content. You've got a lot of YouTube guardian angels redirecting traffic to you, Corey.",True
@amanroy1049,2021-03-04T19:05:46Z,0,I really enjoyed watching this tutorial. Thanks a lot.,True
@oracle11iappsdba,2021-03-03T23:43:46Z,0,I watched this video just once but moved back the time line several times. Result I learned more than what I got in a stupid 1 day paid workshop. Thanks man.,True
@anuragsingh4766,2021-02-24T19:10:09Z,1,Thanks bro for the try block,True
@dlsehapdlf1835,2021-02-21T04:04:59Z,0,ÏÑ†ÏÉùÎãò ÏÑ§Î™ÖÏù¥ ÎÑàÎ¨¥ ÏôÑÎ≤ΩÌïòÏã≠ÎãàÎã§...,True
@mahbuburrahman3777,2021-02-19T02:59:47Z,0,"Hey, Corey thanks a lot for this beautiful video. Let's say I want an  e-mail notification each time you upload a video on your website. How can I do that ??",True
@corneillembiya9248,2021-02-18T08:50:46Z,0,You're the best,True
@mikshubhatt1175,2021-02-17T14:54:57Z,0,just perfect.,True
@hanngoc4970,2021-02-17T09:29:13Z,0,"Hey guys I'm new to Python so please could anyone suggest to me some prerequisites videos, concepts that needed to be learned before this tutorial for a better understanding? Thank you in advance.",True
@jeff5858,2021-02-16T03:35:36Z,0,"How does one go about inputting text to the website, ""submit"", and then parse the response?",True
@gmartirosyan,2021-02-14T17:26:57Z,0,"First of all, the tutorial is great!!! Thank you so very much for making scraping clear and doable! My question is how exactly do you make your code not to overload websites with too many requests?",True
@iftikhar3609,2021-02-14T14:42:07Z,0,Amazing Sir!! But I have one question from the entire video. What we do if we have a different structure for every post. obviously we will not use the loop then we do the hard code for every post??,True
@brucemurdock5358,2021-02-10T05:10:58Z,29,00:00 What is webscraping 00:30 Our end-goal 02:23 Installation of modules/libraries/packages 05:05 Primer on HTML and CSS 08:32 Example 19:27 Scraping the webpage,True
@koteswararaorao1692,2021-02-07T07:35:25Z,0,"File ""f:\phython\beauty.py"", line 1, in <module>     from bs4 import beautifulsoup ModuleNotFoundError: No module named 'bs4'       error is coming please tell me solution",True
@dhy9361,2021-02-03T16:19:05Z,1,"Thank you so much for sharing this video, so helpful! Ë∞¢Ë∞¢",True
@databen7194,2021-02-03T08:55:03Z,0,"Brilliant! A really good tutorial, including fixing what happens when an attribute doesn't exist which is super useful.",True
@sn4k321,2021-02-02T17:53:12Z,0,"Amazing video! I was looking on how to apply the few python knowledge I gathered, thanks for showing this, makes me want to learn more!",True
@JayeshSarvaiya,2021-02-02T14:38:28Z,0,"Really Nice explanations, thank you for the video !",True
@JaviOrman,2021-02-02T12:31:59Z,0,This is so incredibly helpful. Thank you!,True
@Roger11719,2021-01-27T07:45:53Z,0,"5 repos and 5.6k GH followers, must be doing something right.",True
@Raj-uz9nv,2021-01-22T21:02:58Z,0,Awesome xplaination,True
@clintonmusix,2021-01-18T11:21:30Z,0,The best tutor out there! a big fan! Thank you so much! :),True
@systempatcher,2021-01-18T00:53:54Z,0,"Anyone having trouble installing packages in python, here is a way you can do it in the code w/o using console directly:  import os os.system('pip install some_package')  where some_package = beautifulsoup4, requests, etc. I recommend specifying what version you're using, especially if you have an IDE with different versions pre-installed. i.e. for installing lxml for Python version 3.7:  import os os.system('py -3.7 -m pip install lxml')  Don't forget to import lxml where applicable.",True
@FredMny,2021-01-17T12:31:02Z,1,"Thank you!!! I love it how you are able to not over explain, but also without leaving out anything important.",True
@jakesnell7707,2021-01-16T05:28:55Z,3,"Corey you have the coolest videos, you've taught me much my friend.",True
@shivanishimpi7018,2021-01-13T23:20:56Z,0,"At 26.50, how do I scrape out both <p> tags instead of just the primary p tag? Thank you.",True
@abdulahaldhem4511,2021-01-12T18:41:10Z,0,"thanks a lot , its a really full of details and i find it very interesting",True
@zanaprka6889,2021-01-10T14:19:05Z,0,Thank you so much !!!!,True
@FrietPatat,2021-01-09T11:13:31Z,0,"Excellent video, well explained and to the point.",True
@ktgiahieu1,2021-01-08T15:40:02Z,0,"Great video, this helps me a lot",True
@Blackfiregiulio,2021-01-02T18:38:12Z,1,I love you bro. the only video understandable,True
@AhmedAtef-lj4rq,2021-01-01T13:31:45Z,0,"Thanks for the video, could I know the name of your theme?",True
@hackstarcool,2020-12-27T04:36:24Z,0,Great video man and a lot of helpful tips. Thanks a ton,True
@MidjourneyandB,2020-12-22T21:50:17Z,0,I just found your videos. I'm 5 months in to learning coding (toward data science). Your examples and explanations are extremely clear and helpful. I love how large the text is and how clear the narration is as well. Thanks. I will be watching tons more.,True
@Reese_414,2020-12-21T20:16:32Z,0,"Just wanted to share something I do to practice web scraping that others may find useful... Instead of running your request to a live url while working out your code and possibly overwhelming a website, I right click on the browser and select the ""view source"" option. Then select all and copy the source code and paste as an HTML file in the same local folder then scrape through it until I get it working the way I want... May not work with all sites, but good for simple sites that aren't JavaScript heavy...  P.S.  Excellent tutorial, thank you for being so clear and so thorough!.!.!",True
@abdullahsarker3595,2020-12-21T17:52:56Z,1,Subscribers += 1.   Great video! I've never watched such a helpful video about web scraping. Thank you.,True
@haozhang7159,2020-12-16T00:22:58Z,0,what if I want to scrap from a website that requires authentication with username and password that I have,True
@robertohigor4535,2020-12-11T21:55:38Z,0,"Thanks for helping. It's funny cause one of your posts didn't had a link, but you addressed that in your video.",True
@mianali5664,2020-12-10T10:42:08Z,0,"We are providing services Web scraping (web harvesting or web data extraction) is a computer software technique of extracting information from websites. Usually, such software programs simulate human exploration of the World Wide Web by either implementing low-level Hypertext Transfer Protocol (HTTP), or embedding a fully-fledged web browser, such as Internet Explorer, Google Chrome and Mozilla Firefox   Contact Us https://aitomation.com/data-web-scraping/",True
@shivansh9387,2020-12-09T06:30:22Z,0,Why aren't you uploading new videos now??,True
@chipile,2020-12-07T21:34:37Z,0,Best ever! Excellent explanation!,True
@tobaobiwale735,2020-12-07T13:21:56Z,0,"I bought this course on Udemy, and I decided to check youtube for a web-scraping when I was confused. Men, I fell in love with your teaching skills, so understandable in every step, I bet that the Udemy tutor had watched your video to create his own. Ain't rich for a subscription but I bet I will follow you and learn from you at all time, cheers mate!",True
@rampurpraneeth528,2020-12-06T08:06:54Z,0,"when i used this line in for loop: source= requests.get(""https://coreyms.com/"").text soup=BeautifulSoup(source,'lxml') for article in soup.find_all(""article""):     headline=article.a.text     print(headline)     summary=article.find(""div"",class_=""entry-content"").p.text     print(summary)     vid_src = article.find('iframe', class_='youtube-player')[""src""]      vid_id = vid_src.split('/')[4]     vid_id = vid_id.split('?')[0]      yt_link = f'https://youtube.com/watch?v={vid_id}'     print(yt_link)     print()     it throwed me error:  TypeError                                 Traceback (most recent call last) <ipython-input-8-263fe4669a84> in <module>()       6     summary=article.find(""div"",class_=""entry-content"").p.text       7     print(summary) ----> 8     vid_src = article.find('iframe', class_='youtube-player')[""src""]       9       10     vid_id = vid_src.split('/')[4]  TypeError: 'NoneType' object is not subscriptable    please corey help me out , i am unable to figure out.",True
@rampurpraneeth528,2020-12-06T05:28:50Z,0,what if there two para's(lets say p1 and p2) in a div  and now i want to extract p2 from the div. please write the code how access p2.,True
@subhambijarnia3143,2020-12-05T13:25:17Z,0,"this is good video to get knowledge, also this tutorial help to complete my first project. Thank You",True
@lilpinkie12,2020-12-05T04:05:02Z,0,do you need to know python to do this?,True
@ScharadaLP,2020-12-04T16:33:56Z,0,Thanks for the Video ps. parsing a wikipedia table is bad (yes wikipedia has an api to get the articles but in every way i need to parse it.,True
@jeanpaulvillarschmiel266,2020-12-03T23:07:21Z,0,"GREAT VIDEO. Honestly, just with this example, I managed to pull a huge project. Thanks! Well Explained.",True
@santiagocarranza6234,2020-12-03T22:45:13Z,0,4 the algorithm,True
@Josiasnyc,2020-12-03T09:40:59Z,0,"All of your videos are just phenomenal. Well done for the amazing work you do! I'm glad we have people like you, very competent, professional, knowledgeable and straight to the point. 10/10. Have you considering writing? You should!",True
@uguree,2020-12-02T23:37:55Z,0,What a great video. Thanks a lot.,True
@daringetae5136,2020-12-01T04:09:33Z,1,Best explanation I've found so far on how to scrape websites using soup. Worth watching yours.,True
@hacninetushar,2020-11-27T15:21:43Z,0,"If anyone doesn't know html, then I will recommended to learn html otherwise you can not grab this properly. But if you know html then It is nothing to you.",True
@hacninetushar,2020-11-27T15:14:42Z,0,Sorry for disturbing your website.,True
@vatsal_gamit,2020-11-20T17:16:12Z,0,Thank you so much for very simple & straight to the point explanation!!,True
@pkavenger9990,2020-11-18T06:54:24Z,0,"Seriously your teaching style and explaining is amazing, you even explained what split does, most people just assume that you already know about it but even then you explained it and it refreshes everyone memories and helped those who forgot due to some reason.",True
@chianingchang7627,2020-11-17T13:32:12Z,0,This video is amazingly helpful. Clearly demostrate the logic concepts step by step. Thanks a lot Corey!!,True
@mgrespawners7033,2020-11-17T08:08:38Z,0,666K Subscribers OH NO,True
@Creatorcube_,2020-11-17T01:34:42Z,0,You have 666k subs lol,True
@salah2fois,2020-11-15T15:46:13Z,10,"Using Pyton 3, I added this part: csv_file = open('web_scraped.csv','w', newline = '') in order to avoid empty lines in the csv file.  https://stackoverflow.com/questions/3348460/csv-file-written-with-python-has-blank-lines-between-each-row",True
@padmavathynarasareddygari1213,2020-11-15T14:50:11Z,1,"Corey I am creating a python script that can answer questions by searching them on google. I tried selenium and webbrowser and stuff but these modules open a new tab in chrome. I want it so that  it will print the answer. For example, if we input something like ""Why must we eat food""  it must print the first result in google. If you can help me with I will be very grateful to you.",True
@lewishuxtable1892,2020-11-15T11:47:32Z,0,"this was great, not a complaint at all but is anyone else having trouble getting the csv to create?",True
@lRedMonkey,2020-11-14T21:45:30Z,0,te pueden quitar lo que uses en el scraping de otra p√°gina web?,True
@tushardalave4619,2020-11-13T10:00:28Z,0,Vrey good information üî•üî•üî•,True
@mehwhyausername1,2020-11-13T01:44:04Z,2,"yeah, but what if the data you want isn't in the html, and instead relies on a json querry?",True
@intesartaieb8590,2020-11-11T07:00:06Z,0,"your explanation is amazing, thank u so much",True
@todddelozier8172,2020-11-09T21:34:41Z,0,But what if you have a real website with crazy HTML like nothing shown in this video? lol,True
@dvwegner,2020-11-08T00:45:19Z,1,How do you comment out a line without going to the beginning of the line and typing in the #?,True
@saba1551,2020-11-07T12:05:24Z,0,"Could you show how can one collect source code from github. Com. Its not showing anything code part in(list of folders and files) text, how can i use it for this??!!!",True
@gouripeddipawansreekar1752,2020-11-04T15:05:23Z,0,Someone please help me! when enter command in windows  'python cms_ scrape.py'  this was appearing .....python: can't open file 'cms_scrape.py': [Errno 2] No such file or directory..please anyone help me..,True
@4122inc,2020-11-03T20:28:31Z,0,"I know this is an older video but it's really great how you explain in detail exactly why you did everything! For a newbie like me, other videos left gaps.",True
@AbuAhmedAlsudani,2020-11-02T21:06:12Z,0,"It is amazing and helpful, it exactly what I looking for. but I have a question: Is that possible to requests multiple webpages at once and read those links for that webpage from a txt file? Thanks in Advance üíïüíï",True
@nabilazulkifli7153,2020-11-02T17:13:23Z,0,"hello, i just want to say this video really help me for my fyp project. btw, how to save the data that we scrape into the database? i want to save it into mysql. can you help me?",True
@this_is_mac,2020-11-01T02:57:45Z,0,Can you please make a video about facebook API with python?,True
@srancuric7709,2020-10-31T08:43:11Z,0,"Hi, has anyone tried to scrape all this things and images from some web site?",True
@uncertawn,2020-10-30T13:34:27Z,0,Thank you so much!! That actually helped,True
@isomane7911,2020-10-29T16:54:56Z,0,"thank you so much Corey for all the knowledge you're sharing with us, no words would express how thankful i am for that also i can't stress enough how much satisfaction it gave me when i fixed that try-except part by myself and then afterwards it turned out thats actually what you suggested to do ^^",True
@paulseldn,2020-10-26T18:56:25Z,0,"The clearest explanation I have seen of webscraping, and at a pace we can actually follow. Many thanks Corey!",True
@wach2,2020-10-25T19:32:54Z,0,aaa,True
@kamaleshpramanik7645,2020-10-25T04:37:07Z,0,This is awesome awesome video... learned so much from this...,True
@iliveforthevibez6216,2020-10-21T16:46:25Z,0,"I try to get into Data Science and I did a coursera online course to learn python which also contained lessons about html and web scraping with BeatifulSoup4. I did not understand everything that was explained in coursera but your tutorial right here summed everything up in 40 minutes and could have saved me some hours if I had watched it earlier. Instant subscription man, the way you teach (and also speak, I am from Germany so it is easy to understand) is amazing , keep blessing us with your videos !",True
@korigamik,2020-10-14T17:16:37Z,1,I feel like a god after implementing this on an actual website!,True
@aestheticsdiy1839,2020-10-13T17:43:34Z,0,"Hi , Great Video , I also Tried to post a write up tutorial for beginners (Requests and Beautiful Soup). If you have time please read https://medium.com/@harips.mobile/python-web-scraping-beginner-guide-part-1-765b7914f3b3?source=friends_link&sk=3b3c37d65aa952b53030a10ad3f39f90",True
@cristianovivk4935,2020-10-11T15:16:42Z,0,short.crisp.on point.....thnxx for the tutorial,True
@prashantha14r,2020-10-11T10:40:35Z,0,"Loved this tutorial. I have better understanding now. Corey, are you in the process of making Scrapy and Selenium tutorials? If no, please consider to make one. Thanks and Regards",True
@nugrohomoristianto983,2020-10-09T04:31:17Z,0,"Can I ask one question..I have one html like this below :  <div class=""product-list__stock--branch""> 	<div data-id=""2"" data-stock=""1"" class=""class1""> 		<b>Online / COD</b> 		<span>Stock Available</span> 	</div> 	<div data-id=""3"" data-stock=""1"" class=""class1""> 		<b>Branch1</b> 		<span>Stok Available</span> 		<span class=""tag2 tag--warning"" style=""color:white;"">Qty 1</span> 	</div> 	<div class=""class2""> 		Available on 		another 1 store 	</div> </div>  I want to grab second <div.. (Qty 1).. how to do it? thank you Corey..",True
@ankushpokalwar5345,2020-10-08T09:21:30Z,0,as always you are the best,True
@jakobfredriksson2272,2020-10-05T13:45:14Z,0,"Brilliant, as always!  Edit: Nevermind... I digressed a bit with an open question I've solved myself now.",True
@randomguy-tm3df,2020-10-03T05:43:55Z,0,how do I access the div tag that has an id?,True
@deedanner6431,2020-09-30T20:59:36Z,0,When do you need to pass in the class as an argument?,True
@chickentutorials2123,2020-09-30T16:34:38Z,1,Thank you for the tutorial Sir! Still kicking ^^,True
@sohinidey6711,2020-09-30T05:12:41Z,0,Have u full course on web scraping using python?,True
@johangodinho,2020-09-24T19:15:06Z,1,"Hey everyone. Since it's been so long since this video was posted, you may face a ``` nontype: object is not sub scriptable error ``` since one of Corey's post's on his site doesn't have an embedded video, and hence the code kind of crashes. You can easily fix the issue by adding a try and except statement so that the code ignores the post where there is no video. There are also other workarounds but I thought it would be cool if I could help anyone facing the same issue.",True
@kunalduran4494,2020-09-24T14:49:04Z,0,I tried scraping with Flask API: https://youtu.be/KoYM91HZmPU,True
@anakkkk,2020-09-23T21:44:26Z,0,"you are seriously the best, question how can I scrape multiple page at once? if there's no next button. Doing it for food recipes and most of them are categorized.",True
@ozkankurt449,2020-09-23T11:35:28Z,0,Corey Schafer Ger√ßekten √ßok dikkatli becerikli bir kanal takipteyim...,True
@edgarortega7876,2020-09-22T08:20:17Z,0,Awesome Tutorial!,True
@alejandrolike86,2020-09-21T20:21:53Z,0,Thanks man! How can i scrap java code with beautiful soup? For exemple youtube chanal code has java code.,True
@md.bodruzzamansifat7357,2020-09-18T19:04:17Z,0,"Brother,  your videos are always great. I follow them and learnt python very easily. This course worth money but you are serving free. Thanks a lot.",True
@dwiseptihadi6812,2020-09-18T12:51:07Z,0,Thankyou very much sir! I'ts very helpfully my project!,True
@soumyadrip,2020-09-17T20:59:24Z,0,üß°üß°üß°,True
@randyluong6275,2020-09-17T19:36:21Z,1,big thumb in 2020. shout out to Corey.,True
@arushiarora6412,2020-09-17T02:04:09Z,0,"Waste of time, actual coding starts at 12 mins. You could have given timeline to skip video directly to 11 or 12 mins if  one doesn't wanna see theoretical stuff. Wasted 12 minute.",True
@manojuppala3941,2020-09-16T08:53:38Z,3,Corey is the world's best python teacher.,True
@rahulsdev4405,2020-09-15T09:53:04Z,0,Excellent video,True
@PH-md8xp,2020-09-14T07:36:48Z,1,"Another great video Cory, good content & clarity, and you made a fairly complex topic clear and understandable.",True
@rajnigoyal6653,2020-09-13T09:56:20Z,1,Thank you Corey Schafer.. I really loved your teaching style and got every part of this. The best part is pointing out about the problem and give the solution.,True
@srijitdas2207,2020-09-13T05:34:08Z,0,"Hi Corey Sir, Can we make web crawler using BeautifulSoup4? How to do pagination using bs4? How to login into a website using bs4?",True
@arctitan7076,2020-09-12T23:31:32Z,1,Excellent!,True
@user-lh4hv3tx8b,2020-09-12T20:12:13Z,0,Is there a way to learn more on how to read the inspected elements of a website and make sense of it? Should I learn css and HTML?,True
@michaelduckworth3396,2020-09-12T19:08:01Z,0,I cannot pip install lxml and 'from bs4' throws a separate error. I'm on Windows. Did anyone else solve this?,True
@tikkanenfelix,2020-09-12T11:44:56Z,1,"How did u get them in a nice column on the excel sheet, when I do this I just get all the info in two rows without any styling",True
@user-lh4hv3tx8b,2020-09-09T02:33:45Z,3,"Every time I find myself struggling with python as a beginner and going through so many random sources, you always seem to be the clearest.",True
@meenumangla7886,2020-09-07T15:31:19Z,0,Amazing tutorial.,True
@HhhHhh-et5yk,2020-09-07T09:33:47Z,0,U deserve 10 Million subscribers! Thank You Corey‚ù§.,True
@syedsaadsaeedhassni6372,2020-09-07T06:43:48Z,0,A very beneficial video! Thanks alot Corey!! It would be bonus if you teach us the method of fetching data through API's as well,True
@nonamed56,2020-09-06T20:33:11Z,0,7:20,True
@thespartankid,2020-09-05T17:03:55Z,0,How do I keep scraping for the next webpages too?,True
@umangabhattarai7023,2020-09-05T17:03:14Z,0,How can we scrap data for multiple page? I mean to say other remaining pages..,True
@SqueebyJeebies,2020-09-03T19:06:34Z,0,"These videos are great, but I unfortunately got stuck on this. The first time I tried to run scrape. py (10:32 mark on the video), I got this ImportError: No module named bs4. I installed beautifulsoup4, (Successfully installed beautifulsoup4-4.9.1 soupsieve-2.0.1), requests, and lxml. Any guidance would be appreciated. Thank you!",True
@raihantanvir8880,2020-09-01T11:20:02Z,0,How to avoid getting blocked and blacklisted when access denied ?,True
@neighbourhoodcoder5988,2020-08-31T20:09:57Z,0,this 45_M & 47_S tutorial= 10 hours of other tutorials+plus some books+some paid courses. keep it up...respect & love,True
@szendrenko,2020-08-29T23:17:36Z,0,"Kudos on the video, but the section where you describe the structure of HTML is horrible. Firstly, if someone does not already know it - the five minutes of my time you wasted isn't enough to train someone. It's like having a video teaching calculus, but then you break out and spend ten minutes explaining what addition and subtraction are. Rather, you should tell people where to go if they don't already know that material.",True
@sauceontoes3457,2020-08-29T15:42:55Z,0,"When I try to soup.find using a div and class, while printing it comes  'None' everytime, can you please help me",True
@gimmametdeboys1505,2020-08-25T01:39:13Z,1,Why can't all programming tutorials be this easy to follow?,True
@chidinmanwatu7545,2020-08-24T10:43:21Z,0,"Hey Corey, your videos are the best, you're such a good teacher.",True
@giangbioinformatics,2020-08-23T20:13:42Z,0,Thank you for your support !!!,True
@ahmedbouali7000,2020-08-19T17:05:23Z,0,"Somethings are really difficult to do, I remember once I had to hire someone. That's also another issue since most of low cost freelancers do not even understand your queries .. (Btw : I've had great experience with this guy https://bit.ly/3j81V2H)",True
@smruthibt628,2020-08-18T17:21:31Z,0,"does find_all return a dictionary, or a list?",True
@jaikrishnapandit6073,2020-08-18T06:06:32Z,0,every time i have any doubt in web scrcping i play this video again a i get the problem solved,True
@tirthajotisinha9088,2020-08-13T04:34:41Z,0,And this would be the best video for web scrapping using python.Thanks a lot for making this a lot simpler.,True
@varadvithalkj1716,2020-08-11T10:57:54Z,0,When you cleared the NoneType error you gained a sub!,True
@asifejaz2311,2020-08-11T07:41:37Z,0,get python scraping project done now visit here https://www.fiverr.com/share/2pV62e,True
@lucasphillips2177,2020-08-10T22:06:39Z,0,Do you have to create a blank csv file before running the code or does the code create a csv file and then write the data in,True
@excessreactant9045,2020-08-10T15:50:31Z,0,Thanks for allowing users to use your website as a tool to learn,True
@maksudulhossainjewel378,2020-08-09T20:29:16Z,0,My methods are not highlighted like yours. soup.prettify both are white. I used predawn dark theme. Could you please suggest?,True
@robertdonato5444,2020-08-09T15:22:10Z,0,got stuck on install beautifulsoup4....SyntaxError: invalid syntax,True
@mavezy,2020-08-08T10:22:39Z,0,Awesome tutorial! good job.,True
@fet1612,2020-08-07T07:45:05Z,0,25:37 Summary text,True
@hemanthkumaar3681,2020-08-07T04:26:40Z,0,<t>wow!! </t> <h2>this tutorial is excellent.</h2> <p.>As im a beginner this is easily understandable</p>  thankyou !!,True
@lyattepeach8201,2020-08-06T07:26:03Z,0,Thank you for explaining what my masters lecturers wont :),True
@fet1612,2020-08-04T21:04:55Z,0,27:40 iframe,True
@fet1612,2020-08-04T20:07:55Z,0,19:30,True
@aero_singh,2020-08-04T17:57:18Z,0,great sir!!,True
@dinht206,2020-08-04T07:55:13Z,0,awesome tutorial bro!,True
@javedmatrah,2020-08-04T01:35:48Z,0,This is an absolutely amazing video.,True
@powerage5818,2020-08-03T20:13:16Z,0,Still epic in 2020,True
@peteh7182,2020-08-03T10:41:54Z,0,"this video was awesome, well done in sharing the knowledge",True
@hermes5456,2020-08-02T08:28:24Z,0,"When I started to see BeautifulSoup videos it was a pain in the ass but now is really fun for me to find this freaking annoying text values, that you for your video man, it help me a lot.",True
@adnanzafar5385,2020-08-02T07:56:53Z,0,"Hi everyone. I have created Python Web Scraping WhatsApp group, You can join https://chat.whatsapp.com/HzX1DzO5IAg1x0FBB7mLUT",True
@jamesjohnathan4424,2020-07-31T14:55:19Z,0,awesome tutorial Corey sir thanks a lot!!! Ya great and awesome.,True
@kelvinjamfee6931,2020-07-30T09:18:22Z,0,THANK YOU .... YOU ARE GOD SENT TO SOME OF US...,True
@wanfaris9473,2020-07-29T02:19:55Z,1,while True:            print ('Thank You'),True
@gulshankumar17,2020-07-28T06:08:06Z,0,thank you so much,True
@iLLestTv,2020-07-26T01:54:08Z,0,21.39,True
@JohnOkelloh,2020-07-25T17:14:11Z,0,"Because of the update paragraph, i was getting TypeError and i modified the code to:  from bs4 import BeautifulSoup import requests  source = requests.get('http://coreyms.com').text  soup = BeautifulSoup(source, 'lxml')  articles = soup.find_all('article')   for article in articles:     headline = article.h2.a.text     print(headline)          summary = article.find('div', class_ = 'entry-content').p.text     print(summary)          try:         vid_src = article.find('iframe', class_ = 'youtube-player')['src']         vid_id = vid_src.split('/')[4]         vid_id = vid_id.split('?')[0]              yt_link = f'https://youtube.com/watch?v={vid_id}'         print(yt_link)         print()          except TypeError:         print()         continue      print()  Thanks a lot sir. You are an amazing teacher",True
@shikhindahikar8488,2020-07-23T20:21:29Z,0,Is it legal to use the public data from websites for some other business purposes?,True
@avyukthnilajagi3328,2020-07-23T12:44:40Z,1,"If anyone is having an issue with the error - ""NoneType has no attribute '__get_item__' then it is because one of the articles on the webpage does not have a youtube video link. The bug can be fixed by using an if statement: if article.find('iframe', class_='youtube-player): you should put all of the youtube video link parsing inside this if statement.",True
@lauraa.3593,2020-07-17T22:49:41Z,1,Excellent! Thank you!,True
@jonathanstudentkit,2020-07-16T14:40:59Z,0,how to open a link e.g. wikipedia if you don't have the html file?,True
@marcmedawar8073,2020-07-14T18:52:08Z,0,anyone else getting an error at the end when doing for loop?,True
@rodrigoledesma2009,2020-07-13T23:33:25Z,0,Thank you so much for the tutorial! I use your logic and it worked awesome! My only problem was how the html was programmed . Nevertheless it was a great intro many thanks!,True
@amoghmulge,2020-07-13T14:33:05Z,2,"Bro , you are a GEM  ‚ù§Ô∏è",True
@paulohsgoes1959,2020-07-11T17:17:59Z,2,"I was quite sure you wouldn't let me down. You're the best, man, because you go straight to the point. Thanks a lot for sharing your knowledge.",True
@samirkhan3096,2020-07-10T10:53:37Z,0,need video on selenium and scrapy,True
@preetiarawal1551,2020-07-07T06:54:13Z,0,"Hi All,  I am using pycharm to run python code,when I installed requests,bs4,beautifulsoup4 in my windows system it installed successfully,But when I import it is giving error.Please let me know  how can I resolve the issue.",True
@allistergraham9448,2020-07-06T19:27:39Z,1,"Very informative video, you're an excellent teacher! While other YouTubers ramble off topic, you get straight to the point, and I really appreciate that.",True
@MalekBenkouider,2020-07-06T00:16:27Z,1,"thank you so much, for me you're the BEST python teacher. I really enjoy watching your videos and learn complex staff in very easy way!",True
@AmanChauhan-hy1sb,2020-07-04T11:06:43Z,0,Guys! Make sure files are stored in ANSI.,True
@adarshtiwari7395,2020-07-03T13:29:30Z,2,I truly appreciate your compassionate teaching and dedication to the tutorials. Thank you for all the teaching!!,True
@buithanhlam3726,2020-07-03T05:06:12Z,1,Thanks! This helps me a lot!,True
@stringguo8265,2020-07-01T16:18:11Z,0,This video really builds up my confidence in programming!,True
@TeachingComputing,2020-06-30T21:12:47Z,1,"@Corey - but how do you then display this dynamically on a webpage? As in, what are the suggested ways to access that CSV file (dynamically) and display the data on your own webpage?",True
@timeforrice,2020-06-30T06:05:22Z,0,Thank you for sharing,True
@melisaliu5727,2020-06-28T09:30:47Z,1,La combinaci√≥n de BeautifulSoup y Octoparse https://www.octoparse.es/  es el mejor posicionamiento preciso y la extracci√≥n r√°pida de grandes cantidades de datos web.,True
@zaferbagdu5001,2020-06-27T15:01:09Z,0,hi i am writing  class name  corectly and result is none what is the problem,True
@user-uh2cr9so8l,2020-06-26T11:37:21Z,0,Thanks again. I think a Selenium tutorial would be useful as well!,True
@alieubadjie7309,2020-06-25T15:21:37Z,0,I will love you to make a video of web scarping  for quotes.toscrape.com and books.toscrape.com using beautifulsoup4 and selenium and adding user menu for login if possible,True
@vatskinshuk,2020-06-24T19:43:11Z,0,Amazing. The way you teach the most complex things in the most simplest way is commendable üëçüèªüëçüèªüëçüèª‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è,True
@Muzahid19dec,2020-06-24T03:15:55Z,0,Thank you. Can't believe I have been building scrapers for months still got so much deep understanding from a single video.,True
@howardxian,2020-06-21T01:45:22Z,0,"Please also create a tutorial on Scrapy, thanks!",True
@shariqahmed7319,2020-06-19T16:53:40Z,0,One of the finest web scraping with BS4 tutorials on YouTube! Thank you so much sir!,True
@zigginzag584,2020-06-19T03:21:13Z,0,what are the key pairs to comment out and indent (manipulate) multiple lines at once while highlighting them? I've tried every combo I can think of and I see it all the time but nobody ever says how they do it. thanks.,True
@jpc_337,2020-06-18T21:13:29Z,0,"Phenomenal lesson, will be referencing later. Thank you so much!",True
@rbk00006,2020-06-18T10:46:20Z,0,"His teaching is so good ,i had a orgasm in the mid video.(no homo).Joker aside Great video.",True
@blade1376,2020-06-17T13:03:59Z,0,Navigating with CSS selectors? BTW great content!,True
@tntcaptain9,2020-06-16T17:06:47Z,4,"This is how to teach in a proper way, in some videos a code is already given and they just read it out which makes it difficult to understand. Thanks Corey, keep up the great work.",True
@codingboy2254,2020-06-14T10:21:23Z,1,Thank you very much sir .,True
@guruprasad5001,2020-06-13T22:37:56Z,1,"Amazing video! the content and the way of explanation was very crisp and clear, i personally feel this is one of the best tutorial for Web scraping, thanks Corey.",True
@anant115,2020-06-13T14:06:19Z,0,Do data scientists use this?,True
@ammarcode,2020-06-13T09:34:08Z,1,"Amazing, Thanks alot",True
@rohanpednekar8074,2020-06-13T06:49:39Z,1,Thanks :),True
@pngrn,2020-06-09T20:11:46Z,0,"Hey please help, when i did the requests function, python did not show the html tags and classes but not the text inside them",True
@jeralgaming853,2020-06-09T07:16:27Z,0,can anyone pls send me cheet sheet (notes) for this video?,True
@JJSogaard,2020-06-08T17:04:52Z,1,"Wow, your Sublime doesn't say 'unregistered'! I don't think I have seen that in a video before...",True
@AmitShukla-qf4mh,2020-06-07T17:18:08Z,1,Great video üôåüôå,True
@ujjawalsharma8363,2020-06-07T03:57:09Z,1,Thanks for such a great video ‚ù§Ô∏è,True
@akhilkn225,2020-06-04T13:26:32Z,0,The one and only helpful video for beginners,True
@dhairyashah1746,2020-06-04T10:49:40Z,0,how can we read data from csv file and use some of it in my own html page??,True
@pratikjoshi677,2020-06-02T18:32:48Z,0,"I'm Getting 0 while printing the len function: Here is my code Thanks in advance from urllib.request import urlopen as uReq from bs4 import BeautifulSoup as soup my_url = 'https://www.daraz.com.np/catalog/?_keyori=ss&from=input&page=3&q=headphones&spm=a2a0e.11779170.search.go.15bb2d2btaSWVj' uClient = uReq(my_url) page_html = uClient.read() uClient.close() page_soup = soup(page_html, ""html.parser"") containers = page_soup.findAll(""div"", {""class"":""c2prKC""}) print(len(containers))",True
@rakeshrayudu4930,2020-06-01T06:58:20Z,0,"Hi Corey.. Thanks for the tutorials.. I'm not able to parse the text directly, I have to use encode method which is converting the text into byte code.. If I don't use encode, it is throwing UnicodeEncodeError: ascii code can't encode character '\u2013'.. can you please help me with this? I'm using python 3.6.9.. thanks..",True
@cklam813,2020-05-31T16:43:37Z,0,wonder how to deal with the error : 'cp950' codec can't encode character,True
@chandramorgan8866,2020-05-30T10:36:17Z,0,"great and awesome video, i wonder how to parse CSS elements from website for scraping?",True
@mayaramein,2020-05-29T14:14:14Z,1,Easiest Tutorial on youtube thank you,True
@divyagurumoorthy3354,2020-05-26T11:04:37Z,0,"Thank you so much sir :) This was so clearly explained and included some possibilities of error, which I actually did face, and you also told us how they could be solved as well.  I just have a question. In the 'find' method, only the first occurrence of that particular tag/class is retrieved. Is there a way to extract the 'nth' div/ nth occurrence of a particular class instead of using find all? Thanks a ton :)",True
@vishvips,2020-05-25T16:17:03Z,0,Thank you once more for the step-by-step real life examples. Can you please do a video for xml processing?,True
@JoshuaDHarvey,2020-05-24T19:53:37Z,0,"Great video, thank you Corey!",True
@Hamzaelbouti,2020-05-24T17:55:57Z,0,"i cant  get the script from script tag """"""as string""""""",True
@javedmatrah,2020-05-24T15:40:23Z,0,Wonderful,True
@joysharma8599,2020-05-24T09:21:11Z,0,"Hey Corey, Please create some videos on numpy!",True
@A_Mindful_Journey,2020-05-23T13:47:37Z,1,What an amazing tutorial!! Thank you Corey! :),True
@abidvu2472,2020-05-22T01:39:02Z,1,So clear. Very easy to understand. Thank you.,True
@namankumar2008,2020-05-21T05:08:10Z,0,"sir i  am getting an error 	 ImportError: cannot import name 'beautifulsoup' from 'bs4'   plzz help",True
@connorhayes2374,2020-05-20T00:16:26Z,0,"Note for Windows users: When using open() on a windows machine, you have to specify utf-8 encoding with open('file', encoding='utf-8'). Windows does not default to utf-8 and fails to encode some common bytes",True
@pydocs-pro,2020-05-16T18:52:46Z,1,"Corey, this is just THE BEST explanation about web scrapping with python. Just notice that you could explore a little bit more about the page response with the get method. Sometimes I have trouble trying to access one specific site, and I have to manage it in different forms. And some more detailed explanations about when it's possible and not possible to scrape data from websites.  Only this detail that I've missed. All the rest it's just perfect.",True
@courtney2394,2020-05-16T14:04:00Z,0,Python holy grail!,True
@joost0400,2020-05-16T00:54:51Z,1,"Thanks, Corey. This was really helpful! Excellent video.",True
@orangeshoes,2020-05-15T18:37:49Z,0,"Getting these question marks ÔøΩÔøΩÔøΩÔøΩ  in place of  - ' "" _  when scraping the said website. Please help.",True
@orangeshoes,2020-05-15T18:34:24Z,0,"Hi, thanks for the video! It was a good mini-project! :)  I have an issue, I hope you (someone) can help out.   Getting ÔøΩ in place of ', '', - and some other characters.  Here's my code -  https://repl.it/talk/share/replacement-characterreplacement-characterreplacement-character-Characters-are-not-getting-printed-instead-getting-replacement-character/37693",True
@mcdaddy1334,2020-05-14T08:52:38Z,1,VERY NICE!,True
@thaungthan5882,2020-05-13T15:36:43Z,1,"Very helpful! Thank you, Corey.",True
@gwanghyeongim768,2020-05-12T02:25:18Z,6,Thank you Corey. I can personally assure that your work doesn't go for nothing. I hope I can donate more to your patreon in the future.,True
@nickpolawris2196,2020-05-11T07:59:58Z,0,very helpful,True
@solarsystemsportspridictio8069,2020-05-10T14:30:48Z,0,"how to kicked sports data, by time and loop calculation help me out",True
@_boris,2020-05-10T12:36:51Z,0,"Whoever gets weird symbols when opening the .csv in *Excel*, change this line: csv_file = open('cms_scrape.csv', 'w', *encoding='utf-8-sig'*) Thanks once again Corey for brilliant content üíé",True
@louislai4125,2020-05-10T09:37:24Z,1,This was really clear and easy to understand. Thanks!,True
@xintongliu8068,2020-05-09T04:04:15Z,0,Brief conclusion: This video is some basic sytax for the BeautifulSoup. 1. How to get access to first element. 2. How to get access to the specific ones.  3. How to parse by using split. 4. Deal with missing information. 5. Create and write csv file.,True
@lucastoccheton989,2020-05-08T19:49:18Z,1,Absolutely the best. Didn't need anything else for my first web crawler!!! Thanks you!,True
@viralvideos9227,2020-05-08T19:10:38Z,0,sir how to do xml parsing ?,True
@rajmani1991,2020-05-07T15:14:01Z,0,Hey ...Can there be a python code where i would like to append a html file into an another html file into a particular div,True
@lucaspinsdorf6794,2020-05-05T19:35:43Z,0,"Hello! Perfect video! Would just like to know if you have some tips to getting the same kind of information (same structure of the data) from different url's of the same website. The url's are: ""www.yyyy.com/id=1"" I just have to change the 1 to 50.000. Thank you!",True
@bro9105,2020-05-05T10:41:49Z,0,"10: 32 when I run i get, attributeerror: module 'html5lib.treebuilders' has no attribute '_base' Can anyone help?",True
@rajtiwari665,2020-05-03T00:22:54Z,0,thanks a ton...,True
@_J_L_,2020-04-30T14:44:58Z,0,I was looking for 20:14 at the beginning damn man hahah but still nice video,True
@farhadhossain8108,2020-04-28T09:30:44Z,0,"Scraper API handles proxies, browsers, and CAPTCHAs, so you can get the HTML from any web page with a simple API call! Scraper API offers 1000 free API calls without Any credit card required. One of the most frustrating parts of automated web scraping is constantly dealing with IP blocks and CAPTCHAs. Scraper API rotates IP addresses with each request, from a pool of millions of proxies across over a dozen ISPs, and automatically retries failed requests, so you will never be blocked. Scraper API also handles CAPTCHAs for you, so you can concentrate on turning websites into actionable data. If you wish to try¬†Scraper API¬†here is a 10% coupon for you to give it a try ‚Äî apiscraping10",True
@jenn6997,2020-04-27T18:22:39Z,0,"Hi Corey, I have a question about grabbing the website URL. Why can't we just use ""src"" as our video link? As the one you get at 29:43 ? If I click what we get from vid_src, it will be directed to the video page. In this case, why do we even need to get the video ID and then create the link? Thank you so much. Have a great week!",True
@iflyenglish,2020-04-27T07:24:06Z,0,Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you Thank you,True
@JorgeAlvarez-mf6kc,2020-04-26T15:46:17Z,0,"Great tutorial, thanks man",True
@kvnptl4400,2020-04-26T09:38:34Z,0,Which IDE Corey is using? that gives output in same as coding window,True
@augustinjoseph5635,2020-04-25T11:48:43Z,0,"Hello,sir I am augustin. When I tried to scrape my own website (http://augustinblogger.epizy.com/) I got an error stating ""enable JavaScript in your browser"" I tried to scrape on pycharm, QPython, Pydroid, Termux. I also referred internet but I could not find a solution that satisfies my problem. Please help me out sir.",True
@varunabhi,2020-04-25T04:26:48Z,4,No where I have seen advanced topics explained in an easy way like this. Even in paid courses THANKS Mr.Corey. THANKS A LOT!  I'd learnt much from your videos in a easy way.,True
@vinayagarwal1623,2020-04-25T03:35:53Z,0,"Hey Corey, could you please make a video about dynamic web scraping using selenium. I was having trouble with a website that changes the position of buttons after some clicks. I love your in-depth explanation about topics, so i know your video will clear all my doubts. I searched for a solution everywhere, i couldn't find anything helpful.",True
@abdulhamidkhorajiya2256,2020-04-24T19:16:56Z,1,excellent üëç,True
@sohansoharab1670,2020-04-21T11:43:22Z,0,How do I catch dynamically generated source attribute from image tag?,True
@martinkaspar5095,2020-04-20T23:16:23Z,0,awesome - this is just awesome - many thanks for this great rundown in BeautifuSoup. it is just great: keep up the superb job!,True
@mikecelia2290,2020-04-19T01:42:41Z,1,Great video,True
@abdulmalikgiwa920,2020-04-18T17:20:49Z,1,"This is a very good and explanatory video Corey, been having issues understanding beautifulsoup but this just broke it down perfectly. I was referred here from coursera, great one üëçüèΩ",True
@nevilholmes5900,2020-04-18T17:13:34Z,1,thanks,True
@user-cy3je1xd1c,2020-04-18T15:56:52Z,1,"Corey, thank you so much for such amazing videos!",True
@hybouichang5931,2020-04-18T15:55:09Z,1,"Thnaks a lot, very clear and good to discover BeautifulSoup !",True
@johanjim4940,2020-04-18T10:37:28Z,0,*_hello_*,True
@albertwalker9396,2020-04-17T19:03:25Z,1,"Excellent, I found this video after trying to follow some other vids with continual syntax error. I haven't touched Python for several years (retired) and found this video an excellent guide to getting reacquainted Thanks for your efforts. I have subscribed to your channel.",True
@samikmehta33,2020-04-17T10:51:56Z,0,"When i tried to parse instagram page, i was unable to parse that page using above tools. Can you please help me out?",True
@tarunsukhpalani9514,2020-04-17T04:44:27Z,3,"Master Corey, you are a magician. I just mesmerized.",True
@baibxu1141,2020-04-15T02:43:43Z,1,This. ! Video!,True
@garydunken7934,2020-04-14T07:14:38Z,2,Thanks a lot Corey. It tremendously helped me to understand BeautifulSoup and quickly use it for a small web scrapper script that I needed. This 45min learning was so value adding for me.,True
@fubrian2945,2020-04-13T02:45:39Z,0,"Should rename this video to: Python Tutorial: Web Scraping with BeautifulSoup, Requests and HTML",True
@sushiliang,2020-04-12T22:57:52Z,0,"Hi Corey, is it possible to show how to scrap a website with 'load more' button?   I tried to with loop yet the href does not show the web page number",True
@user-di4bt7qu2i,2020-04-12T00:55:42Z,1,"Excellent video Corey, thanks.  I finally got to see it because we're all quarantined to our houses due to the virus.  Videos like this make it bearable.",True
@saicharan6112,2020-04-11T06:25:40Z,0,what exactly is parser ?,True
@mohamedabdo-xg6tw,2020-04-10T15:06:15Z,1,"I don't know why some people disliked this video? I paid a money to learn this and the content of the class was way bellow this level, thank you for the great Tutorial!",True
@humayunahmadrajib9451,2020-04-09T19:18:38Z,1,Thank you sir for great video.,True
@JoshKindhart,2020-04-09T02:30:07Z,0,"@coreyschafer How would I iterate through table data on finviz.com to scrape Top Gainers? When I try {""class"": ""table-light-cp-row""}, bs4 can't find it.",True
@salmanb9129,2020-04-07T15:07:47Z,0,"hey great video, just wanted to ask, my CSV doesn't automatically open up with a table and the height of all the rows are too big, is there any way to fix this? Thanks again",True
@MakerMotion,2020-04-06T19:31:45Z,0,here is web scraping for dataset creation => https://www.youtube.com/watch?v=30dRI2nvGNE,True
@krshah2008,2020-04-06T06:00:23Z,1,good stuff,True
@soumyakumar7021,2020-04-05T17:04:09Z,0,why is it important to do the csv_file.close()?,True
@proudnepali3848,2020-04-05T07:24:44Z,0,"Are you from Georgia, Sir?",True
@proudnepali3848,2020-04-04T06:34:03Z,0,10:00 why not import lxml?,True
@meezanmalek9593,2020-04-03T18:19:39Z,1,thanks bro keep going,True
@RadioactiveNinja,2020-04-02T12:35:23Z,19,One of the best tutorials Ive ever followed. Hopefully you help kickstart my career in data science!,True
@yaboi2043,2020-04-02T12:11:52Z,1,"This is the only video I could find which explains this topic in a simple, understandable way. Thank you!",True
@athirakrishnan6612,2020-04-01T14:22:09Z,1,Amazing content.   As a beginner in web scrapping . You content was informative and to the point. Thank you.,True
@ishanpand3y,2020-03-31T13:41:30Z,0,"Sir, when I scraped data in sublime I was getting question marks inside the box how can I resolve it?",True
@varuncanamedi5399,2020-03-30T18:13:36Z,0,"i downloaded the html file on my laptop but when i pass it in the string, i get an error 'file not found'. what should i do?",True
@darkmaraux,2020-03-30T07:14:30Z,1,This is so clean... omg! Best video!,True
@TobySullivan,2020-03-29T02:48:44Z,1,lit!,True
@JoaoPaulo-re5yz,2020-03-28T09:04:39Z,0,"Great video! If you are a dotnet developer, there is a tool that helps in extracting information from HTML pages, it is called DotNetExpose. You can install using Package Manager. Follow the links: Github: https://github.com/joao2391/DotNetExpose Nuget: https://www.nuget.org/packages/DotNetExpose/  #webscraping #csharp #dotnet #webcrawler #HtmlAgilityPack #DotNetExpose #python #beautifulsoup #CoreySchafer",True
@ldragogaming95,2020-03-28T08:32:55Z,1,Nice video  IBM staff suggested this link,True
@HairusBag,2020-03-25T20:04:17Z,1,"Hi great tutorial as always.  But i have i question: Is there a difference when scraping a XML SITE MAP. because when i use soup = BeautifulSoup(source, 'lxml') and use it to print out i dont get the source code but <loc> tags...how to scrape those ? thanks",True
@nileshsuryavanshi8792,2020-03-22T10:47:50Z,0,"I am a fan of you, sir. Love the way you teach each topic.",True
@avral4148,2020-03-20T20:25:24Z,0,Always the best videos are from you side...,True
@cheekygnome,2020-03-20T03:57:15Z,0,"To get these examples to work on Linux Mint I had to install the parsers with, for example, sudo apt install python3-lxml.  Pip appeared to be installing them, but I kept getting a bs4.FeatureNotFound error asking if I wanted to install a parser.  You can also ignore all of that and just use, for example, BeatifulSoup(html_file, ""html.parser"") to get the examples to work.",True
@ericmoran92,2020-03-19T16:35:37Z,0,"For anyone following along, toward the end, make sure you indent csv_writer.writerow. I forgot to do this and ended up with only 1 row returned in my csv.",True
@eizastanford8593,2020-03-19T00:32:36Z,0,"Thank you so much for your video! I tried looking at tutorials online from numerous articles, but I couldn't truly wrap my head around BeautifulSoup; even after looking at my final pieces of code for long periods of time, I felt my way of scraping was very inefficient and ineffective. Now, thanks to your tutorial, which has *so* much common sense by the way, I can now write readable code to scrape ebay listings and results!",True
@alexanderten5497,2020-03-18T06:00:25Z,0,The best mentor in my life:),True
@devsaki,2020-03-17T14:28:44Z,0,"Amazing video and very easy to follow. I landed here by recommendation by the instructor in the data science course https://www.coursera.org/learn/applied-data-science-capstone as a reference for scraping websites, which is a task in one of the assignments. Thank you very much.",True
@amirhosseinshahabnia,2020-03-17T03:48:17Z,0,"This is so great, thank you sir!",True
@iainhmunro,2020-03-15T21:16:11Z,0,Hi Corey   Everything works with the exception of the scrape.py file creating the CSV file.   Any suggestions ?,True
@sansamman4619,2020-03-15T14:42:10Z,0,You are a true man.,True
@syedh7843,2020-03-14T17:34:41Z,0,"Hello, Is it possible to extract a link as a clickable hyperlink as it appears on a web page? Thank you",True
@noorahmednatali2249,2020-03-05T23:02:23Z,0,How can we download the image,True
@cat47,2020-03-05T14:09:17Z,1,19:36m,True
@mikijafe,2020-03-05T11:41:31Z,0,"great teacher, thank you!",True
@clairein1433,2020-03-04T05:46:10Z,0,Thank you so much for making this video! I'm from China and I've searched many courses to learn Web Scraping. But it is you who make me successfully run my code.,True
@TheBoglodite,2020-03-03T16:19:43Z,0,"What is the practical use of web scraping? It seems very interesting to learn, but what is it used for?",True
@sonamrinzin8004,2020-02-27T06:03:23Z,0,Is there any means to download sample html file for this tutorial?,True
@3765sor,2020-02-26T06:04:25Z,0,"i was getting to point at 23:33 where i want to print article... it doesn't show the whole thing just a small portion of it form the middle...  was there a reason for that?    EXAMPLE:  <article class=""post-1670 post type-post status-publish format-standard has-post-thumbnail category-development category-python tag-gzip tag-shutil tag-zip tag-zipfile entry"" itemscope="""" itemtype=""https://schema.org/CreativeWork""><header class=""entry-header""><h2 class=""entry-title"" itemprop=""headline""><a class=""entry-title-link"" href=""https://coreyms.com/development/python/python-tutorial-zip-files-creating-and-extracting-zip-archives"" rel=""bookmark"">Python Tutorial: Zip Files ‚Äì Creating and Extracting Zip Archives</a></h2> <p class=""entry-meta""><time class=""entry-time"" datetime=""2019-11-19T13:02:37-05:00"" itemprop=""datePublished"">November 19, 2019</time> by <span class=""entry-author"" itemprop=""author"" itemscope="""" itemtype=""https://schema.org/Person""><a class=""entry-author-link"" href=""https://coreyms.com/author/coreymschafer"" itemprop=""url"" rel=""author""><span class=""entry-author-name"" itemprop=""name"">Corey Schafer</span></a></span> <span class=""entry-comments-link""><a href=""https://c...",True
@automationra,2020-02-25T06:58:44Z,0,"I like your video, very informative Can you show us how to make this with define and class?",True
@johnjacobs6234,2020-02-21T22:00:47Z,4,"Just a note, BeautifulSoup doesn't work with dynamic content. If you see something like:  ::before (html content) ::after  That content is dynamically loaded by your browser from some sort of redirect or Javascript.  The html inside it doesn't exist when BeautifulSoup parses everything.",True
@faustopf-.,2020-02-20T02:20:51Z,2,Best scraping web video ever! Thank you so much for this gem!!,True
@prashantsinghchauhan4430,2020-02-19T17:50:42Z,1,"Awesome, thanks you very much.",True
@sansan4607,2020-02-18T13:45:16Z,1,"wow this tutorial is completely clear to understand, you save my life man, thanks...",True
@s.m.shafiqahmed5350,2020-02-17T06:42:41Z,1,very good and helpful tutorial,True
@sameerk12982,2020-02-11T23:37:29Z,1,Thank you very much Sir for this excellent tutorial. üëå,True
@acassio,2020-02-08T23:14:09Z,1,I just wanna say a HUGE thank you. :),True
@muhammadzilalabhamidpahmi6694,2020-02-08T05:17:47Z,1,"Very good video and explanation, thank you!",True
@josephsteen230,2020-02-05T22:03:58Z,0,"Outstanding, Corey. I really enjoy and appreciate the clear information in your videos. Keep it up, and I am joining your patreon.",True
@ship2nip,2020-02-01T22:26:24Z,0,"Hi Corey,  When I was trying to follow your tutorial end up getting below error. Can you help to fix that. Thanks in Advance! Nipun  Code: ========= from bs4 import BeautifulSoup import requests source = requests.get('http://coreyms.com').text soup = BeautifulSoup(source, 'lxml') print(soup.prettify()) =========== Traceback (most recent call last):   File ""/Users/nipunchaudhary/python_learning/hello.py"", line 7, in <module>     print(soup.prettify()) UnicodeEncodeError: 'ascii' codec can't encode character '\xbb' in position 2769: ordinal not in range(128) [Finished in 1.2s with exit code 1] [cmd: ['/usr/local/bin/python3', '-u', '/Users/nipunchaudhary/python_learning/hello.py']] [dir: /Users/nipunchaudhary/python_learning] [path: /usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin]",True
@sng8240,2020-02-01T04:22:37Z,1161,*Great video! Even the IBM staff suggested watching this video to complete a part of a course offered by them. Did you know? Congratulations!*,True
@fazalmehmood6802,2020-01-31T01:28:34Z,0,"Hi, can you please make a video on dynamic web scraping ?  :)",True
@deojeetsarkar2006,2020-01-30T09:08:41Z,0,Can someone tell me where my csv file is stored if I'm using idle??,True
@sobo5476,2020-01-29T10:34:40Z,0,"Followed the tutorial but used a diff web-page that contained special chars, if the page you are scraping has these then it won't write to the csv file, in this case you can update the code to say csv_file = open('cms_scrape.csv', 'w', encoding='UTF-8'), I'm still learning but this lets the data be written to a csv file.",True
@oseliocandido1807,2020-01-29T04:06:26Z,1,Your videos are great and they are helping me a lot these days. Keep the excellent job!!,True
@ankushsingh3354,2020-01-27T16:42:38Z,0,"Great video for any class of learner, this was my introduction to web scraping and I feel little confident to scrap few datas from websites. Thanks a lot .",True
@sachin-chaurasiya,2020-01-24T14:20:15Z,0,in this video you have only scraped the  one page. but if I want to scrape all the pages on your site what would I do?? pls reply:),True
@nitzkit,2020-01-23T03:06:59Z,0,"Thank you so much for the video, for whatever reason I forgot to not use "".text"" to see the HTML code and it was a little frustrating a first but then I saw my mistake lol",True
@antoniobelancic9498,2020-01-22T19:54:41Z,1,"You are a great teacher, thanks very much for this video !",True
@jackfrost8969,2020-01-22T12:40:50Z,1,still this is the best tutorial,True
@kitty6,2020-01-21T23:44:45Z,1,"Excelente tutorial ( excellent tutorial thanks)",True
@CodeWithRafiq,2020-01-21T18:48:56Z,1,"Thank you very much for this wonderful video.. From  :   Bangladesh",True
@priyamvashi2187,2020-01-21T12:12:40Z,0,Thank you so much  <3,True
@danielmarsh5282,2020-01-18T13:35:09Z,0,"probably not going to get a reply, but im using a rasbery pi, when i try to pip install any of these i always get an error... I dont know whythis is happening",True
@pravinbagul5305,2020-01-18T06:16:49Z,2,Thanks Corey for making my python journey very simpler with your tutorials!!!,True
@saikiranedits802,2020-01-16T12:34:28Z,0,‚ù§ from Indiaüòä,True
@ashokramuni4427,2020-01-16T09:37:47Z,0,How can we scrape next pages in the website,True
@byom.cybertechie,2020-01-11T18:56:50Z,1,It was really an excellent video. Thank you:),True
@antonsujarwo2369,2020-01-11T08:59:37Z,0,"please help me, is anybody in here have a video tutorial link on how to extract data from webisite that required username and password for login. i am an admin of such website and i want to extract all the name, phone number, citizen id and email from that website to excel??? many thanks before",True
@Radiohead305,2020-01-08T19:50:21Z,0,Can someone explain to me how I can prevent '\n' from appearing when I try to print the output? Thank you.,True
@robo9798,2020-01-05T23:18:06Z,0,"I've really enjoyed your tutorial but your editor markers has give me 30 mins of work/depression, just because I wrote (at 9:40) '_simple.html_' instead of 'simple.html' and (at 10:06)  '_lxml_' instead of 'lxml' just because there was underlines under the ' ....",True
@mdkaifkhan4445,2020-01-05T09:49:14Z,1,You have taught to scrap data from first page of your website. How to scrap data from entire pages of your website,True
@maicomcoelholopes9032,2020-01-03T01:55:23Z,3,"Corey muito obrigado eu sou brasileiro, seus tutoriais s√£o excelentes e me ajudam muito, principalmente porque n√£o tenho dinheiro para comprar  cursos, muito obrigado",True
@unknown-bc3uh,2020-01-02T17:56:49Z,0,"Hi, Thank you so much for this useful tutorial. I was looking for exactly what you mentioned here.",True
@drinkingineasterneurope6947,2019-12-31T19:39:17Z,0,"I very rarely comment or like vidoes or even subsribe to channels. But Corey man you are doing great work. I learn alot of good practices and alot of stuff for python. I really enjoy your channel and i like every video. I can support only with likes, shares and subscrition for now. Please make a video about all your ideas that you have you wont get wrong. I enjoy everything that you make, its very usful when trying to learn python. I know its a good day when i am searching for a topic and see Corey Schafer video!",True
@zaheerhabib3967,2019-12-31T09:34:24Z,0,if we are using online Jupiter note book on IBM lab; how we can access this said file through there? please advise.....,True
@ferreiran1281,2019-12-30T16:26:46Z,0,"First of all I would like to thank you Corey for the best coding videos I found on YT. I just have a simple question , and ill explain it. I am trying to get data from big websites, but its not possible to get the html info by just look up in the codes for some keyword. Does this method only works with smaller websites?",True
@ankeshsingh2576,2019-12-29T19:24:33Z,0,"Great work, Must say, Helped a lot to start my NLP from your channel.",True
@JenPurple2022,2019-12-27T23:03:11Z,2,"Clear and easy to follow, best tutorials! If I learned from you at first, I would not quit due to mounted frustration and limited understanding of available tools.",True
@rodrigolumi,2019-12-25T19:36:27Z,0,Excellent video. Thanks,True
@rahuldas6777,2019-12-21T21:13:43Z,1,"Thanks, this was very helpful!",True
@mdempse1,2019-12-17T21:37:33Z,0,"Corey, at this part of the code: vid_src = article.find('iframe', class_='youtube-player')['src'] print(vid_src)   I get this:   Traceback (most recent call last):    File ""c:/Users/mdempse1/Documents/PythonTraining/mike.py"", line 16, in <module>     vid_src = article.find('iframe', class_='youtube-player')['src'] TypeError: 'NoneType' object is not subscriptable   I assume it has something to do with the class_'youtube-player'....or??? Stuck!   Thanks,   Mike",True
@deveshdatwani8696,2019-12-17T15:27:34Z,1,Good job at explaining. Much appreciated. I really feel the documentation online of BeautifulSoup is really weak and lacks clarity. I am facing a lot of issues while creating a project.,True
@AdmMusicc,2019-12-17T06:48:12Z,0,Why is the program giving me FileNotFoundError when I have clearly defined an html file in the same directory as the python file? Help! :(,True
@user-te7ei6yy6i,2019-12-10T08:19:46Z,2,"I'm viewer from Russia, your English speaking is very clear. Thx.",True
@vaibhavwadate1172,2019-12-09T10:32:50Z,0,"hey can i upload the video for, extract signature from body of emails. save the signature in csv file",True
@ssquare1,2019-12-06T07:34:09Z,0,"As Corey's website has changed little bit, i.e only the first article consists of video and rest , just the youtube link.  Here's a link will fetch all data on Dec 2019: https://ideone.com/DDZb1v",True
@JamesHahnII,2019-12-05T17:13:58Z,3,Been struggling mightily with BeautifulSoup for the past couple weeks. You cleared up a ton of confusion for me. Thank you!,True
@tomerharari633,2019-12-04T19:25:16Z,0,"Hey Corey, Great video and thank you so much. I'm having an issue with simply printing header tags. my code looks like this:  secondClass = soup.find('div',class_=""second_Class"") #second_Class is the name of my div   header_tag = secondClass.h1.a.text   #I have header 1 with an anchor tag inside it print(header_tag)   and I keep getting this error: AttributeError: 'NoneType' object has no attribute 'h1'  What am I doing wrong??",True
@jagadeeshsali711,2019-11-30T07:05:08Z,0,how to scrape of wepsite home page team page contact page,True
@ModatherAbozaid,2019-11-28T02:46:40Z,1,"Alslamu Alikum Mr. Corey, thank you for such comprehensive tutorial. I wish you would make a tutorial on using scrapy as well because i couldn't find a good one like yours on YouTube so far. I wish you all the best.",True
@koraironams4656,2019-11-25T22:24:05Z,0,Please help! If I want to input a word that exists on a website so it finds it and gets the number which sits near it(which changes every 5 seconds). how do I do that?,True
@pjmclenon,2019-11-25T18:13:41Z,0,hello it doesnt work i get no links for the vids in the csv file Lisa,True
@alextakele9652,2019-11-18T12:49:01Z,4,"Thank you, I am data science student from university of gondar,Ethiopia,I seriously admire you way speech,thank you for all you did!",True
@tiga1662,2019-11-17T05:15:06Z,0,yo what . editor you using?,True
@nigelblanchard5571,2019-11-13T15:59:21Z,0,I wandered if you had finally blocked access to public scraping your website ?,True
@nigelblanchard5571,2019-11-13T15:58:29Z,0,"Hi, Corey I am getting an error running this code on Windows10 in SLT as ""File ""C:\Users\nigel\AppData\Local\Programs\Python\Python38\lib\site-packages\bs4\__init__.py"", line 213, in __init__     raise FeatureNotFound(  bs4.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?"" I looked on Stack but cannot determine a fix? Any advice. it seems to be on line with - soup = BeautifulSoup(source, 'lxml')?",True
@mohanlpuri1,2019-11-09T11:41:26Z,5,"I have watched couple of videos on web scrapping with Python. This video is very clear, and pace of delivery and the example teaching of the author is excellent.",True
@soureachsak5027,2019-11-05T15:33:57Z,0,"Hello! I have one problem. I have written the code the same way as you do, but i try to scrape Wikipedia. There is no error, however when i inspect the page in the browser and make a side by side comparison with my result, there are many differences. It seems like some text are missing. In other word, it is not exactly the same. Why is that? Is it because of the parser?",True
@dennisasamoah2213,2019-11-01T04:46:03Z,1,Legend,True
@18nikhilchauhan80,2019-10-31T17:24:24Z,3,thank you so much. i got my first client just because of you.,True
@patrickduhirwenzivugira4729,2019-10-31T06:29:42Z,1,Thank you very much!!!!!,True
@sairamsubramaniam8316,2019-10-31T06:15:45Z,17,You are the best programming teacher I ever had.,True
@helenk852,2019-10-31T00:25:57Z,1,Very appreciated!  So clear.,True
@MrRegrog,2019-10-28T15:44:51Z,1,He does it again! Thank you,True
@samueltukua3061,2019-10-26T01:33:11Z,6,I started watching your videos years ago and I was afraid you wouldn't be around when I returned from my programming hiatus. Thank you for still being here!,True
@Romaiing1,2019-10-23T12:40:22Z,0,I have a problem with this site: www.leboncoin.fr I can't scrap whatever the media i use. Do you know why ?,True
@idrishchy4025,2019-10-21T19:59:28Z,0,could you explain how to access the following all paragraph      <div class=main>    <div class=another-div>   <p>paragraph content </p>  </div> <p>p content </p>   <p>p content </p>  <p>p-content </p>    <p>p-content </p>           </div>    I want scrape all the paragraph text inside main div,True
@CoolZikri08,2019-10-21T18:09:00Z,0,"Just an awesome vid as always, Thanks!  while working on this project with SublimeText 3 on Windows and opening the CSV file with Excel I encountered a small problem when there was an extra line between the data, after googling it I found out that we should add ""newline=''"" after opening the CSV file. it should look like this  csv_file = open('cms_scrape.csv', 'w', newline='') as noted in the stackoverflow question it only happens in Python 3.",True
@jamesreichert,2019-10-18T07:29:22Z,1,Great video. Thank you!,True
@balrajashwath98,2019-10-15T11:27:53Z,1,"Simple, crisp, clear and brilliant!",True
@stanleyjohn4670,2019-10-15T04:56:36Z,1,"At 31:40: When you want to receive the id from the string; instead of using a split method, is it okay to do it like this?: for i in vid_id:  if i == ""?"":   index = vid_id.index(i)   print(vid_id[:index])   break   I know that your method is easiest and convenient but is there anything wrong with this method of writing?",True
@mattiapapa8097,2019-10-13T10:35:04Z,1,"Man thank you so much, this video was enlightening!",True
@stanleyjohn4670,2019-10-12T14:23:49Z,0,When does a person usually use a web scraper? I mean in terms of practical sense. Why do I need to scrape someone else's or my own site for information?,True
@muhee80.,2019-10-12T11:56:27Z,1,Hello hi,True
@bishwasbh,2019-10-12T04:19:23Z,0,"If you enduring through an error of *BeautifulSoup User Warning*, just have a check here: code.neptechofficial.com/python/how-to-get-rid-of-beautifulsoup-user-warning",True
@maximiliancynke3920,2019-10-09T09:26:51Z,1,Very helpful vid :^) !,True
@andrenevares7543,2019-10-07T03:17:43Z,0,"Sorry .   I am a newbe... Anyone has this problem?      vid_id = vid_src.split('/')  TypeError: 'NoneType' object is not callable.   Visual Studio Code do not recognize this",True
@andrenevares7543,2019-10-07T03:14:54Z,2,"Hello.... I a from Rio de Janeiro, Brazil...  You are the best of the best!  You rock!!!!  Thanks to sharing with us?  I want to contribute with you.   Can u get in touck please?  It¬¥s gonna be a pleasure.",True
@ziadammouri7789,2019-10-05T16:58:52Z,0,You are awesome man with the way you teach! You should write a book using python the impressive way! I have a question can you show us how to data scrape a website need username and password .? Thanks,True
@Yarrney,2019-10-04T13:53:53Z,1,Thanks corey,True
@elliottcarter7700,2019-10-02T18:45:10Z,1,I can always count on clear and concise explanations from Corey Schafer! Thanks!,True
@joeharyar9873,2019-10-02T08:13:37Z,0,"Hi Corey, first of all..thanks for sharing this tutorial. Your explanation clear and easy to understand. Full star for you. Good Job man... anyway...do you have video that show how to collect data from rest api, do some filtering/extract data and final send the clean data to flask html. If it is not available..I would like to request one...if you have the video please advise me...Thanks.",True
@saritaprabhu,2019-10-02T06:26:22Z,3,You're a legend! There's a lot to learn from you. üôá,True
@sreejithmunthikodu,2019-09-27T18:37:01Z,4,"If I want to learn anything in python, I always search for Corey Schafer  on youtube and never  had to look beyond that!!! Really appreciate your great work!",True
@appliedstatistics2043,2019-09-26T11:18:33Z,2,"simple and fast, best tutorial ever. Now I'm trying to scrape the IMDb review for text mining",True
@myyoutubechannel2858,2019-09-26T05:12:05Z,1,Thank you Corey. A *simply fantastic* tutorial.,True
@Mohib3,2019-09-25T17:42:02Z,0,how can i get requests in atom. I have it installed but it won't work. Works perfectly on IDLE,True
@azusapink,2019-09-24T20:57:21Z,0,Does he have one where he extracts a zip file?,True
@ArmorBearerSlave,2019-09-12T22:49:59Z,1,Excellent!,True
@acidaioli3579,2019-09-12T17:16:45Z,0,"When exporting to .csv, I get a .TUTORIAL file instead. Anyone knows how to fix this?   Great video!",True
@xoxUnD3R0aThxox,2019-09-11T02:09:08Z,0,"How can I retrieve the fasta sequence and the length of sequence from this page:   https://phytozome.jgi.doe.gov/phytomine/portal.do?class=Protein&externalids=Cre35.g759247.t1.1",True
@vishalverma-wx7eo,2019-09-09T11:51:50Z,0,"I can't parse the full HTML from the website https://www.machinehack.com/course-cat/practise/. I am using lxml parser, but when I opened my beautiful soup, it contained incomplete HTML, i.e. not all articles were covered. Infact, only 1st article was covered and rest were missing from the HTML. Can you please tell how to solve this issue ?¬† Thanks",True
@imadoulhou7854,2019-09-09T01:08:57Z,1,tnx,True
@keshav5944,2019-09-08T12:38:55Z,1,Very nice video,True
@sthitaprajnamishra9831,2019-09-07T08:35:32Z,0,"Start at 8:35 if you want to skip the intro, a mini HTML tutorial and installation of the packages.",True
@rverm1000,2019-09-05T23:34:49Z,0,the video is  outdated. had to add from (from bs4 import BeautifulSoup) to get the first ten minutes of the video to work with no errs in the code but it return nothing. no website headers or body.,True
@jagjeetrandhawa1731,2019-09-03T10:53:52Z,1,Thank you,True
@orpat007,2019-09-01T18:56:07Z,1,Nice information packed in a lecture under a hour.,True
@susanthahettiarachchi2642,2019-08-30T10:32:46Z,0,pip install bs4 works too.,True
@zackeryhatch436,2019-08-25T03:22:37Z,0,How can you use this terminal in windows?,True
@valivalizada,2019-08-24T16:38:45Z,0,Can we get from all news websites? please reply,True
@pulkitsharma3148,2019-08-23T06:46:25Z,1,thank you so much corey,True
@aytekinozhan7554,2019-08-21T09:03:36Z,1,"Corey, You are awesome. :)",True
@sarasaber1827,2019-08-20T10:59:16Z,2,great great great,True
@sudheerveturu6068,2019-08-20T07:16:11Z,1,This is exactly what I was looking for. Thanks mate!,True
@acuencadev,2019-08-16T16:53:10Z,0,"This is pure gold!  Said that, I did not like your approach to get the YouTube video Id. I used regex instead as it is more efficient and clean. If anyone is interested find the code below:  import re video_id = re.search(r‚Äùembed\/(.*?)\?‚Äù, video_src).group(1)  Cheers,",True
@SerenityNow_4K_3Dsound,2019-08-16T04:16:43Z,1,Thank you Sir!,True
@haoli4164,2019-08-14T04:11:13Z,0,"Thank you so much Corey!! This is definitely the best! But I do have one question-- when I tried to save the scraped headlines, summaries and the video links into a csv file like you did, it gave me blank rows in between. So I get 21 rows (11 + 10 blank ones) in my csv file. I work in Windows so I don't know if that is the reason.",True
@deepakpratap3792,2019-08-12T09:41:09Z,1,Hey @Corey Schafer...It's a great video...I learned lots of here...I am wondering the scraper give us result for page 1 only...is that possible it can scrape all pages in a site...Please provide some advice or any link so that can be helpful..Cheers :) Thanks a lot again..,True
@chitowndev,2019-08-12T08:28:22Z,1,Amazing video! Gave me some insight on a project of my own! Thank you !!!,True
@woundedhealer8575,2019-08-11T05:48:45Z,0,Is it possible to have a program find out how many people visit a certain web page that you don‚Äôt own?,True
@TaskSwitcherify,2019-08-08T18:37:06Z,0,Wouldn't it be MUCH more exciting to start the video with scarping sale prices or discounts from another website?..,True
@senseibunny3667,2019-08-08T15:13:06Z,1,thx very good video with nice explanation!,True
@jitendraraghuwanshi1365,2019-08-05T14:45:51Z,1,I OWE YOU MAN BIG TIME,True
@adebayooladipo859,2019-08-04T19:36:34Z,1,"Good job, bro!",True
@pawanblaze7439,2019-08-03T09:02:30Z,1,How can I scrape from a website with multiple webpages? The webpages have an identical template.,True
@rakeshkumar10,2019-08-02T14:23:58Z,0,"Thank you very much corey. Due to this video, I am able to build my first web-scrapper. How can I scrap the whole website? Do you have any idea how to do that?",True
@Ultrakicks,2019-08-02T02:51:17Z,1,This was a wonderful video that helped me understand the basic of web scrapping with Python. Thank for you so much for the in-depth tutorial!!,True
@amitanand9125,2019-07-31T17:09:39Z,2,Corey Schafer : I don't know if Python is easy or you made the Python Learning very easy.I did watch almost all your videos till date and refer my friend to do so. Thank you for making our live easier with such a ease of learning,True
@arafat_ar13,2019-07-30T07:50:12Z,0,Your videos are just so high quality and easy to grasp. Thanks for these. But I had a question. Can you explain what are CSS selectors? And how they might be used?,True
@ElliyahuRosha,2019-07-29T14:19:03Z,1,Perfect!,True
@shilpapatil1012,2019-07-24T06:04:53Z,0,Below is also a great article on Web Scraping using Python & Beautiful Soup and what we can do with scrapped data. Complete Source Code is also provided. https://www.opencodez.com/web-development/web-scraping-using-beautiful-soup-part-1.htm,True
@alimansour3626,2019-07-23T21:56:48Z,1,"First let thank you for precise and great explanation for all the subjects you have covered. I have a question too! regarding beautifulsoup4. I am looking at a website that has three divs with the same name, how can I skip over one and choose the second or skip over the first two and choose the third one. Thank you again.",True
@Metachief_X,2019-07-19T00:44:09Z,0,"hey corey, can you make a video for scraping pdfs?",True
@amysandstrum531,2019-07-18T17:50:30Z,3,"Thanks! I have very limited knowledge of html but was able to scrape price information off of websites. Just for funsies :D  Really, all i did was tweak it and instead of div they use span class, so i switched 'div' with 'span' and got the same result.",True
,2019-07-16T09:20:26Z,1,"clean, simple, direct, effective. a bitchass tutorial. thank you.",True
@fabiomachado3961,2019-07-16T01:28:35Z,0,"Este foi o melhor v√≠deo de web scraping que assisti em todo o YouTube, explica√ß√µes simples, diretas e eficientes. Muito obrigado por compartilhar!",True
@qianlima2196,2019-07-16T00:44:39Z,19,"I spent 1 hour to figure out why my outcome is different from yours, then I finally realized it's because your website content has changed!",True
@rverm1000,2019-07-13T20:49:13Z,0,"<!DOCTYPE HTML PUBLIC ""-//W3C//DTD HTML 4.01//EN"" ""http://www.w3.org/TR/html4/strict.dtd""> <html>   <head>    <title>     This domain may be for sale    </title>    <meta content=""This domain may be for sale"" name=""description""/>    <meta content=""domain for sale"" name=""keywords""/>   </head>   <frameset border=""0"" rows=""100%,*"">    <frame frameborder=""0"" src=""https://form.jotform.com/81154656345257""/>   </frameset>  </html>    Traceback (most recent call last):    File ""untitled1"", line 15, in <module>      summary = article.find('div', class_='entry-content').p.text  AttributeError: 'NoneType' object has no attribute 'find' not sure why it does this",True
@jeffreyzhao9156,2019-07-12T23:52:58Z,0,why not use a with as statement for writing the csv file?,True
@mtsalis31,2019-07-12T15:42:49Z,0,what about detecting if an alert is shown to the web and I want to get the text from the alert (javascript alert)?,True
@rockybhai-cn3qw,2019-07-12T03:13:21Z,0,Sir I am using your website for scrapping. I am your student sir. please don't take any action.,True
@imtiazshahed944,2019-07-11T17:45:35Z,0,nice video. I like this. Would like to know some field where we could apply this scrapping tech. and secure the job. Thank you for the video,True
@robinkh6017,2019-07-10T12:23:21Z,0,Not very easy to follow this example when it involves simple.html which we do not have access to,True
@mohaham9864,2019-07-10T00:20:34Z,1,very very informative thanx alot,True
@youngstar3426,2019-07-08T23:05:54Z,0,How would you get an image from a website?,True
@princeps656,2019-07-06T16:40:48Z,0,"sir i am trying to get <div class = ""col-xs-12"">  from this website       ""https://www.gartner.com/reviews/review/view/634478""  and i tried    response = requests.get('https://www.gartner.com/reviews/review/view/634478').text   soup = BeautifulSoup(response,""lxml"")   article = soup.find('div' , class_ = 'col-xs-12')   but i am getting NoneType object please help!",True
@Adamattia1,2019-07-06T07:09:04Z,0,"Thank you so much! Hope I didn't ping your website too much while following around with this tutorial, was a massive help :)",True
@AymenLagha,2019-07-06T00:13:46Z,2,when I was here 25:10 I was like that's not the headline that I got then I realised that he updated his site and then I just felt stupid lol,True
@varunkulshrestha647,2019-07-03T19:33:20Z,0,sir i tried to convert your website data scrapped into  csv by i am getting an error in the corey.csv file as web scraping/corey.csv is not UTF encoded saving disabled see console for more details,True
@jenkatan7113,2019-06-29T22:06:02Z,0,"Thanks for the thorough explanation. I'm a noob that just discovered your videos, instant subscribe.  I'm using this to scrape data from my tumblr. The url changes anytime I navigate to another page. is there any way to scrape the entire thing without changing the url to website.com/page/2.../page/3....etc",True
@amitjajoo9510,2019-06-29T17:49:18Z,1,thx sir for th8is beautiful content,True
@samha1513,2019-06-25T18:50:28Z,0,Great work as always. But how can you interact with the webpage to go-to the next page? I have tried selenium but it's pretty slow. Is it possible to use the request lib to click on the links? Thanks,True
@yeyzon,2019-06-24T21:40:46Z,1,"This is great, thank you!",True
@TeddyTheBigTeddyBear,2019-06-24T03:00:53Z,0,Maybe this would help to understand everything about scraping https://websitescrapingtutorials.wordpress.com/2019/06/23/how-to-scrape-yelp/,True
@lawrencekrukrubo2640,2019-06-23T22:15:43Z,3,"This is just amazing, your knowledge, no your practical knowledge is amazing",True
@env0yw576,2019-06-22T14:10:41Z,0,how  to get the site need Login firstÔºåthanks alot,True
@storyfactory1603,2019-06-22T08:33:14Z,0,I want to scrap youtube video subtitles can u help me,True
@kanika724,2019-06-19T10:56:13Z,3,Corey a Big Bow from India..... really you are too amazing,True
@patrioticghanaian1883,2019-06-19T04:19:36Z,2,"Great tutorial as always. Just one issue though: I encountered an encoding error looking like this:  UnicodeEncodeError: 'ascii' codec can't encode character u'\u2013' in position 29: ordinal not in range(128) I solved that by using the encode(utf8) to encode the html text to utf-8 format like this:  #For the headline headline = article.h2.a.text.encode('utf8') #For the summary summary = article.find('div', class_='entry-content').p.text.encode('utf8')  The rest is the same! Keep up the good work man!",True
@rohithp9774,2019-06-17T06:57:42Z,0,why can't we scrape complete amazon page without headers?,True
@chaos299909,2019-06-15T08:09:07Z,1,"I used requests and BeautifulSoup to write a python script, that allows you to scrape all historical data of a cryptocurrency by simply putting in the name of currency. https://github.com/gitFaisal/crypto_currency_scraper",True
@talbarak8861,2019-06-14T07:45:24Z,0,"When trying this in Visual Studio Code, I got ""no bs4 module could be found"". So, I used ""pip install bs4"".",True
@aryanchauhan8066,2019-06-13T11:40:16Z,1,"thanks, man through this I am able to scrap live cricket scores  from cricbuzz.com",True
@manisrujan2545,2019-06-13T10:12:04Z,0,"I have a doubt why does sometimes,the downloaded HTML file using requests look different from code in inspect elements ?",True
@lardosian,2019-06-12T20:58:04Z,0,Is this an alternative way of getting data as opposed to an API for example?,True
@akshaybhadange2492,2019-06-10T21:11:16Z,1,thanks sir very helpful,True
@nickgibra1861,2019-06-08T22:11:48Z,2,Thank you very much for this tutorial. Your explanations were better than some courses and books that I tried. Thank you again.,True
@TheDevilOfJesters,2019-06-07T13:23:38Z,1,Thank you so much.   You answered several of my questions and literally saved my ‚Äòavoiding boredom‚Äô project,True
@harshitkhandelwal707,2019-06-04T15:27:14Z,2,"East and West, Corey Schafer is the Best!",True
@virtualreality9377,2019-06-04T12:23:01Z,2,Thanks man.,True
@carlosmatosfanpage2856,2019-06-03T23:06:43Z,1,Is this legal,True
@mggarekar,2019-05-30T23:13:01Z,1,nice,True
@avinashkumar4229,2019-05-29T19:58:01Z,1,thanks a lot,True
@skhanal123,2019-05-29T17:19:12Z,1,Thank you for making this video. It is really easy to understand web scraping for beginners with this video.,True
@alikisultanate,2019-05-27T20:07:09Z,2,Corey.. after watching this scraping tutorial.. im more liking these scraping techniques.. You are an Excellent Tutor :),True
@shazkingdom1702,2019-05-27T12:30:46Z,1,""" üòÆ üòâ üëå üòÆ üòâ Beautiful üòÆ üòâ üëå üòÆ üòâ """,True
@ramtube,2019-05-26T09:23:54Z,0,Thanks A Lot,True
@IamKhoramdin,2019-05-20T17:30:25Z,1,WOW,True
@gfplatinum,2019-05-19T23:43:00Z,1,"Excellent video, very helpful and easy to follow. Many thanks!",True
@Tashik19,2019-05-18T19:07:47Z,1,Awesome! Thanks a lot!,True
@imtiazshahed944,2019-05-15T23:41:00Z,56,"Corey Schafer Thanks a million. best tutorial I have ever seen on Web Scrapping in Python, No one explain like you in a very single point of code. That's how we learn. great job and keep it up.",True
@maxkiley3369,2019-05-13T03:29:36Z,1,Your a great teacher,True
@oguz-kagan,2019-05-11T12:21:39Z,0,"HELP! couldn't seperate columns. it just shows commas between headline,summary,video_links. Anybody ? i guess it's because of old version excel :/",True
@oguz-kagan,2019-05-11T12:01:17Z,0,thank you so much!,True
@gravmagsuite1788,2019-05-08T17:59:18Z,0,I've tried in some urls and i've got some errors...,True
@deboparnabanerjee4185,2019-05-06T20:27:17Z,0,"how to scrape if even the class is same, no other detail is given and it is under the same tag?",True
@harshshah552,2019-05-03T20:33:07Z,0,"Hi, can you also post a tutorial about how to use the public APIs you mentioned in the end?",True
@Humanstartups,2019-05-01T04:58:26Z,0,"I have an excel code below that scrape morningstar for apple financial information, so I can I convert it into python? Thanks   =arrayformula(SUBSTITUTE(SUBSTITUTE(SUBSTITUTE(SUBSTITUTE(SUBSTITUTE(IMPORTHTML(""http://financials.morningstar.com/finan/financials/getFinancePart.html?t=AAPL&region=usa&culture=en-US&ops=clear"",""table"", 1), ""<\/td>"" , """" ),""<\/tr>"",""""),""<\/th>"",""""),""<\/thead>"",""""),""<\/span>"",""""))",True
@musicquotes5357,2019-04-30T09:03:51Z,0,Any sample websites to work with just to learn and explore more.... Almost every website deny scraping their website..,True
@maraffio72,2019-04-30T01:40:58Z,0,"Great video. Thank you. I am wondering if there are any specific techniques to scrape websites which include dynamic content generated by interacting with user input (e.g. search text, drop down cells)",True
@SaiKiran-ti6rv,2019-04-29T08:41:34Z,0,"Hi Corey, can you make an extended version to this video by caching the requested data and storing in various formats such as python dict, databases and other",True
@NeBueR4U,2019-04-25T01:54:46Z,2,"I just loved the way you explained every bit about this topic. Crisp, clear and to the point. :) I have subscribed your channel for more content.",True
@efqanmustafayev5189,2019-04-24T12:24:36Z,3,"Thanks for video, sir.     How we can scrape login required websites?",True
@nibernator,2019-04-23T04:50:12Z,1,"Can anyone help me?  I tried running the code but I get this error: bs4.FeatureNotFound: Couldn't find a tree builder with the features you requested: lmxl. Do you need to install a parser library?  I installed all the pip stuff in the terminal before running... I don't understand. (I'm on MacOS and Python 3, and all the pips installed just fine.  I tried this on Python 2.7 and this doesn't work either.",True
@tashdeepsinghsaluja5120,2019-04-22T12:28:22Z,0,"This tutorial was based for scraping a single web page,do you have any tutorial regarding scraping the whole website? It would be a huge help if you reply.Btw thanks this video was helpful too..",True
@rickgateiro,2019-04-21T02:45:57Z,1,your video saved my life! thanks a lot!,True
@majmulBahrain67,2019-04-16T20:40:01Z,1,Great video very helpful !,True
@Unifono2012,2019-04-16T19:02:39Z,1,amazing. thanks so much!,True
@catherineliu1850,2019-04-14T23:55:02Z,1,Great thanks for your share. It is very detail. I can watch it again and again.,True
@cw9249,2019-04-12T17:43:11Z,1,you are incredible at teaching in a way that helps people understand,True
@arnelseco6429,2019-04-12T06:44:33Z,2,"I watch the video till the end, the explanation is very clear and easy to follow. Thanks Sir for this educational video. GodBless",True
@huzailjamil5240,2019-04-10T12:31:25Z,0,How can i change this code to scrap data from whole website link email address for leads ? For example i've a website with email and these emails categories by the city ? is there  a way to search all the page of a website to get the email instead of manual approach?,True
@johncorcoran8666,2019-04-08T13:39:37Z,0,thank you for the great video. is beautiful soup compatible with Spyder & if so how do I install it?,True
@harystore6691,2019-04-06T00:47:13Z,1,Excellent video very good way to explain,True
@prabav86,2019-04-05T12:03:00Z,1,"Hello from Canada! I've been impressed with the way you teach Python and related subjects. So I was referring/recommending your youtube videos to my friends. Recently, I'm finishing up online course on Data Science from IBM, I was pleasantly surprised that course recommended your video on webscrapping! All your hard works helping a lot of folks out there. Simply outstanding! take care",True
@alexpaes9161,2019-03-31T16:33:13Z,19,"It could be possible to hit ""like"" twice for ur videos! Mate, ur a legend! Congrats!",True
@MC4IOSgamer,2019-03-30T18:12:01Z,0,what if for a given class there are multiple <p> 's how would I approach this?,True
@shyambhumukherjee3616,2019-03-30T16:29:56Z,0,visit https://shyambhu20.blogspot.com/2019/01/web-scrapping-things-you-will-not-know.html for learning web scraping in details with python codes snippets available.,True
@balasubramanian4314,2019-03-28T22:59:04Z,2,ONE OF THE BEST DEVELOPER I HAVE EVER SEEN in this planet! Hats Off to your skills!,True
@triptijain2139,2019-03-28T18:34:58Z,1,you are an awesome teacher,True
@saiprasadhakki,2019-03-25T07:00:28Z,0,Python 2 or 3????,True
@Nearco1000,2019-03-21T21:13:23Z,11,"Just curious about those 34 slackers that did Thumbs down on this vid, seriously?.  It's very clear and straight forward, plain English, highly understandable .......................Thumb up.... Very appreciated #Corey, I was looking for this, great vid, again and again tku for your contribution.",True
@JethroYSCao,2019-03-15T23:01:07Z,0,"Corey, why aren't you using conda instead of pip to manage your packages? I see you have anaconda installed. Plus conda takes care of managing python environments for you too, so you don't need to use things like venv anymore either.",True
@italianstallionboy,2019-03-14T19:40:08Z,0,"Hi, thank you for this v helpful video! One question I hope you might be able to answer - despite import csv the module 'csv' has no attribute 'writer'. I am using Pycharms and have searched around but unable to come up with any solutions apart from search and rename any 'csv.py' file in directory (which i have done). Anyone please able to help?",True
@shubhamsaxena4548,2019-03-11T18:57:32Z,0,How to scrap LinkedIn data using python,True
@themustknowfacts510,2019-03-10T04:33:47Z,0,How can we do the YouTube video scraping?,True
@classicguy7813,2019-03-08T19:21:15Z,0,Can you make a quiz app through Flask web application or how to use best python on web?,True
@lucaslau8379,2019-03-06T15:37:42Z,0,"<td class=""dojoxGridCell"" idx=""3"" role=""gridcell"" style=""width:40%;"" tabindex=""-1"">                LOWER GROUND FL. PLAN </td>   if it's like this how to I scrape only the text?       I tried:  drawing_no = article.find_all('td', class_='dojoxGridCell', idx='3')  print(drawing_no)",True
@frankconte2457,2019-02-28T17:20:10Z,0,"As always, I appreciate your great videos. I'm happy to be Patreon patron! I was wondering if you could help me with an issue. Using this tutorial as a model I tried to scrape code on my own website. However, even after closely following you, I could not replicate your python script. Here is the code I am trying to scrape (particularly, the elements ""h2"", ""pbanner"" and the link which is  served from the class ""button big""   <article data-position=""left"">       <div class=""inner"">        <img alt=""BPDNewsHEROTobin"" src=""Archives/History/HERO2-13-19c.jpg""/>        <h2>         BPD remembers the service and sacrifice of Officer Charles E. Deininger        </h2>        <p class=""pbanner"">         Killed in the line of duty on this day, Feb. 13, 100 years ago        </p>        <ul class=""actions"">         <li>          <a class=""button big"" href=""http://bpdnews.com/news/2019/2/13/bpd-remembers-the-service-and-sacrifice-of-officer-charles-e-deininger-killed-in-the-line-of-duty-on-this-day-100-years-ago"">           Read more          </a>         </li>         .        </ul>       </div>      </article>  ''I get good results with the folllowing code (based on yours) #headline = article.h2.text print(headline)  banner = article.find('div', class_='inner').p.text print (banner)  buttonLink = article.find('ul',class_='actions') print (buttonLink)  What's giving me a problem is the split method that follows. I can't seem to determine how best to split the webpage data. I get a nonetype object is not callable error. Any advice is appreciated. The most recent Requests tutorial was most helpful in learning how to pull data.",True
@SurajSingh-tz1wr,2019-02-27T11:54:59Z,2,Thank You Very Much!! Love from India!!,True
@tarungarg2695,2019-02-26T17:56:57Z,0,Thanks For Such an awesome Video !! very Well explained. One question though. The output CSV file came for me is having one empty row between two row contains information. How can I solve this?,True
@parveenmann7813,2019-02-24T15:10:27Z,1,nice Mr. Schafer its really informative,True
@koushikahamedkushal,2019-02-23T19:01:24Z,1,very very very nice video.,True
@psyche2739,2019-02-22T08:30:46Z,1,Damn! I have learned a lot and the English is so clear. Your method the way you teach is awesome!. Thank you so much! :),True
@manishkhanna76,2019-02-22T05:07:13Z,0,"Your articulation and presentation is impressive. It really inspire on how one should teach.   About the topic, I feel that getting the video id from the URL could also be done as follows -  #Step 1 - Split source URL on '?'  ### This will give us only 2 elements. And we know that the video id will always be in first  #Step 2 - Split the first element from Step 1 based on '/' ### Here we know that the video id will always be the last element  # IMO this could relieve us from counting and hard coding the indexes.  v_id = v_src.split('?')[0]                                          #Step 1 v_id = v_id.split('/')[len(v_id.split('/')) - 1]            #Step 2",True
@rb8058,2019-02-18T17:06:12Z,4,Great introductory information! Would love a similar one for how to scrape javascript rendered websites!,True
@bobjime510,2019-02-14T13:04:42Z,2,thank you brother  ilove u,True
@leosimon1746,2019-02-13T19:22:18Z,2,I have to say you did a great job! You covered pretty much everything that a novice programmer needs to know about scraping. I immediately developed my own solution after watching the video. Thank you so much!!!,True
@musarathjahan5095,2019-02-09T03:32:19Z,1,"Thank you for this wonderful video. I have ben struggling to get data through web scrapping, and was successful after watching this video.",True
@Hephasto,2019-02-08T11:34:43Z,0,beautiful soup.. wtf who the hell figures out such dump namings in IT.. great tutorial though,True
@pankajkumar-dm9ys,2019-02-02T06:58:10Z,0,I have  to find the 5 app I'd and app name from Google play store how can I get the HTML source code???,True
@1harru,2019-02-02T06:05:00Z,0,"Thanks for this video Corey.. I love your teaching....  Can you also make a video on how to scrape from websites that load data dynamically (Ajax + JS), covering 'infinite scrolling', 'load more' pagination... I'm not able to find the right tutorial/blog post... Would be very helpful in future... Thanks again for all your videos and keep uploading good content...!!",True
@robertlee9761,2019-02-02T04:50:32Z,2,"Superb tutorial, by far one of the best explained BeautifulSoup tutorials to date. Thank you Corey.",True
@gameexplorer9213,2019-01-28T03:47:36Z,1,Great quick tutorials,True
@W00IS-J,2019-01-23T02:29:35Z,0,"Corey, thanks for the vidoe. I am a complete newbie but wanted to just copy what you've done and learn from there. I, however, get an error message after copying the codes on the 20 min 50 sec mark on the video. First of all when I run the file it's displaying a different web site address and then saying 'AttributeError: module 'requests' has no attribute 'get'. What would be causing this problem, you would know?",True
@gokuls4048,2019-01-22T05:04:29Z,0,Anybody knows how to scrap the  physical file to get downloaded  during crawling.?,True
@emekaorji2312,2019-01-20T18:09:36Z,0,"Please how did you come about the title ""simple.html"" am asking because the wikipedia page am to scrap data from is given to me as an url link. what should I do?",True
@allahakbar9580,2019-01-18T00:00:03Z,5,"Such a beautiful and comprehensive explanation!  I liked the idea that you started from the simplest things, like scraping a small HTML file, not an entire website! Because that what I could not find in the many videos I watched about BeautifulSoup, they jump into the deep straight ahead!",True
@trouserpython3857,2019-01-17T08:14:49Z,2,Fucking excellent video!,True
@jarodmorris611,2019-01-16T05:07:30Z,0,"How fast can you roll through a list of URLs?  100 / min?  500 / min?  How do you balance getting the data as fast as you can, but not trigger a server thinking you're attacking it?",True
@jiamingqu1644,2019-01-13T21:07:51Z,1,"great video, thank you",True
@user-ex6pk6fh4p,2019-01-09T12:58:52Z,3,"Thanks, man. You're great! Everything is clear for the beginner like me.",True
@user-gx9hk8gt3k,2019-01-09T11:06:25Z,0,Python 2?,True
@edtix,2019-01-06T06:01:22Z,0,What if the site requires login? I need to scrape my earnings from auction portal but it obviously requires login... Unfortunately the site has no API :(,True
@colinburgess4316,2019-01-06T02:43:52Z,0,"I use coderunner on my mac and cannot import beautifulsoup, or really any libraries, even they are on my computer. I am also having difficulty using the pip command. Any advice?",True
@rahulparmar208,2019-01-02T17:00:57Z,0,How to use those public api to scrape,True
@MrAKGarg007,2018-12-30T09:35:58Z,0,"Hi, Big Thanks for this tutorial, really saved my days and tons of searching. Just one thing to ask -> At 45:08, you said they even block your program, I think they block our IP address or something else? - Just for educational purpose.",True
@HarishS12137,2018-12-26T09:32:16Z,0,how do we do the same for multiple pages? rather than going one by one?,True
@harrisonhobs1130,2018-12-26T03:27:07Z,0,"Thanks for this wonderful tutorial, I really got everything. I have a question though. This was done with your site's html design. I just would like to know how to go about it on a site that doesn't have an article header, but instead just has mutiple div tags. What then should be done?",True
@TmanD54,2018-12-21T05:21:52Z,0,"any idea why when i write to my csv file, it skips are row? so A1 would write, A2 is skipped, A3 writes. very strange",True
@svmathtutor,2018-12-20T20:40:53Z,0,"At 16:22 how did you get the menu item Tools to flash? I'm assuming you used the shortcut Ctrl + B to automatically do the Tools > Build step without moving the mouse.  I was wondering how we could run python without going to the terminal or clicking on any Run button.  How did you get your Sublime Text to flash whenever you use a shortcut so we can see which menu item flashes. Thanks Corey.  When I use the same shortcut Ctrl + B, nothing flashes.",True
@kimmag,2018-12-20T06:41:17Z,0,"Excellent video, I've learned a bunch! However I do have an issue with the CSV-file that was generated - it all ends up in one row comma-seperated. I tried to basically copy-paste your code into mine, but it all ends up rather plain text in one row and several columns. This is most updated excel in O365.  Do you have any ideas why this happen? Greets!",True
@akrammalek2561,2018-12-19T01:50:51Z,1,"amazing video, information, and amazing man",True
@KenPryor,2018-12-19T00:04:08Z,18,This was the first of your tutorials I've seen. I definitely subscribed after this great video. I've struggled with learning Python and this was very helpful.,True
@mankaransingh2599,2018-12-18T17:59:19Z,6,"Most professional guy on youtube, who dosent boasts to be know stuff.",True
@eyoba6027,2018-12-18T13:11:32Z,7,"My first video from your channel and it didn't took me long to press the subscribe button. You are just perfect, no second wasted. Every word is important and worth mentioning. Cheers!",True
@Radiant-hf2vh,2018-12-18T13:07:15Z,1,Crystal clear explanation,True
@bloom9191,2018-12-16T12:56:02Z,0,What should I do if there is multiple collums with the same name?,True
@edy3569,2018-12-13T01:00:49Z,0,Great video as usual.Excellent demonstration of parsing.One question:how would you do that to retrieve all that data from all the pages?I'm sure that you would put all that code in a for loop that would loop through all the pages.But how could you determine that number of pages without hardcoding it?I mean how exactly would you write that for loop?,True
@SergSolod,2018-12-12T18:05:11Z,1,Thank you for all tutorials! Great job.,True
@sacrifice666,2018-12-11T06:42:52Z,0,u are fucking robot :D,True
@vatsalaykhobragade,2018-12-07T04:49:02Z,0,please make a video on flask whooshalchemy. btw nice video.,True
@narmadhaanu1539,2018-12-06T10:43:40Z,0,"Any one can tell,  how to find number of occurrence of a particular word in a given website using python beautiful soup...",True
@codewithkolhar3131,2018-12-05T05:47:14Z,1,Corey you made my career from an absolute IT nerd to hardcore Python developer. Thanks to you. You are gr8. God bless you.  looking forward to learn Machine learning. It would be great if you make some videos on it. Thanks.,True
@codergun5880,2018-12-04T13:14:24Z,0,"help anyone, i want to use scrape data in django. for  eg, i want to scrape quotes of the day(that change every day)from website and use it in my own websites.",True
@samareshyadav9681,2018-11-30T10:41:05Z,0,I want to download files using scraping techniques,True
@razvanafloarei6256,2018-11-25T17:50:30Z,1,"How do I web scrape on Windows? I tried installing beautifulsoup, but I believe it's only for Linux.",True
@ahmedabdelmalek2379,2018-11-23T07:15:12Z,0,anything for Scrapy¬†?? :D,True
@Ace-nz2pd,2018-11-20T22:41:03Z,1,First video of watching your channel. Awesome explanation!,True
@yangfeng4801,2018-11-20T19:23:25Z,0,Your videos on Python are always super clear! I am wondering whether you can also generate some on scraping data from social media using Python?,True
@okaysidd,2018-11-18T09:06:36Z,0,"How did writing into the csv file just once worked? Shouldn't we need to write to the file everytime we  get a new Headline, summary and link? Using a loop?",True
@gravytrain666,2018-11-14T03:25:43Z,1,excellent video!!! thankyou so much,True
@SagiPolaczek,2018-11-11T18:51:42Z,2,liked before even watching... again!,True
@danielmerchad7402,2018-11-07T19:10:02Z,1,How are you so good at making me  watch all your videos??!!,True
@dp0813,2018-10-27T15:44:45Z,0,"Holy bejebus, dude.   This one video answered sooo many questions i had after trying to build a scraper & referencing 2 other tutorials.  SMH!  Can't wait to get home & fix my script based on this tutorial!  Thanks!",True
@TalSofer16,2018-10-23T14:46:13Z,1,you are the best!,True
@AliRadmehrir,2018-10-22T12:53:06Z,0,"if print(soup) cause an error, you can use print(soup.encode(""utf-8"")) instead",True
@farmakoxeris,2018-10-21T21:47:25Z,0,"Usually, http requests are sent through port 80 or 8080. What about other ports? I have a connection through a router and the port is different. In the web browser I have to type the IP and the port eg. 192.193.194.195:520. Can it work with Beautifulsoup?",True
@GoibniuNihiliste,2018-10-19T06:25:49Z,1,"what if there are multiple ,p. tags like, lets say 3 of them. and I only want to grab the text of he second ,p. tag in a paragraph",True
@stephenm6309,2018-10-14T01:26:09Z,1,This is great man thank you,True
@artazasameen4974,2018-10-13T18:55:50Z,0,"Sir, I am a great fan of yours. Because of you I learnt regular expression and more. Could you please add some videos on the tkinter module for gui programs and  how do we create freezed binaries out of .py files",True
@saurav0777,2018-10-11T09:54:25Z,0,"(Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1045)'))) i am getting this error can you please advise?",True
@jivneshsandhan1660,2018-10-09T15:10:25Z,1,Nicely explained. Thank you very much.,True
@darnaud3679,2018-10-09T11:24:03Z,0,Automate Everything with web bots! This actually made my life easier... https://simplestipsandtricks.blogspot.com/2018/10/the-power-of-headless-chrome-and.html,True
@paulzakey,2018-10-07T14:06:57Z,0,"im unable to scrape a website "" https://www.hackathon.com/city/india/bengaluru"" could u help me out with that it doesn't have a public Api",True
@nicholasmaloof8378,2018-10-02T15:50:44Z,0,"Do you have any advice on resources we could check out for web scraping responsibly? I want to use web crawling/web scraping for work, as my job sometimes involves a considerable amount of data entry. Also, any advice on how to properly read a robot.txt file? Thank you for the tutorial!",True
@nishanthchandrashekar1413,2018-09-29T16:07:16Z,1,"Beautifully explained man, thank you very much",True
@ln9808,2018-09-26T05:36:28Z,1,Excellent tutorial - thanks a lot!,True
@Skaxarrat,2018-09-18T09:18:09Z,0,Nice video as always Corey. Just a question: I've dabbled with Scrapy too. When you should use Scrapy and when bs4?,True
@Darthdeedee91,2018-09-18T01:38:29Z,0,Can you use this to go into your gmail account and grab emails and scrape content from it?,True
@RobinIsBetterThanYou,2018-09-09T19:16:03Z,0,"I have, from what i can tell, the exact same code, yet when i run the final program i get a traceback error telling me that: AttributeError: 'builtin_function_or_method' object has no attribute 'writerow' please can someone help me?",True
@baconsledge,2018-09-05T00:50:29Z,23,"As always, Corey‚Äôs videos are top-notch. Thank you, Corey!",True
@leonardogrinstein9815,2018-08-27T17:35:18Z,0,Hi Corey. I loved your video and I am following your channel. But I couldn't use any of the tactics you explained in this video to grab the SongName of this URL - https://www.azlyrics.com/lyrics/gunsnroses/sweetchildomine.html. Mayble you should add a trick to explain what to do in situations like this.,True
@danieldaanna,2018-08-27T12:32:53Z,1,"Hi Corey! My intention is not to scrape webpages, but to extract data from purchase orders in html format and use this data to create an invoice!  So thank you very much for this small but complete tutorial! This is really handy!",True
@sandeepmishra2,2018-08-27T00:16:43Z,0,"Awesome Tutorial!!Corey  I have one question , How we will collect data from multiple pages in website?",True
@murugan0723,2018-08-20T06:25:41Z,1,"Hi Corey Schafer,  Your videos are really fantastic it helped me so much in learning python.  Unlike other channels you video is very simple and professional. Easy to understand, and my request for you is can you do a separate tutorial video for python urllib library.",True
@TheScrpk,2018-08-12T07:49:36Z,0,"Hey Corey, firstly thank you for the amazing tutorial. Really helped me to understand webscraping in a crisp manner. I just had one question, I ran the script and the csv that got generated had blank rows in between each entry and it wasn't structured as a table for me. Would be really helpful if you could suggest how to incorporate the same in the code. TIA :)",True
@abellara9169,2018-08-08T10:21:57Z,0,Is this legal?,True
@markgacoka9704,2018-08-07T20:59:52Z,1,Make more videos... You're the best!,True
@farmakoxeris,2018-08-07T13:06:32Z,0,I got a UnicodeEncodeError. How can I gewt rid of it?,True
@farmakoxeris,2018-08-07T11:59:30Z,0,I have a webpage that has a bug. Therefore I need to save the data in a file and then process it (I know what must be done). Is there any way I handle all these data as a huge string? Just put it in a file and then process the file.,True
@farmakoxeris,2018-08-07T11:57:36Z,0,soup.find('article') gives you the first article (Number one? Number zero? What's the first?). soup.find('article') gives you all articles.  How can I get a particular article? Let's say that there are 20 articles and I want to get the article number 11. How can it be done?,True
@ryankao1983,2018-08-06T02:50:38Z,0,Is it possible to do a series of web scraping via scrapy tutorials for text contents and images? Thank you.,True
@CharanTeja-cm8ug,2018-08-05T14:26:48Z,2,"This is the video , which i saw completely. print('Excellent')",True
@sbarter,2018-08-04T23:10:45Z,0,Beautiful soup can be used to save images as well right?,True
@TheSagitube,2018-08-02T16:41:51Z,0,how to select a date in a datepicker on a webpage using python?,True
@wildcat0871,2018-07-30T11:48:13Z,0,"Hi Corey, first of all I want to thank you for your teachings, your videos are spectacular and I am learning a lot with them much more than with books. Are you planning to make a series about scrapy too? I love web scraping but I am struggling with some advanced uses of scrapy and your videos could help a lot, me and others interested in this topic. My best wishes for your channel. Thanks",True
@kaisun1661,2018-07-27T15:44:25Z,1,Thank you! it works very well,True
@visheshmangla8220,2018-07-24T18:30:14Z,1,great explanation.I really liked it:),True
@MistaT44,2018-07-23T20:50:09Z,1,You are the best teacher!!!!!!!,True
@pythonocean7879,2018-07-17T19:25:07Z,1,you are something really extra ordinary üòòüòòüòòüòòüòòüòòüòòüòò,True
@increadibleangel7980,2018-07-14T16:49:46Z,1,it was awesome,True
@rafaelbenetton3674,2018-07-12T20:18:18Z,0,"i have only one phase without span, div, id, class, how i can get it? <body>www.google.com</body>",True
@justinceiley9398,2018-07-12T01:08:51Z,1,"You're python tutorials are honestly the best thing ever. I'm only a sophomore in high school but learning to code has been a hobby of mine for about two years. I just recently started to learn python more in depth (classes, 3rd party modules, reading and writing files etc.) and your videos explain the concepts with such detail and understanding that by the end of the video I feel like I really have a grasp on the subject of the video. So really just thank you for making these videos and empowering others with the skills of programming.",True
@krishnanarwani8105,2018-07-06T16:47:54Z,0,lxml is unable to install in my lappy showing an error: -  FileNotFoundError: [WinError 2] The system cannot find the file specified   please help me out I'm tired of all this now  BTW your tutorials are really great.I love them Watching,True
@fabiodeabreu915,2018-07-05T21:05:10Z,0,"Great video thanks a lot.Just one doubt can someone explain to me this line vid_src = article.find('iframe' , class_='youtube-player')['src']   He said it has to do with dictionaires but still I dont get.",True
@anoubhav,2018-07-04T16:55:27Z,0,Do you have videos on web crawling? Thanks,True
@adityatripathi9865,2018-07-04T14:48:51Z,3,your understanding of python is very deep and your teaching method is excellent,True
@sinogarcon,2018-06-29T10:15:01Z,0,There is a difference between the result csv file you showed in this video and the actual csv file one scraped by using the code. I find there is an extra blank row between each iteration. Can you show me how to remove the blank row in the code?  Thank you.,True
@TherandomclipTCP,2018-06-25T19:09:42Z,1,Thank you so much Corey for this beautiful video. You taught such a vast topic in a very very simple manner. It's really appreciable.,True
@mohammedzia1015,2018-06-22T19:59:50Z,0,"Thanks Corey for this excellent tutorial. I tried this in Sublime Text and got an Import Error: No module named bs4. But when I did the same using a normal .py file and executed the python script from terminal, I am getting the result. Why the SUBLIME text is not recognizing the BeautifulSoup package ? how to fix this ?",True
@isaach3099,2018-06-21T21:15:33Z,0,"Is there a way just to print the content of the page? this is my code    import requests from bs4 import BeautifulSoup  r = requests.get(""https://zillow.com"") c = r.content soup = BeautifulSoup(c, ""html.parser"")  print(soup.prettify())  and then i got the code for the website",True
@jeffmyers1784,2018-06-20T17:49:54Z,0,"Help! I'm getting this error after print( soup ):  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/inspect.py"", line 57, in <module>     for k, v in dis.COMPILER_FLAG_NAMES.items(): AttributeError: module 'dis' has no attribute 'COMPILER_FLAG_NAMES'  What does this mean?? I can't continue working with the video until this works!",True
@Ramm165,2018-06-12T19:14:06Z,0,hi corey can we extract  youtube videos url with python ?,True
@hajajmaor,2018-06-11T20:21:50Z,1,The best video I found on YouTube. Search for a long long time but this is simple one the most understood one and the best one thank you man,True
@Theminecrafter2598,2018-06-11T10:05:21Z,0,"i have been trying this on different websites and each time i run the code it comes back with 'none', what am i doing wrong?",True
@elchakiboo,2018-06-06T20:47:01Z,0,"Hi Corey, thanks for your video. Just a small late feedbacks, you could avoid the try/except block by accessing your dictionnary with a method get articledict.get('src', None). Also, regular expressions should allow you to parse the video id in a strait forward manner. That's said, thx again for your work",True
@nickspiess4951,2018-06-06T16:05:25Z,0,"I'm getting a UnicodeEncodeError when importing the original text from your site saying 'acsii' codec can't encode character'\xbb' in position 2423.  I've found multiple issues like this online, but can't figure out how to convert that character into something that is readable.",True
@samdavepollard,2018-06-05T20:46:36Z,266,"45 minutes of pure, unadulterated, hardcore geek-porn. Absolutely loved it. Thanks, Corey. Even by your standards this one was pretty special.",True
@rancoxu,2018-06-03T14:26:09Z,1,Thx a lot!,True
@samsrichamp903,2018-06-01T10:09:01Z,0,please make one video on restful also,True
@Keyandcartracking,2018-05-29T11:17:23Z,1,"Corey... I have struggled to find a way to scrape table data from a website that generates tables using javascript.  I finally found a solution to my dilemma.  I am using Selenium, Beautiful Soup, and Pandas.   It would be great if you could build a teaching tutorial to explain why it is so difficult to access tables generated by javascript and explain why this code below solves this problem.   cheers...            html = self.driver.execute_script(""return document.getElementsByTagName('html')[0].innerHTML"")         soup = BeautifulSoup(html,'lxml')         table = soup.find_all('table')[0]         df = pd.read_html(str(table))[0]",True
@fatherhotdog6370,2018-05-29T04:05:59Z,0,"Hi Cory. Another excellent video. I am just curious. With writing a scraping script to bring in some basic data such as: articles, videos, images etc. It is pretty easy to simply go in and copy and paste or do a save as.  How is web scraping need and used in the real world?  is this how real-estate site and job sites pop-up all over the place?  Do a lot of companies simply scrape data from a competitor's site and re-package the data instead of purchasing access to a database?  Where is the line between simply collecting data and being considered a hacker?",True
@maudentable,2018-05-26T10:19:10Z,0,Woow what a great video.,True
@RamisaAnjum,2018-05-25T20:05:35Z,1,"Yours tutorials are much easier than programming books. Thanks a lot. I was thinking of building  a program that would show the title of the latest episode of my favorite cartoon. But hearing your last advice , I'm a bit worried :(",True
@J38x729,2018-05-25T19:56:41Z,0,"If you cant install lxml than run this command instead ""pip3 install lxml""",True
@Masonx42,2018-05-25T09:27:55Z,732,"Hello,I'm a viewer from China, comparing with other youtube python tutors, your English speaking is very clear for me to understand. I just registered as a one dollar patron for a little support.If I can find a job as programer later,  I will contribute more to help you continue making these high quality videos. Thank you Mr Corey!",True
@JithuNair95,2018-05-22T14:56:03Z,0,"I really desperately need this! Hope this helps me. :( I am somewhat stuck in a situation, thank you for this.",True
@kps2642,2018-05-21T11:11:52Z,0,"great video, what I like to do is scrape the website and deploy on my server and use it as a rest api via node js, really easy too",True
@6Sambora,2018-05-20T08:23:50Z,0,What‚Äôs the difference between Requests and BeautifulSoup,True
@Petrock508,2018-05-18T19:25:22Z,0,"Great vid, thanks!  How do you deal with a tag that has more than one class?  e.g. <h2 class =a b c>",True
@PrinceKumar-um8mw,2018-05-16T16:24:22Z,0,"I liked your video very much. I have one question, could you please tell me how to navigate through the web pages to extract the data. For example: navigating through the web page by clicking on Next button. Looking forward for your reply.",True
@TruthSikher,2018-05-15T15:41:14Z,0,"What would people suggest as a good way of learning this? I understand how things work in the video, but end up forgetting them later.",True
@profetik777,2018-05-13T02:17:36Z,0,thanks so much man!,True
@cheddarking83,2018-05-12T13:47:43Z,0,"Hey Corey, great tutorial and intro to scraping I learnt a great deal. Do you have a guide on how to scrape multiple pages? In the video it scrapes only the articles on your home page, but how do we go about scraping the other pages 2, 3, 4, ... etc? Thanks!",True
@edsonaraujo523,2018-05-04T23:11:44Z,0,Very good Corey! Thank you,True
@MrKashyani,2018-05-04T15:54:44Z,3,"Man..The way you explains !!! It works like a charm. Be it Regex or web scarping, it's just awesome ! Love your posts.",True
@riderblack6401,2018-04-26T20:13:09Z,0,Corey your fucking awesome!,True
@elliottcarter7700,2018-04-25T21:43:57Z,1,This was a great video Corey. It was a helpful refresher for me which in turn will help me with a python web app project i'm working on. Thanks again!,True
@KawsarJami,2018-04-24T04:01:19Z,0,"web scraping is great! i can do any scaping with pythin and scrapy for you, see my profile here https://goo.gl/iTHgqT",True
@donovankeating8577,2018-04-19T20:45:05Z,0,"On 24:42 , why isn't the header tag specified too?",True
@donovankeating8577,2018-04-19T19:18:14Z,0,Love your tutorials man! You thinking of makinh Django tutorials any time soon?,True
@youssefesseddiq7453,2018-04-18T12:22:33Z,0,Thanks bro for this but how we parse a ol it always gives me none :/ ! In fact when I print the whole html code we parsed those <ol>'s don't even show up.,True
@RP-mp4ow,2018-04-13T14:57:29Z,0,Thank you very much for this video- best tutorial on BeautifulSoup I've come across!,True
@thedrei24,2018-04-11T22:32:57Z,0,"great detailed explanation, i like your music too, it makes everything so much more clear",True
@nehat786,2018-04-11T17:52:53Z,0,Man you are awesome. Your videos are very well detailed and easy to understand.  Feeling lucky to found you brother.  Thanks a lot! .  Keep up the good work,True
@chandanpradhan449,2018-04-10T10:06:54Z,1,"Great, you are great teacher in this world",True
@SkySesshomaru,2018-04-09T20:48:10Z,0,"Oh my god, I love you. Subbed. Thank you SO much. That was just amazing.",True
@user-zq4ix8ps6g,2018-04-09T15:07:57Z,0,"Hi Corey, your python tutorial videos are really helpful, and I've learned a lot from these. I've got a problem with grabbing info from web written by javascript. it's seems BeautifulSoup can't parse javescrip code(<a title=""go to page 2"" href=""javascript:__doPostBack('ctl00$ContentPlaceHolder1$pager','2')"">2</a>). So, would you pls post a video to show how to solve this kind of problem? using headless browser or manually analyze javascript code before sending further requests, any kind of solution is OK. Just want to know how you solve this kind of problem. THANKS!",True
@525gigidy,2018-04-05T18:26:58Z,0,how did you pull up the thing on the right side of your screen? I got chrome so I can see the parts of websites but I dont understand how you went from the command line installing pips to black thing on the right of your screen,True
@liameneuk,2018-03-31T14:17:45Z,0,Hello. Can this technique be used to monitor website changes? Thanks!,True
@jitendratrivedi7889,2018-03-24T22:22:37Z,0,"Great Video, Any video series on EDA with pandas ..",True
@jamesdarlack4898,2018-03-21T11:19:31Z,0,EXCELLENT!    Nice concise intro.,True
@arreankit,2018-03-18T05:16:14Z,0,Great Video !! Just edited your code to scrap all 12 pages information of your website.,True
@richardwest9500,2018-03-16T03:47:50Z,0,Can you suggest a proxy to protect my IP address when scraping sites data?,True
@vinnnnnny12345,2018-03-16T03:43:04Z,0,"After storing the data in csv file, how would I export it to be displayed on my web application for users to see?",True
@rajnilguha1036,2018-03-12T19:34:56Z,0,Corey could you please see if it would be possible for you to make a series of django videos.,True
@sudipta_samanta,2018-03-10T16:05:52Z,0,"Hi Corey I really love your tutorials. I have a question.. when you said that for using a new library we should go through the documentation. Now, I tried that and when I open the documentation it's just overwhelming. So how should I look at the documentation and what are the things I should look at ?",True
@H3champ1,2018-03-05T05:07:10Z,0,One question I have is when splitting the links for a youtube video yours was split from '?'. is that because it is embedded in a page? Just looking at a video from youtube you would have to split from 'v=',True
@notgate2624,2018-03-04T23:56:29Z,0,"Easy one-liner for the link once you get the source.   link = 'youtu.be/'+re.search(r'embed/(.*)\?',src).group(1)  and for printing  print(headline,summary,link,'\n',sep='\n')  great video as always :)",True
@JeffthePharmacist,2018-03-02T04:41:40Z,0,"I keep getting an error ""no module named bs4"" anybody know why?",True
@weitingqi428,2018-02-28T09:17:21Z,0,Can you tell us how to scrape multiple pages that have some patterns,True
@zeus1082,2018-02-27T05:36:15Z,0,Please do tutorials in django..Anyone could excel in programming if they watch your videos.,True
@mahender8029,2018-02-25T10:50:29Z,0,for summary  we could have also used : summary = article.div.p.text,True
@arjungaihre9152,2018-02-22T20:46:38Z,0,"Hey Corey, I found this tutorial very helpful. I run your code at my environment with all the libraries installed, and I got this output: Python Tutorial: Context Managers ‚Äì Efficiently Managing Resources In this Python Programming Tutorial, we will be learning how to use context managers to properly manage resources. Context Managers are great for when we need to setup or teardown some resources during use. So these can be used for: open and closing files, opening and closing database connections, acquiring and releasing locks, and much much more. Let‚Äôs get started‚Ä¶ https://youtube.com/watch?v={vid_id}  What's missing here is {vid_id}...instead of getting the ID, I got this . Can you please help me out with this? Thank you",True
@ashishm8413,2018-02-21T18:35:02Z,5,It's nice how you break down the subject into small increments that others can understand and build upon easily. True quality of a great teacher. Thank you!,True
@darylsato7600,2018-02-21T00:49:41Z,0,"Corey, echo great video!¬† Just started using Python.¬† Can follow your logic but I keep getting No Module named BeautifulSoup errors.¬† I believe this to be a set up issue¬†(file, folder,¬†location..).¬†¬† Searched internet in vain but can not seem to find a tutorial that is clear, crisp, concise..¬† on set up.¬† I'm running Windows and have installed Python 2.7 and Python 3.6.¬†¬† I installed all pkg's with success using your Atom tutorial.¬† help?",True
@hashcoder,2018-02-17T00:42:50Z,5,"I've tried today! Successfully. Thank you, Corey!",True
@soumitripattnaik,2018-02-15T18:51:07Z,0,How do you do this man!,True
@ismailhammounou1135,2018-02-14T15:56:58Z,2,You Are Really Good. The Best of The Best. What about scrapy ? Multiprocessing ?  Django ? You really deserve money for this Work. My respect ! chapeau fr√©ro,True
@geekyprogrammer4831,2018-02-12T18:21:57Z,85,Best Python WebScraping video on YouTube! Seriously brother you deserve money for this masterpiece! Keep it up :'),True
@failuregreat9424,2018-02-12T04:40:38Z,198,"you never fail to impress me with your teachings! I don't watch videos at all once, because I feel it's easier to learn watching by 'parts' ‚Äî but again and again, I'm watching the videos and I feel 'wow.. this is really well done, I have to like this, it's the least I can do' and I realized I already liked before lol",True
@vgnshiyer,2018-02-08T14:06:41Z,0,Web scraping from multiple websites?,True
@DonVTOL,2018-02-07T16:43:50Z,0,How did you not get the UnicodeEncodeError?,True
@GeoffGroves,2018-02-05T13:49:56Z,1,"Great Corey! Something of note for new MAC / Py 3 users: If you have Python 3 installed, then you have to specify pip3 (pip3 install...)  in your terminal commands for all library installs (soup, requests, html5lib etc) as MAC OSx ships with PY 2.7.   Also, if you are building in Sublime as Corey does, you need to install a python 3 build package, otherwise Sublime will try to build it with Py 2.",True
@kamalsahoo3679,2018-02-01T00:43:22Z,1,"Hi Corey.  Thanks a lot.  Traceback (most recent call last):   File ""scrap.py"", line 22, in <module>     summary = div.find('div', class_='headerAbNormal').p.text AttributeError: 'NoneType' object has no attribute 'text'  How to fix the issue. Please guide me.",True
@0xBerto,2018-01-31T18:07:06Z,0,What about pushing  info we scrape into an app?,True
@elabeddhahbi3301,2018-01-30T19:51:00Z,0,can u do mechanize,True
@DistortedV12,2018-01-29T18:39:48Z,0,can't you use css selectors too?,True
@minghaotao6259,2018-01-29T04:23:02Z,0,Awesome video! Thank you!,True
@OrientalMelodies2010,2018-01-25T03:43:41Z,5,An awesome video. Your way of moving from one idea to another is amazing. I have been searching YouTube for years for a good tutorial video explaining web scrapping with BeautifulSoup and finally found it. Thanks a million!,True
@dylanduregger4906,2018-01-25T03:20:45Z,0,"What do you do if you want to get data from a tag, but there are multiple of the same exact tag?  for example: <div id=""sortable"">      <td align=""right"">27</td>      <td align=""right"">30</td>      <td align=""right"">19</td> If i just want the second one how would I do that? If i use soup.find(""div"", id=""sortable"") it only comes up with the first one? What would i do if i just want the middle or last one?",True
@karishmashaik8572,2018-01-24T17:23:03Z,0,Hi Corey ! Your videos are extremely useful. Could you please videos of django framework if any on YouTube. Thanks!!,True
@dr.yashveeryadav1711,2018-01-23T18:28:33Z,0,Very nice and explained wonderfully...,True
@corpknut80,2018-01-21T18:18:24Z,0,"My f*** god, the underscore!! I have been trying for hours to use the class tag!! Thank you !!!!!!",True
@dylanduregger5614,2018-01-21T17:04:57Z,0,"Hey, I am having trouble with Sublimetext3 when I try to import requests. It keeps saying""no module names requests"". Anything i can to do fix it?",True
@DanielWeikert,2018-01-12T18:25:52Z,0,Great work Corey. Your tutorials are really good. What if I need to scape an infinite scroll website with login data? I probably need to use scrapy or sth. similar. Can you do a tutorial for this as well? Thanks a lot,True
@sujalpadhiyar5731,2018-01-12T08:37:02Z,0,"Hello Corey, the way you explain & present commands and examples are very nice . Please upload some video related to data science like some libraries like numpy, pandas, skit-learn",True
@samp9418,2018-01-11T08:29:55Z,0,This video is awesome! It was really helpful! You are really thorough and clear about explaining everything. Thank you!,True
@matheusaffernandes,2018-01-05T13:41:08Z,0,Great video! Thanks!,True
@joaofarinha551,2018-01-04T23:25:46Z,0,"Hi Corey. One question: When a create the CSV it's placing everything in one column. What am i doing wrong?  Btw Thank you very much for your help in the video, it was a really good explanation :)",True
@johnslater8898,2018-01-04T02:04:16Z,0,A very fine video; well done.,True
@Apatten001,2017-12-29T23:03:12Z,0,Very useful video!,True
@elabeddhahbi3301,2017-12-27T17:58:28Z,0,can u help us with more network programming somthing big and from scratch,True
@ahsin.shabbir,2017-12-25T00:05:41Z,0,"Very informative and clear tutorial. One thing I would like to add though is that the BeautifulSoup, requests, and lxml libraries can be added from the ""project interpreter"" in PyCharm. This is an alternative for those who are having issues with the ""pip install"" method of adding libraries.",True
@TheFourOnSix,2017-12-23T16:22:32Z,0,"Maybe this is more of a question about ajax calls, but I'm trying to scrap my school's class system (kind of like Canvas), take the assignments, and use the Todoist API to add them to my Todoist as tasks. The problem is obviously that the page is dynamically generated. Is there anything in particular that I should look for in order to get the call after?",True
@orangeflowerlove,2017-12-19T12:04:11Z,0,"Great video! I really enjoy it and learned a lot. What's your suggestion for the next step if I want to learn to scrap the whole website, not only a webpage?",True
@eduardoreis3795,2017-12-17T01:09:18Z,0,Excelente video! Muito obrigado.,True
@MiguelSantos-dl4il,2017-12-10T19:32:38Z,1,"Hey Corey! I'm new to Python and I really liked the video. I have some few questions: 1. You said that if I want to scrape websites like Facebook, Twitter, etc., I need to use an API. So how do you use/implement an API to a Python Script? 2. Does adding a time-delay to my script good enough so that it wouldn't get blocked when scraping? Thank you in advance!",True
@vl7283,2017-12-08T15:38:20Z,0,Thank you SR. for your great tutorials!!,True
@martinkaspar5095,2017-12-07T20:24:14Z,0,hello - well it would be great if you show the code - that you develope - do you offer it at github somewhere !? that would be great-,True
@onetwo352,2017-12-05T20:43:14Z,0,When I run the code I get this: UnicodeEncodeError: 'ascii' codec can't encode character '\u2019' in position 231: ordinal not in range(128),True
@riptorforever2,2017-12-03T14:43:05Z,0,Thank you for the lesson! From Pernambuco/Brasil,True
@haroldthibault9921,2017-12-01T11:17:39Z,0,That was a really good tutorial again ! Lots of interesting informations and advices indeed .,True
@arifsali,2017-11-26T16:15:48Z,0,"This worked beautifully! Thank you. One question. Is there a way to limit, or define a boundary of text one can scrape from a website? For example, what if your website had thousands of blog posts, and I only wanted to scrape ten and not all? Is this possible?",True
@ayushchoudhary1081,2017-11-26T15:53:38Z,0,How to scrape sites which require authentication?,True
@tomtravolta4833,2017-11-26T15:20:55Z,1,"Hi Corey I am having this error after entering line 8 at timestamp 20:50 of the video: ""UnicodeEncodeError: 'ascii' codec can't encode character u'\xbb' in position 2678: ordinal not in range(128)""  I installed all the prerequisite packages and have used Python 2 and 3, nothing seems to work! Any ideas on how to fix this issue? Thanks!",True
@MyTube4Utoo,2017-11-26T02:17:44Z,0,"Great tutorial, thanks!",True
@mayukh_,2017-11-22T19:57:09Z,0,"Hey Corey...awesome video man. Can you please do a video on python 3.6 async io functions. Everywhere I saw it, I didn't understand.",True
@kkambanite,2017-11-18T15:12:50Z,0,great stuff!,True
@sheldonfourie5959,2017-11-18T14:14:48Z,0,how would we scrape images to a folder with a custom name from the site like h3 tag for the item and product code of the item and color tag - eg B300 productName Color.png and then @images in csv file link to that exact name,True
@adityaverma6120,2017-11-17T17:54:41Z,0,"@Corey Schafer, a video on Deep Copy vs Shallow Copy?",True
@hpavan5952,2017-11-15T03:17:27Z,0,Can u pls provide a tutorial on django ?,True
@absar66,2017-11-15T01:22:26Z,0,Another great video..thanks Corey..pls do a tutorial (in your unique style :-) ) on debugging using ‚Äúpdb‚Äù..many thanks..,True
@Rasstag,2017-11-14T23:31:50Z,0,Excellent... to the point... question: would BeautifulSoup be the choice for scraping a web page with something like 'dynamic html'?,True
@dpoznyak,2017-11-13T14:42:43Z,13,Corey your Python tutorials are great! You explain everything very well. It would be great if you could make a series of Django tutorials for beginners! Keep up the good work!,True
@ZEDAWMN,2017-11-12T17:37:41Z,0,Hello and thank you! Very good explanation. I have a question if the site has some components loading from JS which module do you suggest for this situation? I have used dryscrape but now is deprecated.,True
@ivanyakushchenko6915,2017-11-12T09:45:09Z,1,"As usually, great video, thanks a lot!",True
@alisefidmouy9615,2017-11-11T20:06:43Z,0,Hi Corey! thank you for this tutorial. Please start to make a tutorial for django.,True
@wsgsantos,2017-11-10T18:31:19Z,0,This class was very useful. Thank you Sir.,True
@PyMoondra,2017-11-10T18:14:30Z,0,Thanks Corey. Is this how most embedded videos work? They have an id within their source that you need to extract( and then recreate a new link)  I always have trouble dealing with javascript components with bs4.,True
@calebnjiiri9959,2017-11-10T14:59:34Z,0,"Hey thanks for the video, great content. One question what if i want to scrap data from a website that requires me to login.",True
@venkysmoments9155,2017-11-10T11:52:08Z,22,Corey please add tutorials related with multithreading and multiprocessing in python.,True
@gesuchter,2017-11-10T10:59:24Z,1,Love your videos about libraries! Thanks for the great tutorial! <3,True
@nenojay6832,2017-11-10T07:04:24Z,0,"i love it , thx for the info",True
@fconteEBdotcom,2017-11-10T02:19:19Z,0,A very good introduction to BeautifulSoup. Thanks!,True
@jasonyan8145,2017-11-10T01:04:38Z,0,"Hi, What is the font you are using? Thanks.",True
@playgoods,2017-11-09T22:14:12Z,0,awesome,True
@Jo-id9zm,2017-11-09T15:27:01Z,1,"Thanks a lot, man! Keep up the good work.",True
@MarkJay,2017-11-09T07:03:32Z,27,Another great video Corey! Keep them coming.,True
@YunikMaharjan,2017-11-09T05:45:43Z,0,please do a video on python setuptools,True
@wolfisraging,2017-11-09T03:29:06Z,4,"Holy maaaaan, you are truly most amazing.... Big fanüòä",True
@wolfisraging,2017-11-09T03:18:52Z,0,"I am glad you are still alive... Great video, thank you very much..",True
@darshanmm9,2017-11-09T02:40:08Z,0,Excellent tutorial Corey. Thanks alotüëçüëçüëç,True
@joenickson2370,2017-11-08T22:58:19Z,0,Starting Java soon,True
@greob,2017-11-08T18:56:57Z,0,"Very nice! By the way, I think commenting on a video also ""helps"", if I recall correctly.",True
@silverzero9524,2017-11-08T18:54:46Z,2,and yeah probably ur website will be RIPPED soon,True
@hasanfares5774,2017-11-08T18:27:00Z,17,thanks was just taking an online class about it and couldn't understand until I got the notification you just uploaded wow you really are in sync with your followers,True
@silverzero9524,2017-11-08T17:31:22Z,8,awesome was just surfing the web about bs4 and u uploaded this awesome  awesome awesome thx,True
