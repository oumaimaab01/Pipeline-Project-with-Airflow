author,updated_at,like_count,text,public
@coreyms,2020-02-14T14:37:58Z,199,"I hope everyone had a great week! We've got a long video this week, but we go over a lot of important topics about how to analyze data in Pandas. We will learn how to answer very interesting questions such as ""What is the most popular social media site by country?"". I put timestamps together for this video so that you all can skip around if you need to go back and watch a specific section. Here are those timestamps: Aggregate Column - 2:00 Aggregate DataFrame - 3:55 Value Counts - 7:51 Grouping - 12:30 Multiple Aggregates on Group - 26:00 People Who Know Python By Country - 27:20 Practice Question - 34:20 Concat Series - 37:27  Have a great weekend everybody!",True
@YuHan-qs3gy,2024-05-29T20:53:19Z,0,"when i typed df.groupby([""Country""]) it keep saying 'list' object is not callable",True
@mahhingaminggate5028,2024-05-25T10:05:56Z,0,"Here is the code I used for Finding Percentage ,    total_num=Country_grp['LanguageWorkedWith'].count()  # Combine the results into a DataFrame result = pd.DataFrame({     'Total': total_num,     'PythonUsers': python_users })  # Calculate the percentage of people who use Python result['Percentage'] = (result['PythonUsers'] / result['Total']) * 100 result.sort_values(by=['PythonUsers'],ascending=False,inplace=True) result",True
@Aman-yu4re,2024-05-18T08:09:18Z,0,"df.median() , throws an error for me i am working on the 2022 year survey",True
@Boat-xs8lm,2024-05-17T13:25:14Z,0,Is df.median not working anymore if the df contains strings ?,True
@Boat-xs8lm,2024-05-17T13:20:13Z,0,"Thank you,I am very lucky that I found your tutorials.",True
@RomanchakAnimeDuniya,2024-05-15T06:21:27Z,1,for everyone who is getting error in median function  you can use the following parameter to get the fnction working  just pass numeric_only = True in the paranthesis like the code below  df.median(numeric_only=True)   Welcome in advance,True
@sAkIBtHewOlVeRiNe,2024-05-02T13:45:27Z,0,my_grpby_filt = df.groupby('Country')  my_grpby_filt['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').agg(['mean']))  I use groupby function to my dataframe and than use language column where apply method is used and use lambda function.,True
@simonacumpanasu1420,2024-04-24T11:49:45Z,0,"Hello there! Don't forget to note index_col='Column' near schema_df = pd.read_csv('survey_results_schema.csv'. I forgot it and I did not understand why I received a KeyError. :/ Super helpful video! Thank you, Corey!",True
@felixtrost5673,2024-04-15T15:35:53Z,0,"Using `.contains(""Python"")` looks like a bad practice to me. Imagine searching for ""C"" users and also getting all ""C++"" and ""C#"" results",True
@anahitaghafari3561,2024-04-04T00:49:08Z,0,"This is my solution: country_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').value_counts(dropna=False,normalize=True)).loc[:,True]",True
@spicyshizz2850,2024-04-01T00:12:49Z,1,Had to do df.median(numeric_only=True) for 4:45,True
@utkarshujwal3286,2024-03-20T17:58:40Z,0,"python_people=country_grp['LanguageHaveWorkedWith'].apply(lambda x:x.str.contains('Python').sum()) python_people.rename('Pythonic People',inplace=True) # used regex non_python_people=country_grp['LanguageHaveWorkedWith'].apply(lambda x:x.str.contains('[^Python]').sum()) non_python_people.rename('Non-Pythonic People',inplace=True) new_df=pd.concat([python_people,non_python_people],axis='columns',sort=False)  new_df['Percent']=new_df['Pythonic People']/(new_df['Pythonic People']+new_df['Non-Pythonic People'])",True
@chahineatallah2636,2024-03-19T18:31:06Z,0,"great video Corey!! a lot to learn and practice, do you have a video for merges/join in pandas?",True
@sahilsondhi3143,2024-03-17T21:36:18Z,0,The way I approached it: group_by_country = file.groupby('Country') people_who_know_Python = group_by_country['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').sum()) country_respondents = file['Country'].value_counts() perct_of_people = people_who_know_Python/country_respondents *100 Please let me know if this is a good approach or not.,True
@rishikaanand4169,2024-03-14T09:38:03Z,0,"what percentage of people from each country know python ? for this question i got a similar answer using the code below: country_uses_python = country_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').value_counts(normalize=True)) would this be correct ?",True
@kapibara2440,2024-02-14T18:12:43Z,0,"Brilliant here is not so much of a sponsor but the better off, an adjective describing your videos ‚ù§‚ù§‚ù§‚ù§",True
@cziffras9114,2024-02-13T23:21:28Z,0,"Here's my solution (absolutely awful to see, it sounds more like a joke to me, it looks like I tried to complexify it as much as I could XD):   ``` country_grp['LanguageWorkedWith'].apply(lambda x: f""{np.round(100*x.str.contains('Python').sum()/len(x), 3)}%"").loc['United States']  ```",True
@AmmyJain,2024-02-06T14:37:21Z,0,country_grp['LanguageHaveWorkedWith'].apply(lambda x: x.str.contains('Python').value_counts(normalize=True)),True
@lvcas9313,2024-01-31T11:37:14Z,0,"Weird. df.median() returned an error: ...   'Information Services, IT, Software Development, or other Technology']  [nan 'Appropriate in length' 'Appropriate in length' ... 'Too long'   'Appropriate in length' 'Appropriate in length']  [nan 'Easy' 'Easy' ... 'Neither easy nor difficult'   'Neither easy nor difficult' 'Easy']] to numeric Like why isn't considering the numeric columns only? df.describe() worked tho... BTW I am using the newest survey dataset",True
@yosephkurabachew6539,2024-01-25T08:39:00Z,1,"perfect content. one flaw is that , you never explained what a ""lamda"" function is and went straight to using the function  in your previous videos. you did the same thing here. now i have to first study lamda.",True
@user404notfound46,2024-01-23T14:44:43Z,3,Those using pandas 2.2.0¬† Use this :  df.median(numeric_only=True),True
@naren2412,2024-01-20T11:40:35Z,0,The Dataset that he's using is for the year 2019 JIC.,True
@xuanyibutzin4775,2024-01-18T22:34:31Z,0,Super helpful video! Thank you Corey!,True
@milenkamoschella2891,2024-01-09T23:34:34Z,0,Great Tutorial,True
@vignatej663,2024-01-09T18:24:32Z,0,"country_group[""LanguageWorkedWith""].apply(lambda x: (x.str.contains(""Python"").sum()*100/x.str.contains(""Python"").count())) Thsi is an easy solution for our problem",True
@user-vy8nh9uj9r,2024-01-01T18:57:50Z,0,Thank you very much,True
@AlejandroGalue,2023-12-22T15:10:50Z,0,"I used the following to calculate the percentage of users that know Python per country:  python_df = country_grp['LanguageHaveWorkedWith'].apply(lambda x: 100*(x.str.contains('Python').sum()/x.count())).sort_values(ascending=False)  That only includes the percentage, although I got essentially the same results.",True
@zhenpan2048,2023-12-15T13:03:25Z,7,"numeric_columns = df.select_dtypes(include=""number"") medians=numeric_columns.median() print(medians) # this is a way of getting the medians of numerical values        as I use df.median(), it gave me value error that says could not convert string to float""I am not a student who is learning to code""     thanks for great work. I learn more from you than from my professors. Thank you so much for great efforts!üòé",True
@lakewobegonesbest8725,2023-12-01T05:06:24Z,0,"Very informative, thank you! I only have one question: what‚Äôs twitter?",True
@StockGarjanaHindi,2023-11-27T15:14:54Z,0,"hi Corey, I am using df.median() method but it is showing me error saying: TypeError: could not convert string to float: 'I am a developer by profession' Does anyone has any idea about it?",True
@prakhararora8981,2023-11-25T17:47:45Z,4,hey if ur df.median() doesn't work and ur getting typeerror and valueerror u can do df.median(numeric_only=True),True
@shanghainewbison7687,2023-11-24T08:10:18Z,0,"One way to calculate the percentage of  people know python in each country. def know_python(string):     return 'python' in string.lower() if isinstance(string, str) else False   df[""know_python""] = df[""LanguageWorkedWith""].apply(know_python) df.pivot_table(index=""Country"", values=""know_python"").sort_values(by=""know_python"", ascending=False).head(20)",True
@thotarohith2060,2023-11-14T19:40:32Z,0,"Best method for finding the percentage of people using python in each country:   filt=df['LanguageWorkedWith'].str.contains('Python',na=False) python_count=df.loc[filt]['Country'].value_counts()  python_count.rename('p_c',inplace=True) python_count  -- total_count=country_grp['Country'].value_counts()  total_count.rename('t_c',inplace=True) total_count -- result_horizontal = pd.concat([total_count, python_count], axis=1) import numpy as np result_horizontal.replace({'p_c':np.nan},0,inplace=True) result_horizontal['perc']=(result_horizontal['p_c']/result_horizontal['t_c'])*100 result_horizontal",True
@nishitkekane1344,2023-11-06T17:45:40Z,0,"for practice question, filt=(df['Country']=='India')      df.loc[filt]['LanguageWorkedWith'].str.contains('Python').value_counts(normalize=True)*100",True
@charithjeewantha,2023-11-04T05:54:16Z,0,"Hey, quick question... When I run: country_grp['ConvertedComp'].median() , I get 6222.0 for the Afganistan. But when I do,  another_filter = df['Country'] == 'Afghanistan' df.loc[filt]['ConvertedComp'].median()  I get a different. Can you please explain why",True
@turksonmichael1236,2023-11-02T18:16:19Z,0,Thank you for this. Had clearer understanding of pandas than before. Wish you the very best,True
@marvinespejon7938,2023-10-25T14:55:09Z,0,How can I extract the number of person of top common education level of each country?,True
@soheylmoheb7273,2023-10-23T19:13:16Z,1,"more efficient way:   country_grp = df.groupby(""Country"") print(country_grp[""LanguageWorkedWith""].apply(lambda x: x.str.contains(""Python"").value_counts(normalize=True)).loc[""Iran""])",True
@abdulkadirguven1173,2023-10-22T09:52:57Z,0,"For the percentage of programmers who use python i did like this :  country_uses_python = country_grp['LanguageWorkedWith'].apply(lambda x : x.str.contains('Python').sum()) total_country_count = country_grp['Country'].agg('count') (country_uses_python / total_country_count) * 100",True
@omj7113,2023-10-22T08:04:32Z,0,"Thanks a lot for your teaching! Here is the my solution at the end of the video: # group object['column'] is a Series object, so the input of the function is a Series, ana the output value of the function is a float def percent_know_python_each_country(countrySeries):     num_know_python = countrySeries.str.contains('Python').sum()     num_all = len(countrySeries)     percent = round((num_know_python / num_all * 100), 2)     return percent      country_group['LanguageWorkedWith'].apply(percent_know_python_each_country).sort_values(ascending=False).head(30)",True
@Halo_M320,2023-10-20T14:37:33Z,0,"My solution:  country_grp[""LanguageWorkedWith""].apply(lambda x: x.str.contains(""Python"").value_counts(normalize=True)).loc[""United States""].loc[True]  Alternative to apply method on the whole DF and round the percentage to two decimals:  print(round(country_grp[""LanguageWorkedWith""].apply(lambda x: x.str.contains(""Python"").value_counts(normalize=True)).to_frame().loc[pd.IndexSlice[:,True],:]*100,2))",True
@rohitvishwakarma2871,2023-10-03T17:50:36Z,0,The üêê,True
@-Mohamed_bayan,2023-10-03T02:12:54Z,0,"country_group[""LanguageHaveWorkedWith""].apply(lambda x:x.str.contains(""Python"").sum()*100/len(x))",True
@RAJASEKARCMR,2023-10-01T06:15:29Z,0,4:47 df.median() not working now,True
@fvdvhome,2023-09-29T13:53:01Z,0,"Mr. Schafer, I am so happy I found your teaching. I have been on a journey to become a data analyst, and after completing the Google Analytics Course , I realized that I needed to learn much more. I am currently finishing a Python Course through Coursera offered by IBM.   Not every professional, no matter how good they are, have the natural ability to teach.  Your method and technique are so amazing and helped me to overcome some of the confusions I had with coding in Python. I learned so much from just this video alone.  I will definitely visit the site you referenced, and look forward to learning more from your videos.  Thank you so much!",True
@GuangshengLi,2023-09-26T08:04:05Z,0,can below codes achieve the same result? Thanks country_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').sum()/x.count()),True
@oscarsibanda9454,2023-09-21T05:41:34Z,0,"Bravo Corey, Bravo!!!",True
@Dynamyalo,2023-09-19T14:08:20Z,1,"7:17 Ok, who is working 4850 hours per week?",True
@artygecko7429,2023-09-18T17:06:30Z,1,"If anyone's getting an error when using .median() on the whole data frame, add the numeric_only=True argument:  data_frame.median(numeric_only=True)",True
@mehdiezzine292,2023-08-31T21:31:59Z,0,"hey wouldnt it be smarter to use count on the country_group['languageworkedwith'] object and use that as a our total population , because some people might of not answered that question and were counting them too with corey's method.",True
@midprogramming,2023-08-22T23:23:48Z,0,Can replacing .sum with .value_counts(normalize=True) work or no? I'm working with a different dataset not involving strings but rather integers so im not sure how to test it without asking you.,True
@finncollins5696,2023-08-05T16:06:24Z,0,"thanks so much for this series. started from the first video two weeks ago, now in the 8th. this series so far made a lot progress in me,. thanks so much, .May God Bless You. Love from Sri Lanka...",True
@the-royal-mart0001,2023-07-26T06:55:17Z,0,solution to problem in 1 line: group['LanguageHaveWorkedWith'].apply(lambda x: x.str.contains('Python').sum())/group['LanguageHaveWorkedWith'].count(),True
@mosama22,2023-07-17T16:12:53Z,1,"I have a question please: Would it be right if we said that ""Grouping is for categorical data, while aggregating is for numerical ones?"" Thank you Corey, really don't know what to say üòäüòä",True
@cuckoo_is_singing,2023-06-20T05:50:19Z,0,"a handy solution for the question: country_grp[""LanguageWorkedWith""].apply(lambda x:x.str.contains(""Python"").sum())/df[""Country""].value_counts()*100",True
@RahulGupta-ke9su,2023-05-31T19:57:56Z,0,THANK YOU FOR GIVING US GOOD CONTENT,True
@FuckYouTube385,2023-05-24T05:24:35Z,0,24:50,True
@dariodcr,2023-05-08T16:56:17Z,0,"When I run ""python_df['PctKnowsPython'] = (python_df['NumKnowsPython']/python_df['NumRespondents']) * 100"" I get this error. Any help to understand is appreciated. Thanks.  KeyError                                  Traceback (most recent call last) File ~/.local/lib/python3.11/site-packages/pandas/core/indexes/base.py:3802, in Index.get_loc(self, key, method, tolerance)    3801 try: -> 3802     return self._engine.get_loc(casted_key)    3803 except KeyError as err:  File ~/.local/lib/python3.11/site-packages/pandas/_libs/index.pyx:138, in pandas._libs.index.IndexEngine.get_loc()  File ~/.local/lib/python3.11/site-packages/pandas/_libs/index.pyx:165, in pandas._libs.index.IndexEngine.get_loc()  File pandas/_libs/hashtable_class_helper.pxi:5745, in pandas._libs.hashtable.PyObjectHashTable.get_item()  File pandas/_libs/hashtable_class_helper.pxi:5753, in pandas._libs.hashtable.PyObjectHashTable.get_item()  KeyError: 'NumKnowsPython'  The above exception was the direct cause of the following exception:  KeyError                                  Traceback (most recent call last) Cell In[67], line 1 ----> 1 python_df['PctKnowsPython'] = (python_df['NumKnowsPython']/python_df['NumRespondents']) * 100       2 # Calculation of the % people whom know Python.       3 python_df  File ~/.local/lib/python3.11/site-packages/pandas/core/frame.py:3807, in DataFrame.__getitem__(self, key)    3805 if self.columns.nlevels > 1:    3806     return self._getitem_multilevel(key) -> 3807 indexer = self.columns.get_loc(key)    3808 if is_integer(indexer):    3809     indexer = [indexer]  File ~/.local/lib/python3.11/site-packages/pandas/core/indexes/base.py:3804, in Index.get_loc(self, key, method, tolerance)    3802     return self._engine.get_loc(casted_key)    3803 except KeyError as err: -> 3804     raise KeyError(key) from err    3805 except TypeError:    3806     # If we have a listlike key, _check_indexing_error will raise    3807     #  InvalidIndexError. Otherwise we fall through and re-raise    3808     #  the TypeError.    3809     self._check_indexing_error(key)  KeyError: 'NumKnowsPython'",True
@jeremine9259,2023-05-06T11:05:37Z,0,"Just want to share here my solution for the practice question (but with the survey of 2022): --- country_group['LanguageHaveWorkedWith'].apply(lambda x: x.str.contains('Python').value_counts(normalize=True)) --- And also give thanks to your wonderful videos, Corey! It's been 3 years and they're still among one of the best tutorials.",True
@kartikeyachoudhary5742,2023-05-04T16:03:26Z,0,This is how i did it: country_grp['LanguageHaveWorkedWith'].apply(lambda x:x.str.contains('Python').sum()/x.value_counts(dropna=False).sum()) I have just used lambda function first to find person who knows python and also to find the total count of person it the country group  I have also used the parameter 'dropna= False ' inside the value_counts method so that it will include NA terms also.,True
@taylormccoy7492,2023-04-25T21:20:56Z,0,Here's a simple solution: country_grp['LanguageHaveWorkedWith'].apply(lambda x: x.str.contains('Python').sum()/x.count()). My name for the col is different because I used the most recent  dataset as opposed to the 2016. Pretty sure this is the most simple solution since the count function just gives use the total number of respondents in the survey and doesn't require you to alter that number any further. But I could be wrong.,True
@jkp2319,2023-04-08T21:47:51Z,0,"For his practice problem, did anyone lese just divide the result by country_grp.size()?  Unfortunately, it works like his method where NaN values are treated as 0, rather than dropping them, but it's pretty easy.  I still prefer Felipe Gomez's solution of adding /len(x) to the lambda function, though  country_grp['LanguageWorkedWith'].apply(lambda x : x.str.contains('Python').sum()) / country_grp.size()",True
@mohamedaboobacker8950,2023-04-02T06:26:00Z,0,"df_Python = country_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').sum()) df_Python.value_counts(normalize=True)",True
@anantharjun9662,2023-03-25T16:41:16Z,0,Heyyy coreyyy I got drops in my eyes after watching the way you taught....you made my day‚ù£Ô∏è‚ú®love you so much corey,True
@adisonfryman144,2023-03-18T00:11:50Z,0,"If anyone else is having issues with this tutorial will they let me know. I've read so many comments and I'm not seeing anyone having issues. But I can't usually use :  python_df.sort_values(by ='PercentknowPy', ascending = False).head(50) python_df  or anything else like it... after trying for hours to look for some typo or some cell not being run correctly, or a kernal issue...(I don't really like Jupyter Notebook right now) Chat GPT finally told me I should save it to the original dataframe if I want to see the changes.   like this:  python_df = python_df.sort_values(by ='PercentknowPy', ascending = False).head(50) python_df  Bam there it is...but I just can't figure out why its working for Corey and note me. lol  Things like this keep happening in this tutorial , I just don't know if its because I am making some mistake I am unaware of, or if one of the many components had changed in a new release. I'd love someone's thoughts!!!! Thanks!",True
@AkshayGhadi01,2023-03-16T20:28:50Z,0,"Hello Corey Sir, I love your teaching a lot. You are the best. Thank you",True
@majilarohit4,2023-03-15T00:03:55Z,0,Amazing videos. Thanks a lot for creating such an amazing series.,True
@brandibooth,2023-03-13T01:56:44Z,0,Thank you Corey!,True
@zekomo8726,2023-03-06T16:04:47Z,0,.value_counts(normalize=True)),True
@aguanut,2023-03-06T00:02:46Z,0,Brilliant!,True
@vijaychopra6158,2023-03-03T15:35:38Z,0,Awesome video. Well-explained and to the point!,True
@saadchaudhry9110,2023-02-24T18:40:05Z,0,"you teach really well, I am learning a lot...Thanks. I have also learned other topics from your videos....I was stuck on opening and reading a csv file in python, till I saw your video and learned it....I am an absolute beginner...üòÖ...Thanks",True
@karthickpoovarasan2068,2023-02-13T17:58:34Z,2,I've solved the practice question in a slightly different manner  No_of_respondent = df1.groupby(['country'])['country'].count() No_knows_python = df1.groupby(['country'])['languageworkedwith'].apply(lambda x : (x.str.contains('Python').sum()))  Percent = (No_knows_python / No_of_respondent)*100  Explanation for not using sort method -> i use groupby in both the variable so output should be the same set of rows,True
@aktanbekaidarov3470,2023-02-07T09:02:43Z,0,country_grp['LanguageWorkedWith'].apply(lambda x: (x.str.contains('Python').sum()/len(x)) * 100),True
@kumarshivam8077,2023-01-29T12:47:18Z,0,Nothing can match clearity of your video.,True
@abrahamalvarez2730,2023-01-22T22:22:43Z,0,how do you save the new column that you created it in mint 41 in the original file?,True
@ZsoltPal23092011,2023-01-18T23:37:44Z,0,so many thanks for this!,True
@guilhermechina0506,2023-01-14T06:12:49Z,0,"didn't know about the concat method. So i took both the Series (knows python e total respondents) and created a dataframe for each one. Then i sort both dataframe, so that they could match the index row, since they have all the same countries as indexes. Then I created a new column in total respondents and equaled itself to the knows python dataframe. Created the pct columns after that, and that's it.",True
@jamespolaroid4856,2023-01-08T10:31:31Z,0,"Hi, thats my solution for the question:  country_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').value_counts(normalize=True))",True
@yuval1588,2023-01-02T15:35:49Z,0,"29:04 So we create a  filter (a True/False series ), then use  that filter to create a new fata frame, and  create a new filter off the new data frame?",True
@siyulucywo2987,2022-12-24T22:42:37Z,0,Thank you for the instruction. It is very clear and easy to understand. ,True
@yaweli2968,2022-12-23T09:51:49Z,0,"I just found your channel. Great work. I like how you break it down for a beginner like myself. If possible, can you please show how to use groupby with pd.cut, bins and labels for histogram plot, say on a column like age or any numeric column. It should give the counts on the y axis of histogram and the interval of groupings on x. Thanks.",True
@sanjeevKumar-eg6hp,2022-12-15T09:18:51Z,0,Thanks for such a detailed explanation.,True
@mariosconstantinou8271,2022-12-01T15:38:45Z,0,"When we used country_grp['MainBranch'].value_counts().loc['United States of America'], I tried it by writing country_grp.get_group('United States of America')['MainBranch'].value_counts() and I got the same result. Are both ways correct and it just boils down to preference?",True
@ravikumar1232,2022-11-29T18:24:59Z,0,My Approach group_country['LanguageHaveWorkedWith'].apply((lambda x: (x.str.contains('Python').sum()/len(x))*100)),True
@harshinimedha7807,2022-11-27T14:27:11Z,0,"Thank you a billions sir for this pandas series, it is really very helpful ‚ô•Ô∏è",True
@akosasuke5128,2022-11-24T01:53:41Z,1,Corey Shafer deserves a YouTube Teacher award,True
@betsynwankwo1094,2022-11-18T07:38:31Z,0,Coding is made easy with your teaching. Thank you üòä,True
@edwardhsu4393,2022-11-14T15:51:00Z,0,Thank you fir your sharing. It is really useful,True
@RoyalMamba.,2022-10-31T22:56:22Z,1,"Here is my method ..... percentknowsp = Country_grouped['LanguageWorkedWith'].apply(lambda x : x.str.contains('Python').value_counts(normalize = True))  Now if we want to convert this series object into a dataframe  we can simply do it using to_frame() method  percentknowsp = percentknowsp.to_frame()  After converting it we can see that it is converted  to the series but it not that clean looking though. So what we can do is convert it into the pivot table but pivot tables take three values  ie the index , columns and the values . Hence first we need to create an index and extra columns    finalpercent = percentknowsp.reset_index().pivot(index= 'Country' , columns= 'level_1' , values= 'LanguageWorkedWith')  Now we are done with it we just need to rename our final columns  finalpercent = finalpercent.rename(columns = {True : 'KnowsPython' , False : 'Don\'t know python' } )  Let me rewrite the whole code again : percentknowsp = Country_grouped['LanguageWorkedWith'].apply(lambda x : x.str.contains('Python').value_counts(normalize = True)) percentknowsp = percentknowsp.to_frame() finalpercent = percentknowsp.reset_index().pivot(index= 'Country' , columns= 'level_1' , values= 'LanguageWorkedWith') finalpercent = finalpercent.rename(columns = {True : 'KnowsPython' , False : 'Don\'t know python' } )  Bam ! Now we have a clean looking DataFrame .",True
@buzz.b,2022-10-18T16:28:24Z,0,Thank you for the last example (percent that knows python). It was great to see how the different methods learnt can come together in a practical example; this really helped consolidate the knowledge gained.,True
@web64dev,2022-10-12T13:17:26Z,0,country_grp['LanguageWorkedWith'].apply(lambda x: (x.str.contains('Python').sum()/x.count())*100),True
@nilkanthdeshapande9869,2022-09-29T16:07:01Z,0,Hey Corey .. Your content is really helping me to understand the pandas .. Please make the vedio for Groupby function on multiple index,True
@houssemmeghnoudj4430,2022-09-27T15:12:05Z,0,"Hello, about the question in the video, I don't know if my attempt is right but here it is: 1) To take into account the NaN values (so they are involved in the calculation):               country_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').sum() / len(x)) 2) Not taking into account the NaN values:              country_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').sum() / x.count())  Since the information of how many entries are in country_grp and are grouped by country I think it is inefficient to look for the number of entries elsewhere, thank you for the course !",True
@satheshkumar7638,2022-09-24T16:51:22Z,0,Nalla solli thara pa Corey mama thank you ..!!!  Tamil people entha comment partha like poduga,True
@arsentavakulov5455,2022-09-24T11:42:53Z,0,"I think the shorter  but not detailed way could be:  ppl_python=dataset.groupby([""Country""])[""LanguageWorkedWith""].apply(lambda x: x.str.contains(""Python"").sum())  total_people=dataset.groupby(""Country"").apply(len)  percentage=ppl_python/total_people*100  #for example  percentage.sort_values(ascending=False).head(50)",True
@jongcheulkim7284,2022-09-21T02:32:57Z,0,Thank you,True
@manish_chandra,2022-09-20T09:36:03Z,0,One of the best and most easily understandable vid on Pandas. Thank  you for creating this !!,True
@paulohsgoes1959,2022-09-20T01:03:33Z,0,Excellent job,True
@hoomandehghani3430,2022-09-19T19:11:48Z,0,"by_country['LanguageHaveWorkedWith'].apply(lambda x: x.str.contains('Python')                                            .value_counts(normalize=True)                                            .mul(100)                                            .round(decimals=2)                                            .astype(str)                                            + ""%"") \                                     .loc['Yemen']",True
@akshayagarwal314,2022-09-19T17:28:27Z,0,"I did this:  Here, I felt that instead of dividing by the number of respondents from that country, I divided by the number of people who responded to the Language Worked with question from that country.  def apply_filter_language_python(x):     if x.notna().sum() > 0:         return x.str.contains('Python').sum()/x.notna().sum()     elif x.notna().sum() == 0:         return 0     else:         return 'Error'  new = country_group['LanguageWorkedWith'].apply(apply_filter_language_python) print(type(new)) print(new.sort_values().head(50))",True
@keenchkaat1543,2022-09-09T09:56:49Z,0,When trying to perform groupby with .loc.....i am ending up getting this error --> 'No axis named .... for object type Series' any help?,True
@fiefiego2298,2022-09-07T09:12:53Z,1,"thank you Corey!! this is a wonderful pandas series!! you make the concept so easy that even a python beginner (that is me) without programming background in colleague can understand!! i'd like to share my solution as well: (since i don't know concat method, i calculate the answer first then convert them into a dataframe by dictionary) know_py = country_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').sum()) answer = df['Country'].value_counts() per_cent = know_py/ answer result = pd.DataFrame({'answer': answer, 'Python': know_py, 'percentage': per_cent})  i find you stop uploading new tutorials for a long time, hope everything goes well with you. and strongly looking forward to hearing from you soooooon!!  thank you & greeting at 2022 sep 7th :)",True
@usernoneofyourbusiness,2022-09-04T23:03:16Z,0,"To find the percentages I did:    country_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').sum()/len(x))   Since x is a series, len(x) will be the number of items in the series. Or in this case, the number of people in the group in total.",True
@felipegutierre7037,2022-08-16T23:19:46Z,0,Thanks Corey! You are so cute >.<,True
@Rave_Consolidated,2022-08-09T23:46:22Z,0,how do you apply the strip() to the complete dataframe,True
@user-qn5by5iv7u,2022-08-07T09:17:04Z,0,2022,True
@nowknow0,2022-08-03T10:01:36Z,0,"More Shortcut of the Last Questions Code:   ## Q: What % of people from each country know Python? ## Code:  country_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').value_counts(normalize=True))",True
@briananderson2283,2022-07-29T20:25:58Z,0,Hi!  To get the % of people per country who know Python I did the following:  country_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').value_counts(normalize=True))   It is not organized but I think it worked.,True
@anubhavrauniyar3192,2022-07-28T05:20:21Z,0,We Love You Corey Schafer!!!!!!!!!! Lots of Love From India‚ù§,True
@onurkoc6869,2022-07-16T08:09:41Z,0,thank youuuuu professor we glad to listen you:)),True
@laythkal-shblawi7101,2022-07-07T04:07:25Z,0,"what I did is count all ppl that knows python and dividid by each country  country_grp = df.groupby('Country')  python_count = 0 pyArry = country_grp['LanguageHaveWorkedWith'].apply(lambda x: x.str.contains('Python'))  for py in pyArry:          if py == True:         python_count += 1 print(python_count)    country_grp['LanguageHaveWorkedWith'].apply(lambda x: x.str.contains('Python').sum()/python_count*100).nlargest(10)   results for top 10 countries  Country United States of America                                20.041717 India                                                   13.150885 Germany                                                  6.817953 United Kingdom of Great Britain and Northern Ireland     5.400583 Canada                                                   4.003317 France                                                   3.576096 Brazil                                                   2.389928 Australia                                                2.088359 Netherlands                                              2.088359 Poland                                                   2.040611 Name: LanguageHaveWorkedWith, dtype: float64",True
@wornoutrecords9567,2022-06-23T09:47:35Z,0,"Why does country_grp[""LanguageWorkedWith""].apply(lambda x: x.str.contains(""Python"").mean()) not work?",True
@iradukundacynthia3038,2022-06-20T18:49:12Z,0,Thanks a lot. This helped me a lot!!!,True
@brewtalxxx,2022-05-31T15:08:04Z,1,"Thank you so much for this video. I learnt way more from this than the many hours I spent sitting in class listening to a teacher who just wanted to end the lesson early or have long lunch breaks. This is really precious. And thanks for the reassurance that if I find this difficult, there's nothing wrong with me LOL.",True
@jaxnaur218,2022-05-31T07:35:01Z,0,"For vedio like this, you can get it free. It is amazy! Thanks for your work bro. God bless you!",True
@sourabhzambre2105,2022-05-26T08:13:52Z,0,My Solution -> cntry_grp['LanguageWorkedWith'].apply(lambda x : x.str.contains('Python').value_counts(normalize=True)).loc['Uganda']  I do think its correct ü§î,True
@seyedmortezamirhoseinineja944,2022-05-25T19:24:31Z,0,A simpler way of figuring out the percentage:  country_groups['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').sum()/len(x)*100),True
@vinuvarshith6412,2022-05-23T09:04:33Z,0,"var=ctr_grp['LanguageWorkedWith'].apply(lambda x:x.str.contains('Python').value_counts(normalize=True)) var_1 = pd.DataFrame(var) var_1.reset_index(inplace=True) var_1.rename(columns={'level_1':'Knows Python?','LanguageWorkedWith':'Percentage'},inplace=True) var_1['Knows Python?'].replace({False:'Don\'t Know', True:'Knows'},inplace=True)   var_1  Lengthy, but I wanted to show the result in a DataFrame that's why.",True
@orestescarafia5672,2022-05-17T18:15:07Z,0,"When you get the % sortedby , could you use a filter for example filt= (python.df[""NumRespondents""]>40) and apply it to the dataframe so you get info more precise?",True
@fabianperson,2022-05-09T23:32:11Z,0,"Hey Corey, thanks for the wonderful tutorial!  Here is my solution to the problem:  country_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').mean() * 100).sort_values()  Whenever you are intersted in percentages/ratios, it is very convenient to use the mean() function. It's a little abstract, but it basically is the number of true answers divided by the total number of answers. Multiply this by 100 and you get a percentage.  Cheers :)",True
@kynaston89,2022-05-09T14:31:59Z,0,"Hi Corey, I have watched your video many times to apply on what I am doing. I am not really working with data as my main job but I love it. I have a question, how can we know the number of people those know Python only from each country. Much appreciated.",True
@ainurat5240,2022-05-09T11:40:36Z,0,.apply(lambda x: x.str.contains('Python').value_counts(normalize=True)),True
@benja5019,2022-05-02T04:06:29Z,0,amazing video!,True
@panagiotisgoulas8539,2022-04-30T23:42:23Z,0,Is there a fast/elegant way without using Counter class or playing with frequency dictionaries that I can get a series with the count of every programming language?  For example you can do df['LanguageWorkedWith'].str.contains('Python').sum() and get the number of times Python is met. But I would like a series with all programming languages and their count numbers without having to pass each programming language as an argument on the str class above.  If that 'LanguageWorkedWith' had just a 1 programming language per row I could do .value_counts() and get it over with.,True
@biprarshichakraborty1255,2022-04-27T21:20:45Z,0,"I actually did the following, and I think it gets the job done in one line of code; country_grp['LanguageWorkedWith'].apply(lambda x: 100*x.str.contains('Python').sum()/x.notna().count())  Do correct me if I'm wrong.",True
@vojislavmladenovic2968,2022-04-27T09:45:42Z,0,df.groupby('Country')['LanguageWorkedWith'].apply(lambda x: 100*x.str.contains('Python').sum()/ (x.count() + x.isnull().sum() ) ),True
@jawadmansoor6064,2022-04-20T12:01:12Z,0,"9:08 if you have to do that to a specific country e.g. UK, how many people hobyist from UK and how many are not, how do you do that?",True
@MauriceWilliams,2022-04-19T23:33:51Z,0,Corey this Tutorial was awesome my Guy!,True
@BillyHudson1,2022-04-17T01:51:25Z,0,"Very helpful, thank you. Solve multiple problems for me",True
@BillyHudson1,2022-04-17T01:38:14Z,0,33:07,True
@Coney_island23,2022-04-14T18:13:41Z,0,excellent!!,True
@sithabiledlamini6125,2022-04-14T17:36:29Z,0,Never used lambda,True
@MrVassuraw,2022-04-14T02:19:43Z,0,"can we use agg function and return some function based on multiple columns. Something like this -  df.groupby(df.BOOKING_DATE).agg(Booked=(('FLAG', 'ZLINEITEM') ,(lambda j, i: i.sum() if i.eq(1).any() and j.eq('X')  else None)))",True
@arashfasih7323,2022-04-12T00:21:17Z,0,Your technique for  explaining things are truly great.,True
@bosorensen,2022-04-07T08:55:10Z,0,Excellent videos!!! Thank you,True
@josemanuelmunoznaranjo1822,2022-04-06T10:43:04Z,0,"Very good explanation, thanks!!!",True
@drotta45,2022-04-04T07:57:44Z,0,This is my solution   country_group['LanguageWorkedWith'].apply(lambda x : x.str.contains('Python').value_counts(normalize=True)),True
@1976turkish,2022-04-01T22:34:28Z,0,Thank you,True
@charimuvilla8693,2022-03-30T01:58:47Z,0,At 35:40 since you want to get the percentage of boolean values that are 1 you can pretty much just replace .sum() with .mean(). It's sum/length.,True
@SimonYells,2022-03-29T14:44:18Z,0,Great video! Thank you so much !,True
@freehappymeal,2022-03-25T19:36:29Z,0,"This was a very helpful video. Thank you, Corey!",True
@chanchalarya983,2022-03-08T14:48:21Z,0,how to groupby for product amount greater the $10 ???? plz tell,True
@daltonkurnia5035,2022-03-04T16:56:11Z,0,just want to comment to help increase the algorithm to find this video. so informative and helpfull. thanks for the sharing,True
@kuricom,2022-02-15T21:08:10Z,0,Oh Boy. This guy is Great.,True
@slimyelow,2022-02-08T10:27:09Z,0,Dude from Sao Tome and Principe is definitely watching this video.,True
@astali5674,2022-02-05T23:13:28Z,0,"country_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').value_counts(normalize = True)), this is my answer to the percentage of python users in each country, I m not sure if it is right?",True
@giuliodesabbata6357,2022-02-05T11:12:48Z,0,"""and if i run this""",True
@muntadher8087,2022-02-03T13:10:47Z,0,Thank you so much!,True
@yashjain1272,2022-02-02T14:56:03Z,0,country_grp['LanguageWorkedWith'].apply(lambda x:x.str.contains('Python').value_counts(normalize=True)) let me know if this was the correct way,True
@saraghafelehbashi5808,2022-01-28T04:23:44Z,1,Wow! what a fantastic explanation! I saw lot of videos! but you are different! i know why? because you are using pandas with great examples and nice explanation! thank you again!,True
@renatasadretdinova3483,2022-01-26T21:57:31Z,0,"very useful, thank you!",True
@__-qo9ub,2022-01-18T06:36:41Z,0,"grped_bycountry[""LanguageWorkedWith""].apply(lambda x : x.str.contains('Python').value_counts(normalize = True))",True
@MrJeeoSoft,2022-01-17T23:01:33Z,0,Impressive!,True
@premgarg5534,2022-01-13T04:40:19Z,0,Where is this dataset used in video  Great Tutorials BTW!!,True
@bevg1,2022-01-13T04:17:18Z,0,amazing video!,True
@bhavishyakumargoyan2634,2022-01-12T05:39:44Z,0,sir where is the csv file used in this video,True
@dennisp5302,2022-01-07T05:40:16Z,0,I just went through Part 8 a second time. Thanks a bunch!! I learned a lot.,True
@saraning498,2022-01-05T16:03:40Z,0,"I have another solution to the question, but my results are slightly different from yours.    def use_python(Language):     a=Language.str.contains('Python').sum()     b=Language.count()     return (a/b)  country_grp['LanguageWorkedWith'].apply(use_python)  country_grp['LanguageWorkedWith'].apply(use_python).loc['Japan']",True
@adamk1520,2022-01-03T19:38:00Z,0,"If you compare what you are doing here in Pandas vs SQL in a relational db environment, the SQL in a RDBMS is significantly more efficient and straight forward.  I imagine there are different reasons for why you would use one over the other.",True
@lion87563,2021-12-30T17:08:33Z,0,"So the main goal of GroupBy objects is to create new Data Frames, with easier manipulation of data from some original Data Frame?",True
@SaintPepsiSanCoca,2021-12-29T06:57:55Z,0,Jeez this one was tough!,True
@dmg8529,2021-12-18T16:17:10Z,0,"I hope my solution to practice problem works: please let me know if I'm wrong since i dont have data to validate my soln. country_grp['LanguageWorkedWith'].value_counts(normalize=True).loc['Python']; (here country_group is dataframe.groupby['country'] as in the vid.)",True
@SudhirKumar-rl4wt,2021-12-12T10:54:52Z,0,# % of people said they know python country wise  country_group['LanguageHaveWorkedWith'].apply(lambda x : 100 * (x.str.contains('Python').sum()/x.count())),True
@tanmaychakraborty5472,2021-12-05T16:19:56Z,0,"python=country_group[""LanguageWorkedWith""].apply(lambda x: x.str.contains('Python').sum()) country_res=df[""Country""].value_counts() python/country_res",True
@NedimMalik,2021-12-03T10:54:57Z,0,"This is my solution, not the prettiest but the most basic one ;) :   #Grouped by countries sorted_countries = df.groupby(['Country'])  #Total number of people in each country country_total = sorted_countries.size()  #People working with Python in each country langworked = sorted_countries['LanguageWorkedWith'].apply(lambda vrb: ( vrb.str.contains('Python').sum()))  #Percentage of people that python by country print(((langworked/country_total)*100).head(50))",True
@joncochran9647,2021-11-27T03:15:30Z,0,I've watched quite a variety of different data analysis tutorials and this one was easily one of the most engaging for me. Having interesting data really helps.,True
@snaidu70,2021-11-24T20:49:49Z,0,"Corey, thank you for your amazing work. Your work is truly inspiring. On a side note, the error messages in this Pandas library need to be better.",True
@markh.9568,2021-11-17T06:13:25Z,0,country_grp['LanguageWorkedWith'].apply( lambda x: x.str.contains('Python').mean()) Multiply by 100 if you prefer whole number percentages,True
@md.abdullahalmasum4942,2021-11-09T12:47:45Z,0,best video. thanks corey,True
@maririasere5132,2021-11-06T19:44:10Z,0,where can I find your actual data set .please help me .the one your using in the video,True
@S3bbas8aheri,2021-11-06T12:43:25Z,0,"Your explanation is very excellent. It helped a lot   Please connect Thanks",True
@marcello4258,2021-11-03T19:45:59Z,0,I guess one of the advantages having those grouped objects compare to filterin will be performance since since if you do multi manipulations on it you do not need to rerun it on the whole dataset every time,True
@GUPTHACS,2021-10-31T10:18:21Z,0,really very helpful and easy to learn pandas. Thank you so much.,True
@ramanaambore9013,2021-10-26T13:57:23Z,0,country_grp['LanguageWorkedWith'].apply( lambda x: x.str.contains('Python').mean()*100),True
@antoniodefalco6179,2021-10-25T21:49:58Z,0,"you're a amazing teacher man, thank you for this free content",True
@krgoutham8852,2021-10-25T16:44:18Z,0,"1. In group by method, is there a way to get the total sum in the last row ? ( Similar to how we get in the pivot table output in excel ) 2. The Group by output does not show the count of missing ( NA) values . Any way to get this ?",True
@kaviranjitha6624,2021-10-25T07:36:24Z,0,"Hi, While I'm reading CSV Survey file i didnt get Social Media column. In that file there is no SocialMedia column Why...? Pls help me.......",True
@ironpolux,2021-10-25T01:45:22Z,1,Question : is there a way to do a groupby (Age) and calculate the median of ConvertedComp if the LanguageWorkedWith contains SQL ??,True
@VinhTran-mp9tn,2021-10-24T09:35:40Z,0,Thanks you so much. So helpful,True
@mohammadyahya78,2021-10-15T14:48:40Z,0,Can you please do a video on groupby('column').cumcount() ?,True
@mohammadyahya78,2021-10-15T13:40:24Z,0,Thank you very much. Can you please do more advanced pandas techniques for combining and grouping data?,True
@vijaybhatt4347,2021-10-14T04:27:05Z,0,You're Genius  Love From India  You mentioned India in your tutorial  Love this gesture üá∫üá∏üáÆüá≥,True
@ironpolux,2021-10-13T22:30:21Z,0,"Really enjoying this series, thank u Corey!",True
@ironpolux,2021-10-12T15:39:20Z,0,YES please! a video about multiple indexes pls!,True
@user-db5yx3fi4u,2021-10-08T03:57:14Z,0,the way I used to solve the problems is that: country_grp['LanguageWorkedWith'].apply(lambda x: (x.str.contains('Python').sum())/(x.count()))  but the result seems to be a little bit different. still working on it.,True
@jasiwhirl4223,2021-10-02T10:42:18Z,0,"Hi, thank you, Corey, for this videos!! This is to share my approach: df_python_pct=df_grouped['LanguageWorkedWith'].apply(lambda x:(x.str.contains('Python').sum()/x.count()*100)",True
@AAND8805,2021-10-01T06:27:08Z,0,"I am following your pandas series since the last 3 days and may complete in 1 or 2 days max, I will come back to the series to revise it, very well made Series and keep up the good work !üòÄ",True
@bhargav1811,2021-09-25T09:30:08Z,0,Every second of your python video are really worth it!!!,True
@rajsuriyang3427,2021-09-24T11:17:08Z,0,I want Multiple index video,True
@mlrpawrao,2021-09-24T02:55:21Z,0,"For getting Percentage of respondents knowing python ,  Can we use below?  country_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').sum()/len(x))*100  Let me know if this works..",True
@way_to_be_analyst6042,2021-09-18T11:39:19Z,0,im just diving into pandas and would like to say - GREAT THANK YOU for such nice and detailed explanation.  great job!,True
@ahmedidris305,2021-09-13T10:05:43Z,0,"Hello, Corey! Thank you very much for this crystal clear tutorial series in Pandas. I have learned a lot through it. You made Pandas very intuitive to get.  For the percentage of individuals who know Python per country I used the following solution: survey_df.groupby(['Country']).apply(lambda grp: (grp['LanguageWorkedWith'].str.contains('Python').sum() / len(grp.axes[0]) ) * 100 )",True
@bouchradahamni9881,2021-09-12T20:10:31Z,0,"great great great  explanation , thank you",True
@rahulranjan8682,2021-09-12T07:02:49Z,0,make video on multiindex series. how to use them!,True
@shanayasingh6864,2021-09-11T08:57:58Z,1,I am a huge fan of your videos. Thanks a lot for making this wonderful tutorialüòá,True
@rohithkumar8492,2021-09-08T10:16:38Z,0,Thanks a lot Corey,True
@mohammedhilali,2021-09-04T12:29:46Z,0,"Hello Corey,  Thanks a lot for the videos! you make this topic a lot simpler.  I just wanted to share something regarding LanguagesHaveWorked grouped by Country (on 36:00). I think the below code is rather simpler if we just wanna look at the percentages only, but I don't how reliable this method might be  country_grp['LanguageHaveWorkedWith']\ .agg(lambda x: (x.str.contains('Python').sum()*100/len(x)))",True
@paulorcordeiro3916,2021-09-03T11:43:33Z,0,"Corey, the content of your videos are amazing. This tutorial in special is sensational.",True
@shivanigangwar4959,2021-09-01T08:46:17Z,0,"I have 3 columns, I want to sum over col1 and grouby col2 and display all three. how can I do that ?",True
@ltoco4415,2021-08-30T13:49:19Z,0,Would love to see a video on Multi-level indexing.,True
@karthikeyasankaramanchi8256,2021-08-26T11:58:23Z,0,"It is too late, But I would like to share my solution for calculating percentage of people in the survey who knows Python country_group[""LanguageWorkedWith""].apply(lambda x:(x.str.contains(""Python"").sum())/len(x))",True
@varunkamra2144,2021-08-24T07:16:55Z,0,Awesome explanation,True
@datalove6577,2021-08-23T10:48:29Z,1,"My solution  :)  python = country_grps['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').sum()) random_series = country_grps['LanguageWorkedWith'].count() random_df = pd.concat([python, random_series], axis='columns') random_df['Percent'] = ((random_df['Python'] / random_df['TotalNo']) * 100)",True
@aj35lightning,2021-08-23T05:44:32Z,0,pls make a video on how to deal with multindexes,True
@themoonlight1922,2021-08-22T15:54:50Z,1,My version of practice : # task : find the % of people who know python for each country def count_python(languageWorkedWithCol):     totalPeople = languageWorkedWithCol.str.contains('Python').count()     if totalPeople == 0:  # otherwise divide by 0 below may happen         return 0;     peopleWhoKnowPython = languageWorkedWithCol.str.contains('Python').sum()     return peopleWhoKnowPython * 100 / totalPeople country_grp['LanguageWorkedWith'].apply(count_python),True
@themoonlight1922,2021-08-22T15:38:46Z,1,"def count_python(languageWorkedWithCol):     return languageWorkedWithCol.str.contains('Python').sum() country_grp['LanguageWorkedWith'].apply(count_python)   my understanding :  by calling the apply() at the country_grp, for every country, apply() will call the count_python() upon the col 'LanguageWorkedWith' Please tell me whether my interpretation for the apply method is correct or wrong.",True
@gireeshkodali1231,2021-08-22T05:34:49Z,0,"In order to get the num of respondents from each country who knows Python, one can do the below as well:   python_filter = df['LanguageWorkedWith'].str.contains('Python',na=False) df[python_filter].groupby('Country').size()",True
@panpan4433,2021-08-21T20:48:53Z,1,"For your exercise (What % knows Python) , I divided the sum in the lambda function by x.count() then multiplied by 100 :     country_group['LanguageWorkedWith'].apply(lambda x: 100 * x.str.contains('Python', ).sum() / x.count())  Thanks for the free content, awesome",True
@denizcicek7333,2021-08-21T13:02:19Z,0,"You are just wonderful, it makes so much fun watching your tutorials. I finde directly the answer, those I need.  God bless you brother.",True
@Sara-fp1zw,2021-08-21T07:59:07Z,0,country_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').value_counts(normalize=True))['Pakistan']  i tried this to get % of ppl working with python and it somehow worked :),True
@manavarora3686,2021-08-19T17:55:50Z,0,Who in hell dislikes these videos?,True
@theunknown2090,2021-08-17T16:11:00Z,0,How to create a dataframe where all the groups names are index and all the group  elements are in one row   Df   Country   India.                Row1                          Row2                           Row3    Usa.                Row7                        Row 8,True
@dimaua1830,2021-08-15T03:00:45Z,0,"# same idea, but slightly cleaner  python_pct = country_uses_python / country_respondents * 100 python_df = pd.concat([country_respondents, country_uses_python, python_pct], axis='columns', sort=False) python_df.rename(columns={'Country': 'NumRespondents', 'LanguageWorkedWith': 'NumKnowsPython', 0: 'PctKnowsPython'}, inplace=True) python_df",True
@nsgarcia10,2021-08-13T05:01:48Z,0,"When doing a sort value such as the PctKnowsPython, how do we set a minimum amount of responses (50 for example)?",True
@ajinzrathod,2021-08-13T04:38:04Z,0,Why is df['Respondent'].count() throwing a keyError ?,True
@yejia0217,2021-08-12T20:54:49Z,0,"Hi Corey, really enjoy your video series, they are very helpful for me on my way becoming a data scientist. Thank you very much!  And during this video, I can't help myself thinking a scenario, and that is, how could we create a Series, that contains the most popular Social Media for each country, along with their percentages? I have tried a couple times but just couldn't figure it out. If anyone can help me out with that, really appreciate it!",True
@wakil08,2021-08-11T11:40:41Z,0,"Great series of videos!, Thanks Corey, you explanation is simply magical and I learnt a lot from it. Just on the homework question for the percentage of the people that know python per country, I did it in the same line by extending the lambda function:  python_knows =country_group['LanguageWorkedWith'].apply(lambda x:                                  x.str.contains('Python').sum()/x.shape[0]*100)",True
@smitpatel1358,2021-08-10T16:53:12Z,0,"Great Series, Corey! Thank you very much!",True
@vanshsharma6525,2021-07-30T06:23:30Z,0,I have another method in which we can use value_count function where we used sum function and though I am a beginner I think Corey's method is a bit wrong as it is also considering the NA values which are there is the language workedwith column which is not right  Kindly help me on this thing üòÄ,True
@gregbrown9287,2021-07-29T21:43:37Z,0,"When calculating the average of respondents that know python per country, I believe dividing the sum by len(x) within the lamda fucntion would have also yielded the answer.",True
@sadraplyrics1,2021-07-26T15:15:04Z,0,"I was just wondering if on 35:38 you could have just modified the lambda expression so it could just do all the calculations in place like so: country_grp[""LanguageWorkedWith""].apply(lambda country_ser: (country_ser.str.contains(""Python"").sum()*/country_ser.value_counts().sum())*100) What I tried to do was to count the sum of total respondents for each country and do all the necessary calculations inside the lambda,  and, though the result that I got were similar to yours, they still were slightly different.  And also, thank you so so much! That pandas series is so cool and informational that I don't even have enough vocabulary to say how grateful I am!",True
@51pcmurphy,2021-07-18T21:07:45Z,0,"I believe this video is not current enough for you to receive this message, but I have learned more from you in this series of Pandas Video then I have with LinkedLearn and UDEMY.",True
@hozaifafouad,2021-07-13T02:35:42Z,0,Broooo you're awesome! mashallah,True
@tourist1870,2021-07-10T12:28:32Z,0,"It's maybe not the best solution in terms of complexity and clear overview but it was first that came to my mind:  country_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').value_counts(normalize=True))   We only obtain a True/False values with the percentage of each country but still it's one line of code and imo it's the best way when the time matters. For particular countries we can also append .loc['Country_1', 'Country_2'...]",True
@pawlowski6132,2021-07-07T11:21:57Z,0,12:05 value count in %,True
@dries59dep,2021-07-06T19:45:55Z,0,"how do you get the help for the commando's from pandas ? I have enabled hinterland, but even then i get no help here ...",True
@devendarreddydev8545,2021-07-06T12:34:01Z,0,Sir if you don't mind please do tutorials on machine learning,True
@eddg985,2021-07-05T13:58:34Z,0,"My solution:  country_sum = country_group['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').sum()) country_total = df['Country'].value_counts() country_percentage = (country_sum / country_total * 100) country_info = pd.concat([country_total, country_sum, country_percentage], axis='columns') country_info.rename(columns={'Country': 'TotalRespondents', 'LanguageWorkedWith': 'UsesPython', 0: 'UsesPythonPercentage'}, inplace=True)",True
@dheeraj3945,2021-06-30T07:03:36Z,0,"I might be too late to question but , I've noticed that the words in Column names in the schema data frame start with an upper case. Is that a standard convention?",True
@arjungoud3450,2021-06-29T17:52:00Z,0,"It is very helpful, thanks a lot.",True
@shivamagrawal8983,2021-06-23T13:48:26Z,0,"If there was a god of python, It would you Mr. Corey!",True
@aborucu,2021-06-23T08:25:05Z,1,Perfect explanation. Making  a convoluted yet so important concept crystal clear through step by step  explaning and also giving connections to pandas object types. Cheers!,True
@snehalbhartiya6724,2021-06-16T13:39:56Z,0,dope stuff bro,True
@user-tb2jp7kg2c,2021-06-16T07:12:24Z,0,"Corey, thank you very much for your free videos!",True
@RavenEX1980,2021-06-16T01:58:59Z,0,"best tutorials ever, i have read lot of books, but your technique is global and works best...keep on the good word @Corey Schafer",True
@mescalinesam,2021-06-09T22:18:12Z,0,Solved the task given using this --    df.groupby(by = 'Country')['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').value_counts(normalize = True)),True
@TheGreatAnnouncer,2021-06-07T21:57:26Z,1,Thanks for everything big man,True
@pewolo,2021-05-31T05:37:49Z,36,"Let's all admit that this dude is a hard working man and his work is just a wow! I've been following him for quite some time now and I am always impressed by how thoughtful, tactical and clear his explanation is in every tutorial he makes.   Hat off to you, dude!",True
@yaoimilk8929,2021-05-30T19:11:07Z,0,"This was amazing, thank you so much!",True
@rabago85,2021-05-30T08:21:40Z,0,"35:55. I don‚Äôt have the data or code to run to see if this would work right now, but at first glance I‚Äôd run: .apply(lambda x: x.str.contains(‚ÄòPython‚Äô).mean())  Taking the mean of a list of Boolean should give the percentage of true vs total number.",True
@mahalingamsundararaj7003,2021-05-25T14:47:04Z,0,How mulitiple indexing is working,True
@alejandropereyra438,2021-05-21T15:58:07Z,0,"This video is so useful , the simplification that python does for the problems is so helping. is the best language  in the programming of code. And the proffesor of this video is really a genius. !!! thanks.",True
@lefttraces7207,2021-05-16T11:52:15Z,0,44:30 -  U S A ! U S A ! U S A !,True
@RishiSaikia,2021-05-16T11:24:53Z,0,country_grp['LanguageWorkedWith'].apply(lambda¬†x:¬†x.str.contains('Python').sum())¬†/¬†country_grp['Respondent'].count(),True
@ayusshrathore,2021-05-03T05:46:09Z,0,I hope this can too find the percentage of people who know Python from India. country_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').value_counts(normalize=True)).loc['India'],True
@studiesmail2677,2021-05-02T22:23:23Z,0,I am waiting for your playlist on machine learning.,True
@studiesmail2677,2021-05-02T22:20:38Z,1,"To find the number of people who knows python in india , instead of using country_grp[""LanguageWorkedWith""].apply(lambda x:x.str.contains(""Python"").sum()).loc[""India""] we can also use country_grp.get_group(""India"")[""LanguageWorkedWith""].str.contains(""Python"").sum()",True
@user-tx3mo1ez2n,2021-05-02T04:22:36Z,0,I subscribed.,True
@franciscomiranda3239,2021-04-23T08:27:55Z,0,Source code??,True
@akashshiva5100,2021-04-22T04:50:50Z,0,"in the new version of python (like I am using python 3.9 ) the outputs of the count, median functions, and many other functions are changed",True
@vagelisilias,2021-04-19T12:41:54Z,0,"I am a GIS student and I want to thank you because I'm doing my last assignment for university and I'm using Geopandas, matplotlib, pandas, cartopy and forth on and you helped so much with your videos, I have build a nice map and I have produced different tables with my data. Thanks god you are out there and sharing your knowledge free",True
@felipegomez3047,2021-04-18T22:36:05Z,69,"I'd like to share my solution to the practice question:  country_grp['LanguageWorkedWith'].apply( lambda x: x.str.contains('Python').sum() / len(x) * 100 )  As you can see it's just as symple as adding "" / len(x) * 100 "" in the lambda function, where len(x) is the total number of users for each country.",True
@samtaylor2169,2021-04-16T11:58:33Z,0,You are the man,True
@chandragupta2828,2021-04-15T11:53:02Z,0,"country_grp[""LanguageWorkedWith""].apply(lambda x: x.str.contains('Python').mean()*100)",True
@Loopyrad,2021-04-14T16:49:34Z,0,Great tutorials! Thanks allot for your work! :) Solution for percentage of persons knowing python for each country: df2.groupby('country')['prog_lnguages'].apply(lambda x: x.str.contains('python').sum() * 100 / x.count()),True
@chukchai,2021-04-09T15:20:57Z,0,"I used this technique to work out the percentage, does it work?  country_group['LANGUAGEWORKEDWITH'].apply(lambda x: x.str.contains('Python').value_counts(normalize=True).sum())",True
@sulaiman1408,2021-04-09T13:33:46Z,0,"Hi, Corey. Thank you for all what you did. You made learning Python be more easy. I have question. What is the difference between (pd.concat) and (pd.merge)? When I usually want to merge two datasets, I use (pd.merge). Now it seems confusing to me that the two functions do the same!",True
@ranjeetnbittu,2021-04-08T13:00:46Z,0,"Thank you for the nice video, but I have a question: how to combine multiple excel sheets having lets - say 100 columns (huge number of columns) and different excel file is having different structures. let me expand my question bit more: having 5 or more different excel sheets (different files) and 100 columns are in column, but every file is having few different columns as well. So how to combine these all files/sheets data into one excel file. Thank you so much in advance to you for looking into my queries and hoping to get some solutions for the same. I like to watch your videos and learnt a lot from them. Keep sharing you knowledge.",True
@bernardorinconceron6139,2021-04-07T22:06:37Z,0,"I really find your videos really good, and well explained. Thank you very much indeed.",True
@ashishacharya4719,2021-04-05T09:39:29Z,0,you should have  used count method in case of LanguageWorkedWith since some of the people have skip the suryey country_grp['LanguageWorkedWith'].count(),True
@nabildatascience7422,2021-04-03T14:36:41Z,0,i liked your video better then the platform i am learning from,True
@fhdhejeh63,2021-04-02T12:14:40Z,0,Than you a lot for this series it has been very helpful to me . However I would appreciate some advice on how some beginner like myself can improve his skills since it is very easy to forget what we learn,True
@prashantdas3618,2021-04-01T09:16:55Z,0,"#Ques at 34:20, what percentage of people from each country know Python?  dfp = df.loc[df['LanguageWorkedWith'].str.contains('Python', na=False), :] # people who work with Python  pythoners = dfp.groupby('Country')['LanguageWorkedWith'].count()  everybody = df.groupby('Country')['LanguageWorkedWith'].count()  derived = pd.concat([pythoners, everybody], axis='columns')  derived.columns = ['Pythoners', 'Everyone'] # renaming columns  derived['Percentage_of_Pythoners'] = derived['Pythoners'] / derived['Everyone'] * 100  print(derived)",True
@walternyc,2021-03-31T16:01:19Z,0,Working on a project evaluating an employee survey and this is just what the doctor ordered. Thanks! One of the best channels in YouTube for data analysis hands down,True
@rukhan8900,2021-03-26T00:30:17Z,1,The reassurance at the end was so appreciated as a beginner. Thank you for your help !!!,True
@shameekagarwal4872,2021-03-19T13:01:02Z,0,what i had come up with  challenge_group = df.groupby(['Country']) get_percentage = lambda x : x.str.contains('Python').sum() / len(x) challenge_group['LanguageWorkedWith'].apply(get_percentage)  its almost what you did... thanks a lot!,True
@harisjaved1379,2021-03-16T05:24:35Z,0,Dude this is amazing! Nice work,True
@vishwask.sharma9249,2021-03-07T15:54:04Z,0,"As Corey had said to try the query yourself, I've done that. But it is just raising a warning and gives the percentage, the percentages are a little different from what the original ones from the video and idk why is that happening. PS. I've used the same 2019 data soln:  country_grp['LanguageWorkedWith'].apply((lambda x: x.str.contains('Python').sum()/x.count()*100)).loc['Country_Name']",True
@rafiullah-zz1lf,2021-03-03T16:46:20Z,0,Hey bro i m trying to regex data on my data can u do a video,True
@cindycrawford3250,2021-03-03T01:17:11Z,0,"Awesome videos! Thanks for everything, ive learned so much watching your videos, congrats from Brazil =)",True
@saiakhil4751,2021-03-02T17:04:39Z,0,I signed up for brilliant org just for Corey Schafer.  Thanks for sponsoring him.,True
@varunrajbelgaonkar7808,2021-03-02T15:36:20Z,0,"I want to get count of every language used by respondents.  languages = df[""LanguageWorkedWith""].str.split("";"") lan_counter = Counter(languages.apply(pd.Series).values.ravel())   This code returns lot of NaN value. Plz suggest some better way to do it? Thanks1",True
@Youngcl77,2021-03-01T00:50:55Z,0,"Thank you very much, Corey, for the great video! I am getting involved with the data team at my company, and this has helped me tremendously!",True
@tarunmahendra4233,2021-02-26T06:12:51Z,0,we can use   country_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').value_counts(normalize = True))  if we want the percentage of respondents who know python in each country.,True
@ssigitas69,2021-02-20T13:24:56Z,0,"I'm watching all this series of video and very happy with that. Very clear explanation and useful tutorial. Thanks so much. I tried to do to show all columns on Pycharm, how you doing here, display_max_columns, 85, but it didn't work for me. Does it just for Jupiter notebook?",True
@egebayraktar6620,2021-02-19T00:20:59Z,0,"Great tutorial, thank you!",True
@nickt423,2021-02-18T20:43:13Z,0,"Hello Corey (or anybody else), @21:46 How would return just the top row for each country? I want it to look something like this... Country           Social Media Afghanistan    Facebook         15 Zimbabwe       Facebook          3",True
@somthingwrong3602,2021-02-14T17:37:41Z,0,–í –∫–æ–Ω—Ç–∞–∫—Ç–µ(v konta:kte) -- In contact (literal translation) .,True
@asawanted,2021-02-11T18:08:04Z,0,country_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').value_counts(normalize=True))  This is what I came with,True
@joaniradhima8813,2021-02-10T11:58:03Z,0,"Simple one-line solution if you only need the percentage of True  country_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').value_counts(normalize=True)).loc[:, True]",True
@darkmatter4235,2021-02-09T04:00:00Z,0,"I use this to get % people from each country who learned Python:  country_gr[""LanguageWorkedWith""].apply(lambda x: (x.str.contains(""Python"").value_counts()/(x.count()))*100)",True
@prakharshukla1846,2021-02-07T15:42:02Z,0,"country_group[""LanguageWorkedWith""].apply(lambda x: x.str.contains(""Python"").sum()/len(x))  percentage of people working with python for different countries",True
@adarshtiwari7395,2021-02-05T13:21:35Z,0,Two of my favourite people on earth:  1. Corey Schafer 2. Corey Taylor,True
@ishajain1083,2021-02-04T16:21:07Z,0,Where can I find this dataset?,True
@yossefdawoad4311,2021-02-04T00:46:15Z,0,"here's i believe a quick and easy way solution for the practice country_grp['LanguageWorkedWith'].apply(pctOfPyDevs) where: def pctOfPyDevs(x):     all_Devs = x.count() #count all developers in the specific country which is possible by the groupby object in pandas     PyDevs = x.str.contains('Python').sum() #count python developers in the same specific country      return (PyDevs/all_Devs) * 100 #returning calculations (part / whole) * 100  **Note** this returning a Series of the DataFrame not a dataFrame since we don't specify any additional columns",True
@sahajrajmalla,2021-02-02T02:43:09Z,0,"I don't understand, why do we need to use grouping for? I mean it's like filtering. What's difference between them?",True
@keramatjahangiri,2021-01-31T19:06:56Z,0,"Thank you, I can't find the link to download the file :(",True
@joshuaj.aguero2225,2021-01-31T06:22:48Z,0,"I am using filters to get data on the median ConvertedComp by age. I used the following code:  a=19 agelis=[] meanlis=[] medianlis=[] while a>18 and a<51:     age_df = df.groupby(['Age'])     age_group=age_df.get_group(a)     mea=age_group['ConvertedComp'].mean()     med=age_group['ConvertedComp'].median()     agelis.append(a)     meanlis.append(mea)     medianlis.append(med)     a+=1  ...it worked ok, but when it populates the lists it is going onto a new line each after each value is appened. So the list is in a rather long vertical orientation. I fixed this manually to make my plot, however this would not be a feasible with really large lists of data. I am very new to coding and data analysis. I just started learning a few days ago by watching YouTube, so I'm sure there is a much better method. Is this just a crude piece of code? Is there a much better way to return the values I'm looking for and append them onto lists as they are generated?",True
@ssakatausa,2021-01-27T04:10:32Z,0,Here is my answer to the exercise question.  country_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').sum() / x.size * 100).sort_values(ascending=False),True
@tz1938,2021-01-24T18:12:20Z,0,"Your videos are AWESOMEEE! And btw, curious about how multiple indexes work in a group by object...",True
@richarda1630,2021-01-23T00:47:50Z,0,Fantastic video! great explanation of a complex topic for beginners. Thanks so much! definitely bookmarked for re-watching :),True
@jamiebrown2175,2021-01-21T02:57:17Z,0,"New question: What is the most common programming language cited by country?  I'm not sure how to unpack 'LanguageWorkedWith' for counting since it may have multiple entries.  Anyone?  Corey - like so many of your fans, I'm very grateful for all your efforts and your masterful teaching style.  Thank you!",True
@abdelrahmanali4550,2021-01-17T19:40:56Z,0,Thank you Corey. I am learning a lot from you.,True
@satyamgaba,2021-01-16T19:08:56Z,0,Best Valentine's Video!!,True
@prashantsingh395,2021-01-16T09:39:41Z,0,this works with the query but also returns the non python users percentage.. country_grp['LanguageWorkedWith'].apply(lambda x:x.str.contains('Python').value_counts(normalize=True)*100)   ...ps.. really resourceful course ..,True
@jiawenhuang3986,2021-01-14T05:09:10Z,0,"ctry_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').sum()/x.count() if x.count() !=0 else np.nan).to_frame().sort_values(by='LanguageWorkedWith',ascending=False)  In this way, you exclude those who do not answer the language in the survey.",True
@smartboy8918,2021-01-13T12:30:49Z,0,"at 19:00, using .loc u got 20,00 rows and using group by u got 9,000 rows, how??",True
@akshat2778,2021-01-13T05:50:27Z,0,I did by this method... Idk if its efficient or not   country_grp['LanguagesWorkedWith'].apply( lambda x : x.str.contains('Python').value_count(normalize = True)).loc[<country name>]   The answer I am getting is  a bit more... So can anyone help me figure out how is this wrong!?,True
@ashkanfarahani6532,2021-01-07T16:19:52Z,25,"Hi Corey. I think this might be a relevant simpler approach for getting percentage. I used value_counts(normalize=True) instead of sum.   df.groupby(['Country'])['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').value_counts(normalize=True))  This of course return both percentage who know Python and Who don't know. So if we want to get for a specific country, for instance Japan, then:  df.groupby(['Country'])['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').value_counts(normalize=True)).loc['Japan'][1]",True
@mustafakoyalen2145,2021-01-03T14:55:04Z,0,i couldnt find social media column,True
@federicohan1458,2021-01-03T05:09:02Z,0,"I found amusing explaining what a percentage% is after going over apply & lambda methods, but that's exactly the thoroughness that makes your videos so loved :)",True
@G_i_D,2020-12-30T21:57:39Z,0,Valentines Day gift :),True
@simplelife8722,2020-12-29T12:15:41Z,0,"Hi Corey/All,   Please find below solution I developed for the Practice Problem:  # Percentage of people in a country that have worked with Python country_group['LanguageWorkedWith'].apply(lambda x: 100 * x.str.contains('Python').sum()/x.isnull().count())  I think this solution would be more efficient as we are doing all the calculations in the lambda function call itself. Kindly share your views on this.   Thanks! :)",True
@25691331,2020-12-24T05:32:52Z,0,"@Corey This code will help get us the Number of People who have Python Proficiency compared to the total in that country.  df.groupby('Country').apply(lambda df:df['LanguageWorkedWith'].str.contains('Python',na=False).sum()/                            df['Country'].count())",True
@jnchacon,2020-12-22T21:00:17Z,1,Hi! Please do a video explaining mutiple indexes!  Great video serie! Thanks a lot.,True
@kejor8617,2020-12-19T15:04:16Z,0,python_df['PctWhoKnwsPython'] = (python_df['NumKnowsPython']/python_df['NumberOfRespondents'])*100 I made it like this :),True
@KevinTempelx,2020-12-14T00:07:02Z,0,Thank you!,True
@sayarmandal1885,2020-12-11T08:11:02Z,0,"Thanks, Corey. This is one of the most comprehensive pandas tutorials on YouTube. Love from India. I also noticed a subtle issue. We are adding the number of respondents who filled their Country and not who filled LanguageWorkedWith. Someone can fill Country and not LanguageWorkedWith.",True
@sayarmandal1885,2020-12-11T07:34:11Z,0,"knows_python = country_grp[""LanguageWorkedWith""].apply(lambda x: x.str.contains(""Python"").sum()) total_entries = country_grp[""LanguageWorkedWith""].count() knows_python/total_entries",True
@KevinTempelx,2020-12-10T02:58:22Z,0,Thanks!,True
@qigangdeng8636,2020-12-06T01:23:34Z,0,"Hey, Corey, I see many people gave their own answer which are wonderful. So want to give my one here, which looks like more a beginner answer: #create a new column called: 'Python use' df['Python_use'] = (     df['LanguageWorkedWith'].str.contains('Python')     ) #.value_counts() the 'Python use' column as it is a boolean type: country_grp = df.groupby(['Country']) Python = country_grp['Python_use'].value_counts(normalize=True)  Thanks for your great Lectures! I watched from part 1. I am your big fan now.",True
@mohammadghouse25,2020-12-02T14:02:16Z,0,Best Pandas playlist in youtube. One point solution for python learners,True
@jijiitalia3777,2020-11-26T19:58:15Z,0,"Hi, great tutorial. I did the same things that you did, but I got this error: TypeError                                 Traceback (most recent call last) <ipython-input-50-5b05d5e34158> in <module> ----> 1 c_d= pd.concat([c,d], axis='columns')  c:\users\mj\desktop\the_project\venv\lib\site-packages\pandas\core\reshape\concat.py in concat(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)     282         verify_integrity=verify_integrity,     283         copy=copy, --> 284         sort=sort,     285     )     286   c:\users\mj\desktop\the_project\venv\lib\site-packages\pandas\core\reshape\concat.py in __init__(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)     357                     ""only Series and DataFrame objs are valid""     358                 ) --> 359                 raise TypeError(msg)     360      361             # consolidate  TypeError: cannot concatenate object of type '<class 'int'>'; only Series and DataFrame objs are valid",True
@donnillorussia,2020-11-25T15:03:51Z,0,"Can't you just modify your lambda function to get the percentage? Like this: country_grp['LamguageWorkedWith'].apply(lambda x: round(100 * x.str.contains('Python').sum() / x.shape[0], 2))",True
@deniscampana8345,2020-11-25T09:43:52Z,0,"Thanks so much Corey ! It's clearly impossible not to understand what you explain on all your videos : It's fluid, straightforward, crystal clear ! And more over your english : Whaoooo ... Congratulations  !! I wonder if I've learned more Pandas or english !! 200% great !!",True
@engr.mohammadiqbalkabir1507,2020-11-24T15:04:51Z,0,This is really one of the best pandas videos I have ever watched but unfortunately I cant download the data file . would you please help me to get the data . Thank you,True
@bahramaghaei339,2020-11-22T18:50:48Z,0,"I believe, you coiuld calcualte the percentages of python users for each country much simpler by using this approach,   pd.DataFrame(country_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').sum()/len(x)))  Thanks for sharing",True
@ask9014,2020-11-22T03:25:50Z,0,https://translate.google.com/#view=home&op=translate&sl=ru&tl=en&text=%D0%B2%20%D0%BA%D0%BE%D0%BD%D1%82%D0%B0%D0%BA%D1%82%D0%B5  this is how to pronounce –≤–∫–æ–Ω—Ç–∞–∫—Ç–µ and means in contact,True
@milrione8425,2020-11-18T21:53:16Z,3,"I love how you are just using the same data throughout the whole series. Thank you so much, Corey!",True
@fuzzywuzzy318,2020-11-18T10:21:38Z,0,"I've been learning a lot with you, far more than I learned in college,  and your content  is free,!! but my master collage tuition is expensive",True
@fuzzywuzzy318,2020-11-18T07:34:56Z,0,ÂæÆ‰ø°ÔºåÊñ∞Êµ™ÂæÆÂçöÔºÅ i am from china!!,True
@nicoloretis6328,2020-11-13T11:25:44Z,0,"If you found the correct code, congratulations. For those, instead, who just enjoy the show..",True
@BTECE_VilleshRP,2020-11-11T10:41:15Z,0,There are no ads interrupting in the middle. Your presentation is very good.  Thanks corey,True
@adithkrishnan9538,2020-11-10T04:42:25Z,0,My solution : knows_python = country_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').sum()) knows_general = country_grp['LanguageWorkedWith'].apply(len)  percent_knows_Py = knows_python/knows_general * 100 percent_knows_Py.sort_values(ascending=False),True
@parsahosseini4241,2020-11-08T22:56:42Z,0,"47 minutes of a pure pandas tutorial from a god in python, man you're a heroüî•üî•",True
@anron5754,2020-10-30T04:54:49Z,0,Love you video! best one out there thank you so much!,True
@Schneebisme,2020-10-29T14:28:53Z,0,"I solved the coding exercise by doing:  country_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').sum()/x.count()) The difference with this solution compared to Corey's one is that Corey's takes the NaNs in when computing the ratio, whereas this one does not. Depends on the purpose I guess!",True
@robertosborne1147,2020-10-28T10:54:54Z,0,Great description.,True
@AkashSingh-yp8ip,2020-10-27T19:44:26Z,0,I truely appreciate your hardwork and knowledge and you effort to make things easier for learns.. cheers Corey,True
@MehmoodAhmedMooD,2020-10-20T09:57:42Z,0,Yes please do make a video on multiple indexes in a series,True
@victoriay2205,2020-10-15T19:38:18Z,0,Where can we find the csv file? Thank you.,True
@tarungupta5994,2020-10-15T09:32:55Z,3,"Hey Corey, Thanks a lot for these tutorials. It would be great if you can prepare some tutorials on Numpy, Matplotlib as well. Thanks in Advance!",True
@steveneven9408,2020-10-11T17:26:37Z,0,"Great videos but unfortunately, it's so hard to follow as the data source is not provided.  It would be nice if you can provide the data source that you used so we can follow along.",True
@Diallo268,2020-10-10T15:46:32Z,0,So you can also put *100 after the .value_counts(normalize=True) to get more readable %s,True
@daniellabrito27,2020-10-05T08:25:53Z,0,Where to get this data set ?,True
@mahamanoumar1802,2020-10-01T09:02:27Z,0,"I realize that you don't know much on China, my Hero Corey. hahaha",True
@IIAndersII,2020-09-28T10:16:12Z,0,Is it just me or is he drawing out his explanations a lot? Like he could explain this in half the time probably,True
@ashokbabug40,2020-09-25T09:47:32Z,0,Lots of love from India sir Thank you for the great work.Thank you for making easy python very easy,True
@snehadeore6327,2020-09-24T08:01:52Z,0,"Thank you Corey for this wonderful tutorial ! I had a query.  I tried to use count() method instead of sum() considering it will give me same result. But it does not. I thought, if Series.str.contains('Python') will return True, in that case, count() will keep adding such cases but it does not. Then what it counts ? country_uses_python_sum = country_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').sum()) country_uses_python_count = country_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').count())",True
@MrShree370,2020-09-22T11:20:34Z,0,@Corey Schafer thanks man! you exactly told me what i needed to do and just like that was done with something which i was crying about for past two days !!!,True
@Terence818,2020-09-20T22:35:17Z,0,"Yes Corey, having a future video on multi-index will be very helpful!",True
@BHARATHEEYUDU.,2020-09-19T12:53:16Z,0,"How to find nth highest salary each geoup wise  Below example data frame   Employee={'EMPNO':(111,112,114,115,223,226,228,300,333,345,356,320),'Salary':(4000,6000,2000,8000,2000,1000,3000,500,700,300,200,700),'EMPCODE':('MGF','MGR','MGR','MGR','CLERK','CLERK','CLERK','PEON','PEON','PEON','PEON','PEON')} Employee           emp_df=pd.DataFrame(Employee) emp_df",True
@yashkumarsinghpatwa9267,2020-09-17T07:15:08Z,1,Hey Corey Schafer Thanks a lot for this amazing series which helped me to upgrade my skills which I was unaware of that.,True
@salimbo4577,2020-09-15T09:25:45Z,0,"note : when applying groupby passing the column name to the fctn didn't work for me  you  have to pass a dataFrame you want apply an aggregation fctn on to the groupby() fctn like this  county_group=df,groupby(df['Country'])",True
@salimbo4577,2020-09-15T08:36:52Z,1,happy to see Algeria in the stackoverflow's coutry list in the  survey_results datasset LOL .  btw thanks a lit man .your vids are very helpful,True
@aminebouaita9202,2020-09-13T15:35:36Z,1,"Tunisia says hello and thanks, good methodology attacking this subject",True
@Yasharvl,2020-09-12T19:24:31Z,1,Thanks Corey! This is pure gold!,True
@anuraagpandey8316,2020-09-11T21:52:06Z,1,"Your content is really good. But can you make them shorter, the size of the videos I mean. :D :D",True
@pedrofrohmut2471,2020-09-11T18:15:11Z,0,"# Lambda version of people that knows python percentage by group country_group[""LanguageWorkedWith""].apply(lambda x : x.str.contains(""Python"").sum() / len(x))",True
@KumarGauravhi,2020-09-10T15:43:46Z,0,"Here i am able to use the head/tail command ..please explain a bit that at which point of time we can use head/tail...python_df.sort_values(by = 'total_prcnt',ascending = 'False',inplace=True).head(10) python_df.. Thanks in Advance !!",True
@KumarGauravhi,2020-09-10T15:42:20Z,0,"First of all i would like to thank you for wonderful session ..it's really fantastic...i have some doubts from this session.actually I would like to know , in order to calculate percentage of people who knows Python you have used Normal Method like division(/), but i am trying to calculate using (normalize = True ), i am getting an error.. please find the code for this......python_df  = pd.concat([country_respondents,country_uses_python],axis = 'columns',,normalize = True).. at which point of time we can use mathematical operator and normalize = True .Please Explain !!",True
@arpitagec9,2020-09-09T22:25:16Z,0,"Impressive content!!üëå Can't thank enoughüôè  ## All Education levels available with numbers df['EdLevel'].value_counts()  --> Bachelor‚Äôs degree (BA, BS, B.Eng., etc.)  being most common  ## Education levels across countries country_grp['EdLevel'].value_counts()  ## Respondents with Bachelor's degree across countries country_ppl_bachelors_degree=country_grp['EdLevel'].apply(lambda x: x.str.contains(""Bachelor‚Äôs degree"").sum()) country_ppl_bachelors_degree  ## Total Respondents country_respondents=df['Country'].value_counts() country_respondents  ## concat series to form a df bachelors_df=pd.concat([country_respondents,country_ppl_bachelors_degree],axis='columns',sort=False) bachelors_df  ## Rename columns to make sense bachelors_df.rename(columns={'Country':'NumRespondents','EdLevel':'NumWithBachelorsDegree'},inplace=True) bachelors_df  ## % of respondents with Bachelor's degree across countries bachelors_df['PctWithBachelorsDegree']=(bachelors_df['NumWithBachelorsDegree']/bachelors_df['NumRespondents'])*100 bachelors_df  ## Sort by PctWithBachelorsDegree (descending) bachelors_df.sort_values(by='PctWithBachelorsDegree',ascending=False,inplace=True) bachelors_df.head(50)",True
@sachin1905,2020-09-07T06:27:24Z,0,hi @Corey Schafer  @Anubhav Tomar  I am not able to locate the .csv file that is being used in the video in the link mentioned underneath.. can anyone  guide/share with  me to the csv file pls,True
@mohameda.abokhoshiem2624,2020-09-06T01:43:24Z,0,"You 're great, man. Thank you.",True
@faizanafridi9682,2020-09-03T06:16:28Z,0,"i would like to show my code for the percentage problem cntry_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').value_counts(normalize=True))[:,1]",True
@dileeppavansurya7735,2020-08-30T21:11:47Z,0,We can also find the percentages usnig a lambda function country_grp['LanguageWorkedWith'].apply(lambda x: (x.str.contains('Python').sum() / len(x)) * 100),True
@Aaronisification,2020-08-30T20:54:09Z,0,"How I went about answering the question: 'What % of people from each country know Python?'  Here's my solution. I modified the code you left us with slightly. I took out the sum function and replaced it with value_counts() and included the normalize = True argument to return proportional counts:   ***> country_grp['LanguageWorkedWith'].apply(lambda c: c.str.contains('Python').value_counts(normalize=True))  This gave us back proportions of respondents, grouped by each country, who did and did not include 'Python' in their 'LanguageWorkedWith' answers.   Also, as shown in the video, adding the .loc['<country>'] would let us zero in on a country of interest.   Hope I did this right!",True
@weiyancheng6360,2020-08-30T02:58:44Z,0,"Hi Schafer, thanks a lot for making these great vidoes and sharing the programming knowledge with us.   I have watched your python, django tutorials and now this pandas topic and matplotlib is my next plan.  I am 35 years old with no  basic knowledge about programmnig, but your great work helped me a lot to learn new things.",True
@Aaronisification,2020-08-29T21:33:12Z,0,"you know the world is upside down when the free content on YOUTUBE is head and shoulders above crooked Universities. THANK YOU, COREY!",True
@ashishdeora8522,2020-08-29T16:27:14Z,0,"df1 = country_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').sum()) df2 = df['Country'].value_counts() df3 = (df1 / df2)*100 df3.loc['United States']",True
@imrans5538,2020-08-28T14:49:53Z,0,multi index plz,True
@anoopkg8681,2020-08-24T15:59:00Z,0,Thanks for the video series,True
@PythonDev1566,2020-08-20T23:12:29Z,0,"I noticed that when using get_group, you had to know the exact spelling of the country, is it possible to use wild cards for the group?  so instead of typing United States, you can just type group.get_group('United*').  If it's not possible, is there something else that can search the group?  Also, thanks very much for putting all of these videos together and for sharing all your knowledge.",True
@aggelosdidachos3073,2020-08-18T17:12:07Z,0,Is it possible to incorporate a regular expression inside the parenthesis of .contains() ?,True
@mohit7717,2020-08-18T12:09:07Z,0,"sir one place u use ""schema_df.loc['SocialMedia'] "" something when i use the same thing it gives error",True
@belleriveblvd,2020-08-18T01:18:35Z,0,"Corey, I learn a lot from your videos. But this one has been especially helpful. Thanks.",True
@yl3155044,2020-08-10T13:45:40Z,0,Thank you so much for this high-quality tutorial ! I have one question here. What's the difference between the df and the country_grp? What does groupby do behind? Thanks,True
@youssefdirani,2020-08-09T06:20:39Z,0,Fluid,True
@mail2divakar,2020-08-06T20:19:30Z,0,"Hi Corey, I have a scenario where I need to group my dataframe (on routes) by two columns (START & STOP) and output the most frequent occurring combination, How to do that, Tried myself but to no luck",True
@shreddersengupta7384,2020-08-02T17:35:13Z,0,byCountry['LANGUAGEWORKEDWITH'].apply(lambda series: (series.str.contains('Python').sum()/len(series)) *100 ).head(50),True
@philipmanatad5253,2020-08-02T05:41:29Z,0,"Hi Corey. in the group by method in 32:58, in the apply() method, the x in the lambda represent the series? in the apply method in the previous lectures isn't the apply method use in every cell/value in a series? Not in the series itself just like the 32:58? I'm new to python.  Thanks!",True
@tomasroldanborjas6749,2020-08-01T16:33:41Z,0,"This is the code I wrote for calculating in percentages how many people used Python in each country:  def perc(val):     cont = val.str.contains(""Python"")     percs= cont.value_counts(normalize=True)     if True in percs:         return percs[True]     else:         return ""NaN""  country_grp[""LanguageWorkedWith""].apply(perc).head(10)  Basically, I started using str.contains() so as to pass the booleans to percentages with value_counts(). Since there are some countries that end up having blank values, the conditional checks if there actually is a key named True (which would have the desired percentage). If there is, it returns its value. If not, it just returns ""NaN"".",True
@SamOween,2020-07-30T18:28:18Z,0,"Corey man, you are the fuckin' BOSS brother! Big, BIG respect from the UK!",True
@parthrawri3001,2020-07-30T12:48:17Z,273,I love the fact that there are no ads interrupting in the middle. So thoughtful. ‚ù§Ô∏è,True
@maheribnerahman7783,2020-07-29T14:46:57Z,1,Really appreciate your teaching strategy man..have been learning a lot from you since the quarantine started.Love from bangladesh,True
@WrongSmth,2020-07-29T07:22:28Z,0,"Hey, Corey. I'm a network engineer and I'm learning pandas to be able to do some packet analysis and your videos really help me a bunch! This is my solution for the coding problem from the video. Hope it helps!  know_python = country_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').sum()) total_respondents = country_grp['LanguageWorkedWith'].apply(len) know_python / total_respondents",True
@scorpp149,2020-07-27T11:17:53Z,0,G <===== Group created by groupby('Country') G['LanguageWorkedWith'].apply(lambda x : (x.str.contains('Python').sum() * 100) / len(x)).loc['India'] <=== country we want to see the % of,True
@enanenan2142,2020-07-26T20:57:04Z,0,Love your presentation!,True
@mohamadalissa125,2020-07-26T20:32:59Z,0,I think this is easier way to calculate the percentage of people who know Python per country  country_group['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').value_counts(normalize = True)),True
@nirmalhruday1,2020-07-23T12:10:43Z,0,"I tried solving your problem with the example you gave just before. I am not sure if this is correct, please comment. group = df.groupby(['Country']) group['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').value_counts(normalize=True))",True
@vladislavmoroshan3749,2020-07-22T19:09:47Z,0,"Russian social network VK –í–∫–æ–Ω—Ç–∞–∫—Ç–µ is pronounced  VKONTAKTE. Meaning ""in contact"" or ""in touch"".",True
@alabhyaalabhya9859,2020-07-19T13:50:48Z,0,"try this as the solution to question asked by respected Corey sir at 34:35 : l_countries = pd.unique(csv.dropna()['Country']) a = [(i, ((gbo.get_group(i)['LanguageWorkedWith'].str.contains('Python').sum()) / (gbo.get_group(i)['LanguageWorkedWith'].count()) * 100)) for i in l_countries]",True
@ssss54,2020-07-19T06:01:21Z,1,Can we have a video on Group By and then how to use it for plotting. When we do group by the structure of the dataframe changes and it is not easy to utilize that data for plotting. If there is already a video then if you could probably guide me to that video. Also how doing group by on multiple columns in one go changes impacts the output. In the current video we have done group by with only one column,True
@seydoudia7828,2020-07-12T22:12:20Z,0,"Hey Corey, thanks for the excellent series. I think at 40:58 the Merge function is better suited, https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html ; I expected Megre function to appear at episode #6 of this series. Voila my grain of salt to the best Pandas tutorial known to mankind ;)",True
@IrshadKhan-vk8rn,2020-07-12T04:40:45Z,0,my approch to the problem C_uses_python = country_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').sum()) C_total = country_grp['Country'].value_counts() percentage = (C_uses_python/C_total)*100  first calculating how many people in each group uses python in second it calculate the total no of people in each country percentage is calculated by th formula and result is awesome powesome :-},True
@LibardoLambrano,2020-07-07T16:50:46Z,4,Thanks Corey for sharing these videos. Pretty clear explanations. You are a great teacher.,True
@2rajim,2020-07-06T16:37:38Z,0,for each country % of people knows python: Country_group['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').value_counts(normalize=True)*100),True
@adithkrishnan9538,2020-07-06T05:42:14Z,0,Thanks for this amazing series on pandas! Pls also do an entire series on NumPy as well!,True
@marcmedawar8073,2020-07-04T11:03:39Z,0,Can someone share with a datasets so I can practice with?,True
@srich-k,2020-07-03T06:25:04Z,3,A much simpler way of finding the percentage of people from each country who know python is by using the mean() function Something like this :   country_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').mean())  P.S: Corey's method produces a much detail-oriented version of this result,True
@ftedg,2020-07-02T09:40:45Z,2,A very quick way to get the % of people from each country know Python:  df.groupby(['Country'])['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').sum()/x.shape[0])],True
@aayushkhandelwal3909,2020-07-01T03:22:04Z,0,Question Solution:- Anyone can suggest me that this is correct or not .... country_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').value_counts(normalize=True)),True
@Blueshockful,2020-06-30T11:51:02Z,3,"Im browsing thru some of the videos to brush up on Python, and this is the first python video that didnt get me bored. Concise and brillliant. Love your videos! keep up the good work :)",True
@dhineshbabu9376,2020-06-30T08:47:45Z,0,Helped me a lot for an important assignment. Thanks for all your great work.. :),True
@samratsengupta8881,2020-06-29T18:44:09Z,0,"hey Corey, could you please let me know about multiple indexes....please",True
@samratsengupta8881,2020-06-29T18:42:52Z,0,"good job Corey, your content is well suited for preparation of data science",True
@shashwatdev2371,2020-06-27T19:10:48Z,0,"Sir my second solution country_grp['LanguageWorkedWith'].apply(lambda a:a.str.contains('Python').value_counts()) first was this which did not return a DataFrame object for i in df['Country'].unique():     filt=df['Country']==i     print(i)     print(df.loc[filt,'LanguageWorkedWith'].str.contains('Python').value_counts(normalize=True))",True
@debasisnath9916,2020-06-27T06:08:25Z,0,Any subject which is taught by you can't be hard to understand!,True
@shashwatdev2371,2020-06-26T22:42:22Z,0,"Sir my solution I know answer is not a Data Frame object but it prints the correct result. What's your opinion?please reply. for i in df['Country'].unique():     filt=df['Country']==i     print(i)     print(df.loc[filt,'LanguageWorkedWith'].str.contains('Python').value_counts(normalize=True))",True
@karthiavenger4577,2020-06-25T13:44:27Z,0,Love you Corey please make videos on machine learning and other data science Lib . Love ‚ô•Ô∏è‚ô•Ô∏è‚ô•Ô∏èyou soooooo much learning sooo much from you,True
@maanavdoshi3100,2020-06-24T18:42:14Z,0,"Hi Sir, I have a doubt. How do i group my dataframe and create a new aggregate column which uses custom function and takes 2 arguments, a column of grouped dataframe and a character?  Case: I have a df with user_id, occupation, gender and i want to find out male% and female% in each occupation.",True
@ankitbillore8221,2020-06-24T10:52:41Z,0,country_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').value_counts(normalize=True)),True
@KarthikG30,2020-06-17T17:06:49Z,0,country_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').sum())/ country_grp['Country'].value_counts()*100.00    Please review this code,True
@AmanChauhan-hy1sb,2020-06-17T04:46:54Z,1,Thanks a lot Corey! Got to learn complex syntax in simple ways.  You are amazing teacher.,True
@bixbe_sglearn,2020-06-15T13:35:44Z,1,LOL! Weibo and WeChat are HUGE!,True
@saiyedali561,2020-06-15T10:39:29Z,0,plz  make series of numpy ----------> Request,True
@saiyedali561,2020-06-15T10:26:41Z,0,multiple indexing concepts should be covered is my point of opinion.,True
@akritisstory850,2020-06-13T16:29:38Z,1,you are a great teacher Corey.,True
@mohammedafaounoddenahmed8420,2020-06-13T09:46:37Z,1,Craziest like to dislike ratio ever . Amazing,True
@ubaidimtiaz3557,2020-06-11T17:31:09Z,0,"Answer to question @34.38 filt=df['LanguageWorkedWith'].str.contains('Python',na=False) df.loc[filt]['Country'].value_counts(normalize=True)",True
@yashmore7732,2020-06-11T15:28:02Z,0,I am doing it this  way:---  responses = df['Country'].value_counts() filt = country_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').sum()) coutry_respondents.sort_index() filt = filt/(coutry_respondents.sort_index()) filt,True
@nicholaspolino2657,2020-06-08T12:15:05Z,4,"LOL @ ""If I did this correctly, and it's definitely possible I made a mistake."" Happy I found these videos, thanks.",True
@guanfuqiao5879,2020-06-08T00:18:49Z,2,"ddf['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').sum()/len(x)).sort_values().plot(kind='barh') x here in the lambda body is already the series, the lengeht should be the number in the correspoing country who write this survey. I think...",True
@ishmeetbindra5428,2020-06-06T20:40:10Z,0,"Thanks for creating such great lectures, really love your stuff.  Regarding the last question, in each country, we have a couple of people who have not responded. As shown in the video we are considering them as we are picking data from df[country].value_count(). My question is in realtime scenario its possible many people would have skipped that question, do we still consider them?  Also, I have made a solution without considering them, although this only returns a single column of percentage and multiple columns can be added.  country_group['LanguageWorkedWith'].apply(lambda x: (x.str.contains('Python').sum()/x.count())*100)",True
@edoardolanari2626,2020-06-06T15:09:37Z,0,My 2 cents:  1.0*country_grp['LanguageWorkedWith'].apply(lambda x : x.str.contains('Python').sum())/df['Country'].value_counts(),True
@janardhangurram3413,2020-06-04T19:23:11Z,0,"Hi Schafer, I am fascinated with your way of dealing pandas. I am new to python .I have question for you.  What if I want to look for specific rows in data frame like as 20th row -30th row. what should be the code for it .",True
@gauravmarwaha8466,2020-05-30T11:17:56Z,1,wonderful video again...!!,True
@nakulamate3558,2020-05-29T10:16:15Z,1,country_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').value_counts(normalize=True)).loc['United States'] that gives the same result,True
@samcathcart5388,2020-05-26T14:39:44Z,0,"Hi Corey tk u for gr8 vid on grouping and aggregating. Do u have a vid on groupby function for  datetime object, I am trying to work out how to group data for days, months and years. I did watch vid Working with Dates and Time Series Data and it did not deal with groupby.",True
@mByyurt,2020-05-26T12:01:25Z,0,"Also about the problem, couldn't we do smt simple like lambda x: x.str.contains('python').sum()/x.count() ?",True
@mByyurt,2020-05-26T11:00:49Z,1,Great stuff. Thanks a lot.,True
@raghuramabl6729,2020-05-25T10:58:45Z,0,i did like this is it ok   country_grp['LanguageWorkedWith'].apply(lambda x:x.str.contains('Python').value_counts(normalize = True)),True
@ankitranjan7670,2020-05-23T07:04:41Z,4,We can do this in the lambda function for getting the percentage : lambda x : x.str.contains ('Python').value_counts(normalize=True)  And I would love to thankyou for all these videos!,True
@joysharma8599,2020-05-21T14:55:44Z,0,Please make some videos on Numpy ... This series is super awsome!,True
@shikharsaxena9989,2020-05-20T21:58:27Z,0,how to add them(agg) to the original dataframe,True
@shikharsaxena9989,2020-05-20T21:41:26Z,3,after this lecture i started loving the complex coding of pandas and matplotlib. really you are an amazing teacher,True
@aayushipawar915,2020-05-17T20:13:46Z,1,"Hey Corey, Thanks a ton for this amazing videos. love them and they are so easy to learn",True
@dailydevtips,2020-05-17T08:01:10Z,0,Kindly help me solve this question: What is the most popular level of education in each country?,True
@tejasjoshi3345,2020-05-15T18:35:47Z,0,"Hello Corey,  At 30:07 in the video, would the following statement be more accurate as we want to know how many people know Python in India filt = df['Country']=='India' df[filt]['LanguageWorkedWith'].str.contains('Python').count()  I am a bit confused about the sum function ?? Thanks in advanced. Keep up the revolutionary work.",True
@Watercoloeur,2020-05-12T08:43:02Z,0,"I just created a var from the number respondents from each country and divided the python users by country by that var and multiplied by 100. count_by_country = df['Country'].value_counts() (country_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').sum()) / count_by_country)*100",True
@ArvindVishak97,2020-05-11T13:19:20Z,0,"Corey: Upon doing a count() on the series, there's 8844 Indian respondents that answered the LanguageWorkedWith question as compared to 9061 Indian respondents to the survey, which I believe causes an error in the calculation? Shouldn't the number being divided by, while calculating percentages, be the # of respondents that answered the question and not the total respondents?",True
@akhilsharma4004,2020-05-11T03:35:04Z,0,Hey Corey how is it going firstly i am thankful to you for deep insight into Pandas .I just have one query in Video number.8 of Pandas Tutorial you taught us that how can we concate two series to form one Dataframe  using Lambda function now i would like to find the proportion of total participants whose salary is greater than 2000 USD using a lambda function but i am really struggling with lambda function can you please help me out how can i create a lambda function to find records for which Salary > 2000,True
@user-sl4sj2cs6w,2020-05-10T07:29:27Z,0,"your presentation is very good, those who are not native speaker in english can also understand the content very clearly! also, this has helped me to understand python is not as difficult as imagine. thanks so much corey! it would be great if in future there is machine learning related class for python =)",True
@leobehe2829,2020-05-09T22:14:18Z,0,"For your practice question, I just divided your Python sum in the lambda expression by the size of the series. As such:   country_grp[""LanguageWorkedWith""].apply(lambda x: x.str.contains(""Python"").sum() / x.size)",True
@gauravsrivastav212,2020-05-09T06:37:35Z,0,"Corey. in your last video 'Sorting'. You mentioned outliers from the data frame and you were gonna teach us how to remove or find or something to do that in this video or may be I got you wrong. I hope you read this comment and teach us that one thing you left here.   And, you are the best man. Thank You for this great content.",True
@TimeWithSomi,2020-05-08T18:12:24Z,0,Video is good. Multi Index pls,True
@kpratik5551000,2020-05-06T04:08:10Z,0,Very easy and simple to understand.,True
@jerrysong325,2020-05-03T19:49:06Z,0,For country_respondents I used .count() method on the DataFrameGroupBy object. This gets you a slightly different answer which is due to the fact that some rows with a valid Country entry may not have a valid LanguageWorkedWith entry. In this case df['Country'].value_counts() would give a higher value than if I apply ['LanguageWorkedWith'].count() method on the grouped by dataframe since the later excludes casdes where either Country or LangaugeWorkedWith has a NaN value.,True
@piyushkonher8405,2020-05-03T17:50:43Z,0,Some of the functionality is so similar to R that I normally get confuse which console to use R or python,True
@saisrinivas9882,2020-05-03T14:59:30Z,0,for suppose i wanna find a country with highest number of population and both country and population are two diffferent columns in dataframe how do i do it?,True
@kawaljeetsingh865,2020-05-02T14:49:55Z,0,"country_grp.get_group('India')['languageworkedwith'].str.contains('Python',na=False).value_counts(normalize=True)   I Used This Command to Get the result for any single country. can someone please tell me , how to get the result for all the countries in One Command.?",True
@Esscapade,2020-04-30T16:39:46Z,0,Rather than using Lambda function I tried the following: but came back with an Error   def func1(language):  y=0  kount=0  x=df['LanguageWorkedWith']  y=x.str.contains(language).sum()    return y func1('Python')   country_uses_python=country_grp.apply(func1('Python'))   Please advise what am I doing wrong .,True
@vijayotnm,2020-04-28T22:36:11Z,0,Excellent vidoe,True
@Esscapade,2020-04-27T14:49:23Z,0,"Using Normalize: we obtain fractions, is there a way to report %ages. Secondly is there a way to control the number of decimal places",True
@slikshot6,2020-04-27T01:17:41Z,0,"@19:15 How are you able to put the two brackets side-by-side in the line: df.loc[filt]['socialmedia'].value_counts() I dont get why it works with df.loc, but when I tried to set a variable ""group"" to the groupby function, it doesnt work?  group = df.groupby('column1') group.get_group('value') print(df.loc[group]['column2'].value_counts())",True
@hhsstt9322,2020-04-25T22:40:32Z,0,Nice video. I enjoyed it very much. I also tried to solve the task. Is it the case that the following line will solve you task as well?   country_grp['LanguageWorkedWith'].apply(lambda x:x.str.contains('Python').sum()/len(x)),True
@prajwalshelar1618,2020-04-25T19:31:29Z,0,Great explaination...many things got cleared..thanks alot,True
@piotrmazgaj,2020-04-24T17:58:18Z,0,"Yep, multiple indexing pls, never heard of it in this context.",True
@mohamedshalaby80,2020-04-22T20:29:43Z,0,PercentPythonIndia = Country_grp['LanguageWorkedWith'].apply(lambda x : x.str.contains('Python').value_counts(normalize=True)).loc['India'][True],True
@ledung907,2020-04-22T10:10:20Z,0,"My solution to the problem:  country_grp['LanguageWorkedWith'].apply(lambda x: (x.str.contains('Python').sum()) / x.size * 100), Anyway, great tutorial ^_^",True
@anubhavtomar1384,2020-04-20T16:48:28Z,517,"3:10 median function 5:00 describe function 7:20 count() 8:05 value_counts() 12:51 grouping the data 14:39 groupby() function 16:07 get_group(), grabbing a specific group by name 17:30 doing same by using the filters 18:40 using value_counts on filters 20:20 value_counts() for groups 21:49 using loc to find for one country 23:40 percentage by using normalize 25:00 median by country group 26:13 agg function for multiple functions 27:30 using filtering to get python users by country 30:20 error on using same approach for groups 31:40 apply method to run that on group 35:40 finding the percentage of people using python in each country(group) 37:40 using concat for combining series in a dataframe  45:30 adding percentage column",True
@sonikagoyal9479,2020-04-19T16:25:20Z,0,My Solution for the problem   import pandas as pd survey = pd.read_csv('/content/drive/My Drive/Data Science/survey_results_public.csv') Respondents = pd.DataFrame(survey['Country'].value_counts()) survey_Country = survey.groupby(['Country']) survey_Country['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').sum()) Respondents['KnowsPython'] = survey_Country['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').sum()) Respondents['pct'] = (Respondents['KnowsPython']/Respondents['Country']) * 100  Respondents,True
@ahmedhawater7522,2020-04-17T22:58:27Z,3,"Man you are one of the best teachers who ever learned me something, much love and support ‚ô•Ô∏è",True
@polgimeno,2020-04-16T18:42:29Z,1,"Daamn that was a fantastic one! helped a lot, thanks.",True
@tanvirkaisar7245,2020-04-16T16:30:06Z,0,"Hey Corey! I am trying to find how many of the respondents from each country are over 30 years of age. So I wrote this, country_grp['Age'].apply(lambda x: True if (x > 25) else False).sum( ) But its throwing an error- ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool( ), a.item( ), a.any( ) or a.all( ). Where did I go wrong?",True
@ayushsrivastav8220,2020-04-15T09:48:06Z,11,"My solution for the practice question that you had given: country_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').value_counts(normalize=True)).loc['India'] Check this out,hope it works correctly.",True
@user-iy2ln6rp9n,2020-04-15T05:40:06Z,0,(36:18) I added just a short method to get percentage of python users. country_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').sum()) -> country_grp['LanguageWorkedWith'].apply(lambda x: (x.str.contains('Python').sum())/x.count()),True
@mggarekar,2020-04-14T01:41:22Z,2,nice video :) i liked the q/a approach at the end where you left it open.,True
@ajitsekhar2716,2020-04-13T04:46:26Z,0,Please do a video on multiple index.,True
@clemensdie6191,2020-04-12T06:34:11Z,0,"Hey Corey, first of all, I really enjoy all of your videos and they helped my a lot learning Python.  While I was trying to solve the practice task, one question came to my mind: How can I only grab all of the 'True' Values of this Series?  Input: country_group['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').value_counts())  Output: Country                                          Afghanistan                                False       31                                            True         8 Albania                                    False       60                                            True        23 Algeria                                    False       86                                            True        40 Andorra                                    False        7 Angola                                     True         2                                            False        2 Antigua and Barbuda                        False        7  Thank you in advance,  Greetings from Germany",True
@prasannarahavendraanand8217,2020-04-10T15:46:15Z,5,"Hey Corey! For the question you gave: The percentage of people by country who use python. There is an efficient solution too (Without creating a separate dataframe).  country_grp[""LanguageWorkedWith""].apply(lambda x:(x.str.contains(""Python"").sum()/len(x))*100) Actually what I am doing here is, in the lambda function, at the return part, I divide the No. of python users by the length of the given series and then multiply it by 100. This gives the percent of python users in each country. This approach might be a bit code efficient but can be a bit confusing for some.",True
@kelvinedozieobed4899,2020-04-07T11:21:04Z,1,"Thanks for all your lectures. The Russian Social media is pronounced as ""V - CONTACT""",True
@darkmaraux,2020-04-07T05:30:06Z,0,Sure we want the MULTINDEX class! <3,True
@marcusagrippa7584,2020-04-05T16:16:24Z,0,"There are small differences with your rates and mine but I do not understand why. Here is my solution for Japan (Especially, I just added ""value_counts(normalize=True)).loc[""Japan"""" to your code):   country_grp[""LanguageWorkedWith""].apply(lambda x: x.str.contains(""Python"").value_counts(normalize=True)).loc[""Japan""]  output: ---------------------------- False    0.529716 True     0.470284 -----------------------------  But your result is 46.547315. If I convert mine as percent it is 47.0284. Why there is a difference? I have checked all the countries and I've seen difference in all countries. Could you explain why?",True
@Ahsoka501st,2020-04-04T21:58:48Z,18,Possible solutions for the question at 34:28 country_grp['LanguageWorkedWith'].apply(lambda series: series.str.contains('Python').sum()/len(series)),True
@alias7611,2020-04-03T15:28:58Z,0,"df.groupby(""Country"")[""LanguageWorkedWith""].apply(lambda x: x.str.contains(""Python"").sum()*100/len(x))",True
@jiangxu3895,2020-03-30T22:13:00Z,0,"for the question, I just test this one and it works, just use value_counts(normalize=True) instead of using sum()   country_group['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').value_counts(normalize=True))",True
@jiangxu3895,2020-03-30T21:45:22Z,6,I just discover that your way of teaching is to tell not only how to do it but why this is how to do it. thumb up!!,True
@2w2e-channel,2020-03-30T14:31:15Z,1,"Corey, Thank you for the nice vide series. Could you please provide a video on multiple indexes? Also, do you have any plans for other Python's libraries? such as Numpy, Sklearn?   Regardless, Thank you so much for nice videos.",True
@jiangxu3895,2020-03-30T06:50:48Z,2,Very interesting tutorial. Thumb up! Particularly at 33:30 !!,True
@ManishKumar-yf8jg,2020-03-27T10:16:39Z,0,"Thanks for teaching this in an easy way!!! @Corey Can you please create series on Rest Api tried many way to learn but want easy, simple and best way",True
@muhammadsalmankhan9326,2020-03-25T17:31:19Z,0,country_grp['LanguageWorkedWith'].apply(lambda x:x.str.contains('Python').value_counts(normalize=True)) is it true answer ??,True
@MatthewFoulk,2020-03-25T14:48:20Z,2,Really appreciate the addition of practice problems. It helps me to grasp the material,True
@hkiscrazy,2020-03-23T16:01:59Z,1,"on an average, how much did you earn as developer?",True
@sherryshen2780,2020-03-22T21:23:22Z,0,Thanks to your clear video and examples. Pretty useful to me!,True
@aftabk1013,2020-03-22T13:48:51Z,0,Does it include pivot table??,True
@sebastianhernandez3059,2020-03-20T18:20:33Z,2,This was awesome! Every step had me locked in to see the results hahaha.,True
@matthiashupfer2659,2020-03-20T12:43:11Z,3,These tutorials are well thought out and really great in explainatory purposes. Greats skills here from Corey! Thank you.,True
@juancarcelen3437,2020-03-19T16:24:59Z,0,"Hi Corey thank you so much for posting these videos. Your tutorials have helped me transition the concepts I know into actual useful code. I would like to test my progress and would really appreciate if you can put out a link with some data analysis projects (i.e. a database to download, questions to answer using data analysis, and the code that was written to answer those questions).  Thank you so much and keep the videos coming you're an amazing teacher!!",True
@soumyajitdey5720,2020-03-17T14:47:02Z,0,"I don't know what I did to be honest. I was trying different methods and came up with this ---------   python_pct = country_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').value_counts(normalize=True)) country_knows_python = python_pct.loc[:, True] df_python_pct = pd.DataFrame(country_knows_python) df_python_pct.rename(columns={'LanguageWorkedWith': ""Pyhton_known_percentage""}, inplace=True) df_python_pct['Pyhton_known_percentage'] = df_python_pct['Pyhton_known_percentage'] * 100 df_python_pct.sort_values(by='Pyhton_known_percentage', ascending=False)   Corey don't laugh. It works!  I will now use the concat method to do all of these operations. Great video.",True
@aboalifan123,2020-03-17T14:33:42Z,2,"This is my solution, hope it's okay: country_group['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').value_counts(normalize = True)).head(50)",True
@soumyajitdey5720,2020-03-17T06:00:07Z,0,Corey it'd great if you make a cheatsheet with all the commands and their functionalities. It will be a handy way to look for the exact command as needed.,True
@moushumitamanna,2020-03-14T13:33:25Z,1,"First of all, Thank you so much for all your tutorials. You are a great teacher.  and yes, please make a video on Multiple Indexing.",True
@veenak108,2020-03-10T21:31:33Z,0,Thank you again for the great videos !!! Please do a video on Multiple Indexing!!,True
@veenak108,2020-03-10T21:31:23Z,0,Thank you again for the great videos !!! Please do a video on Multiple Indexing!!,True
@gwanghyeongim768,2020-03-08T08:47:41Z,0,"Hi. Again, thank you for all the good works you've done. Please keep it up. As for making ratio of python knowers by respondents of countries, I personally make the variable first, PctKnowsPython, and then rename it.  country_grp = df.groupby(['Country']) numpy_country = country_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').sum()).sort_values(ascending=False) -> number of people who know python by country country_resp = df['Country'].value_counts().sort_values(ascending=False) -> number of respondents by country pynum_by_con = (numpy_country / country_resp) * 100 -> my version of PctKnowPython py_df = pd.concat([country_resp, numpy_country, pynum_by_con], axis='columns')  -> showing the dataframe which has three columns. The last column name is 0. py_df.rename(columns={'Country': 'NumRespondents' , 'LanguageWorkedWith': 'NumPythonKnower', 0: 'PctKnowsPython'}) -> showing the renamed dataframe.  py_df.rename(columns={'Country': 'NumRespondents' , 'LanguageWorkedWith': 'NumPythonKnower', 0: 'PctKnowsPython'}, inplace=True) -> applying the change.  Hope this may be helpful.",True
@HearterSG,2020-03-08T02:40:50Z,0,This is an incredible tutorial! Thanks Corey!,True
@diegoalarcon6062,2020-03-06T12:44:59Z,8,"I don't care if some of your videos are long, in other channels they're just redundant but that's not your case! If you start doing short videos we may be losing all that valuable information that you provide to us. So far, this is the best Python channel I've seen. Greetings from Medell√≠n, Colombia.",True
@sergior.m.5694,2020-03-05T07:01:15Z,1,"Pandas is something I can't use without documentation by my side, even after a year there is a ton of things I have to look up (unlike SQL, wish pandas had SQL support like PySpark).",True
@harekrishnarakhee,2020-03-04T12:28:50Z,0,"It gave me  huge clarity about grouping, ultimate info found in your videos. In waiting of your next videos. Do video on data analysis on any big data with whole process like cleaning, visualisation and model building",True
@jiading170,2020-03-03T10:28:59Z,0,"What % of people from each country know Python? you can use the python built-in fuc, len().   country_grp['LanguageWorkedWith'].apply(lambda x: (x.str.contains('Python').sum() / len(x)) * 100)   you got a pct Series and could do sth more of it.",True
@rauberhozenplotz7009,2020-03-03T10:01:07Z,1,Helps me to get into my PhD. Thanks a lot for uploading this!,True
@Al-Ahdal,2020-03-02T21:02:02Z,0,"It is requested to kindly make videos on data wrangling and data manipulation, cross tab, data filtering and aggregation and calculations. Thank you Corey Schafer for your excellent work. Please let me know which Python library is sufficient for all this work, I am an Accountant by Profession, someone telling me that PANDAS is enough for you.  Awaiting your response and advise on this please.",True
@johnrogers3315,2020-03-02T07:45:13Z,1,many thanks for the wonderful series,True
@andreykaok9497,2020-02-29T12:53:27Z,32,"Just for info (23:35) VK (–í –ö–æ–Ω—Ç–∞–∫—Ç–µ) means ""In touch""  pronounced v-con-tak-tea (stress on tak)  Major (but former) founder Pavel Durov now is running the 'Telegram'",True
@laurentb6563,2020-02-27T19:06:59Z,0,wow,True
@ishanpand3y,2020-02-27T00:56:47Z,5,"Undoubtedly this is the best python learning place. #8 done. Thank you, sir. üß°ü§çüíö",True
@stressfreetrading1341,2020-02-25T09:29:56Z,11,NAMASTE!! Corey Schafer..  Love From India,True
@Brian-wy2od,2020-02-25T03:12:05Z,1,So great video. Thank you very much!!,True
@arindambaruah6672,2020-02-24T18:43:30Z,1,"Instead of counting in all the respondents from the survey, what I did was I discarded the 'NaN' values from the 'LanguageWorkedWith' columns since we are not really sure what languages they work with exactly:  country_grp = df.groupby(['Country'])  python_count_per_country = country_grp['LanguageWorkedWith'].apply(lambda x : x.str.contains('Python').sum())  prog_languages_count_per_country = country_grp['LanguageWorkedWith'].apply(lambda x : x.value_counts().sum())  (python_count_per_country / prog_languages_count_per_country) * 100   #Returns list of countries with their python users percentages.   #In case you want the python users percentage of a specific country, you can always do something like: (python_count_per_country['United States'] / prog_languages_count_per_country['United States']) * 100",True
@mohammadsalimkhan4974,2020-02-24T17:42:06Z,1,Good work Corey. Loved all the explanations:-),True
@yuewang9623,2020-02-24T05:04:58Z,3,"Every time I saw a new post, I click the 'like' button before watching:D",True
@michaelx5039,2020-02-23T14:34:23Z,0,"Hi Corey, when I was trying to get the respondents from each country(eg. Japan), I tried this:  Country_Grp['LanguageWorkedWith'].count().loc['Japan']   , the result is 387. but the result of the following code: df['Country'].value_counts().loc['Japan']   is 391.  Do you have any idea what led to the difference of these two methods? Thank you so much!",True
@sayantanchakraborty75,2020-02-23T08:24:36Z,1,Best videos on pandas on YouTube by Corey Sir. Loving them and normally  wait for the next videos. Lots of love for you from India. <3,True
@email4pranav,2020-02-22T18:37:11Z,0,Could you please make a vedio on selinium  webdriver,True
@bobchannell3553,2020-02-22T17:31:23Z,0,"This was a lot to learn in one video. That's why I went back and watched it again this week. At the end, I added something I think would be useful in what I do. I added a filter to select records where the number of respondents is >= 5.   filt = python_df['NumRespondents'] >= 5 python_df.loc[filt]",True
@sumranms,2020-02-22T17:14:13Z,1,I really like the way you speak. Your language is clearly understandable and you have a great accent. :),True
@elghark,2020-02-22T16:12:19Z,1,"For those interested about last example: In order to find top percentage of python users by country ONLY for consistent number of respondents, I used something like this: high=python_df[python_df['NumRespondents']>=100] high.sort_values('Pct',ascending=False,inplace=True)",True
@elghark,2020-02-22T14:15:40Z,0,Try doing this: country_grp['ConvertedComp'].median().nlargest(10) Look at 2nd and 3rd position. Is there something wrong????? Or maybe those salaries are in local currencies?,True
@benjaminjimenez9579,2020-02-21T22:07:31Z,0,"I'm trying to answer the question of, ""What is the most common education level?"" So far I've been able to answer the question of, ""What is the most common education level in a given country?"" with the line:  country_grp['EdLevel'].value_counts(normalize=True).loc['United States']  How can I make this easier to read? Like say, put it in its own table or dataframe. Thanks.",True
@abhishek8311,2020-02-21T20:24:33Z,0,"@Corey: Thanks a ton for this beautiful video. Can you please let me know how to use the group by if I want to find the median Salary of Python developers working in India? I used str.contains('Python') to get the python, how am I supposed to integrate group by with this? Again, Thanks a lot for helping us out.",True
@tannersmith3573,2020-02-21T17:19:28Z,0,"Hey Corey, I just joined the channel a few weeks ago and I have already watched hours of your content. Very well done. If you are taking requests, I would love to see examples/tutorials on the tempfile package. A quick youtube search shows that there are not any realistic options. Looking forward to the rest of the pandas series! https://docs.python.org/3/library/tempfile.html",True
@Tigrex281,2020-02-21T15:56:35Z,0,"Hey Corey,   first of all thank you very much for all those fantastic videos. I also have tried to answer the question of percentage knowing python for each country. I came up with following solution:   PrctKnowPython = country_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python', na=False).value_counts(normalize=True)).loc[:,True]   One advantage of this approach is, that you can just remove na=False and ignore NaN values in your data.",True
@joaodias4419,2020-02-21T01:04:15Z,1,"So here's my solution :)     pctPython= country_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').value_counts(normalize=True)*100) pctPython.loc[(slice(None),True)]   This works fine On the first line, we're getting a multindex series like so:          Afghanistan  False    79.487179                         True     20.512821   Well, we're only interested in what comes after the True index, so the second line of the code takes care of that. The slice(None) in the loc there makes you select all the contents of that index level. In this case, all of the countries. So, all we're doing is selecting each country's ""True"" index.   It should give something like : Afghanistan                        20.512821 Albania                                27.710843 Algeria                                 31.746032         and so on",True
@hebalye372,2020-02-20T16:16:15Z,0,I am really interested in multi-index topics in pandas. Looking forward to it!,True
@revitallevi9572,2020-02-18T21:45:27Z,0,"a much easier way to get the % of people who know python, is just to replace the 'sum' over all the booleans with 'mean'.",True
@arkahm,2020-02-18T18:12:06Z,0,"Great Tutorial! You have increased my knowledge of Python immensely, allowing me to move forward in my main project I am working on!  I do not use Jupyter, using strait python code to do this, but the same principles apply. I do have a question though. When I do a .head() on my groupby object it doesn't .head() it.  The df comes back truncated instead. Any ideas why this happens?",True
@simplewithoutle5354,2020-02-18T04:36:32Z,0,"Hi Corey, could you make a tutorial on sklearn kmeans clustering as well? Your tutorials has been really useful and I have been struggling with this topic, it would be amazing if you could help. Thank you so much for all that you've done!",True
@rafael_tg,2020-02-18T02:17:04Z,1,Thanks for the video,True
@DanDan-jy4fn,2020-02-18T00:32:56Z,0,"It is no more accurate to set country_respondents= country_grp ['LanguageWorkedWith'].count() , instead of country_respondents = df['Country].value_counts() ??",True
@CwMuller,2020-02-17T22:50:38Z,0,Just a quick tip for new Jupiter Notebook users: if you are uncertain about what parameters are available to you while using Pandas or other python libraries: you can press shift+tab multiple times while the cursor is inside the parentheses of a function call and the function doc - string will appear in a box. Very useful for quickly checking documentation; especially with a deep library like Pandas.,True
@bazakovdaniyar6674,2020-02-17T21:02:43Z,0,Please make a falcon tutorial!!!!!!,True
@nawendusingh2858,2020-02-17T01:00:51Z,0,Axis was never explained in these videos.Is it bcoz its too easy and we are supposed to learn that ourselves.just curious,True
@sany2k8,2020-02-16T15:22:06Z,0,"You're awesome as always sir, need video series on apache spark using pyspark",True
@Schmidt3k,2020-02-16T15:11:56Z,31,"For your practise question, use .mean() instead of .sum() .mean() on a Series of bool will give you the fractions in a quick and easy way. Multiply by 100 for %.  edit: As per discussion below, .mean() ignores NA values whereas Corey's approach treats NA as '0'. An alternative is thus: mygroups['LanguageWorkedWith'].apply(lambda x:x.str.contains('Python').fillna(0).mean())  Now, the results should be equal to Corey's.",True
@kanikaru1887,2020-02-16T12:44:15Z,0,Can you do a series in web scraping? Your teaching is amazing. So please consider my request,True
@jianhongsong6140,2020-02-16T11:51:55Z,0,"I really enjoy your tutorial. One question, how can we see the top three social media‚Äôs in each country?",True
@yunfengliang6746,2020-02-16T09:33:49Z,1,"Thank you very much for the great video. for the percentage calculation, I use the following code based on what is learned:   country_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').value_counts(normalize=True)).loc[:,True]",True
@panagiotiskaramertzanis7383,2020-02-16T08:49:26Z,1,"Thanks for the nice videos. One more possible solution  import pandas as pd from random import shuffle random.seed(12345)   # create the starting dataset countries = ['US','Germany','UK']*4 shuffle(countries) languages = ['python;c++','java','SQL;python','go']*3 shuffle(languages) df = pd.DataFrame({'country': countries, 'languages': languages})   # apply the grouping operation res = df.groupby('country')['languages'].apply(lambda x: pd.Series([x.str.contains('python').sum(), len(x), x.str.contains('python').sum()/len(x)], index=['numKnowsPython', 'numTotal', 'pctKnowsPython'])).unstack(level=1)   # result print(res.to_markdown()) # | country   |   numKnowsPython |   numTotal |   pctKnowsPython | # |:----------|-----------------:|-----------:|-----------------:| # | Germany   |                3 |          4 |             0.75 | # | UK        |                1 |          4 |             0.25 | # | US        |                2 |          4 |             0.5  |",True
@antonyjohne,2020-02-16T05:41:38Z,37,"Hey Corey! Thanks a million for the Pandas Series. As always, very intuitive and easy to follow.  Now that you've taught Matplotlib and Pandas, would love to see a new Numpy series in order to complete the Data Science trinity. Please consider adding a Numpy Series.",True
@jasonlmay,2020-02-16T05:19:20Z,5,"You could also solve the question in the video by using a pandas pivot table.  here is the code: table = pd.pivot_table(df, index='Country', values=['Hobbyist', 'LanguageWorkedWith'],                        aggfunc={'Hobbyist': 'count',                               'LanguageWorkedWith': lambda x: x.str.contains('Python').sum()}) table['percent'] = (table['LanguageWorkedWith'] / table['Hobbyist']) * 100 table.sort_values(by='percent', ascending=False)",True
@noureddineettayyeby5210,2020-02-15T21:14:29Z,1,Thank you for this awesome series and multiplexing would be great,True
@AlexBerkk,2020-02-15T20:11:02Z,0,"I think, you counted NaN's with other respondents and i'm not sure it gives you correct percentages for Python users. I calculated them that way: country_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').sum() / x.count()) but it gives me a warning: RuntimeWarning: invalid value encountered in long_scalars   """"""Entry point for launching an IPython kernel.   Huge thanks for your tutorials, btw!",True
@bobchannell3553,2020-02-15T18:50:03Z,1,"Thanks for doing this video in a detailed way, like you always do. Just under an hour is a good length for a video like this. Thanks!",True
@shivavijaya1537,2020-02-15T15:46:17Z,2,Hey Corey ! It was awesome and thank you for sharing your knowledge. Could you please do a video series on mongoDb using python . Thanks :),True
@rangavembar,2020-02-15T07:26:00Z,0,Who the hell dislikes these videos? Must be someone like Einstein!!,True
@jonathanstudentkit,2020-02-15T05:37:44Z,0,"if you take the median salary of such a list, you can't necessarily read anything from it. It may A not be a good or sufficient estimator for what you want to cover,  and B it certainly will be biased  or conditional as only a subgroup has answered the question in the first place.",True
@ahmedabdulrahman8567,2020-02-15T05:22:44Z,1,very useful ... thanks Corey for the great effort,True
@yuanchima,2020-02-15T04:35:53Z,4,"My solution to the practice question:   def pctKnowsPython(x):     try:         return x.str.contains('Python', na=False).value_counts(normalize=True).loc[True]     except KeyError:         return 0   pctKnowsPython = country_grp['LanguageWorkedWith'].apply(pctKnowsPython)",True
@jorgetiz99,2020-02-15T04:06:59Z,4,"This has to be one of the best videos on youtube about Pandas, thank you so much. Greetings from Per√∫.",True
@Technology-Posts,2020-02-15T02:49:01Z,1,Thanks Corey.  I have waited for this video whole week.  Great explaination,True
@kylebeckhorn885,2020-02-15T01:46:29Z,196,"Yes please, do a video on the topic of MULTIPLE INDEXING!!",True
@YeekyYeeky,2020-02-15T01:08:12Z,5,"one of the best thing that happened  to me when I woke up  (I am on the opposite side of the world to Corey Schafer) is finding that Corey just upload another Pandas tutorial video , thank you !",True
@MK-yl7jl,2020-02-14T22:13:47Z,1,444k subscribers. Cooooooool   Wish 4444k subscribers Corey.,True
@Davidkiania,2020-02-14T21:16:00Z,19,Best video in the series loving them and normally can‚Äôt wait for the next.,True
@tolex3,2020-02-14T20:51:28Z,2,"I've been doing data analysis using Python & Pandas for a few years now. Still, I'm picking up new things from your videos. Very clearly explained! Thank you!",True
@erfannariman,2020-02-14T20:45:04Z,1,"Small note: at 19:06, the more correct syntax would be to select your column within the .loc method: df.loc[filt, 'SocialMedia'].value_counts().",True
@jongyoonsohn8559,2020-02-14T20:00:07Z,85,"I'd like to share my solution to the practice question.   ctr_knows_python = country_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python', na=False).value_counts(normalize=True)) ctr_knows_python.rename({False:'Don\'t know', True:'I know'}, inplace=True) ctr_knows_python   Hope this helps too!",True
@scottbrewer474,2020-02-14T19:59:52Z,2,"I was thinking of just dividing by x.value_counts() within the lambda function to get the percentage, but I think that while his method is more verbose, it has greater clarity as it captures the part and the whole for easy review.",True
@merajajam425,2020-02-14T18:22:08Z,89,"The level of my programming in Python has been substantially improved since I have started watching your great videos. Many thanks, Corey. Would you please prepare some videos regarding the networkx module as well?",True
@coffeeiot8468,2020-02-14T18:14:43Z,0,"Muito bom, sempre conte√∫do de qualidade.",True
@AugustoGeografo,2020-02-14T18:13:30Z,1,"Corey, at 21:50 the groupby object forms a series with multindex. I'll try later to use pivot_table() to make index the countries and the columns representing different social apps. Although it won't be tidy data, I think it will be useful to explore it.",True
,2020-02-14T17:49:00Z,4,"You should be able to get the percentage by simply using .mean() instead of .sum() in your apply(), since .str.contains returns a 0 or 1 for each row the mean of 0/1 values is the percentage of of 1 in total. The result would be in 0..1 range  (i.e. 0.48 for usa instead of 48) but you can then multiply the resulting series by 100 just like in Your example. One quirk is that if there are nulls in this question the .str.contains may return null for those rows and then the .fillna(0).mean() should get you the same results as in Your example. It's great though that You used this approach as not each problem can be solved with simple change and actually requires to compute multiple series, combine them and work on resulting dataframe.",True
@ankitdubey-wf2so,2020-02-14T17:21:40Z,1,I am always waiting for your next videos .you are god for me..thanks a lot for uploading ..,True
@ekaterinadranitsyna5107,2020-02-14T17:18:22Z,1,You also can get the share of developers who know Python by taking the mean of this boolean series where you specify str.contains('Python'). It will divide the sum of True and False by the number of True and False values.,True
@OceanAlves23,2020-02-14T16:27:58Z,1,"Obrigado, boa semana üëèüëçüëçüëç",True
@akiratoriyama1320,2020-02-14T14:58:57Z,2,Thank you sooooo much!!!!!!!!,True
@ugandandev,2020-02-14T14:56:42Z,2,Corey Again. Very fantastic tutor. I press the like button before I watch.,True
@elnazdehkharghani6121,2020-02-14T14:55:18Z,4,"You make all your subscribers happy with just uploading your videos !!! Thanks, Corey",True
@AugustoGeografo,2020-02-14T14:51:41Z,3,"Always looking forward for your videos, Corey.",True
@AugustoGeografo,2020-02-14T14:51:30Z,3,"Always looking forward for your videos, Corey.",True
@vishallimgire6181,2020-02-14T14:50:19Z,2,Waiting for this video thanks Corey,True
@amir_forooghi,2020-02-14T14:44:29Z,7,YESSSS !!! Corey`s video for groupby. I press like before I watch it. Groupby is just a superpower. Thank you for this awesome series Corey. You are the best.,True
@coreyms,2020-02-14T14:37:58Z,199,"I hope everyone had a great week! We've got a long video this week, but we go over a lot of important topics about how to analyze data in Pandas. We will learn how to answer very interesting questions such as ""What is the most popular social media site by country?"". I put timestamps together for this video so that you all can skip around if you need to go back and watch a specific section. Here are those timestamps: Aggregate Column - 2:00 Aggregate DataFrame - 3:55 Value Counts - 7:51 Grouping - 12:30 Multiple Aggregates on Group - 26:00 People Who Know Python By Country - 27:20 Practice Question - 34:20 Concat Series - 37:27  Have a great weekend everybody!",True
